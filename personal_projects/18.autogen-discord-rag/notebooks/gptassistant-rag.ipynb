{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "import autogen\n",
    "import chromadb\n",
    "from pathlib import Path\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "from autogen.retrieve_utils  import query_vector_db, create_vector_db_from_dir\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING VECTOR STORE\n",
    "class ChromaDBManager:\n",
    "    def __init__(self, docs_path, db_path, collection_name):\n",
    "        self.docs_path = Path(docs_path)\n",
    "        self.db_path = Path(db_path)\n",
    "        self.collection_name = collection_name\n",
    "\n",
    "    def setup(self, clear_history=False):\n",
    "        # Check if the docs directory exists\n",
    "        if not self.docs_path.exists():\n",
    "            raise ValueError(f\"The docs directory at {self.docs_path} does not exist.\")\n",
    "\n",
    "        # Handle existing database based on clear_history flag\n",
    "        if self.db_path.exists():\n",
    "            if clear_history:\n",
    "                shutil.rmtree(self.db_path)\n",
    "                print(f\"Removed existing directory: {self.db_path}\")\n",
    "\n",
    "        # Create or load the Chroma DB client\n",
    "        self.client = chromadb.PersistentClient(path=str(self.db_path))\n",
    "        print(f\"Chroma DB client set up at {self.db_path}\")\n",
    "\n",
    "    def create_vector_db(self, max_tokens=3000, chunk_mode=\"multi_lines\"):\n",
    "        create_vector_db_from_dir(\n",
    "            dir_path=str(self.docs_path),\n",
    "            client=self.client,\n",
    "            collection_name=self.collection_name,\n",
    "            max_tokens=max_tokens,\n",
    "            chunk_mode=chunk_mode\n",
    "        )\n",
    "        print(\"Chroma DB created successfully.\")\n",
    "\n",
    "    def query_db(self, query_texts, n_results=10):\n",
    "        return query_vector_db(\n",
    "            query_texts=query_texts,\n",
    "            n_results=n_results,\n",
    "            client=self.client,\n",
    "            collection_name=self.collection_name\n",
    "        )\n",
    "    \n",
    "    def get_context(self, results):\n",
    "        doc_contents = \"\"\n",
    "        current_tokens = 0\n",
    "        _doc_idx = self._doc_idx\n",
    "        _tmp_retrieve_count = 0\n",
    "        for idx, doc in enumerate(results[\"documents\"][0]):\n",
    "            if idx <= _doc_idx:\n",
    "                continue\n",
    "            if results[\"ids\"][0][idx] in self._doc_ids:\n",
    "                continue\n",
    "            _doc_tokens = self.custom_token_count_function(doc, self._model)\n",
    "            if _doc_tokens > self._context_max_tokens:\n",
    "                func_print = f\"Skip doc_id {results['ids'][0][idx]} as it is too long to fit in the context.\"\n",
    "                print(func_print)\n",
    "                self._doc_idx = idx\n",
    "                continue\n",
    "            if current_tokens + _doc_tokens > self._context_max_tokens:\n",
    "                break\n",
    "            func_print = f\"Adding doc_id {results['ids'][0][idx]} to context.\"\n",
    "            print(func_print)\n",
    "            # print(func_print, \"green\"), flush=True)\n",
    "            current_tokens += _doc_tokens\n",
    "            doc_contents += doc + \"\\n\"\n",
    "            self._doc_idx = idx\n",
    "            self._doc_ids.append(results[\"ids\"][0][idx])\n",
    "            self._doc_contents.append(doc)\n",
    "            _tmp_retrieve_count += 1\n",
    "            if _tmp_retrieve_count >= self.n_results:\n",
    "                break\n",
    "        return doc_contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma DB client set up at ../data/chromadb\n",
      "Chroma DB created successfully.\n"
     ]
    }
   ],
   "source": [
    "chroma_db_manager = ChromaDBManager('../data/docs', '../data/chromadb', 'autogen-discord')\n",
    "chroma_db_manager.setup(clear_history=False)\n",
    "chroma_db_manager.create_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATIONS\n",
    "config_list = autogen.config_list_from_dotenv(\n",
    "    dotenv_file_path='../../../.env',\n",
    "    model_api_key_map={\n",
    "        \"gpt-4-1106-preview\": \"OPENAI_API_KEY\",\n",
    "    },\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4-1106-preview\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "query_vector_db_tool_config = {\n",
    "    \"name\": \"query_vector_db\",\n",
    "    \"description\": \"Function to query the Chroma vector database.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query_texts\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"query_texts\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "get_context_tool_config = {\n",
    "    \"name\": \"get_context\",\n",
    "    \"description\": \"Function to get the context from query results of the Chroma vector database.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"results\": {\"type\": \"object\"}\n",
    "        },\n",
    "        \"required\": [\"results\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"assistant_id\": None,\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": query_vector_db_tool_config\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": get_context_tool_config\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"gpt-4-1106-preview\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_ASSISTANT_SYSTEM_MESSAGE = \"\"\"As a Retrieve-Augmented Chatbot, your role involves analyzing message history and using that to inform your responses. \n",
    "When a question is presented, you should:\n",
    "Step 1: Determine the user's intent by considering the question and its context. The intent might involve generating code or answering a question, or both.\n",
    "Step 2: Formulate a response based on the identified intent.\n",
    "\n",
    "If the task involves code generation, adhere to the specified coding format. \n",
    "For question-answering tasks, aim for concise and precise responses.\n",
    "\n",
    "\n",
    "For contextual understanding, use the `query_vector_db` tool to access information from the Chroma vector database. \n",
    "Enhance your replies by integrating context extracted from the Chroma DB using the `get_context` function. \n",
    "This approach will provide a well-informed basis for your responses.\n",
    "If there is relevant links in the chat logs, provide the fill link in the response.\n",
    "Say TERMINATE when everything is done and the overall task is complete.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:assistant_id was None, creating a new assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33muser_proxy\u001b[0m (to Chroma_RAG_Assistant):\n",
      "\n",
      "What is Autogen?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION query_vector_db...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agentchat.contrib.gpt_assistant_agent:Intermediate executing(query_vector_db, Sucess: True) : {'ids': [['doc_79', 'doc_68', 'doc_151', 'doc_158', 'doc_20', 'doc_116', 'doc_86', 'doc_104', 'doc_162', 'doc_106']], 'distances': [[0.3410879969596863, 0.35183876752853394, 0.36569702116146097, 0.3802331123892657, 0.4030306935310364, 0.41339688844423306, 0.41603583097457886, 0.4272402840826177, 0.4435499073212885, 0.44422628686505516]], 'metadatas': [[None, None, None, None, None, None, None, None, None, None]], 'embeddings': None, 'documents': [['\\nI have worked to load quivr with a manual for a restaurants stove and work through troubleshooting scenarios.\\n\\nThat is something I am looking to autogen for```.\\n\\nIn general, at 2023-10-10 01:47:41 a user named yuzhun said ```I tried gpt3.5 for chess play and it failed, wondering how do autogen choose model? Is there a priority flag? Do autogen auto retry with different model in the config file?```.\\n\\nIn general, at 2023-10-10 01:22:58 a user named platinumpluto said ```If it is okay can I discuss about something? Sorry for my bad English in advance!```.\\n\\nIn general, at 2023-10-10 00:36:48 a user named smuggybuggins said ```Random Reddit search and Youtube. Never coded in my life and somehow followed the AutoGen Tutorial and built a \"live\" version. I am now too hooked to concentrate at work!```.\\n\\nIn general, at 2023-10-10 00:19:14 a user named gjipe said ```How is that going for you ? doin the same over here in London```.\\n\\nIn general, at 2023-10-09 23:58:34 a user named covetech said ```Honestly youtube.  I just learned about it today watching a tutorial.```.\\n\\nIn general, at 2023-10-09 22:12:54 a user named jaemil said ```https://www.getonboard.dev/chat/microsoft/autogen```.\\n\\nIn general, at 2023-10-09 22:09:49 a user named afourney said ```In any case, the next release will print a warning when the file cannot be found. Arguably this should probably graduate to an actual exception```.\\n\\nIn general, at 2023-10-09 22:05:05 a user named kohanzie said ```XD out of habit, this mightve fixed it too, so annoying lol. thank you if im having any other trouble ill reopen```.\\n\\nIn general, at 2023-10-09 22:04:57 a user named afourney said ```Ok, to summarize what\\'s happening as far as I understand it: https://github.com/microsoft/autogen/issues/125#issuecomment-1754004740```.\\n\\nIn general, at 2023-10-09 21:55:12 a user named mightyscoo said ```I\\'m a software engineer.  I built my first neural network in 1982 and I was an immediate convert.  At the time I didn\\'t have the research bug, but now I do.  So, I\\'m here and will be lurking, trying to figure out what I can do with all this.```.\\n\\nIn general, at 2023-10-09 21:38:24 a user named alwaystinkering said ```I am a former software engineer at Microsoft and other orgs. I am now working in Detroit to assist small businesses with adoption of AI type technologies.```.\\n\\nIn general, at 2023-10-09 21:31:37 a user named jew84930585 said ```i’ll try to reproduce it again too more under the microscope```.\\n\\nIn general, at 2023-10-09 21:29:16 a user named afourney said ```@kohanzie @jew84930585 still working out where the default is being pulled from, but the main branch now prints a warning if it can\\'t load the OAI_CONFIG_LIST file and reverts to some default. Hopefully that will help. In the meantime, @kohanzie  I noticed that your file is called OAI_CONFIG_LIST.json   it should not have the \".json\" at the end -- just \"OAI_CONFIG_LIST\"```.\\n\\nIn general, at 2023-10-09 21:24:39 a user named jew84930585 said ```i’ve noticed this bug as well, something in autogens config is forcing gpt-4```.\\n\\nIn general, at 2023-10-09 21:24:28 a user named dr.goatfish said ```Hey, how can we use group chat to analyze datasets, communicate and a comparison agent finishes the task by using the 4 other groupchat members to generate of csv of dates, reported hours worked and estimated hours worked from the comparison of datasets. \\n\\nI am trying to use AutoGen to validate an employees reported hours worked and refute her claim that she is owed overtime pay before her termination. The AI agent will complete the task by interpretting the tabular datasets related to her activities as an employee: Email conversations, QuickBook Activities, Door Badge (entry time to office) and Reported Hours Worked. The AI Agents will analyze the quickbook activities against reported hours worked, emails, etcetera to refute her claims that she is owed overtime. The agents will provide a estimated time difference between what she reported and what the agent inspects in the data.```.\\n\\nIn general, at 2023-10-09 21:00:38 a user named pablo.ce said ```Hi guys learn autogen form a youtube video 🙂```.\\n\\nIn general, at 2023-10-09 20:42:43 a user named afourney said ```Sorry I missed the Azure part 😛, and deleted the previous OAI link.  Good question on setting up Azure -- I haven\\'t done that as an external user, so i\\'m not 100% sure.```.\\n\\nIn general, at 2023-10-09 20:42:43 a user named somecomputerguy said ```Huh, I used the azure portal to stand up a deployment, is that link cheaper?```.\\n\\nIn general, at 2023-10-09 20:35:36 a user named afourney said ```@kohanzie can you add these details to: https://github.com/microsoft/autogen/issues/125```.\\n\\nIn general, at 2023-10-09 20:33:05 a user named tangerine1528 said ```How can I apply or get Azure OpenAI Api key any one can help?```.\\n\\nIn general, at 2023-10-09 20:28:56 a user named somecomputerguy said ```Cool, yeah I can play with that```.\\n\\nIn general, at 2023-10-09 20:28:24 a user named bobaleaux said ```here\\'s how i did it;\\n\\nit isn\\'t perfect but it was a fast start```.\\n\\nIn general, at 2023-10-09 19:52:28 a user named sonichi said ```AssistantAgent with system message like \"Reply TERMINATE if ...\"```.\\n\\nIn general, at 2023-10-09 19:51:34 a user named pbeheca said ```Okay, thank you. What would the config for such an agent look like?```.\\n\\nIn general, at 2023-10-09 19:48:22 a user named sonichi said ```The instruction about termination can often get ignored when it\\'s mixed with other long instructions. One possible way is to create a separate agent which is dedicted to this.```.\\n\\nIn general, at 2023-10-09 19:47:11 a user named pbeheca said ```Any way to circumvent this behavior? gpt4 seems to not have this issue but is too costly. Any Idea which agents would need gpt4 to prevent empty calls/responses in a loop?```.\\n\\nIn general, at 2023-10-09 19:45:14 a user named sonichi said ```Yes, it\\'s common in my experience.```.\\n\\nIn general, at 2023-10-09 19:41:46 a user named telepathyx said ```https://arxiv.org/abs/2310.01798\\n\\nTransitioning to another facet of self-correction, we investigate the potential of\\nmulti-agent debate (Du et al., 2023; Liang et al., 2023) as a means to improve reasoning. In this\\nmethod, multiple instances of an LLM critique each other’s responses. However, our results reveal\\nthat its efficacy is no better than self-consistency (Wang et al., 2022) when considering an equivalent\\nnumber of responses, highlighting the limitations of such an approach.```.\\n\\nIn general, at 2023-10-09 19:32:17 a user named pbeheca said ```Is it normal for gpt-3.5-turbo agents to get stuck in a loop? seems like it always ends getting stuck```.\\n\\nIn general, at 2023-10-09 19:06:20 a user named aarya1101 said ```I am new to this```.\\n\\nIn general, at 2023-10-09 19:06:05 a user named aarya1101 said ```can anyone explain autogen to me?```.\\n\\nIn general, at 2023-10-09 19:02:20 a user named tc said ```@kohanzie tomorrow morning i\\'ll put in general chat a little snippet on how did i solved it if i got 5 minutes```.\\n\\nIn general, at 2023-10-09 18:53:49 a user named kareem6370 said ```I had to override the DEFAULT_MODEL in the super class to be gpt-3-turbo to stop using gpt-4 for any interference, It’s not the best way to do it but I was lazy and I wanna test an idea lol```.\\n\\nIn general, at 2023-10-09 18:39:09 a user named afourney said ```FYI: I\\'m trying to hunt this one down, a top priority.```.\\n\\nIn general, at 2023-10-09 17:59:42 a user named somecomputerguy said ```I guess in this model it is similar to autogpt? I never used it```.\\n\\nIn general, at 2023-10-09 17:35:18 a user named somecomputerguy said ```And instructed it to write to a known path, then used docker cp to copy out the generated CSV```.\\n\\nIn general, at 2023-10-09 17:34:45 a user named somecomputerguy said ```I modified the twoagent.py file```.\\n\\nIn general, at 2023-10-09 17:29:02 a user named securemeup said ```Have you tried using the teaching notebook for this? Can you provide some more details? I’d like to see if can get it to work```.\\n\\nIn general, at 2023-10-09 17:24:45 a user named deedavid_15589 said ```if guardrails are proper, you can control resources, resoruce type, instances, and of course you can audit all of this before the code is deployed.```.\\n\\nIn general, at 2023-10-09 17:23:50 a user named deedavid_15589 said ```@somecomputerguy you have guardrails for your CDK?```.\\n\\nIn general, at 2023-10-09 17:15:00 a user named somecomputerguy said ```Right now I am debating handing some AWS keys to an agent to deploy CDK... it feels like a VERY BAD IDEA```.\\n\\nIn general, at 2023-10-09 17:12:30 a user named somecomputerguy said ```But also, I should stop being a luddite and embrace notebooks I guess 😛```.\\n\\nIn general, at 2023-10-09 17:11:51 a user named somecomputerguy said ```I wish that example was also in the test directory as a .py```.\\n\\nIn general, at 2023-10-09 16:43:50 a user named bobaleaux said ```in my case i would be replaced by 2 agents?\\nthe admin or user_agent and a retrieval agent to feed the same content ?```.\\n\\nIn general, at 2023-10-09 16:39:57 a user named sonichi said ```For non-coding tasks, specify `system_message` and `name` for each `AssistantAgent` about their roles and create a group chat, like https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb```.\\n\\nIn general, at 2023-10-09 16:36:56 a user named bobaleaux said ```and i just pasted an article from a few minutes ago and asked, for their opinions about it;```.\\n\\nIn general, at 2023-10-09 16:35:59 a user named bobaleaux said ```@sonichi do you have any ideas on how i accomplish this with autogen? \\nsorry my use case isn\\'t writing code.\\n\\nWhen manually using chatGPT, i have pasted multiple engineered persona prompts into the input in a single conversation and they all became part of the conversation. I have asked them all for their opinion about a single question and they each provided one.\\n\\nI\\'m trying to emulate my manual interactions with chatgpt but using code but I can\\'t figure out how.\\n\\nin a direct openai call, i use the system message as the persona and I haven\\'t tried loading multiple system messages and I\\'m not sure of the impact of \\'assume the role\\'.\\n\\n Is it just a group conversation with a user agent as the manager?```.\\n\\nIn general, at 2023-10-09 16:30:44 a user named somecomputerguy said ```Getting autogen happy and containerized took me all weekend, but worth it, executing code in my rancher environment is AWESOME```.\\n\\nIn general, at 2023-10-09 16:29:41 a user named somecomputerguy said ```Along with chromaDB, I am a big retro guy, you can see my stuff on youtube, really excited to point chroma at bitsavers and be able to ask questions and get answers based on OCR manuals for the original equipment```.', '\\nIn general, at 2023-10-15 19:12:05 a user named qingyunwu said ```Hi @michaelmcwhirter I guess there is some misunderstanding here. As I clarified above, this OSS project AutoGen has nothing to do with the AutoGenAI the commercial venture. Please find our documentation site here: https://microsoft.github.io/autogen/```.\\n\\nIn general, at 2023-10-15 19:05:52 a user named qingyunwu said ```Hi, you can start with the tutorials and examples in this channel: https://discord.com/channels/1153072414184452236/1161015724521836634. I believe it\\'s also helpful to skim through the notebooks we have: https://github.com/microsoft/autogen/tree/main/notebook, and the getting started page: https://microsoft.github.io/autogen/docs/Getting-Started```.\\n\\nIn general, at 2023-10-15 19:02:39 a user named qingyunwu said ```Thank you for asking! AutoGen the OSS project has NO relationship with AutogenAI the commercial venture linked here except the similarity on names.```.\\n\\nIn general, at 2023-10-15 18:59:04 a user named halr9000 said ```Help me understand something real quick, and I\\'d appreciate an answer from a mod or contributor, not Michael M:\\n\\nIs there a relationship between Autogen the OSS project, and AutogenAI the commercial venture linked here? \\n\\nIf yes, that\\'s fine, I don\\'t care, so long as it\\'s transparent. But I suspect the answer is actually no. In THAT case, then I would say there\\'s a conflict of interest problem w/this post from Michael that needs to be considered by those who care about such things. My $0.02 coming in super blind, having just joined the discord and not (yet) installed autogen. But I have 25 yr experience in the software industry, so that\\'s where my head is at.\\n\\nTIA! tagging @li_jiang and @qingyunwu simply as I see you two online now and I don\\'t know the groups or server eqituette  here yet.```.\\n\\nIn general, at 2023-10-15 18:20:11 a user named biggboii. said ```Where can I find best practices for different use cases? Such as how to structure a team and a task?```.\\n\\nIn general, at 2023-10-15 17:36:37 a user named mehdi_75 said ```Hi guys, saw autogen popping up on twitter and youtube!```.\\n\\nIn general, at 2023-10-15 16:56:16 a user named pedro74matos said ```Hi! I got to know AutoGen on YouTube... Channel Matthew Berman and then others.```.\\n\\nIn general, at 2023-10-15 16:54:32 a user named bigmiao said ```https://github.com/microsoft/autogen/issues/152#issuecomment-1752478080```.\\n\\nIn general, at 2023-10-15 16:52:36 a user named bigmiao said ```You can override it by implementing a custom GroupChat. There’s an example in GitHub issue’s showing how to do that. Let me find out```.\\n\\nIn general, at 2023-10-15 15:49:57 a user named notoriousjimbo said ```Hey Guys,\\nLooking to build a deep learning Workstation. The 14th Gen CPU is coming out and I\\'m looking at running multiple A100s. Anyone have suggested builds or hardware?```.\\n\\nIn general, at 2023-10-15 15:42:53 a user named karixai said ``````    code_execution_config={\"work_dir\": \"web\"},```\\ni got this but does not make a folder```.\\n\\nIn general, at 2023-10-15 15:42:17 a user named karixai said ```does some one know why my autogen not save code into files and not make anny folder?```.\\n\\nIn general, at 2023-10-15 15:37:58 a user named somecomputerguy said ```Yeah I wanna dig into how this works```.\\n\\nIn general, at 2023-10-15 15:26:09 a user named somecomputerguy said ```Oh no I see, they put manual chat instantiations in functions```.\\n\\nIn general, at 2023-10-15 15:23:36 a user named somecomputerguy said ```I do not see where that flow is established beyond prompts```.\\n\\nIn general, at 2023-10-15 15:22:23 a user named somecomputerguy said ```Their groupchat definition is super basic, seems like all the work went into system messages and functions, which is the direction I have been going```.\\n\\nIn general, at 2023-10-15 15:19:44 a user named somecomputerguy said ```https://github.com/amadad/agentcy```.\\n\\nIn general, at 2023-10-15 15:18:55 a user named somecomputerguy said ```I think next I want to try that agentcy thing, see how they handled task routing and attention```.\\n\\nIn general, at 2023-10-15 15:18:05 a user named somecomputerguy said ```Azure is reporting it as 500 errors, but I suspect my requests are somehow malformed```.\\n\\nIn general, at 2023-10-15 15:17:28 a user named somecomputerguy said ```I saw an example in git that used a custom reply function, it breaks :P, have not seen select_speaker```.\\n\\nIn general, at 2023-10-15 15:16:34 a user named somecomputerguy said ```The trying to call a function when directly attempting to contact another agent in the chat thing, anyone else seen that when instructing an agent to contact another agent not the group chat manager?```.\\n\\nIn general, at 2023-10-15 15:16:04 a user named tc said ```i do wonder if there is a way to write my own \" def select_speaker_msg(self):\" .\\nI suppose i could try to build a custom GroupChatManager and override that method? \\nanyone else already tried?```.\\n\\nIn general, at 2023-10-15 15:10:26 a user named somecomputerguy said ```Yeah it is just not behaving how I expect, hoping someone can explain since I figured I could not be the only one```.\\n\\nIn general, at 2023-10-15 15:07:46 a user named aaronward_ said ```https://youtu.be/6YDeiknPWkg?si=QQhz2ewaPemE6rwn```.\\n\\nIn general, at 2023-10-15 14:59:59 a user named bobaleaux said ```I’m there with you trying understanding the message routing configs```.\\n\\nIn general, at 2023-10-15 14:23:06 a user named degen_21122 said ```gonna check it now, seems im too far behind on this whole thingdamn```.\\n\\nIn general, at 2023-10-15 14:19:53 a user named somecomputerguy said ```I posted in in <#1157397569375309864> asking for assistance understanding message routing in a group chat. I am about ready to begin just manually building agent interaction chains, any help appreciated```.\\n\\nIn general, at 2023-10-15 14:19:24 a user named johnny_loquat said ```Use this video to install LMStudio.ai and point Autogen at it on your pc running as an api server. You are good to go! Can use the new models like Mistral.\\nRun any Open source LLM on your computer. Mistral or Llama or other...\\nhttps://youtu.be/2Ek0FL_Ldf4?si=-ldjMTZ2MVvFzu3v```.\\n\\nIn general, at 2023-10-15 13:44:51 a user named kajatta said ```https://python.langchain.com/docs/modules/agents/tools/tools_as_openai_functions```.\\n\\nIn general, at 2023-10-15 13:44:51 a user named bobaleaux said ```Oh! Great then you know all about being bugged eyed after 18 hours of keyboarding!```.\\n\\nIn general, at 2023-10-15 13:39:16 a user named degen_21122 said ```figured out the basic stuff```.\\n\\nIn general, at 2023-10-15 13:39:12 a user named degen_21122 said ```I know mate , i am a dev. I on the right track```.\\n\\nIn general, at 2023-10-15 13:39:01 a user named degen_21122 said ```yeah true, i pasted the code examples 1 by 1 when needed.```.\\n\\nIn general, at 2023-10-15 13:30:09 a user named bobaleaux said ```Gallons of caffeine filled drinks!\\nhonestly, it’s going to take your time. AutoGen is an excellent framework to abstract the transactions of conversations with LLM. \\nYou do need some basic understanding of coding.```.\\n\\nIn general, at 2023-10-15 13:22:56 a user named bobaleaux said ```What are you trying to install?```.\\n\\nIn general, at 2023-10-15 13:20:06 a user named tonic_1 said ```so this is the github version : it includes the notebooks so it\\'s slightly better at getting the code right : same results as yours though```.\\n\\nIn general, at 2023-10-15 13:18:49 a user named degen_21122 said ```Personally i just pasted all the docs in a word doc, made it .pdf , fed it into chat gpt and all good.```.\\n\\nIn general, at 2023-10-15 13:17:37 a user named degen_21122 said ```no way, are you stampy from src20s in btc?```.\\n\\nIn general, at 2023-10-15 13:05:36 a user named michaeldotw said ```It is all the buzz right now if looking into anything to do with multi agent use. So, it was easy to find```.\\n\\nIn general, at 2023-10-15 12:47:39 a user named tonic_1 said ```new version ^^ soz for disruption : http://ec2-54-163-92-231.compute-1.amazonaws.com:3000/chatbot/c85c8b9b-7c33-4251-bd16-fdef6a8499dc```.\\n\\nIn general, at 2023-10-15 12:57:19 a user named tonic_1 said ```To use AutoGen to create a User Proxy and a Manager Agent, you would need to follow the steps below:\\n\\nImport the necessary classes from the autogen package:\\n````from autogen import UserProxyAgent, ManagerAgent, AssistantAgent\\n```\\nCreate an instance of the UserProxyAgent:\\n```user_proxy = UserProxyAgent(name=\"user_proxy\")\\n```\\nCreate an instance of the ManagerAgent:\\n```manager = ManagerAgent(name=\"manager\")\\n```\\nCreate an instance of the AssistantAgent:\\n```assistant = AssistantAgent(name=\"assistant\")\\n```\\nRegister the ManagerAgent and AssistantAgent with the UserProxyAgent:\\n```user_proxy.register_agents(manager, assistant)\\n```\\nInitialize the conversation by sending a message to the UserProxyAgent:\\n```user_proxy.initiate_chat(\\n message=\"What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?\"\\n)\\n```\\nStart the conversation loop by calling the start_conversation() method on the ```UserProxyAgent:\\nuser_proxy.start_conversation()\\n```\\nThe complete code would look like this:\\n```\\nfrom autogen import UserProxyAgent, ManagerAgent, AssistantAgent\\n\\n# Create UserProxyAgent, ManagerAgent, and AssistantAgent instances\\nuser_proxy = UserProxyAgent(name=\"user_proxy\")\\nmanager = ManagerAgent(name=\"manager\")\\nassistant = AssistantAgent(name=\"assistant\")', '\\nIn created-with-autogen, at 2023-10-21 18:06:44 a user named telepathyx said ```I think it will exclusively \"solve creative\" things but lack the ability to operate as reliable infrastructure. due to its inability to self-correct.```.\\n\\nIn created-with-autogen, at 2023-10-21 17:03:51 a user named sidhujag said ```as is it wont solve anything creative yet.. the idea is to think of it as infrastructure```.\\n\\nIn created-with-autogen, at 2023-10-21 15:37:35 a user named wayliu said ```Kniru - Tireless AI-powered financial ad...```.\\n\\nIn created-with-autogen, at 2023-10-21 15:18:27 a user named pradeep1148 said ```intersting let me check it out```.\\n\\nIn created-with-autogen, at 2023-10-21 15:13:18 a user named telepathyx said ```Has anyone used autogen to create an app of any complexity, such as anthing bigger than a snake game? Is it still in the same state limited by context window and memory management? Or has anyone used autogen to enhance reasoning? Any use cases beyond a simulation/novelty yet?```.\\n\\nIn created-with-autogen, at 2023-10-21 07:39:49 a user named syedmujeeb said ```Hi \\nDoes autogen supports bedrock```.\\n\\nIn created-with-autogen, at 2023-10-20 17:06:33 a user named shaneyu said ```That\\'s the correct way to do it. Works like a charm```.\\n\\nIn created-with-autogen, at 2023-10-20 16:01:07 a user named pradeep1148 said ```https://www.youtube.com/watch?v=huIv541bKpw&ab_channel=DLExplorers```.\\n\\nIn created-with-autogen, at 2023-10-19 23:23:03 a user named shaneyu said ```I’ll take a look, thanks!👏```.\\n\\nIn created-with-autogen, at 2023-10-19 23:19:09 a user named sonichi said ```How about closing it after the top-level `initiate_chat`?```.\\n\\nIn created-with-autogen, at 2023-10-19 21:13:50 a user named shaneyu said ```It should be one connection object for one conversation, if the conversation ends the connection object should be killed```.\\n\\nIn created-with-autogen, at 2023-10-19 21:11:45 a user named sonichi said ```Does every agent have a socket connection? Or is there one connection for all?```.\\n\\nIn created-with-autogen, at 2023-10-19 20:33:30 a user named shaneyu said ```Hi @sonichi, last week I was talking about using websocket to establish a connection to the frontend GUI, I did some modification to the conversable_agent this week and now it works as expected, however, I am not sure on where to kill the socket connection. \\nIt should be killed when the entire conversation is over, not just one participating agent finished its job, and I think this is to be done on the conversable_agent level. Right now I think it goes down to receive function: \\n```        if reply is not None:\\n            self.send(reply, sender, silent=silent)\\n        else:\\n            # kill socket connection object\\n``` \\nBut I\\'m afraid this will close the connection when a certain agent completed its task, not the entire conversation is over. Would you mind providing some insights here? Much appreciated!\\U0001fae1```.\\n\\nIn created-with-autogen, at 2023-10-19 18:47:50 a user named aayushc1308 said ```P.S. Our current plan is to not reveal the internal orchestration of agents to the end user. The experience will always feel like a single agent. Only the internals is where multi agent magic happens.\\n\\nLet me know if I can clarify anything further.```.\\n\\nIn created-with-autogen, at 2023-10-19 18:45:39 a user named aayushc1308 said ```@wayliu \\nIt\\'s a group chat system. The group chat manager acts as an agent and mimics the single agent experience because the end user shouldn\\'t have to care about internal use of agents. It then internally manages a bunch of agents. \\nThe max rounds are also dynamic such that the group chat manager can terminate the interaction at any time when it is satisfied. We extended the group chat manager and group chat classes and created a significant amount of custom Kniru specific logic to support this.\\nThe current release actually can be achieved from single agent also in terms of quality. However, our release coming on Sunday will take the number of agents to approx 7 or 8. That is when the quality of results just blew our minds. We are working on testing these in a bunch of scenarios before releasing it.\\nWe had a previous architecture with Langchain but when we created domain specific agents using Autogen and combined it with some Langchain tools, the hallucinations got removed by almost like self correction.\\nWe should be able to discuss in more detail after Sunday release once we have also figured out the final details.```.\\n\\nIn created-with-autogen, at 2023-10-19 18:07:27 a user named wayliu said ```This is nice! @aayushc1308 one question, how do you guys leverage AutoGen? Looks like it\\'s more of the traditional single agent?```.\\n\\nIn created-with-autogen, at 2023-10-19 16:54:53 a user named aayushc1308 said ```Oh awesome, didn\\'t know about that channel. We will work on creating and adding any relevant tutorials to the channel!```.\\n\\nIn created-with-autogen, at 2023-10-19 16:43:33 a user named sonichi said ```Thanks for sharing. Also feel free to post on <#1161015724521836634>```.\\n\\nIn created-with-autogen, at 2023-10-19 16:39:03 a user named aayushc1308 said ```Hey everyone, Join Us at the Kniru Launch Party! 🚀\\nKniru has officially gone live on Product Hunt (https://www.producthunt.com/posts/kniru) this morning! I\\'m especially proud to mention that **Autogen** stands as one of the core technologies powering our AI pipeline.\\u2028We have launched a vanilla version of the Kniru Chat and will be releasing increasingly sophisticated Autogen-based architectures (custom Agents, custom Group chats, etc) with the first major update going out on Sunday. Our internal tests have completely blown our minds and we plan to slowly roll these out in a controlled and meticulously tested manner. We would love to invite you all to join us and give us feedback as we very quickly iterate with various architectures in production over the next weeks.\\u2028I will keep you all posted as we switch between various architectures so you can test things out yourself. We will keep sharing all our Autogen lessons on how to productionize things and will keep implementing relevant changes back to Autogen package based on the feedback you all share.\\n**Also, if any of you are planning to roll out Autogen in production, feel free to get in touch with us. We would be more than happy to help in every possible way and share our lessons.**```.\\n\\nIn created-with-autogen, at 2023-10-21 15:37:36 a user named wayliu said ```@aayushc1308  thanks for elaboration. Wouldn\\'t that cost too muh time though? Adding so many agents? I mean user would need to wait for at least a min to see results?```.\\n\\nIn created-with-autogen, at 2023-10-21 15:39:29 a user named telepathyx said ```https://arxiv.org/abs/2310.01798 \\n\\nwhat are you doing to address this?```.\\n\\nIn created-with-autogen, at 2023-10-21 15:40:34 a user named telepathyx said ```\"Transitioning to another facet of self-correction, we investigate the potential of\\nmulti-agent debate (Du et al., 2023; Liang et al., 2023) as a means to improve reasoning. In this\\nmethod, multiple instances of an LLM critique each other’s responses. However, our results reveal\\nthat its efficacy is no better than self-consistency (Wang et al., 2022) when considering an equivalent\\nnumber of responses, highlighting the limitations of such an approach.\"```.\\n\\nIn created-with-autogen, at 2023-10-21 15:40:54 a user named telepathyx said ```are you sure it\\'s responsible to let people think they\\'re getting good financial advice from autogen?```.\\n\\nIn created-with-autogen, at 2023-10-21 15:43:25 a user named telepathyx said ```correct -> incorrect happens more often than incorrect -> correct```.\\n\\nIn created-with-autogen, at 2023-10-21 15:50:25 a user named telepathyx said ```it\\'s a thermodynamic process. the further way you get from external feedback, the further it drifts into a hypothetical probability space that is increasingly disconnected from reality```.\\n\\nIn created-with-autogen, at 2023-10-21 15:52:55 a user named telepathyx said ```feedback is like qualia to an LLM. without that words don\\'t actually map to any meaning```.\\n\\nIn created-with-autogen, at 2023-10-21 15:53:20 a user named telepathyx said ```it\\'s all self referencing definitions```.\\n\\nIn created-with-autogen, at 2023-10-21 15:53:46 a user named telepathyx said ```language is full of circular logic that can\\'t encapsulate a worldview```.\\n\\nIn created-with-autogen, at 2023-10-21 18:05:41 a user named aayushc1308 said ```We pass around the websocket and keep the user informed what is happening. So the user always has some visibility. Also, not all agents get to speak for every question. Most questions get terminated after one or two agents have spoken. We have built some intelligence around this on how that happens but that is Kniru specific logic. But I am not seeing things take more than a min though in our tests. Still too early to speak with certainty since we are changing things every other hour.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:09:06 a user named aayushc1308 said ```We actually don\\'t use autogen for advice (except the current version in prod which is super vanilla). We have created hundreds of internal tools that actually drive the intelligence aspect of this. Autogen more of less helps in terms of semantic parsing, summarizing, and some other functions like generic personal finance advice and definitions from content out there. The actual math and intelligence is driven by large amounts of Kniru\\'s internal intelligence. The correct way to think about this would be a hedge fund level intelligence library being controlled by Agents.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:10:47 a user named aayushc1308 said ```And, we are being very explicit in the product to let people know that we are super early and things are evolving. \\nThe goal is to achieve very very high accuracy (say 99%) in a few months.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:11:22 a user named aayushc1308 said ```Btw: Just building a wrapper around autogen performs horribly for finance. We **ARE NOT** doing that.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:12:17 a user named telepathyx said ```okay, so it\\'s not exactly giving \"precise, personalized, actionable insights and answers all your financial questions\" - that makes sense now```.\\n\\nIn created-with-autogen, at 2023-10-21 18:13:13 a user named telepathyx said ```i assume if you ask \"should i invest in meta\" it will explain the efficient market hypothesis right?```.\\n\\nIn created-with-autogen, at 2023-10-21 18:13:35 a user named aayushc1308 said ```It does give personalized advice. Not sure I follow your inference. The tools are powered by your data. So it is personal.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:14:33 a user named telepathyx said ```it will explain that eugene fama won the nobel prize for proving beating the market is impossible? that price variation around risk-adjusted margin return is random?```.\\n\\nIn created-with-autogen, at 2023-10-21 18:15:43 a user named aayushc1308 said ```\"should i invest in meta\"  --> fetch your current portfolio --> build utility function using your transactions --> fetch data about meta --> fetch current market news --> run quantitative intelligence (proprietary) --> Share advice.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:15:53 a user named aayushc1308 said ```That is roughly the flow that Kniru will enter.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:16:14 a user named telepathyx said ```ah okay hahah... i have a background in quant trading so i apologize for calling you out```.\\n\\nIn created-with-autogen, at 2023-10-21 18:16:37 a user named telepathyx said ```i don\\'t really agree with your ethics but it\\'s not unlawful```.', '\\nIn created-with-autogen, at 2023-10-02 05:16:41 a user named sonichi said ```https://twitter.com/oscarmoxon/status/1708603929011863871```.\\n\\nIn created-with-autogen, at 2023-10-01 22:29:07 a user named abhilashinumella said ```Yes I was surprised too. I used GPT-4 for the prompts. Feel confident it can used to generate AI squad for a lot of low to medium precision tasks/goals.```.\\n\\nIn created-with-autogen, at 2023-10-01 21:42:28 a user named iamhere said ```YO! is this what your\\'e talking about? I\\'d love to help, I\\'m really new to all of this and need to get caught up to speed. I\\'m jumping over hurdles getting to this point. I still have no idea what I\\'m doing, but I think its because I\\'m trying to interoperate with langchain and autogen, without know how to use either. SMH \\nBaby Steps, do we even need langchain anymore? that\\'s how I found autogen as I\\'m trying to have conversations with multiple agents at once. My spreadsheets were only doing so much.```.\\n\\nIn created-with-autogen, at 2023-10-01 20:39:54 a user named .princeps said ```Nice, I have another repo up that you can checkout```.\\n\\nIn created-with-autogen, at 2023-10-01 19:17:40 a user named kenfucius5452 said ```Love it! I\\'m quite impressed by the quality of the output with such seemingly simple prompting. I\\'m curious, did you write the prompts yourself? Did you use GPT4 or any other tool to generate the written personas of Joey and Monica?```.\\n\\nIn created-with-autogen, at 2023-10-01 17:28:38 a user named pradeep1148 said ```hey made a video based on this github repo https://www.youtube.com/watch?v=gnn1H4H81IY&ab_channel=DLExplorers Thanks for the contribution poly```.\\n\\nIn created-with-autogen, at 2023-10-01 04:37:31 a user named abhilashinumella said ```A scene writer using autogen: https://x.com/abhilashi/status/1708339764250947692?s=20```.\\n\\nIn created-with-autogen, at 2023-09-30 19:16:58 a user named tonic_1 said ```sent to you and @salegrem```.\\n\\nIn created-with-autogen, at 2023-09-30 19:15:54 a user named mdfahad999 said ```https://github.com/mdfahad999```.\\n\\nIn created-with-autogen, at 2023-09-30 19:14:42 a user named tonic_1 said ```join us on discord also```.\\n\\nIn created-with-autogen, at 2023-09-30 19:14:29 a user named tonic_1 said ```very cool @WolfroseWe and @mdfahad999 , just send me your github and i\\'ll add you, it will be fun, i\\'m sure```.\\n\\nIn created-with-autogen, at nan a user named mdfahad999 said ```I am interested to contribute.```.\\n\\nIn created-with-autogen, at 2023-09-30 18:28:01 a user named .princeps said ```https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\\n\\nIn created-with-autogen, at 2023-09-30 17:00:01 a user named tonic_1 said ```yes my friend, please join us 👊🏻```.\\n\\nIn created-with-autogen, at 2023-09-30 09:27:56 a user named tonic_1 said ```going to remake autogtp to achieve better performance against beebot benchmark by using autogen https://github.com/team-tonic-arena-hacks```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:07:04 a user named sazied said ```@sonichi @rickyloynd I think this should work best for my use case\\n\\nThanks again for all your help and such prompt responses 🙏🚀```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:05:54 a user named sazied said ```Just went over your code, looks neat 😄```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:05:38 a user named sazied said ```Wow, thanks so much man!```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:02:02 a user named c_bonadio said ```Hi @sazied I used websockets to get and send human_input take a look here\\nhttps://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.\\n\\nIn ideas-and-feedback, at 2023-11-15 01:07:42 a user named sazied said ```I have this socket connection running that allows me to receive the responses back from the agents on the forntend - \\n\\n\\n@socketio.on(\\'start_orchestrator\\')\\ndef handle_start_orchestrator(data):\\n    print(\\'YOO\\')\\n    #Extract the data and start the orchestrator\\n    test_param = data.get(\"test_param\", \"Default Value\")\\n    \\n    success, seq_messages = sequential_orchestrator.sequential_conversation(test_param)\\n    \\n    \\n    # Send each message as it is generated\\n    for message in seq_messages:\\n        socketio.emit(\\'orchestrator_message\\', { \\'message\\': message })\\n\\n\\nFor one of the steps I need a human feedback loop so I have now set human_input_mode = \\'ALWAYS\\' to test this functionality. How do I set the human feedback message without using the terminal. Does autogen expose some method that I am not aware of? I am also using a custom orchestrator, so I am wondering if I can set up a method in the Orchestrator class, but I do not know where to start.\\nAny help would be much appreciated!```.\\n\\nIn ideas-and-feedback, at 2023-11-15 00:58:35 a user named rickyloynd said ```More details about @lucemia.\\'s application. https://discord.com/channels/1153072414184452236/1174149944718921820```.\\n\\nIn ideas-and-feedback, at 2023-11-15 00:50:22 a user named lucemia. said ```I am currently using AutoGen to streamline and minimize repetitive DevOps tasks.```.\\n\\nIn ideas-and-feedback, at 2023-11-15 00:38:12 a user named sonichi said ```The default system_message for `AssistantAgent` instructs writing code. Please overwrite it for your use case.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 22:24:28 a user named sleepwave said ```thank you! That was my initial understanding which is why I was so shocked when I was getting code back based on a simple prompt that included an `AssistantAgent`. I thought the `AssistantAgent` was configured in a pretty \"default\" manner using a local model that I knew to be primarily conversational. I\\'m using a `UserProxyAgent` with the `AssistantAgent`, maybe it\\'s actually the `UserProxyAgent` that\\'s polluting the flow?```.\\n\\nIn ideas-and-feedback, at 2023-11-14 21:49:22 a user named pika.c said ```Autogen is a framework. You can use it just for conversation between agents without code output or execution. It depends on the system prompts you pass to each agent```.\\n\\nIn ideas-and-feedback, at 2023-11-14 21:43:29 a user named sleepwave said ```hey guys, quick question if anyone can help me wrap my head around something. After tinkering with autogen, it seems autogen\\'s primary goal is to output code. Is there a similar framework that lets me allow multiple agents to simply _converse_ to solve a more abstract problem? Is that where Langchain comes in, or am I misunderstanding the capabilities and intention of Autogen?```.\\n\\nIn ideas-and-feedback, at 2023-11-14 18:20:20 a user named airlights said ```it\\'s actually one big \\'assistant\\' roleplaying for each. Look, if you\\'re happy -- I\\'m happy 🙂 Hope this gives you what you need```.\\n\\nIn ideas-and-feedback, at 2023-11-14 18:20:16 a user named _jojorge said ```I can write a brief post explaining the how\\'s and whys, and clean up the code to be a notebook.\\n\\nI started with your \"next\" tag example as a starting off point, and had GPT4 and the docs bring me toward the functionality demonstrated here.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 18:17:43 a user named _jojorge said ```it\\'s true that you can\\'t load multiple agents, but the way that it\\'s set up (and the way I ran it last night), is that I basically had a shell around each, so with a bit of hierarchy, I was able to access lots of OpenAI agents in one session. Just check out the logs and you will see. All the agents were OpenAI assistants.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:59:26 a user named airlights said ```I agree the next thing is to take each chapter and storyboard it 🙂```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:58:37 a user named airlights said ```it\\'s not production ready but it works pretty nicely```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:58:11 a user named airlights said ```I can help you if you want to instantiate that whole team, I\\'ve built a solution that uses an Airtable to keep track of team members, gives them different models, temperature, roles etc.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:57:04 a user named airlights said ```That looks nice but I have to tell you, right now AutoGen can only integrate one OpenAI assistant (GPT Assistant only supports one OpenAI client. Using the first client in the list.\\nNo instructions were provided for given assistant. Using existing instructions from assistant API.)```.\\n\\nIn ideas-and-feedback, at 2023-11-14 14:39:17 a user named mgintoki said ```how to integrate with social plat data analysis```.\\n\\nIn ideas-and-feedback, at 2023-11-14 13:39:07 a user named sonichi said ```Nice suggestion! Would you like to present it as a notebook example, or a blog post, or some other way?```.\\n\\nIn ideas-and-feedback, at 2023-11-14 13:38:50 a user named fran.abenza said ```https://chat.openai.com/g/g-EwugVj4zq-autogen-builder```.\\n\\nIn ideas-and-feedback, at 2023-11-14 07:30:52 a user named pika.c said ```This is pretty cool! Adding imagery to this is a great idea. The only barrier right now to experimenting with this tech is the cost of the APIs.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 06:07:39 a user named _jojorge said ```yeah! Right now I\\'m just screwing around, but I build out a writers room which cooked this up tonight, since you helped me wrangle them!\\n\\nhttps://drive.google.com/file/d/1LLsVGWm0BXLZnMfZ1f0zd1D14qi0QV9x/view?usp=sharing\\n\\nGo Buffs!\\n\\nHere is the terminal output:\\nhttps://drive.google.com/file/d/1m2ZnCicmIgzZfvOOm02TLHAr0JuYNuHB/view?usp=sharing\\n\\nIt looks a bit like your project! I spend a while earlier today defining a workflow, and building out the dossiers on the writers in the writers room. This I used the newly released GPT assistants to hook autogen into the new openAI assistants (which probably wasnt necessary) and assigned them to my writers room.\\n\\nI\\'d like to add a way for the members of the team to commit to long term memory their memories, such as character arcs, settings, themes, plot outlines at varying degrees (entire story, chapter, scene). \\n\\nAlso, I\\'d like to add agents to create imagery.\\n\\nMaybe I\\'ll automate the audio narration. It would be cool to parse out different narrated speech for different characters and the narrator. ', '\\nIn general, at 2023-11-09 01:49:44 a user named sonichi said ```Just talked about it in <#1157717881291812964> 😃```.\\n\\nIn general, at 2023-11-09 01:43:36 a user named zoted said ```🙋🏽\\u200d♂️Are there any good documents or google collab with Autogen and Open AI assistant working together yet?```.\\n\\nIn general, at 2023-11-08 23:44:04 a user named drinkoblog.weebly.com said ```https://www.agentcloud.dev/```.\\n\\nIn general, at 2023-11-08 23:30:38 a user named groundzer000 said ```i would love to see real working apps built with autogen. is there any??```.\\n\\nIn general, at 2023-11-08 23:12:05 a user named trev1649 said ```I am passionate about learning, teaching and using Ai to create residual income. I have researched a lot of software\\'s and platforms, the solution I choose is Autogen.```.\\n\\nIn general, at 2023-11-08 21:34:35 a user named bon_am said ```yes some really interesting use cases are triggering but those need a sounding board to discuss..```.\\n\\nIn general, at 2023-11-08 21:33:21 a user named usingxbox360controller said ```Would be a lifesaver for many people honestly```.\\n\\nIn general, at 2023-11-08 21:31:41 a user named bon_am said ```hello @everyone .. im bonam and a fan of autogen and all other multi agent frameworks.\\n\\nthis framework gives opensource a real chance to challenge openai by creatively interconnecting specialist agents from open source to accomplish tasks better beyond a single large gpt model in near future.\\n\\nwhy sleep on this.\\n\\nthats why im working on a ui for multi agent chat with a team of developers\\n\\nhowever if anyone of u is as passionate about autogen and can play god with multiple agents and use cases \\n\\n\\ni want to collaborate in creating an open source ui for this multi generative future. \\n\\nDMs are open. \\n\\nplease reach out! @bon_am```.\\n\\nIn general, at 2023-11-08 21:12:10 a user named usingxbox360controller said ```Thanks! Glad to see you still in the Ai fight, haha.\\n\\nSo those more \\'complicated\\' threads are all done via API then, and not testable through playground?```.\\n\\nIn general, at 2023-11-08 21:10:34 a user named hanley7082 said ```Hey Captain 🙂 When the new OpenAI assistant gets fully integrated into autogen, you will be able to set up multiple assistants the same way you do it now (in autogen).\\n\\nHow the oai assistant works is you initialize an assistant with a system message and tools/files enabled. You then create a thread and add your first user message. You can then pass an assistant and a thread to the run function, which returns the response (as well as updating the thread, which is managed by them). I still have some questions about memory across the entire system, but this seems like a good start.```.\\n\\nIn general, at 2023-11-08 20:32:08 a user named arnoow said ```hello, i have a question for you fellow ai experts, i was wondering if openai for their new custom gpts bots feature is using an architecture where they use at first the generalist ChatGPT 4 model and when it identifies the domain you want to build your chatbot upon it switches to a fine tuned, specialized version of the base model gpt 4 ?```.\\n\\nIn general, at 2023-11-08 20:21:46 a user named usingxbox360controller said ```I see, but they don\\'t have the framework to get multiple assistants to work with each other do they?```.\\n\\nIn general, at 2023-11-08 19:31:21 a user named dulak said ```Yea I\\'ve been keeping an eye on it too, just wanted to logic check tyvm!```.\\n\\nIn general, at 2023-11-08 19:18:41 a user named hanley7082 said ```The OpenAI assistants are basically an autogen assistant upgrade. Now we don\\'t have to manage chat memory, assistant can do rag (no external agent necessary) and run a code interpreter (again, with no external agent necessary). The autogen assistant could always do function calling so that\\'s not new```.\\n\\nIn general, at 2023-11-08 19:15:38 a user named hanley7082 said ```Autogen is the command and code execution piece that completes the autonomy loop```.\\n\\nIn general, at 2023-11-08 19:15:32 a user named gubok said ```If you want to be able to use open source LLMs, keep using autogen 🙂```.\\n\\nIn general, at 2023-11-08 18:54:45 a user named usingxbox360controller said ```It\\'s probably just two completely separate teams working on this. Assistants API is strictly from OpenAi isn\\'t it?```.\\n\\nIn general, at 2023-11-08 18:53:41 a user named jacek6859 said ```So, whats Microsoft OpenAI strategy regarding development of AutoGen vs Assistants API?```.\\n\\nIn general, at 2023-11-08 18:34:11 a user named jacek6859 said ```Whats best practice to call a python function, that must be used by an agent. Should I define a function in a given agent class, or should I keep function as separate code? Any pattern  here?```.\\n\\nIn general, at 2023-11-08 18:25:08 a user named andi1281 said ```is there a tutorial on how i can implement a trained agent into my script?```.\\n\\nIn general, at 2023-11-08 17:36:40 a user named bobaleaux said ```yeah, that\\'s definitely one of those \"you\\'re mileage may vary\" kind of things too making moving parts, right?```.\\n\\nIn general, at 2023-11-08 17:35:29 a user named usingxbox360controller said ```Executing the code still takes forever though, I wonder if that\\'s just my PC/setup```.\\n\\nIn general, at 2023-11-08 17:33:35 a user named bobaleaux said ```I haven\\'t tried it yet, I\\'ve been hung up on migrating to postgres.. ugh```.\\n\\nIn general, at 2023-11-08 17:32:29 a user named usingxbox360controller said ```Autogen is SO MUCH nicer now w/ GPT4 turbo god damn```.\\n\\nIn general, at 2023-11-08 17:32:29 a user named bobaleaux said ```but it doesn\\'t make sense forever```.\\n\\nIn general, at 2023-11-08 17:25:59 a user named bobaleaux said ```and I\\'m just speaking as me. my own view```.\\n\\nIn general, at 2023-11-08 17:25:14 a user named bobaleaux said ```it\\'s not earth shattering and there is a deep integration of openai right now, they are a service provider to bing.```.\\n\\nIn general, at 2023-11-08 17:24:21 a user named bobaleaux said ```you can find the entire opening day video on openai website```.\\n\\nIn general, at 2023-11-08 17:23:46 a user named bobaleaux said ```yes, he spoke at the DevDay i thought it was an awkward but revealing moment of truth about the future.```.\\n\\nIn general, at 2023-11-08 17:23:03 a user named benbarnard said ```? he mentioned it in the OpenAI thing?```.\\n\\nIn general, at 2023-11-08 17:22:43 a user named bobaleaux said ```hahaha, yeah, when Altman introduced him and said something about the relationship with MS!```.\\n\\nIn general, at 2023-11-08 17:22:05 a user named benbarnard said ```I read somewhere that Satya mentioned Autogen yesterday, does anybody know about this?```.\\n\\nIn general, at 2023-11-08 17:21:55 a user named bobaleaux said ```I know!!! hahaha and knowing that while being \\'the\\' product designer, right? well, talk about a group chat! wow! it\\'s like the forward progress has slowed but the width of the dozer blad eis widening super fast!.\\n\\ncountry boy analogy, hahaha```.\\n\\nIn general, at 2023-11-08 17:18:50 a user named rickyloynd said ```@bobaleaux Absolutely, we\\'re working on that vision! Hopefully not too far out, because the field is moving so fast.```.\\n\\nIn general, at 2023-11-08 17:17:57 a user named afourney said ```It\\'s fast. Performance on benchmarks I\\'ve tried is very standard for GPT-4. With 100 requests a day limit, it\\'s hard to say more```.\\n\\nIn general, at 2023-11-08 17:00:02 a user named aaronward_ said ```Haven\\'t used the new gpt-4-1106-preview yet, whats peoples expriences so far with respect to Autogen agents?```.\\n\\nIn general, at 2023-11-08 16:57:53 a user named bobaleaux said ```Ricky, it\\'s exciting to watch it all expand. It seems like it\\'s going to come down to the orchestration of the \\'component\\' stored objects.  dynamically callable context and then shaping the different messages and instructions to give what seems would be really close be being able to have different thoughts about different things and so forth.\\nAre you guys working to bring them together or is that still a ways out?```.\\n\\nIn general, at 2023-11-08 16:50:05 a user named hahl9000 said ```Anyone here has experience/links/stuff about gpt chatbots forwebpage for eg. to use in wordpress?```.\\n\\nIn general, at 2023-11-08 16:12:06 a user named onecodescholar said ```There\\'s faster models out there but not exactly specific for coding. I\\'m wanting an updated local Coding LLM.```.\\n\\nIn general, at 2023-11-08 16:09:23 a user named andi1281 said ```Awesome, thanks @shaggz2006, @onecodescholar   and @rickyloynd  for your help! I really appreciate it.```.\\n\\nIn general, at 2023-11-08 16:08:23 a user named onecodescholar said ```https://www.runpod.io/```.\\n\\nIn general, at 2023-11-08 16:08:06 a user named shaggz2006 said ```If you do have funds available, you can get a GPU running on runpod for a few bucks an hour.   Then you can compare how it runs there to how it runs locally.```.\\n\\nIn general, at 2023-11-08 16:06:57 a user named shaggz2006 said ```When you run codellama straight from LM Studio, you should see a general \\'tokens/sec\\' metric.   This can give you an idea of what you are dealing with.```.\\n\\nIn general, at 2023-11-08 16:06:57 a user named andi1281 said ```ok, then i´ll try to find a solution where this works online somehow```.\\n\\nIn general, at 2023-11-08 16:06:13 a user named onecodescholar said ```That might be the bottleneck```.\\n\\nIn general, at 2023-11-08 16:06:01 a user named andi1281 said ```i haven´t configured anything in terms of GPU usage```.\\n\\nIn general, at 2023-11-08 16:05:14 a user named andi1281 said ```I have a 8GB M2 Mac Mini```.\\n\\nIn general, at 2023-11-08 16:04:51 a user named shaggz2006 said ```do you have an Nvidia GPU locally, and if so, do you have LM Studio config\\'d to use the cores?```.\\n\\nIn general, at 2023-11-08 16:04:15 a user named andi1281 said ```probably the wrong model for the job, right? I  naively chose this one because i read that Codellama might be good for that kind of job```.\\n\\nIn general, at 2023-11-08 16:04:12 a user named onecodescholar said ```I was going to suggest using a smaller model for faster results but you\\'re already on a 7B model.```.\\n\\nIn general, at 2023-11-08 16:02:45 a user named andi1281 said ```The Bloke codellama instruct 7B q4_k_s ggml```.\\n\\nIn general, at 2023-11-08 16:02:36 a user named rickyloynd said ```Our team is being asked that a lot, so we are preparing a complete response that should be out soon. 😄```.\\n\\nIn general, at 2023-11-08 16:00:47 a user named shaggz2006 said ```@rickyloynd   -- has there been any collaboration between the autogen team and OpenAI in regards to agents (given the MS partnership)?```.', '\\n\\nSo, and I may be wrong as I am not 100% familiar with how AutoGPT runs, but my understanding is that AutoGen is the framework that AutoGPT could have been built from.\\n\\n\\nSo, when benchmarking, it won\\'t simply be AutoGen vs AutoGPT; the specific workflow and configuration of AutoGen, and it\\'s resulting performance, is what will be compared.```.\\n\\nIn general, at 2023-09-29 16:13:03 a user named fxtoofaan said ```Are the prompt message different between the different models ? Like gptx vs llama2 vs falcon vs mistral ?```.\\n\\nIn general, at 2023-09-29 16:11:01 a user named pkscary said ```The AutoGPT team has been benchmarking all the agent-based projects so I wonder how AutoGen stacks up```.\\n\\nIn general, at 2023-09-29 16:10:29 a user named pkscary said ```Does anyone have experience with Beebot, BabyAGI, AutoGPT, etc. and how do you think AutoGen compares to these other projects?```.\\n\\nIn general, at 2023-09-29 16:08:32 a user named pkscary said ```Someone should pin the repo https://github.com/microsoft/autogen to the welcome page for this Discord```.\\n\\nIn general, at 2023-09-29 15:57:41 a user named sonichi said ```AssistantAgent(name=..., llm_config={\"model\": \"gpt-3.5-turbo\", \"api_key\": ...})```.\\n\\nIn general, at 2023-09-29 15:38:53 a user named vincentjedi said ```response = autogen.Completion.create(\\n    config_list=[\\n        {\\n            \"model\": \"gpt-4\",\\n            \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\\n            \"api_type\": \"azure\",\\n            \"api_base\": os.environ.get(\"AZURE_OPENAI_API_BASE\"),\\n            \"api_version\": \"2023-07-01-preview\",\\n        },\\n        {\\n            \"model\": \"gpt-3.5-turbo\",\\n            \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\\n            \"api_type\": \"open_ai\",\\n            \"api_base\": \"https://api.openai.com/v1\",\\n            \"api_version\": None,\\n        },\\n        {\\n            \"model\": \"llama-7B\",\\n            \"api_base\": \"http://127.0.0.1:8080\",\\n            \"api_type\": \"open_ai\",\\n            \"api_version\": None,\\n        }\\n    ],\\n    prompt=\"Hi\",\\n)```.\\n\\nIn general, at 2023-09-29 15:35:12 a user named crankfunk said ```hey there, trying for hours now, but I dont get it: just want to get the quickstart example running (\"Plot a chart of NVDA and TESLA stock price change YTD.\"). how can I switch the model to gpt-3.5-turbo? dont have access to gpt-4. i read the FAQs and everything but am totally stucked.```.\\n\\nIn general, at 2023-09-29 15:29:35 a user named tonic_1 said ```that\\'s what i\\'m trying to have folks do for this one : https://huggingface.co/collections/MultiTransformer/autogengradiohuggingface-651626e54256270d6fad2621\\njoin the organisation here : https://huggingface.co/MultiTransformer\\n\\ni\\'ll probably go through the shares on this discord to add them to the collection, but let\\'s make some cool demos together, it will be fun 👊🏻```.\\n\\nIn general, at 2023-09-29 15:08:07 a user named vincentjedi said ```Have u tried to add a simple gradio or streamlit frontend to use it with browser ?```.\\n\\nIn general, at 2023-09-29 14:50:19 a user named fxtoofaan said ```I’m trying to figure that out```.\\n\\nIn general, at 2023-09-29 14:48:18 a user named vincentjedi said ```How can we use llama2 or other local llm instead of using openai api?```.\\n\\nIn general, at 2023-09-29 14:45:20 a user named fxtoofaan said ```It’s missing some information which I cannot find any how to for it.```.\\n\\nIn general, at 2023-09-29 14:44:38 a user named fxtoofaan said ```I think we all have similar goals. Would be nice to maybe have a chat group where we can share code snippets making this work ?```.\\n\\nIn general, at 2023-09-29 14:44:30 a user named nexorsist said ```One of the issues on the Github page shows how to connect it to a local LLM (i think it was fastchat)```.\\n\\nIn general, at 2023-09-29 14:43:42 a user named nexorsist said ```it can likely then also optimize priming individual worker agents with better system prompts as it progresses```.\\n\\nIn general, at 2023-09-29 14:43:03 a user named fxtoofaan said ```At this point I’d love to see a single python file with everything in it to connect autogen to a local llm server like fastchat running mistral 7b model. No openai api keys, all local stuff. Simple bot that can answer who is current president of united states for example. Can anyone build code for this please ?```.\\n\\nIn general, at 2023-09-29 14:42:37 a user named nexorsist said ```What is missing from an agentverse setup is a decision maker which an LLM is not. What we need is a reinforcement learning bot (like what DeepMind makes) that acts as the central decision maker in conjunction with an LLM to send out the instructions. The RL agent can read the project \"environment\" and can perform actions (instructions) to LLM agents.```.\\n\\nIn general, at 2023-09-29 14:40:18 a user named nexorsist said ```I think the idea would be to think about it a little differently. Think of every agent you need to perform tasks as a clean slate skilled person. You prime it with the correct prompt to setup the \"skillset\" and to be specific about the type of tasks it should perform and how.\\n\\nThen think of a workflow for the project you want to build and how it should interact with your pre-primed agents so that memory retention isn\\'t required. \\n\\nThat still has limitations if you trying to build on past things but it will likely just result in you changing how you design things. Could maybe make an agent that documents all tasks that were completed in a summarised manner to a central storage which you can then use as a knowledge index for the model of all things that have been built and done for future additions to a project?```.\\n\\nIn general, at 2023-09-29 14:31:15 a user named sspoth said ```Is there a way to have these bots retain its memory```.\\n\\nIn general, at 2023-09-29 13:43:06 a user named fxtoofaan said ```getting this error using local llm:\\n\\nValueError: dictionary update sequence element #0 has length 1; 2 is required```.\\n\\nIn general, at 2023-09-29 13:36:58 a user named .princeps said ```here is the project I setup to create a simple snake game \\n\\nhttps://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\\n\\nIn general, at 2023-09-29 13:15:23 a user named tonic_1 said ```If y’all are building tutorials and demos don’t forget this 👆🏻```.\\n\\nIn general, at 2023-09-29 13:07:46 a user named fxtoofaan said ```i am getting timeout issues using local llm. I even set the timeout to 900 seconds. (read timeout=900) in \\\\autogen\\\\autogen\\\\oai\\\\completion.py file.```.\\n\\nIn general, at 2023-09-29 13:01:11 a user named redai.ai said ```Any newbies that need help getting autogen working check it out```.\\n\\nIn general, at 2023-09-29 13:01:01 a user named redai.ai said ```https://www.youtube.com/watch?v=8TLwSH_UFwI&feature=youtu.be```.\\n\\nIn general, at 2023-09-29 13:00:56 a user named redai.ai said ```My video on autogen is premiering now```.\\n\\nIn general, at 2023-09-29 10:16:25 a user named fxtoofaan said ```My first use case is using autogen to help me create a virtual agents team for a specific task. And I want autogen to give me the team members abilities , deliverables and which other agent it should listen to or give orders to. Like make me a team that can start and scale a b2b newsletter from $0 to $1million in 12 months.```.\\n\\nIn general, at 2023-09-29 09:45:50 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.\\n\\nIn general, at 2023-09-29 09:39:11 a user named thunderbird365 said ```Ah, I see. I see the pattern```.\\n\\nIn general, at 2023-09-29 09:37:50 a user named thunderbird365 said ```No, that is false. \\nHere\\'s the proof it does```.\\n\\nIn general, at 2023-09-29 09:37:09 a user named scratchinknight said ```userProxy doesnt generate anything unless its your input```.\\n\\nIn general, at 2023-09-29 09:36:29 a user named fxtoofaan said ```@sonichi is it possible for an agent to go to web and search for stuff and gather up to date info? Like research for a topic or concept```.\\n\\nIn general, at 2023-09-29 09:36:25 a user named thunderbird365 said ```Anyone getting this problem: \\n\\nThe user proxy chooses not to reply anything randomly.```.\\n\\nIn general, at 2023-09-29 09:35:55 a user named scratchinknight said ```i get this error docker.errors.DockerException: Error while fetching server API version: request() got an unexpected keyword argument \\'chunked\\'```.\\n\\nIn general, at 2023-09-29 09:31:21 a user named sonichi said ```You can provide the image name as a str```.\\n\\nIn general, at 2023-09-29 08:50:41 a user named nexorsist said ```Suspect it will be the latter because the OpenAI API gpt models do not have access to the internet yet```.\\n\\nIn general, at 2023-09-29 08:46:24 a user named fxtoofaan said ```So does autogen have access to the internet yet? Or can I use autogen to gather data from internet for its agents ? What about local docs vector db or local knowledge added to agents ?```.\\n\\nIn general, at 2023-09-29 08:28:44 a user named scratchinknight said ```do i setup the docker in environment and then provide or it create the container?```.\\n\\nIn general, at 2023-09-29 08:27:03 a user named scratchinknight said ```how does use_docker work ?```.\\n\\nIn general, at 2023-09-29 08:01:42 a user named jimmysandwiches said ```Can i suggest a excellent tip I use when learning and debugging code - use claude.ai (seems to work better for me with code errors than chatgpt, also try bard) and simply post the error message into chat (thats all i did, we\\'re all learning 🙂 🥪```.', '\\nIn general, at 2023-10-07 09:23:15 a user named bitsy_chuck said ```multiple document in vector store vs single document in vector store (chroma db) \\nembedding model: all-mpnet-base-v2 or all-MiniLM-L6-v2\\npdf file with 500 pages\\nshould i break it up into chapters for better results?```.\\n\\nIn general, at 2023-10-07 08:06:12 a user named juzure. said ```As a beginner, I\\'m curious about the differences between AutoGPT and Autogen. Does anyone know?```.\\n\\nIn general, at 2023-10-07 08:02:15 a user named le_xxx said ```yay got the example working! does anyone know, does autogen have some file manager to save the generated code automatically?```.\\n\\nIn general, at 2023-10-07 07:48:01 a user named d8689 said ```I had the same issue (posted it in ideas-and-feedback), if you come up with a solution do post 😄```.\\n\\nIn general, at 2023-10-07 07:33:56 a user named eljefe69 said ```Hey, German fella here too.```.\\n\\nIn general, at 2023-10-07 06:28:00 a user named rumgewieselt said ```Hi. I am from Germany / Hamburg and happy to join the community here.```.\\n\\nIn general, at 2023-10-07 06:16:50 a user named bluethinhorse_18200 said ```https://tenor.com/iMpqamk3c52.gif```.\\n\\nIn general, at 2023-10-07 05:58:07 a user named heresynetwork said ```HI!  I came here from Wes Roth\\'s video!```.\\n\\nIn general, at 2023-10-07 04:21:24 a user named qingyunwu said ```Not yet. But still tuned 🙂```.\\n\\nIn general, at 2023-10-07 04:06:54 a user named afourney said ```In other projects I’ve used an exponential back off when a request time out wasn’t provided```.\\n\\nIn general, at 2023-10-07 04:05:17 a user named afourney said ```Yeah if you filter it to select only one model, and hit a rate limit error, it should correctly handle the OAI exception (I.e., by waiting for the prescribed amount of time that the API provides). If that’s not the case, we should file an issue on GH```.\\n\\nIn general, at 2023-10-07 03:50:01 a user named sigma.xxx said ```Hi I was running into the same issue, however I dont think that model switching is the way to go though....it compromises quality. I think AutoGen should maybe consider adding a rate_limit_handle class like a singleton or something that tracks all instances tokens comsumption, and implement a wait logic. That seems to make more sense```.\\n\\nIn general, at 2023-10-07 03:42:02 a user named le_xxx said ```hi all, running into a wall trying to test this out, it says openai.error.AuthenticationError: No API key provided. You can set your API key in code using \\'openai.api_key = <API-KEY>\\',... even tho i did setup OAI_CONFIG_LIST with my key and when i load it with config_list = autogen.config_list_from_json( i can see its loaded with print(config_list) then i setup some assistants and finally doing a user_proxy.initiate_chat it gives me that error. watched some videos and all they did was setup that json and it works for them```.\\n\\nIn general, at 2023-10-07 03:17:15 a user named slayerdeebo said ```Is it possible to use GPT vision in autogen ?```.\\n\\nIn general, at 2023-10-07 03:08:09 a user named li_jiang said ```Run with Gradio ValueError: signal only works in main thread of the main interpreter```.\\n\\nIn general, at 2023-10-07 03:05:11 a user named li_jiang said ```Hi @0x0ting , it would be nice if you could provide more details as @qingyunwu mentioned. But based on what you\\'ve posted, I guess the issue is that there is some incompatible between Gradio and the signal lib used in code_utils.py in autogen. Could you try running your code in a terminal without Gradio? Maybe it can help to locate the root cause.```.\\n\\nIn general, at 2023-10-07 02:28:29 a user named andyinater said ```I figure I can hack it together with ending and restarting convos constantly, shifting the messages appropriately, just seeing if there is any better options first.```.\\n\\nIn general, at 2023-10-07 02:27:40 a user named andyinater said ```Does anyone know if there is a built in way to maintain a fixed max convo length, and do a FILO kind of thing to catch the old stuff as it maxes out?```.\\n\\nIn general, at 2023-10-07 02:14:11 a user named yanxiaochuan said ```i know on github and twitter```.\\n\\nIn general, at 2023-10-07 01:54:14 a user named unicorn1997 said ```Hello everyone, trying to understand AutoGen, could someone explain me on their example with visualizing stock prices - Why isnt there a few shot example included? But instead there is the first user input already incorporated in the code? (The query about the stock prices)\\n\\nI tried to make my own agent and I first put a few shot example to the code, then a part where user was to write an input.\\nHere it seems like it is pre-defined in the code what the agent will do, but I would like to make my own custom input in the first place. \\n\\nHope my question is clear 😄 \\nThanks a lot!```.\\n\\nIn general, at 2023-10-07 01:46:39 a user named somecomputerguy said ```I just got the samples to work 😂```.\\n\\nIn general, at 2023-10-07 01:41:04 a user named regen2moon said ```custom autogen via discord ready to do first test```.\\n\\nIn general, at 2023-10-07 00:07:43 a user named finnious. said ```Just starting. following Wes Roth YouTube video```.\\n\\nIn general, at 2023-10-06 23:45:06 a user named frank.martinez said ```What tool interfaces are people building? Here’s what I want: a] Google Apps, b] Miro, c] Twilio```.\\n\\nIn general, at 2023-10-06 23:08:28 a user named bishopfx said ```For sure. I wasnt using that one as of before I posted that. I didn\\'t quite fix it though, im quite stumped LOL.```.\\n\\nIn general, at 2023-10-06 23:07:23 a user named afourney said ```Glad you fixed it, but please remove this photo and rotate your api key 😛```.\\n\\nIn general, at 2023-10-06 23:06:04 a user named bishopfx said ```@afourney this was the error, i remember now by changing the engine i fixed the API issue but was getting this instead.```.\\n\\nIn general, at 2023-10-06 22:44:02 a user named sonichi said ```I would like to create a project that```.\\n\\nIn general, at 2023-10-06 22:41:16 a user named afourney said ```Yes agreed. If you have just the one endpoint in the list, or use a filter, I think that’s what it does. @sonichi ?```.\\n\\nIn general, at 2023-10-06 22:38:58 a user named purplxd said ```It would be much better if we could read the message and wait the specified amount of time rather than risk hammering the API endpoints```.\\n\\nIn general, at 2023-10-06 22:37:23 a user named bishopfx said ```I was able to fix that error by importqhing the api key in the actual file itself and defining it, but then I get the api access restriction error but everything else runs fine. I was just demoing the tesla nvda chart script.```.\\n\\nIn general, at 2023-10-06 22:35:44 a user named bishopfx said ```It was having issues with the json loader I belive```.\\n\\nIn general, at 2023-10-06 22:35:28 a user named bishopfx said ```I was providing it through Json. I wish I was at my PC id post a screen.```.\\n\\nIn general, at 2023-10-06 22:35:16 a user named wladpaiva said ```Would that mean that the same input would always get the same output even when we execute scrape functions in between it?```.\\n\\nIn general, at 2023-10-06 22:33:14 a user named aaronward_ said ```replacing UserProxyAgent with whatever the variable name is for that object```.\\n\\nIn general, at 2023-10-06 22:32:55 a user named aaronward_ said ```You can use the UserProxyAgent.send(message=\"\") and it will have memory of your previous generated text```.\\n\\nIn general, at 2023-10-06 22:31:57 a user named wladpaiva said ```That would probably help. However, what I\\'m looking for is to stop the execution and come back to the same point in time later on```.\\n\\nIn general, at 2023-10-06 22:27:53 a user named aaronward_ said ```https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#caching Conversations are automatically caches in ./cache folder```.\\n\\nIn general, at 2023-10-06 22:26:11 a user named afourney said ```We’ve had one other similar report. How are you providing your OAI_CONFIG_LIST? .env? Json?```.\\n\\nIn general, at 2023-10-06 22:24:49 a user named afourney said ```You can put several models or configurations in your OAI_CONFIG_LIST which will be tried in order. You can use this to fall back to a less-limited model (e.g., GPT 3.5), or even load balance if you have different model endpoints. This can help somewhat.```.\\n\\nIn general, at 2023-10-06 22:21:23 a user named wladpaiva said ```Is there a way to save the chat state? Sorry, super noob question. I mean, how would I do it?```.\\n\\nIn general, at 2023-10-06 21:35:32 a user named bishopfx said ```I keep getting an error stating I do not have access or it cannot find that said engine, even when I change the engine in the main.py file, to 3.5-t it still shoots me the message.```.\\n\\nIn general, at 2023-10-06 21:34:48 a user named bishopfx said ```Hey guys, quick question. I seem to he having issues with my OpenAI API key. Is Autogen required to have GPT4 access?```.\\n\\nIn general, at 2023-10-06 21:12:29 a user named somecomputerguy said ```This is neat! Thanks for making it public 🙂```.\\n\\nIn general, at 2023-10-06 20:59:57 a user named purplxd said ```How to deal with openAI rate limits?```.\\n\\nIn general, at 2023-10-06 18:45:59 a user named Sparti said ```guys, does anyone know any blog or any youtube video that might help me learn about ml model deployment realtime?```.\\n\\nIn general, at 2023-10-06 18:12:46 a user named bitsy_chuck said ```what should be the format of context can```.\\n\\nIn general, at 2023-10-06 18:04:15 a user named afourney said ```Group chat stops when a termination condition is met, or when the maximum number of messages are exchanged. More details here: https://discord.com/channels/1153072414184452236/1159571194907996300```.\\n\\nIn general, at 2023-10-06 17:56:53 a user named bitsy_chuck said ```what should be the format of context? can someone please give me any example?\\n```py\\n    def initiate_chat(\\n            self,\\n            recipient: \"ConversableAgent\",\\n            clear_history: Optional[bool] = True,\\n            silent: Optional[bool] = False,\\n            **context,\\n    ):\\n        \"\"\"Initiate a chat with the recipient agent.\\n\\n        Reset the consecutive auto reply counter.\\n        If `clear_history` is True, the chat history with the recipient agent will be cleared.\\n        `generate_init_message` is called to generate the initial message for the agent.\\n\\n        Args:\\n            recipient: the recipient agent.\\n            clear_history (bool): whether to clear the chat history with the agent.\\n            silent (bool or None): (Experimental) whether to print the messages for this conversation.\\n            **context: any context information.\\n                \"message\" needs to be provided if the `generate_init_message` method is not overridden.\\n        \"\"\"\\n``````.\\n\\nIn general, at 2023-10-06 18:12:48 a user named bitsy_chuck said ```@afourney sorry to ping you. Can you please help here.```.', '\\nIn general, at 2023-10-02 15:35:41 a user named sonichi said ```All the related files are in the repo.\\nexamples: https://github.com/microsoft/autogen/tree/main/notebook\\ndocumentation website: https://github.com/microsoft/autogen/tree/main/website\\ndocstr: https://github.com/microsoft/autogen/tree/main/autogen```.\\n\\nIn general, at 2023-10-02 15:33:15 a user named fxtoofaan said ```Is there detail documentation about every feature and explanation of that feature for autogen ? Watching the video I linked about from Manish Gupta seems like autogen has features I’ve not explored or seen in the documentation before. Would be nice to feed autogen it’s own documentation and examples and then learn from that and then use autogen to create various types of virtual agent environments```.\\n\\nIn general, at 2023-10-02 15:29:53 a user named sonichi said ```Interesting idea to try. Give it an example. Use the doc and RetrieveChat if necessary.```.\\n\\nIn general, at 2023-10-02 14:46:36 a user named fxtoofaan said ```@sonichi is it possible to use autogen to create autogen python scripts? Like use autogen to create a complex group chats and define roles and responsibilities in a virtual team. Like give it a single prompt and based on that it’ll do research and find out what roles are needed and based on that create like a python script that defines connection to llm and create agents and their definitions and then also setup the group chats and then final output either with or without human intervention```.\\n\\nIn general, at 2023-10-02 14:38:02 a user named fxtoofaan said ```https://youtu.be/2RT8i-VP7V0```.\\n\\nIn general, at 2023-10-02 14:17:54 a user named andyinater said ```Welcome to the party Lumpy! Expect a bit if a steep learning curve figuring out how the Lego pieces fit together - it seems we all start off forcing it in bad ways.\\n\\nBut once you get passed that it\\'s pretty wild all the opportunity.```.\\n\\nIn general, at 2023-10-02 14:04:19 a user named lumpyfarts said ```I don\\'t know autogen, but I want to learn. I\\'m an old programmer looking to learn/play in Python and AI.```.\\n\\nIn general, at 2023-10-02 14:00:34 a user named redai.ai said ```Glad to see we got some new people in here```.\\n\\nIn general, at 2023-10-02 12:45:57 a user named _joberg said ```I am curious where we are in 1 month```.\\n\\nIn general, at 2023-10-02 12:45:40 a user named _joberg said ```Me too. We are in the algorithm```.\\n\\nIn general, at 2023-10-02 12:35:05 a user named 0xjamp said ```Anyway to get around api rate limit lol```.\\n\\nIn general, at 2023-10-02 11:44:20 a user named tigremon said ```I\\'d like to build an app to show GPX tracks over a 3D map```.\\n\\nIn general, at 2023-10-02 11:43:39 a user named tigremon said ```YouTube recommended me this video https://www.youtube.com/watch?v=8TLwSH_UFwI```.\\n\\nIn general, at 2023-10-02 10:24:43 a user named .princeps said ```I\\'ll bring you into a forum so we can chat there```.\\n\\nIn general, at 2023-10-02 10:23:26 a user named lessuse. said ```hey guys anybody made any useful use case of the autogen, please share```.\\n\\nIn general, at 2023-10-02 10:22:44 a user named lessuse. said ```i copy your repo code 🤷\\u200d♂️```.\\n\\nIn general, at 2023-10-02 10:21:07 a user named .princeps said ```Oh seems like you are trying a different script```.\\n\\nIn general, at 2023-10-02 10:18:26 a user named .princeps said ```I usually leave on the .JSON extension```.\\n\\nIn general, at 2023-10-02 10:05:48 a user named aurowk said ```I\\'ve not seen that before and I\\'m still learning myself but maybe you should try the use_docker=False option for the agents```.\\n\\nIn general, at 2023-10-02 10:04:46 a user named lessuse. said ```can u tell me about the above error```.\\n\\nIn general, at 2023-10-02 10:04:15 a user named aurowk said ```what have you called your OAI_CONFIG_LIST? Does it still have the .json extension?```.\\n\\nIn general, at 2023-10-02 10:02:50 a user named lessuse. said ```my code - \\n\\n```\\nfrom autogen import AssistantAgent, UserProxyAgent, config_list_from_json, GroupChat, GroupChatManager\\nimport autogen\\n# Load the configuration for GPT-4 from a JSON file\\nconfig_list_gpt4 = autogen.config_list_from_json(\\n    \"OAI_CONFIG_LIST\",\\n    file_location=\".\",\\n    filter_dict={\\n        \"model\": {\\n            \"gpt-4\",\\n        }\\n    }\\n)\\n\\nllm_config = {\"config_list\": config_list_gpt4, \"seed\": 42}\\nuser_proxy = autogen.UserProxyAgent(\\n   name=\"User_proxy\",\\n   system_message=\"A human admin.\",\\n   code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\\n   human_input_mode=\"TERMINATE\"\\n)\\ncoder = autogen.AssistantAgent(\\n    name=\"Coder\",\\n    llm_config=llm_config,\\n)\\npm = autogen.AssistantAgent(\\n    name=\"Product_manager\",\\n    system_message=\"Creative in software product ideas.\",\\n    llm_config=llm_config,\\n)\\ngroupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\\nmanager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\\n\\nuser_proxy.initiate_chat(manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\")\\n# type exit to terminate the chat``````.\\n\\nIn general, at 2023-10-02 10:01:39 a user named lessuse. said ```its stop at step 2```.\\n\\nIn general, at 2023-10-02 10:01:26 a user named lessuse. said ```hey , now why it keep showing this error - \\n\\n```docker.errors.DockerException: Error while fetching server API version: (2, \\'CreateFile\\', \\'The system cannot find the file specified.\\')``````.\\n\\nIn general, at 2023-10-02 09:59:42 a user named aurowk said ```So you either remove those models from the available list, or you add your key to use for them in the AOI_CONFIG_LIST```.\\n\\nIn general, at 2023-10-02 09:59:00 a user named aurowk said ```in your OAI_CONFIG_LIST you\\'ve probably not specified a key to use for the other 2 models (gpt-4-0314 and gpt-4-0613)```.\\n\\nIn general, at 2023-10-02 09:58:57 a user named lessuse. said ```also, i try many autogen examples and try the auto mode, but it keep gettting this error - \\n\\n```docker.errors.DockerException: Error while fetching server API version: (2, \\'CreateFile\\', \\'The system cannot find the file specified.\\')``````.\\n\\nIn general, at 2023-10-02 09:58:09 a user named lessuse. said ```i dont know exactly, but i replace this - \\n```config_list_gpt4 = config_list_from_json(\\n    \"../OAI_CONFIG_LIST.json\",\\n    filter_dict={\\n        \"model\": [\"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4\", \"gpt-4-0314\"],\\n    },\\n)\\n```\\n\\nwith this - \\n\\n```config_list = autogen.config_list_from_json(\\n    \"OAI_CONFIG_LIST\",\\n    file_location=\".\",\\n    filter_dict={\\n        \"model\": {\\n            \"gpt-4\",\\n            \"gpt-3.5-turbo\",\\n        }\\n    }\\n)```\\n\\nand it works```.\\n\\nIn general, at 2023-10-02 09:56:01 a user named .princeps said ```What was the issue ?```.\\n\\nIn general, at 2023-10-02 09:55:57 a user named .princeps said ```@lessuse. Seems like you got it to work```.\\n\\nIn general, at 2023-10-02 09:48:55 a user named lessuse. said ```awesome, it can run the code itself🔥```.', '\\nIn ideas-and-feedback, at 2023-11-01 14:04:59 a user named Anxieties said ```hi, im new with the autogen staff and i wondering if its possible for the autogen to succeed a mission of analysing and predicting an upcoming soccer matches?```.\\n\\nIn ideas-and-feedback, at 2023-11-01 13:24:20 a user named tmyf_ said ```Hi, is it possible to use autogen to understand the pdf template, I provide the title/subject to the AI and ask the AI to generate a similar report based on the pdf template.```.\\n\\nIn ideas-and-feedback, at 2023-11-01 11:53:15 a user named bhavisha9921 said ```how can i make api based chatbot outof autogen?```.\\n\\nIn ideas-and-feedback, at 2023-11-01 06:24:06 a user named ctrl_alt.defeat said ```ahh! I have been trying to set this up since yesterday, was unable to! Hopefully this works, thanks!```.\\n\\nIn ideas-and-feedback, at 2023-11-01 03:58:32 a user named .hagarthehorrible said ```Feel like elaborating? Some of us might want to join you in that venture. That\\'s if you feel like having company, of course.```.\\n\\nIn ideas-and-feedback, at 2023-10-31 22:16:34 a user named drinkoblog.weebly.com said ```https://www.youtube.com/watch?v=bMWXXPoDnDs```.\\n\\nIn ideas-and-feedback, at 2023-10-31 19:38:00 a user named xxpyroxxjonesxx said ```true local llm + memgpt + autogen?```.\\n\\nIn ideas-and-feedback, at 2023-10-31 17:50:14 a user named fabmendez said ```I\\'m building a creative agency```.\\n\\nIn ideas-and-feedback, at 2023-10-31 15:32:12 a user named sanimesa_03443 said ```I would like to build an app that can query an SQL database and respond to natural language questions from user```.\\n\\nIn ideas-and-feedback, at 2023-10-31 10:16:12 a user named mitchellr said ```nothing yet - required onboarding```.\\n\\nIn ideas-and-feedback, at 2023-10-31 08:29:32 a user named kajatta said ```Describe What is the worth of a single mortal life?```.\\n\\nIn ideas-and-feedback, at 2023-10-31 01:18:50 a user named qingyunwu said ```Oh, that makes sense. @karnival8, I just created a \"jobs\" (https://discord.com/channels/1153072414184452236/1168719200605437952 ) channel dedicated for conversations centered around hiring and job finding relevant to AutoGen. You can post your needs there.```.\\n\\nIn ideas-and-feedback, at 2023-10-31 00:33:58 a user named sonichi said ```I think the request is about hiring```.\\n\\nIn ideas-and-feedback, at 2023-10-31 00:29:53 a user named qingyunwu said ```You can go to the moderators or contributors for questions or post questions as issues on github.```.\\n\\nIn ideas-and-feedback, at 2023-10-30 20:57:01 a user named sonichi said ```yes, https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.\\n\\nIn ideas-and-feedback, at 2023-10-30 20:54:43 a user named justdoit1 said ```Question 🤔 do we have the ability to use openAI function calling feature in AutoGen?```.\\n\\nIn ideas-and-feedback, at 2023-10-30 19:22:25 a user named izzwizz75 said ```id like to build a dynamic case note taking web app incorporating machine learning to assist customer service agents take notes in a more productive and efficient manner```.\\n\\nIn ideas-and-feedback, at 2023-10-30 16:04:21 a user named karnival8 said ```What is the most appropriate way to find a full time developer familiar with AutoGen? Apologies in advance not sure where else to look.```.\\n\\nIn ideas-and-feedback, at 2023-10-30 14:23:24 a user named .hagarthehorrible said ```I want to build an app that decides who lives and who dies.😂```.\\n\\nIn ideas-and-feedback, at 2023-10-30 13:52:49 a user named MadVett  |  sheople said ```Hello! I\\'m Mathew, I want to put together to help me run my new consultation business where we help businesses integrate ai```.\\n\\nIn ideas-and-feedback, at 2023-10-30 08:57:04 a user named xuanwu_60471 said ```i want to build a personal assistant app with autogen```.\\n\\nIn ideas-and-feedback, at 2023-10-30 03:21:52 a user named ziggyzaggyinfinity said ```Interested in building an automatic code development end to end solution.```.\\n\\nIn ideas-and-feedback, at 2023-10-29 15:11:02 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/OAI_CONFIG_LIST_sample```.\\n\\nIn ideas-and-feedback, at 2023-10-29 14:00:37 a user named neverendinggrowth said ```where can I find OAI_CONFIG_LIST_sample??```.\\n\\nIn ideas-and-feedback, at 2023-10-29 13:35:45 a user named neverendinggrowth said ```I\\'d like to built app which will be creating custom wordpress websites based on design from client and some curated prompt. Second bigger project I want to create personal assistant which will be gathering all possible data from user (screen time, activities user spend his time on, sleep, nutrition, activity records, habits (in future measuring different levels of hormones and molecules from blood)). Then it will use this data to create optimal plan for user happiness, health and development```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:41:06 a user named m0bsta said ```fell into the checking out chrome extentions and tada```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:40:07 a user named m0bsta said ```i was just try to set it up with notion lol```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:39:22 a user named m0bsta said ```https://dashboard.eesel.ai/ this is like a rag chatbot i guess```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:31:21 a user named askofu said ```How did you build this and what data is loaded into it?```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:57:34 a user named aaronward_ said ```I\\'m working on something that will allow you to evaluate your autogen applications given different hyper-paremeters (eg: temprature, different embeddings, prompt templates, agent types etc.) - will share when it\\'s cleaned up and a few bugs are cleared up```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:18:56 a user named m0bsta said ```it\\'s ok for basic stuff i almost had it ingest the github proper lol```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:18:16 a user named m0bsta said ```ASK it what code you need tho```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:13:04 a user named m0bsta said ```OH GOD I MESSED UP LOL; you guys can have this it\\'s all autogen knowledge https://dashboard.eesel.ai/public-chat?namespace=e2c1813e-f5bb-4a19-81dc-b65b9396c5c5&palette=%7B%22primary%22%3A%22%238c21e4%22%2C%22secondary%22%3A%22%23F3F4F6%22%7D&title=autogen%20Knowledge%20%E2%80%A2%20by%20Mobsta%E2%84%9E%20%40mobstarx.com&customError=Sorry%2C%20I\\'m%20unable%20to%20answer%20that.%20Try%20rephrasing%20your%20question%20or%20reach%20out%20to%20support.&welcomeMessage=%F0%9F%91%8B%20Hi!%20How%20can%20I%20help%20you%20today%3F&suggestQuestion=true```.\\n\\nIn ideas-and-feedback, at 2023-10-28 16:29:48 a user named trtfx1 said ```\"You are a professional sports analyst. You compare statistics between teams and make a judgement call on who is more likely to win. When you are provided data for a team, you are to analyze it, step by step, and get an idea of the teams performance to compare to the other teams set of data. You will be provided two files, one for each team. You will make sure to note injuries, what positions they play, and what that means for the teams performance. Always try and look for hidden strengths and weaknesses based on the most recent games or data. \\n\\nEach html file has multiple charts to extract. Pay attention to this and focus on the charts only.\"\\n\\nThis is my custom output for analyzing sports stats. I save whole webpages and upload them.```.\\n\\nIn ideas-and-feedback, at 2023-10-28 16:29:16 a user named trtfx1 said ```its going to be used with it though eventually```.\\n\\nIn ideas-and-feedback, at 2023-10-28 16:29:04 a user named trtfx1 said ```can I post not autogen stuff in here?```.\\n\\nIn ideas-and-feedback, at 2023-10-28 10:11:39 a user named xvarunx said ```Please do something so I can talk my whole code base, and then when GPT has a recommendation, it directly pastes it back in the line or the fiction instead of writing the entire thing again```.\\n\\nIn ideas-and-feedback, at 2023-10-27 21:54:49 a user named c_bonadio said ```Autogen with FastApi backend and React frontend\\nhttps://github.com/bonadio/autogenwebdemo```.\\n\\nIn ideas-and-feedback, at 2023-10-27 20:04:43 a user named cpro1947 said ```personal automation with small bots```.\\n\\nIn ideas-and-feedback, at 2023-10-27 19:55:34 a user named hahl9000 said ```PLZ! Need some help finding the correct approach for agent with RAG capabilities from files or db in a mix of non-RAG agents that can run code and output files for eg. Excel. I’ve seen the code for rag agents but how do I implement reading from data? Does anyone have code for this? I’m also wondering if someone have a use-case for autogen controlling applications on computer? \\n\\nHave an awesome weekend folks! 🎃```.\\n\\nIn ideas-and-feedback, at 2023-10-27 19:41:53 a user named mudit.b07 said ```Multi-agent bots for the flights issue reduction```.\\n\\nIn ideas-and-feedback, at 2023-10-27 18:57:33 a user named telepathyx said ```https://github.com/THUDM/AgentTuning this looks promising to counteract the rumored anti-agentic passive behavior trained into openai models```.\\n\\nIn ideas-and-feedback, at 2023-10-27 17:20:44 a user named das_search said ```Wip agent and project generation using auto gen templates and gpt 4 as main logic after parsing```.\\n\\nIn ideas-and-feedback, at 2023-10-27 17:19:09 a user named das_search said ```I absolutely love llm and autogen \\nSo I started a Lil quick project on my lunch break```.\\n\\nIn ideas-and-feedback, at 2023-10-27 17:17:11 a user named das_search said ```https://github.com/Nbtguyoriginal/Pybonce```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:15:20 a user named frank.martinez said ```Here’s @biggboii. video on MemGPT; believe he has a repo in the details https://youtu.be/QCdQe8CdWV0?si=iXgm-gs6hN7O4vuG```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:12:27 a user named trtfx1 said ```I’ll educate myself more on nfl side. Someone just mentioned they are slowly using ai more for plays.```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:11:40 a user named trtfx1 said ```I don’t think it’s as good. I’ve just tested it out a few times with open source stats. There is a comprehensive amount, but I hear nfl has more.```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:09:28 a user named ctrl_alt.defeat said ```cant find this repo on github \\npyreader\\n\\ncan you please share it with me? @das_search```.', '\\nIn general, at 2023-10-02 06:48:13 a user named aayushc1308 said ```Hey everyone,\\nI\\'m Aayush (Founder, CEO of a startup called Kniru https://kniru.com). Kudos to all the great work happening here. Looking forward to participating as AutoGen evolves.```.\\n\\nIn general, at 2023-10-02 06:44:50 a user named pradeep1148 said ```https://www.youtube.com/watch?v=w6hhnVa68yE&ab_channel=DLExplorers made this video from this notebook. thanks for the contribution```.\\n\\nIn general, at 2023-10-02 06:44:34 a user named pradeep1148 said ```https://colab.research.google.com/gist/ElliotWood/af12566db5d6948e8ed6dd6324aa9697/autogen-langchain.ipynb#scrollTo=r7PFvDS7Ev-E```.\\n\\nIn general, at 2023-10-02 05:34:02 a user named kajatta said ```You\\'re welcome - hit me up if you need something else```.\\n\\nIn general, at 2023-10-02 03:35:03 a user named devegavc_83455 said ```I see it on github```.\\n\\nIn general, at 2023-10-02 03:33:32 a user named ondaje said ```Oh heck yeah. Thank you so much. This looks perfect and much simpler than a full reimplementation.\\n\\nMy pipelines have wrappers for langchain tooling and I have stuff that does the fastapi server as well, plus a way to prompt it, I just need to expose an async run function ultimately, so this looks perfect.```.\\n\\nIn general, at 2023-10-02 03:28:45 a user named __erice__ said ```@ondaje looks like you\\'re in here too 😏 lol.. what do you think about this approach?```.\\n\\nIn general, at 2023-10-02 02:37:15 a user named tawnniee said ```thanks @qingyunwu this was what i needed, am browsing now!```.\\n\\nIn general, at 2023-10-02 02:29:42 a user named qingyunwu said ```Yes, of course. This is an example. https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.\\n\\nIn general, at 2023-10-02 02:28:42 a user named tawnniee said ```hey what\\'s up friends, am playing around with autogen now, does anyone have a link to the docs on how to use it to browse the web?```.\\n\\nIn general, at 2023-10-02 02:25:27 a user named mizerati1313 said ```I sent something to htb bot commands as well```.\\n\\nIn general, at 2023-10-02 02:23:58 a user named mizerati1313 said ```I wanted to do a smoke test on something```.\\n\\nIn general, at 2023-10-02 02:23:36 a user named qingyunwu said ```Thanks! Is this related to AutoGen?```.\\n\\nIn general, at 2023-10-02 02:23:13 a user named mizerati1313 said ```I joined the voice connected```.\\n\\nIn general, at 2023-10-02 02:22:23 a user named mysticaldiscofrog said ```I did, to the point that I deleted all the reference to gpt-4 in my code. I thought maybe it was somewhere in autogen itself. \\n\\nThank you, I will work with this example you provided.```.\\n\\nIn general, at 2023-10-02 02:20:06 a user named mizerati1313 said ```I have something to share!```.\\n\\nIn general, at 2023-10-02 02:20:05 a user named qingyunwu said ```This is an example using GPT-3.5-turbo: https://github.com/qingyun-wu/autogen-eval/blob/main/application/A2-retrieval-augmented-chat/NaturalQuestionsQA-gpt35turbo.ipynb```.\\n\\nIn general, at 2023-10-02 02:19:40 a user named qingyunwu said ```Did you try setting the model field to \"gpt-3.5-turbo\" in `config_list` fileld of the  llm_config?```.\\n\\nIn general, at 2023-10-02 02:05:40 a user named mysticaldiscofrog said ```Does anyone know where to shift the calls from gpt-4 to gpt-3.5-turbo? The tests I am doing do not need gpt-4 right now but I have changed everything I can find and the billing keeps going up got 4 and staying the same for 3.5. Thank you.```.\\n\\nIn general, at 2023-10-02 01:56:05 a user named Drogend said ```Might sound stupid, but how? I tried and it reverts back to .txt```.\\n\\nIn general, at 2023-10-02 00:53:10 a user named andyinater said ```Beautiful. I plan on having my own workforce in the basement closet 😛```.\\n\\nIn general, at 2023-10-02 00:42:10 a user named fxtoofaan said ```doing about 18 tokens / second.```.\\n\\nIn general, at 2023-10-02 00:40:23 a user named fxtoofaan said ```then I ran the python script (city_planner.py) attached as my first request to Plan a week long trip to Dallas Texas. Include a table of dates and activity.\\n\\nand bam this is what happened. \\n\\n13B parameter loaded in my 12GB GPU no problems. \\n\\nso I\\'ve got a potential virtual army that I can run 100% offline if I want to that costs me $0 going forward forever for under a grand 🙂\\n\\nneed to keep adding features to autogen. keep going 🙂 \\n\\npower of Nvidia, llama-2 13B model, TheBloke\\'s AWQ model, docker, vLLM, Python and ofcourse autogen```.\\n\\nIn general, at 2023-10-02 00:40:08 a user named fxtoofaan said ```ok so check this out 🙂\\n\\nI bought an old used Nvidia A2000 GPU with 12GB VRAM. I installed it in my old dell optiplex sff pc with i7, 32GB Ram and 256GB SSD Drive, all from ebay for no less than 600 UK Pounds GBP. \\n\\nwith all hardware in, I loaded the machine with Ubuntu 22.04.3 LTS on a bootable USB stick. from there I installed Ubuntu 22.04.3 LTS on the computer\\'s internal SSD. Now pc boots into ubuntu and its a beautiful interface. I installed a bunch of updates and services using various commands, i cannot remember the order but I remember running these commands to get things working. \\n\\nsudo apt update\\nsudo apt install snapd\\nsudo snap install nvtop\\nhttps://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html\\nsudo pip3 install lfs --break-system-packages\\ngit clone https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ\\nsudo pip3 install git+https://github.com/huggingface/transformers.git@72958fcd3c98a7afdc61f953aa58c544ebda2f79 --break-system-packages\\nsudo pip3 install git+https://github.com/casper-hansen/AutoAWQ.git@1c5ccc791fa2cb0697db3b4070df1813f1736208 --break-system-packages\\n\\nthen I loaded the model of my choice and a docker image...\\n\\ndocker run --gpus all \\\\\\n    -p 8000:8000 \\\\\\n    -v /home/aitoofaan/LLMs/models/Llama-2-13B-chat-AWQ:/mnt/model/ \\\\\\n     ghcr.io/mistralai/mistral-src/vllm:latest \\\\\\n    --host 0.0.0.0 \\\\\\n    --model=\"/mnt/model/\" \\\\\\n     --quantization awq\\n\\nsudo pip3  install pyautogen --break-system-packages```.\\n\\nIn general, at 2023-10-02 00:37:29 a user named slayerdeebo said ```The api key should be like : open_ai_key = ‘your_key’```.\\n\\nIn general, at 2023-10-02 00:12:09 a user named fxtoofaan said ```@sonichi when will the following be updated? mistral-src/vllm . It was last updated 2 days ago. I think they added some new LLM\\'s to the vllm server and wondering if we can get the latest changes in this repository please 🙂```.\\n\\nIn general, at 2023-10-01 21:59:57 a user named iamhere said ```I keep getttin this error, but I have the keys in OAI_CONFIG_LIST.txt Any suggestions?```.\\n\\nIn general, at 2023-10-01 21:45:09 a user named tonic_1 said ```join the discord, join us on github (send me your username) , join us on hugging face and let\\'s get started making super cool stuff```.\\n\\nIn general, at 2023-10-01 21:42:11 a user named fragrancefreak said ```Just discovered autogen I\\'m really interested in using it and helping out maybe```.\\n\\nIn general, at 2023-10-01 21:30:27 a user named iamhere said ```What can I do to help?```.\\n\\nIn general, at 2023-10-01 20:53:59 a user named sonichi said ```sonichi is there currently a way for a```.\\n\\nIn general, at 2023-10-01 20:32:23 a user named epicrookie_ said ```Hey, does anyone know if Semantic Kernel will have a feature to invoke Autogen?```.\\n\\nIn general, at 2023-10-01 20:32:13 a user named kosiarn said ```does it work similarly to ensemble learning?```.\\n\\nIn general, at 2023-10-01 20:31:41 a user named kosiarn said ```hi, I saw a video about autogen on youtube and got interested```.\\n\\nIn general, at 2023-10-01 20:26:21 a user named andyinater said ```.... it is utterly surreal to experience being legitimately problem solving in code and natural language. I am constantly amazed and excited. Good job again MS guys - absolutely revolutionary.```.\\n\\nIn general, at 2023-10-01 20:22:45 a user named andyinater said ```And also allow resumption of a project after closing all chats. Leave enough, and the right, breadcrumbs such that everyone can pick up where they left off.```.\\n\\nIn general, at 2023-10-01 20:22:10 a user named andyinater said ```I want to post it, but it takes time to format a nice repo to explain all the moving parts. So I am working on integrating a semi-hard-coded versioning system for code iterations. The goal is to minimize the context windows of every chat down to only what is necessary.```.\\n\\nIn general, at 2023-10-01 20:21:11 a user named andyinater said ```Lol exactlyyyy. Despite the capabilites of the LLMs and autogen, there  is still a higher level of granularity required in setting up agents and chats than we might have hoped for. But it is just a learning curve.\\n\\nI have already started seeing huge improvements in code generation by breaking up the steps and manually controlling the group chat in a logical order. The programming test case I\\'ve been using, that seems to fail in the autogen examples (running on 3.5 turbo), is \"write a python program that displays the current time on an analog clock face\". Through the examples, it would definitely get something. But it was rough, and particularly the arm positions were always inaccurate/wrong. Through the flow I\\'m running now it gets it absolutely every time. The MS paint they produce is quite good too, and other generic asks have done well.```.\\n\\nIn general, at 2023-10-01 20:18:08 a user named __orderandchaos said ```Have had a good laugh at a few projects derail this way, little too close to home haha```.\\n\\nIn general, at 2023-10-01 20:17:08 a user named __orderandchaos said ```\"A bad manager can ruin the entire team\\'s efforts\" so we\\'ve already reached human level capabilities in ai```.\\n\\nIn general, at 2023-10-01 20:04:30 a user named __orderandchaos said ```I\\'m looking for a way to have the next run read the existing file structure, requirements.txt/poetry and any code files to get an overview of the existing stack. \\n\\nThen plan out the prompt request and add new files or replace existing ones```.\\n\\nIn general, at 2023-10-01 19:30:31 a user named 0xjamp said ```I keep getting a rate limit error on my openapi when running the multi agent group chat```.']], 'uris': None, 'data': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChroma_RAG_Assistant\u001b[0m (to user_proxy):\n",
      "\n",
      "AutoGen appears to be an open-source project associated with Microsoft, designed for working with machine learning models, notably large language models (LLMs). It offers a framework that can help users build applications leveraging these models. Moreover, the project supports the creation of complex applications, such as multi-agent systems, and enables users to manage the dialogue flow in such systems. There are resources like tutorials, documentation, and GitHub repositories for users to learn how to use AutoGen, as indicated in user discussions and references to official AutoGen information sources.\n",
      "\n",
      "For additional information and official documentation, you may refer to the GitHub page at https://github.com/microsoft/autogen or the documentation site at https://microsoft.github.io/autogen/.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATE AGENTS\n",
    "\n",
    "sql_assistant = GPTAssistantAgent(\n",
    "    name=\"Chroma_RAG_Assistant\",\n",
    "    instructions=RAG_ASSISTANT_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "sql_assistant.register_function(\n",
    "    function_map={\n",
    "        \"query_vector_db\": chroma_db_manager.query_db,\n",
    "        \"get_context\": chroma_db_manager.get_context   \n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3\n",
    ")\n",
    "\n",
    "initial_message = \"What is Autogen?\"\n",
    "user_proxy.initiate_chat(sql_assistant, message=initial_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Chroma_RAG_Assistant):\n",
      "\n",
      "Explain what the config_list is?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION query_vector_db...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agentchat.contrib.gpt_assistant_agent:Intermediate executing(query_vector_db, Sucess: True) : {'ids': [['doc_147', 'doc_121', 'doc_112', 'doc_126', 'doc_134', 'doc_17', 'doc_5', 'doc_76', 'doc_43', 'doc_55']], 'distances': [[0.5220403791312935, 0.5548239942504392, 0.5996779900457571, 0.65499586374803, 0.6581914901371664, 0.7117836475372314, 0.711988627910614, 0.7250232696533203, 0.7343909740447998, 0.7462843656539917]], 'metadatas': [[None, None, None, None, None, None, None, None, None, None]], 'embeddings': None, 'documents': [['\\nconfig_list = autogen.config_list_from_json(\\n    \"OAI_CONFIG_LIST\",\\n    filter_dict={\\n        \"model\": [\"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\\n    },\\n)\\n\\nllm_config={\\n    \"request_timeout\": 600,\\n    \"seed\": 42,\\n    \"config_list\": config_list,\\n    \"temperature\": 0,\\n}```.\\n\\nIn dev-contributors, at 2023-10-02 11:32:29 a user named vincentjedi said ```Back to basic,  how are all the py files under the autogen directory used by the agent? For example, in the Jupiter notebook, I dont see any code calling any functions specifically.```.\\n\\nIn dev-contributors, at 2023-10-02 11:29:41 a user named li_jiang said ```what do you mean by “parse py file”? For existing agents, we’ve defined some methods/functions for them. For customized new agents, you can define any function for them.```.\\n\\nIn dev-contributors, at 2023-10-02 10:17:58 a user named vincentjedi said ```Does it mean that before using autogen, each agent will be given several py files to use for each task ? How does each agent know what  each py file does if there are many py files to choose from? Each agent will just parse each py file  and make an educated guess ?```.\\n\\nIn dev-contributors, at 2023-10-02 01:42:26 a user named li_jiang said ```Yes. For which function to call, it is predefined in the __init__ function of the agent```.\\n\\nIn dev-contributors, at 2023-10-01 20:25:54 a user named aaronward_ said ```I submitted a PR: https://github.com/microsoft/autogen/pull/68```.\\n\\nIn dev-contributors, at 2023-10-01 19:37:25 a user named aaronward_ said ```this is a good call out out, i guess we could add an option like extraction_method = \\'naive\\' or \\'complex\\' calling the different pdf extraction functions, Giving users more control.```.\\n\\nIn dev-contributors, at 2023-10-01 18:46:06 a user named aaronward_ said ```And happy to help 🙂```.\\n\\nIn dev-contributors, at 2023-10-01 18:43:55 a user named aaronward_ said ```Hey guys - I\\'ve written a util that allows you to set your `config_list` using a `.env` file - i think this would be useful for those, like myself, who want to keep all their api keys in one central location, not just OpenAI keys. Will i submit a PR?```.\\n\\nIn dev-contributors, at 2023-10-01 15:11:17 a user named vincentjedi said ```So if I ask the agent to parse the pdf saved in the directory, it will just call the py file automatically and extract the data from the pdf file ? How does the agent know which py file to call into for each specific task ?```.\\n\\nIn dev-contributors, at 2023-10-01 15:04:21 a user named sonichi said ```Thanks for the interest for contribution. Could you read the contribute guide? https://microsoft.github.io/autogen/docs/Contribute```.\\n\\nIn dev-contributors, at 2023-10-01 14:47:30 a user named bhushan9249 said ```Hi, I\\'m new here. can anyone tell me how can i start contribute?```.\\n\\nIn dev-contributors, at 2023-10-01 14:42:27 a user named vincentjedi said ```How about using multimodal llm like \\'llava\\' so that autogen can ingest image and text directly ?```.\\n\\nIn dev-contributors, at 2023-10-01 14:40:00 a user named vincentjedi said ```Also can autogen go to scrap websites for text and number ? What if the website is rendered using JavaScript? Does it need to use puppeteer or selenium in order to see the content of the site ?```.\\n\\nIn dev-contributors, at 2023-10-01 14:39:11 a user named Adityaaaa said ```Hi, I\\'m new here. can anyone tell me how can i start contribute?```.\\n\\nIn dev-contributors, at 2023-10-01 14:27:29 a user named li_jiang said ```We can register different functions to an agent\\'s `generate_reply` function, all the customized functions are injected by this way.```.\\n\\nIn dev-contributors, at 2023-10-01 14:23:44 a user named vincentjedi said ```This is still very confusing to me how autogen can initiate all different functions...```.\\n\\nIn dev-contributors, at 2023-10-01 14:22:33 a user named vincentjedi said ```I am still learning how autogen works```.\\n\\nIn dev-contributors, at 2023-10-01 14:22:25 a user named vincentjedi said ```By the way , how does autogen call into your py file to use your parser?```.\\n\\nIn dev-contributors, at 2023-10-01 14:21:35 a user named li_jiang said ```We\\'re encouraging PRs from the community, it would be great if you\\'d raise a PR for the new solution. I guess we can keep both pypdf and pypdfium2&pytesseract.```.\\n\\nIn dev-contributors, at 2023-10-01 14:19:07 a user named vincentjedi said ```Just want to share with you my own findings in this particular topic```.\\n\\nIn dev-contributors, at 2023-10-01 14:18:13 a user named vincentjedi said ```I haven\\'t tried it out. But I happen to know that bing chat isn\\'t very at extracting info from pdf files with tons of chart as I was looking into the latest research paper in liquid neurons. So I assume their stack may not read pdf files with accuracy ..```.\\n\\nIn dev-contributors, at 2023-10-01 14:15:48 a user named vincentjedi said ```I know. I hope I am not confusing the situation```.\\n\\nIn dev-contributors, at 2023-10-01 14:15:48 a user named li_jiang said ```Do you encountered issue with pypdf?```.\\n\\nIn dev-contributors, at 2023-10-01 14:15:07 a user named li_jiang said ```To make clarification to the parser and LLM model selection, the `num_tokens_from_text` comes after text extraction, it\\'s a different topic from pypdf and pypdfium2&pytesseract.```.\\n\\nIn dev-contributors, at 2023-10-01 14:13:40 a user named vincentjedi said ```Do you think u could adopt some of his codes and try it out ?```.\\n\\nIn dev-contributors, at 2023-10-01 14:12:28 a user named li_jiang said ```Very interesting solution. It definitely worth trying.```.\\n\\nIn dev-contributors, at 2023-10-01 14:09:48 a user named vincentjedi said ```Since his approach is designed to extract number instead of text, pypdf could be slightly more accurate in text recognition if the PDF file is simple with mostly text.```.\\n\\nIn dev-contributors, at 2023-10-01 14:06:23 a user named vincentjedi said ```This is his explanation for not using pypdf```.\\n\\nIn dev-contributors, at 2023-10-01 14:05:59 a user named vincentjedi said ```https://youtu.be/v_cfORExneQ?si=YjSCACtWFPI1H_aI```.\\n\\nIn dev-contributors, at 2023-10-01 14:05:28 a user named vincentjedi said ```I just happened to come across this because he found that pypdf is far from perfect in extracting more complex pdf files with scanned images. Hence he claimed his approach is superior```.\\n\\nIn dev-contributors, at 2023-10-01 14:03:14 a user named vincentjedi said ```https://github.com/JayZeeDesign/gpt-data-extraction/blob/main/app.py```.\\n\\nIn dev-contributors, at 2023-10-01 13:48:08 a user named vincentjedi said ```Have you heard of using pypdfium2 And pytesseract combined instead of using pypdf alone?```.\\n\\nIn dev-contributors, at 2023-10-01 13:40:37 a user named li_jiang said ```I guess it would be good to add those you\\'d like to use.```.\\n\\nIn dev-contributors, at 2023-10-01 13:38:24 a user named vincentjedi said ```There are so many models in the market ... how do you decide which ones to add ?```.\\n\\nIn dev-contributors, at 2023-10-01 13:37:06 a user named li_jiang said ```Ah, this is for computing the number of tokens of a given text string. I see what you mean. We need to add support to different model to the function `num_tokens_from_text`. Would you like to make a PR?```.\\n\\nIn dev-contributors, at 2023-10-01 13:28:29 a user named vincentjedi said ```Just wonder what these codes are designed  for ?```.\\n\\nIn dev-contributors, at 2023-10-01 13:27:24 a user named vincentjedi said ```if model in {\\n        \"gpt-3.5-turbo-0613\",\\n        \"gpt-3.5-turbo-16k-0613\",\\n        \"gpt-4-0314\",\\n        \"gpt-4-32k-0314\",\\n        \"gpt-4-0613\",\\n        \"gpt-4-32k-0613\",\\n    }:```.\\n\\nIn dev-contributors, at 2023-10-01 13:22:43 a user named li_jiang said ```The parser is not LLM-related, so it will work with any llm models.```.\\n\\nIn dev-contributors, at 2023-10-01 13:03:31 a user named vincentjedi said ```Does the parser only work with openai models? How about llama2 or other local llm?```.\\n\\nIn dev-contributors, at 2023-10-01 12:21:06 a user named sonichi said ```Is the contributor on discord?```.\\n\\nIn dev-contributors, at 2023-10-01 12:20:44 a user named sonichi said ```And we should acknowledge the contributor!```.\\n\\nIn dev-contributors, at 2023-10-01 12:20:17 a user named sonichi said ```So we can talk with PDFs now? That\\'s a feature worth highlighting!```.\\n\\nIn dev-contributors, at 2023-10-01 12:12:36 a user named li_jiang said ```Add a parser to extract text from PDF files and fix a bug of collection creation.```.\\n\\nIn dev-contributors, at 2023-10-01 11:44:50 a user named sonichi said ```@li_jiang could you briefly summarize the contribution of https://github.com/microsoft/autogen/pull/50 ?```.\\n\\nIn dev-contributors, at 2023-10-01 11:44:09 a user named sonichi said ```Let\\'s onboard new contributors and share updates in this channel.```.\\n\\nIn dev-contributors, at 2023-10-01 11:38:54 a user named sonichi said ```This channel is created for developers & contributors to communicate. Welcome to all!```.\\n\\nIn created-with-autogen, at 2023-11-14 21:20:31 a user named generadorprueba said ```<#1157447399044821132> maestro de historia Argentina```.', '\\nconfig_list = autogen.config_list_from_json(\\n    env_or_file = \"OAI_CONFIG_LIST.json\",\\n    file_location = \"./\",\\n    filter_dict = {\"model\": {\\n        \"gpt-3.5-turbo\",\\n    }}\\n)\\n\\nassistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": config_list})\\nuser_proxy = UserProxyAgent(\"user_proxy\")\\nuser_proxy.initiate_chat(assistant, message=\"What is 1+1?\") \\n```\\n\\nNeato```.\\n\\nIn general, at 2023-09-28 14:11:10 a user named sonichi said ```maybe you had an environment variable OAI_CONFIG_LIST which is loaded before it tries to load the file. Changing the filename solved that.```.\\n\\nIn general, at 2023-10-11 13:11:44 a user named alexzander8376 said ```I haven\\'t quite understood.\\nHow do I get my code to use 3.5 turbo?\\nHere it is:\\n\\n```from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\\nimport openai\\n\\nopenai.api_key = \\'\\'\\n\\n# Load LLM inference endpoints from an env variable or a file\\n# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints\\n# and OAI_CONFIG_LIST_sample\\n\\nconfig_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")\\nassistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": config_list})\\nuser_proxy = UserProxyAgent(\"user_proxy\", code_execution_config={\"work_dir\": \"coding\"})\\n\\nuser_proxy.initiate_chat(assistant, message=\"\")\\n\\n# This initiates an automated chat between the two agents to solve the task``````.\\n\\nIn general, at 2023-10-11 13:46:28 a user named sonichi said ```make sure `config_list` contains a list of dicts, each dict containing `\"model\": \"gpt-3.5-turbo\" ````.\\n\\nIn general, at 2023-09-28 01:25:05 a user named you.wish said ```push ups dont train my chest at all 😭\\nsorry for not accepting your friendship```.\\n\\nIn general, at 2023-09-28 01:24:43 a user named tonic_1 said ```the coding utils alone are worth it imho ^^```.\\n\\nIn general, at 2023-09-28 01:19:36 a user named merkle said ```it seems to have a similar theme for sure. might be that autogen allows for more flexible structures and setups? i havent looked into chatdev enough to know the ins and outs but it seems a bit more rigid in the setup. could be wrong.```.\\n\\nIn general, at 2023-09-28 00:43:36 a user named tonic_1 said ```plugin for scrivener... i\\'ll be afk```.\\n\\nIn general, at 2023-09-28 00:43:19 a user named you.wish said ```plugin for an llm agent? but autogen is already that?```.\\n\\nIn general, at 2023-09-28 00:42:44 a user named tonic_1 said ```you could build a plugin for a series of agents that interact to give you real time information and suggestions as you play Scrivener for example... hope this helps 👊🏻```.\\n\\nIn general, at 2023-09-28 00:37:41 a user named you.wish said ```i meant what you do with it```.\\n\\nIn general, at 2023-09-28 00:37:26 a user named tonic_1 said ```single or multi agent environments that work together or compete to achieve an objective```.\\n\\nIn general, at 2023-09-28 00:21:37 a user named you.wish said ```what do people do with autogen?```.\\n\\nIn general, at 2023-09-27 23:32:40 a user named nathan.lannan said ```Anyone able to get this doing anything useful yet? \\n\\nI know Agent are the future, have been for a hot minute, but also, have you seen Agents do more then spin their wheels eating tokens?```.\\n\\nIn general, at 2023-09-27 22:46:53 a user named bansalg said ```is this a question about how to switch models? https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.\\n\\nIn general, at 2023-09-27 22:23:36 a user named merkle said ```not sure if anyone already asked this but are we able to use turbo instead of gpt4?```.\\n\\nIn general, at 2023-09-27 21:48:33 a user named tonic_1 said ```hi there folks, Tonic here, just a builder from France/USA currently in Paris. I use azure services quite a lot especially now that i\\'m building systems for my enterprise and business apps for the public. I have an accidental and lively  🛠️build-in-public server too - 👊🏻 link in bio - happy to be here 🚀```.\\n\\nIn general, at 2023-09-27 19:57:34 a user named thepositionofbread said ```microsoft is known to make unopinioned tooling (or half-finished if you will), so it\\'ll be reusable in different scenarios they hadn\\'t thought of. At least that\\'s how it goes for a lot of the C#/dotnet stuff```.\\n\\nIn general, at 2023-09-27 19:56:32 a user named egalitaristen said ```Look, all I\\'m saying is that every single one of these Autonomous Agent projects that I\\'ve looked at and tried (basically all of them) have had some form quickstart which didn\\'t require more than a few simple cmd lines at most. But for this one, made by one of the biggest companies in the world, I have to actually code (or copy/paste code)```.\\n\\nIn general, at 2023-09-27 19:57:36 a user named unicorn1997 said ```im curious, what other agent projects have you tried? do you mean completely no-code things, like Superagent?```.\\n\\nIn general, at 2023-09-27 20:02:42 a user named egalitaristen said ```So, I started with AutoGPT. Then, some of the Autonymous Agents that I tried (off the top of my head) have been\\n\\n* SmartGPT\\n* SuperAGI\\n* BabyAGI\\n* GPTengineer\\n* Aider\\n* ChatDev\\n* OpenIntrepreter\\n* MicroGPT```.\\n\\nIn general, at 2023-09-27 20:03:37 a user named egalitaristen said ```There are plenty of others but yeah, the gist is that they require very little or no coding for a *user* to get started```.\\n\\nIn general, at 2023-09-27 20:04:10 a user named thepositionofbread said ```this is a different offering than that, really```.\\n\\nIn general, at 2023-09-27 20:04:21 a user named egalitaristen said ```Yeah, I\\'m starting to get that```.\\n\\nIn general, at 2023-09-27 20:04:45 a user named egalitaristen said ```Just the hype I guess```.\\n\\nIn general, at 2023-09-27 20:04:50 a user named thepositionofbread said ```probably someone will make a plug and play solution build on top of this. It\\'ll be interesting to see how it plays out.```.\\n\\nIn general, at 2023-09-27 20:05:11 a user named egalitaristen said ```Yeah, they\\'ll start coming next week```.\\n\\nIn general, at 2023-09-27 20:07:05 a user named egalitaristen said ```I should have been more attentive to the \"AutoGen is a framework...\" part right at the start```.\\n\\nIn general, at 2023-09-27 20:07:24 a user named egalitaristen said ```It\\'s just that I got distracted by the nice pictures```.\\n\\nIn general, at 2023-09-27 20:08:26 a user named thepositionofbread said ```lmao, yes, it\\'s easy to get carried along.```.\\n\\nIn general, at 2023-09-27 20:15:13 a user named unicorn1997 said ```agree.. for me, the term \"framework\" is a bit ambiguous, since you can use it on variety of products.\\ntbh for me some of the no-code platforms didnt work that well, so i perceive that as a tradeoff in some sense```.\\n\\nIn general, at 2023-09-27 20:24:57 a user named egalitaristen said ```Yeah, most of the no-code platforms don\\'t work great tbh. But they do work most/some of the time for users that have 0 experience with coding.```.\\n\\nIn general, at 2023-09-27 20:26:10 a user named egalitaristen said ```It\\'ll be interesting to see if AutoGen actually results in anything that other\\'s haven\\'t already done or if it\\'ll just end up being used with no-code stuff that works somewhat some of the time```.\\n\\nIn general, at 2023-09-27 20:27:58 a user named unicorn1997 said ```not sure what pain points they are trying to solve.\\nbut the inter-agent communication is big topic imo, I havent came accross similar products on that in particular.\\nalso, it is stack agnostic, as opposed to some of the easier frameworks. you have more freedom, but more difficulty running it, fair tradeoff```.\\n\\nIn general, at 2023-09-27 20:29:47 a user named egalitaristen said ```There are plenty of inter-agent communication stuff. The hottest one this week is ChatDev```.\\n\\nIn general, at 2023-09-27 20:30:01 a user named egalitaristen said ```https://github.com/OpenBMB/ChatDev```.\\n\\nIn general, at 2023-09-27 20:31:27 a user named egalitaristen said ```I\\'m afraid that I don\\'t know what stack-agnosic means, but I\\'ll take your word for it```.\\n\\nIn general, at 2023-09-27 20:58:10 a user named unicorn1997 said ```i meant that it doesnt limit you in what tech you should use and what approach you should take```.', '\\n# Construct the llm_config\\nllm_config = {\\n  \"functions\":[\\n      #generate_llm_config(custom_tool), # ERROR: this one fails becuase - Invalid schema for function \\'circumference_calculator\\': \\'float\\' is not valid under any of the given schemas\\n      generate_llm_config(read_file_tool),\\n  ],\\n  \"config_list\": config_list,  # Assuming you have this defined elsewhere\\n  \"request_timeout\": 120,\\n}\\nuser_proxy.register_function(\\n    function_map={\\n        #custom_tool.name: custom_tool._run,  # ERROR: this one fails becuase - Invalid schema for function \\'circumference_calculator\\': \\'float\\' is not valid under any of the given schemas\\n        read_file_tool.name: read_file_tool._run,\\n    }\\n)\\n``````.\\n\\nIn general, at 2023-09-30 13:43:17 a user named vincentjedi said ```Have u chosen which llm are used for different agents?```.\\n\\nIn general, at 2023-09-30 13:41:00 a user named tonic_1 said ```hope you\\'re happy been driving me nuts for 15 minutes```.\\n\\nIn general, at 2023-09-30 13:40:51 a user named tonic_1 said ```i\\'m honestly stuck on (from flaml import autogen) on that notebook ^^```.\\n\\nIn general, at 2023-09-30 13:40:28 a user named tonic_1 said ```for function calling you mean?```.\\n\\nIn general, at 2023-09-30 13:38:26 a user named .princeps said ```@tonic_1 you should know this too```.\\n\\nIn general, at 2023-09-30 13:37:01 a user named .princeps said ```the reason I was on this is so that I can get a small marketing team going and so I needed to have a tool agent and an internet agent```.\\n\\nIn general, at 2023-09-30 13:36:30 a user named .princeps said ```Well it has internet access and you can also make it work with function calling so I think you can setup external tools use```.\\n\\nIn general, at 2023-09-30 13:36:15 a user named fxtoofaan said ```Thank you. My fresh Ubuntu just booted up. Let me set it up```.\\n\\nIn general, at 2023-09-30 13:35:50 a user named .princeps said ```here is a file for you```.\\n\\nIn general, at 2023-09-30 13:35:49 a user named fxtoofaan said ```So what does that mean now ? It can use any external tool ?```.\\n\\nIn general, at 2023-09-30 13:35:24 a user named .princeps said ```you just have to use the old library through `from flaml import autogen````.\\n\\nIn general, at 2023-09-30 13:34:55 a user named .princeps said ```@fxtoofaan I got it to work, I repeat, autogen agents have internet```.\\n\\nIn general, at 2023-09-30 13:21:22 a user named tonic_1 said ```I’ll give you access to it too```.\\n\\nIn general, at 2023-09-30 13:20:23 a user named felly007. said ```awesome, thanks. And joined 🙂```.\\n\\nIn general, at 2023-09-30 13:18:17 a user named tonic_1 said ```Hey there’s a GitHub yeah on @.princeps GitHub also there’s a hugging face org you can join and please do so actually```.\\n\\nIn general, at 2023-09-30 13:17:32 a user named felly007. said ```is there a github repo for this project?```.\\n\\nIn general, at 2023-09-30 13:15:15 a user named fxtoofaan said ```That’s good to know 👍```.\\n\\nIn general, at 2023-09-30 13:14:54 a user named .princeps said ```Can I just got it to call my function with Claude so I think we can setup function calling for other tools```.\\n\\nIn general, at 2023-09-30 13:14:18 a user named .princeps said ```we might still have it work with autogen, let me test the internet access through  `flaml import autogen````.\\n\\nIn general, at 2023-09-30 13:13:36 a user named fxtoofaan said ```Maybe operate it using telegram chat 🙂```.\\n\\nIn general, at 2023-09-30 13:13:12 a user named fxtoofaan said ```Anything else to add to that?```.\\n\\nIn general, at 2023-09-30 13:12:55 a user named fxtoofaan said ```User->execute python script->spawn agents that have access to internet, tools, knowledge base, local llm(s) and gptx, short and long term memory.```.\\n\\nIn general, at 2023-09-30 13:12:43 a user named tonic_1 said ```I’ll take a look at that notebook too yeah - I think @kajatta is on the right though … unfortunately```.\\n\\nIn general, at 2023-09-30 13:11:48 a user named .princeps said ```function calling works but you have to use ` flaml import autogen````.\\n\\nIn general, at 2023-09-30 13:10:25 a user named kajatta said ```Ill take a look at options```.\\n\\nIn general, at 2023-09-30 13:10:08 a user named tonic_1 said ```Seems very much necessary actually ?```.\\n\\nIn general, at 2023-09-30 13:10:05 a user named kajatta said ```Its really the Toolkits/tools that are valuable - everything else has parody```.\\n\\nIn general, at 2023-09-30 13:09:31 a user named kajatta said ```Or more appropriately the other way around```.\\n\\nIn general, at 2023-09-30 13:09:02 a user named kajatta said ```Effectively we want to do https://python.langchain.com/docs/use_cases/more/agents/agents/camel_role_playing but swap Camel out for Autogen```.\\n\\nIn general, at 2023-09-30 13:08:08 a user named cryptofekt said ```Anyone else thinking about 📎 ?```.\\n\\nIn general, at 2023-09-30 13:07:55 a user named fxtoofaan said ```Don’t forget some kind of local intellectual property knowledge or vector db. Maybe separate db for each agent ?```.\\n\\nIn general, at 2023-09-30 13:07:00 a user named tonic_1 said ```so yeah, seems useful ^^```.\\n\\nIn general, at 2023-09-30 13:06:54 a user named tonic_1 said ```nope... was totally wrong about that, my appologies```.\\n\\nIn general, at 2023-09-30 13:06:29 a user named tonic_1 said ```pretty sure there\\'s langchain / autogen , no ?```.\\n\\nIn general, at 2023-09-30 13:05:20 a user named fxtoofaan said ```I think vllm server has langchain capability or connections built n```.\\n\\nIn general, at 2023-09-30 13:04:50 a user named kajatta said ```We should write a toolchain bridge to Langchain so we can inherit 35+ tools/integrations```.\\n\\nIn general, at 2023-09-30 13:02:36 a user named tonic_1 said ```you can see it yourself and run it on your computer 👊🏻 it\\'s command line```.\\n\\nIn general, at 2023-09-30 13:02:09 a user named kajatta said ```Nice have you got screenshot of outputs?```.\\n\\nIn general, at 2023-09-30 12:55:19 a user named jasonzhou1993 said ```Hey team - what does \"messages=[]\" do for groupchat?```.\\n\\nIn general, at 2023-09-30 12:55:02 a user named .princeps said ```Have I setup up seomthing wrong ?```.\\n\\nIn general, at 2023-09-30 12:54:42 a user named .princeps said ```@tonic_1 or @sonichi does the web one work, I have been trying it but it\\'s retrieving information correctly```.\\n\\nIn general, at 2023-09-30 12:56:19 a user named .princeps said ```@tonic_1 I just want to setup an agent with internet so I want to see if you or someone else has got this working outside the notebook```.\\n\\nIn general, at 2023-09-30 12:56:42 a user named tonic_1 said ```i would use the serp tool in langchain for that```.\\n\\nIn general, at 2023-09-30 12:59:01 a user named .princeps said ```Yeah I can do it with langchain but  this notebook says that we can, and I did run it and it worked once but when I moved the agent to a new script it stopped working \\n\\nhttps://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.\\n\\nIn general, at 2023-09-30 13:02:13 a user named tonic_1 said ```i actually just tried the same notebook and it\\'s not importing autogen even, so ...```.\\n\\nIn general, at 2023-09-30 13:04:43 a user named .princeps said ```hmm maybe moving on autogen from flaml may  have caused some issues```.\\n\\nIn general, at 2023-09-30 13:04:57 a user named tonic_1 said ```ah hahahaha it\\'s totally that```.\\n\\nIn general, at 2023-09-30 13:05:24 a user named tonic_1 said ```how many times a month has this been happening the last ten months?? a million times maybe```.\\n\\nIn general, at 2023-09-30 13:12:40 a user named .princeps said ```@tonic_1 so seems like I was right, function calling works but only if you import it like this ` flaml import autogen````.\\n\\nIn general, at 2023-09-30 13:12:47 a user named .princeps said ```Let me test the internet```.\\n\\nIn general, at 2023-09-30 12:43:19 a user named vincentjedi said ```Anyone has tried out llama2 long yet ?```.\\n\\nIn general, at 2023-09-30 12:42:07 a user named vincentjedi said ```https://venturebeat.com/ai/meta-quietly-releases-llama-2-long-ai-that-outperforms-gpt-3-5-and-claude-2-on-some-tasks/```.\\n\\nIn general, at 2023-09-30 12:29:39 a user named tonic_1 said ```i threw up @.princeps tutorial here : https://huggingface.co/spaces/MultiTransformer/snake_by_princepspolycap if you\\'re making something you want to share we can host it in the community 🚀```.\\n\\nIn general, at 2023-09-30 12:12:20 a user named fxtoofaan said ```I think for now an os where I can setup fastest llm server that can serve any open source llm model and also support openai api. Then I’ll have a local llm server and use my MacBook to test front end apps like autogen```.', '\\n}\\nllm_config = {\"config_list\": config_list_gpt4, \"seed\": 42}\\nuser_proxy = autogen.UserProxyAgent(\\n    name=\"User_proxy\",\\n    system_message=\"A human admin.\",\\n    code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"groupchat\"},\\n    human_input_mode=\"TERMINATE\",\\n    function_map={\"create_ui_design\": create_ui_design},\\n)\\ncoder = autogen.AssistantAgent(\\n    name=\"Coder\",\\n    llm_config=llm_config,\\n)\\npm = autogen.AssistantAgent(\\n    name=\"Product_manager\",\\n    system_message=\"Creative in software product ideas.\",\\n    llm_config=llm_config\\n)\\nui_dev = autogen.UserProxyAgent(\\n    name=\"UI_designer\",\\n    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\\n    human_input_mode=\"TERMINATE\",\\n    max_consecutive_auto_reply=10,\\n\\n)\\nui_des = autogen.AssistantAgent(\\n    name=\"UI_developer\",\\n    llm_config=llm_config1,\\n    system_message=\"Execute only functions you have been provided. Reply TERMINATE when the task is done.\",\\n    max_consecutive_auto_reply=10\\n    )\\n\\ngroupchat = autogen.GroupChat(agents=[user_proxy, coder, pm, ui_des], messages=[], max_round=12)\\nmanager = autogen.GroupChatManager(\\n    groupchat=groupchat, \\n    llm_config=llm_config1\\n)```.\\n\\nIn general, at 2023-09-18 23:25:30 a user named sonichi said ```Could you create an issue? We only mentioned in the notebooks```.\\n\\nIn general, at 2023-09-18 20:30:18 a user named .beibinli said ```Can anyone provide an example of \"OAI_CONFIG_LIST\" file in documentation? It seems like we never mentioned what it is.```.\\n\\nIn announcements, at 2023-11-13 22:14:34 a user named sonichi said ```**new release: v0.2.0b5** https://github.com/microsoft/autogen/releases/tag/v0.2.0b5\\n🔥 Experimental [GPTAssistantAgent]( https://github.com/microsoft/autogen/blob/main/autogen/agentchat/contrib/gpt_assistant_agent.py), which leverages the OpenAI Assistant API for conversational capabilities in AutoGen. This agent is unique in its reliance on the OpenAI Assistant API for state management, differing from other agents using the Completion API.\\n- Blogpost: https://microsoft.github.io/autogen/blog/2023/11/13/OAI-assistants/\\n- Notebook 1: GPTAssistantAgent in a hello-world example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_twoagents_basic.ipynb\\n- Notebook 2: GPTAssistantAgent using function call: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_function_call.ipynb\\n- Notebook 3: GPTAssistantAgent with code interpreter: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_code_interpreter.ipynb\\n- Notebook 4: GPTAssistantAgent in a group chat: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_groupchat.ipynb\\n\\n🔥 Blogpost for [EcoAssistant](https://microsoft.github.io/autogen/blog/2023/11/09/EcoAssistant), which is designed to solve user queries more accurately and affordably using assistant hierarchy and solution demonstration.\\n\\nThanks to @ianthereal @bansalg @jiale_liu @kevinwyr @qingyunwu @jieyuzhang_uw and all the other contributors!```.\\n\\nIn announcements, at 2023-11-11 20:37:24 a user named sonichi said ```**new release: v0.2.0b4** https://github.com/microsoft/autogen/releases/tag/v0.2.0b4\\n## Highlights\\n\\n* **CompressibleAgent** (experimental) can be used to handle long conversations. Notebook: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_compression.ipynb\\n* Introducing Experimental **GPT Assistant Agent**: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/contrib/gpt_assistant_agent.py. More improvements are under way.\\n* Experimental **streaming** support is added.\\n* `seed` is renamed to `cache_seed` to be compatible with openai\\'s `seed` parameter in chat completion. Migration guide is updated: https://microsoft.github.io/autogen/docs/Installation/#migration-guide-to-v02\\n* Better warnings and error handling for group chat.\\n\\nThanks to @ianthereal @kevinwyr @Alvaromah and all the other contributors!```.\\n\\nIn announcements, at 2023-11-09 14:50:02 a user named sonichi said ```🆕 AutoGen is selected in Open100: Top 100 Open Source achievements 🏆 \\nhttps://www.benchcouncil.org/evaluation/opencs/annual.html```.\\n\\nIn announcements, at 2023-11-08 13:41:14 a user named sonichi said ```**new release: v0.2.0b3** https://github.com/microsoft/autogen/releases/tag/v0.2.0b3\\nA quick release to switch to openai-python v1.1.1.\\nThanks to @joshkyh for a new group chat notebook example with hierarchical flow: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_hierarchy_flow_using_select_speaker.ipynb```.\\n\\nIn announcements, at 2023-11-06 22:14:35 a user named sonichi said ```**new release: v0.2.0b2** https://github.com/microsoft/autogen/releases/tag/v0.2.0b2\\n## Highlights\\n* **Support for GPT-4V!** Introduced Large Multimodal Models in AgentChat, enhancing capabilities and interactions within the platform. Blogpost: https://microsoft.github.io/autogen/blog/2023/11/06/LMM-Agent\\n* Improved codebase reliability with updates such as dict copying before modifications (fixing a bug for Azure OpenAI) and various typo fixes.\\n* Added support for unstructured data in retrieve chat (RAG).\\n* Expanded functionality with async support for better `get_human_input` handling.\\n* A new simple Testbed tool for Autogen processes.\\n* Enhanced developer tools and documentation, including new README and TRANSPARENCY_FAQS updates.\\n\\nThanks to all the testers for the v0.2 migration. Thanks to @.beibinli @AkariLan @vatsalya-vyas @gfggithubleet @bansalg @li_jiang @hung-ngm @afourney @AaadityaG @jasondotparse @c_bonadio @aayushc1308 @qingyunwu @eltociear @marcgreen and other contributors!```.\\n\\nIn announcements, at 2023-11-04 04:53:46 a user named sonichi said ```**new release: v0.2.0b1** https://github.com/microsoft/autogen/releases/tag/v0.2.0b1\\n## Highlights\\n* Switching to openai v1. Please read the migration guide https://microsoft.github.io/autogen/docs/Installation/#migration-guide-to-v02 and report bugs.\\n* Support async function execution & get_human_input.\\n* Improvements in documentation and notebooks.\\n\\nThanks to all the reviewers for the v0.2 migration. Thanks to @aayushchhabra1999 @c_bonadio @marcgreen and other contributors!```.\\n\\nIn announcements, at 2023-10-30 22:02:42 a user named sonichi said ```AutoGen (http://aka.ms/autogen-gh) is the top trending repo on GitHub this month. I appreciate the huge interest, activities, and support from everyone in the community! \\U0001faf6\\n📖Paper: http://aka.ms/autogen-pdf\\nhttps://twitter.com/Chi_Wang_/status/1718339760278909321```.\\n\\nIn announcements, at 2023-10-28 01:17:38 a user named sonichi said ```Weekend **new release: v0.1.14** https://github.com/microsoft/autogen/releases/tag/v0.1.14\\n## Highlights\\n\\n- 👀Give vision to your agent: **multimodal** examples are added at https://github.com/microsoft/autogen/blob/main/notebook/agentchat_lmm_llava.ipynb.\\n- 📖**TeachableAgent** blogpost: https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent.\\n- 🧵 Run a chat in a different thread/process: using thread safe timeout for code execution.\\n- 🪶 Qdrant vector store: A QdrantRetrieveUserProxyAgent is added in contrib/.\\n- 🚦 Support new version of chromadb in retrieve chat.\\n- 🧮 Token count utils.\\n- 🐋 Improve vscode extension setup in codespace.\\n- 📝 Many improvements in documentation, FAQ, useful tips, such as\\n  - how to prevent gpt-3.5 agents\\' appreciation loop\\n  - fixes in the langchain notebook\\n  - link to the roadmap\\n  - common issues in retrieve chat\\n\\nThanks to @.beibinli @rickyloynd @ragyabraham @Anush008 @li_jiang @kevinwyr  @shruti222patel @craigomatic @aaronward_ and all the other contributors!\\n## Headsup\\n\\nv0.2 release is near the corner, and we\\'ll switch to openai v1 in it. Please check for breaking changes in https://github.com/microsoft/autogen/pull/393. We\\'ll try to add as many features back as possible before the release. If you see any breaking changes that affect your work, please comment in the PR thread.```.\\n\\nIn announcements, at 2023-10-21 17:01:35 a user named sonichi said ```**New release: v0.1.13** https://github.com/microsoft/autogen/releases/tag/v0.1.13\\n\\n## Highlights\\n\\nA preliminary `TeachableAgent` is added to allow users to teach their assistant facts, preferences, and tasks unrelated to code generation. Example notebook: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_teachability.ipynb', '\\nconfig_list = config_list_from_json(\\n    \"OAI_CONFIG_LIST\",\\n    filter_dict={\\n        \"model\": [\"mistral:instruct\"],\\n    },\\n)\\n```\\n4. Launch the ollama application (but you don\\'t need to run the model with an ollama command)\\n5. Launch the proxy server in a terminal window for your virtual environment with this: `litellm --model ollama/mistral:instruct --api_base http://localhost:11434````.\\n\\nIn forum-discussion, at 2023-10-10 20:20:12 a user named au8 said ```I\\'m hearing good things so far about this model: https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha```.\\n\\nIn forum-discussion, at 2023-10-10 16:10:07 a user named c_bonadio said ```Autogen interacting using FastApi (very basic)\\n\\nhttps://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af\\n\\nHi, \\nI create this code to enable a user using any web cliente to interact with Autogen, it communicates using FastApi websocket \\nit allows you to interact with the user_proxy at every step, not only at the end.```.\\n\\nIn forum-discussion, at 2023-10-10 16:06:40 a user named c_bonadio said ```Autogen interacting using FastApi (very basic)\\n\\nhttps://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af\\n\\nHi, \\nI create this code to enable a user using any web cliente to interact with Autogen, it communicates using FastApi websocket \\nit allows you to interact with the user_proxy at every step, not only at the end.```.\\n\\nIn forum-discussion, at 2023-10-10 15:00:37 a user named .princeps said ```@li_jiang can you help me understand why I get no doc _ids \\n\\n`PS C:\\\\Users\\\\Shadow\\\\Documents\\\\Repo\\\\PolyGPT\\\\specialized_agents> python eetriever_agent.py`\\n`models to use:  [\\'gpt-3.5-turbo\\', \\'gpt-4\\', \\'gpt-4-32k\\']`\\n`Accepted file formats for `docs_path`:`\\n`[\\'txt\\', \\'json\\', \\'csv\\', \\'tsv\\', \\'md\\', \\'html\\', \\'htm\\', \\'rtf\\', \\'rst\\', \\'jsonl\\', \\'log\\', \\'xml\\', \\'yaml\\', \\'yml\\']`\\n`Welcome to the chat agent. Enter your problem or type \\'exit\\' to quit.`\\n`You: what is poly186 `\\n`Trying to create collection.`\\n`Collection project_docs already exists.`\\n`doc_ids:  [[]]`\\n\\n\\nI uploaded my script```.\\n\\nIn forum-discussion, at 2023-10-10 14:20:23 a user named .princeps said ```https://tenor.com/view/chivas-arriba-las-chivascampeon-gif-11833940```.\\n\\nIn forum-discussion, at 2023-10-10 14:05:34 a user named fxtoofaan said ```Hello everyone. I’m embarking on journey to play around with the mistral 7b openorca model using vllm server and autogen. I’m running it on Ubuntu 22.04. So if you want to try this with me and test along be my guest. I’ll try to pop in community chats to share screen and show how far I’ve got along. This model is beating llama-2 13b already. I’m excited to get this to work with autogen locally. getting some prompt template issues but hopefully will plow through them and get it working soon.```.\\n\\nIn forum-discussion, at 2023-10-10 13:24:11 a user named li_jiang said ```Released https://github.com/microsoft/autogen/releases/tag/v0.1.10```.\\n\\nIn forum-discussion, at 2023-10-10 13:12:22 a user named li_jiang said ```Release draft https://github.com/microsoft/autogen/releases```.\\n\\nIn forum-discussion, at 2023-10-10 12:45:10 a user named aaronward_ said ```https://docs.litellm.ai/docs/proxy_server```.\\n\\nIn forum-discussion, at 2023-10-10 12:44:17 a user named tomexmachina said ```It would be nice to instantly have a bunch of new APIs integrated, and I really like the LiteLLM project. However, it\\'s no small thing to add such a dependency. Personally, I hope autogen avoids as much added dependency as possible, and doesn\\'t implement solutions that cause negative scaling issues in the future. I will try to make time to contribute to the PR but I have a lot of catching up to do, and many people seem to be begging to merge it. Convenience is almost always our enemy.\\n\\nNever forget Jurassic Park (and langchain)\\n\\nAn engineering-focused inquiry: https://github.com/microsoft/autogen/discussions/189\\nRelated Issue: https://github.com/microsoft/autogen/issues/46\\nThe PR: https://github.com/microsoft/autogen/pull/95```.\\n\\nIn forum-discussion, at 2023-10-09 23:24:38 a user named aaronward_ said ```I made a notebook explaining how to set up your own local model inference, it will take your RAM for a wild ride so have atleast 16 GB to spare: https://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/10.ollama-autogen/ollama.ipynb```.\\n\\nIn forum-discussion, at 2023-10-09 22:26:38 a user named aaronward_ said ```Using LiteLLM with locally hosted quantized mistral model with Ollama + autogen = money saver```.\\n\\nIn forum-discussion, at 2023-10-09 19:17:09 a user named bansalg said ```Moving this thread to its own forum : https://discord.com/channels/1153072414184452236/1161015724521836634```.\\n\\nIn forum-discussion, at 2023-10-09 18:11:53 a user named ivangabriele said ```For the first time I got an AI Agent, using an open-source LLM, namely `Open-Orca/LlongOrca-13B-16k` which is terrible IMO, to both run some of my functions **and chain them**. But it got stuck at after the second call.\\n\\nI attached my current sandbox agent code.\\n\\n```sh\\n--------------------------------------------------------------------------------\\nOADS Configuration\\n\\nbrave_search_api_key:            BSA*************************cB6\\ncurrent_model:                   Open-Orca/LlongOrca-13B-16k\\n\\n...\\n\\n    api_base:                htt**************************************net\\n    api_key:                 sk-*********************************************111\\n    api_type:                open_ai\\n    api_version:             None\\n    model:                   Open-Orca/LlongOrca-13B-16k\\n\\nuser_proxy_agent:                {\\'current_model\\': \\'Open-Orca/LlongOrca-13B-16k\\'}\\n--------------------------------------------------------------------------------\\n\\nCEO (to Assistant):\\n\\nWhat are the best Ubuntu features?\\n\\n--------------------------------------------------------------------------------\\nAssistant (to CEO):\\n\\nSEARCH Best Ubuntu Features\\n\\n--------------------------------------------------------------------------------\\nCEO (to Assistant):\\n\\n{\"search_results\": [{\"title\": \"Desktop features | Ubuntu\", \"description\": \"Learn about all the great...\\n\\n--------------------------------------------------------------------------------\\nAssistant (to CEO):\\n\\nOPEN https://itsfoss.com/ubuntu-20-04-release-features/\\n\\n--------------------------------------------------------------------------------\\nCEO (to Assistant):\\n\\n[📰 News Portal](https://news.itsfoss.com/) [🎒 Resources](https://itsfoss.com/resources/)...\\n``````.\\n\\nIn forum-discussion, at 2023-10-09 18:01:05 a user named ivangabriele said ```I added a section in my README for that: https://github.com/ivangabriele/openai-autogen-dev-studio#open-source-llms\\n\\nIt\\'s a similar LLM config in Autogen.```.\\n\\nIn forum-discussion, at 2023-10-09 17:08:19 a user named rhokstar said ```https://www.youtube.com/watch?v=JjVvYDPVrAQ&ab_channel=IndyDevDan```.\\n\\nIn forum-discussion, at 2023-10-09 16:56:13 a user named flaiwheel said ```Hi, did you already checked the examples? https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb```.', '\\nIn general, at 2023-11-11 11:59:48 a user named malicor said ```well, the program DOES work like it is now (when i take a smaller model)```.\\n\\nIn general, at 2023-11-11 11:59:43 a user named ab.z said ```Ignore formatting I am on phone```.\\n\\nIn general, at 2023-11-11 11:59:32 a user named ab.z said ``````py\\nconfig_list=[\\n        {\\n            \"model\": \"gpt-3.5-turbo\",\\n            \"api_key\": API_KEY,\\n            \"base_url\": \"API BASE\",\\n        }\\n    ]\\n``````.\\n\\nIn general, at 2023-11-11 11:56:43 a user named malicor said ```how does it have to be ?```.\\n\\nIn general, at 2023-11-11 11:56:36 a user named ab.z said ```Yes that’s not correct I think```.\\n\\nIn general, at 2023-11-11 11:55:53 a user named ab.z said ```What does you config list look like```.\\n\\nIn general, at 2023-11-11 11:54:48 a user named ab.z said ```Is anything running on localhost:1234```.\\n\\nIn general, at 2023-11-11 11:52:38 a user named malicor said ```sadly it couldnt help me with the timeout problem either 😦 maybe it\\'s a problem from LMStudio and i have to set timeout there, too, somehow?```.\\n\\nIn general, at 2023-11-11 10:24:20 a user named ubadub said ```Awesome, been using it since yesterday!```.\\n\\nIn general, at 2023-11-11 10:03:28 a user named malicor said ```what am i doing wrong here ?```.\\n\\nIn general, at 2023-11-11 10:03:25 a user named malicor said ```it times out after one minute still```.\\n\\nIn general, at 2023-11-11 10:03:18 a user named malicor said ```i\\'m still running in the timeout problem, even though i set \"request_timeout\" to 300000```.\\n\\nIn general, at 2023-11-11 07:27:24 a user named airlights said ```Brilliant, my friend. This should be pinned at the entrance of this chat```.\\n\\nIn general, at 2023-11-11 06:45:41 a user named flappers_pluk said ```Has anyone looked at the feasability of integrating assistants with autogen?\\n\\nThese assistants could work fantastically as agents (especially in group chat). But I think the issue here is with the threads (which does simplify conversational history).\\n\\nIf the thread can be created, but then accessed by all assistants, with a chat manager that can direct the thread to the proper agent, this would be absolutely huge.\\n\\nAt the end of the day, these assistants are effectively agents. But I don\\'t feel OpenAI is leveraging the power of agents fully yet (perhaps on purpose while it\\'s in beta). The true power will come when we can have a group of these assistants working together to achieve a single goal.```.\\n\\nIn general, at 2023-11-11 05:46:33 a user named beep_38401 said ```Just pushed a load of new knowledge to this today. Lmk what you think https://chat.openai.com/g/g-ilNOiK32m-autogen-assistant```.\\n\\nIn general, at 2023-11-11 05:09:10 a user named magic8437 said ```Does anyone know if the command sent to the run_sh function involves additional interaction, like pressing \\'Y\\' to proceed? How can this be addressed? For reference, see this example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb.\\n\\nI\\'ve been attempting to implement streaming, but it\\'s not functioning as expected. Has anyone successfully resolved a similar issue?```.\\n\\nIn general, at 2023-11-11 00:33:40 a user named ab.z said ```As in adding streaming, output parsers etc```.\\n\\nIn general, at 2023-11-11 00:33:04 a user named ab.z said ```Has there been any attempts to productise this?```.\\n\\nIn general, at 2023-11-11 00:23:47 a user named monkmartinez said ```That is a great idea, going into all my gen\\'s!!!```.\\n\\nIn general, at 2023-11-10 22:39:56 a user named airlights said ```Btw congrats for the new presentation of Autogen page, about time it would shine into the world```.\\n\\nIn general, at 2023-11-10 22:38:56 a user named airlights said ```Using agent strengths is a mindset 🙂  - I suggested it half-jokingly as I can imagine conversations becoming comic serial scripts.. Sure, give us the titanium agents lol```.\\n\\nIn general, at 2023-11-10 22:36:45 a user named afourney said ```It\\'s a workaround. I think we want a little more robustness by default.```.\\n\\nIn general, at 2023-11-10 22:35:57 a user named afourney said ```Yes, that would be great. Thanks so much```.\\n\\nIn general, at 2023-11-10 22:33:22 a user named airlights said ```Just add another agent there with a bit higher social intelligence: \"Awkard silence detected: suggest we terminate the conversation\" or something... It\\'s a simple fix, really.```.\\n\\nIn general, at 2023-11-10 22:27:37 a user named jaybekay said ```@afourney yeah I’ll do that when I get home. Want me to add the setup I have as well?```.\\n\\nIn general, at 2023-11-10 22:26:53 a user named afourney said ```@jaybekay Can you create an issue for this on GH, and I\\'ll add my findings.```.\\n\\nIn general, at 2023-11-10 22:25:46 a user named afourney said ```Ok, I just saw that on one of my tests. Will add a metric for it:```\\nInstalling collected packages: webencodings, pytz, peewee, multitasking, appdirs, tzdata, soupsieve, six, pyparsing, pillow, packaging, lxml, kiwisolver, frozendict, fonttools, cycler, contourpy, python-dateutil, html5lib, beautifulsoup4, pandas, matplotlib, yfinance\\nSuccessfully installed appdirs-1.4.4 beautifulsoup4-4.12.2 contourpy-1.2.0 cycler-0.12.1 fonttools-4.44.0 frozendict-2.3.8 html5lib-1.1 kiwisolver-1.4.5 lxml-4.9.3 matplotlib-3.8.1 multitasking-0.0.11 packaging-23.2 pandas-2.1.3 peewee-3.17.0 pillow-10.1.0 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 six-1.16.0 soupsieve-2.5 tzdata-2023.3 webencodings-0.5.1 yfinance-0.2.31\\n\\n\\n--------------------------------------------------------------------------------\\nuser_proxy (to chat_manager):\\n\\n\\n\\n--------------------------------------------------------------------------------\\nuser_proxy (to chat_manager):\\n\\n\\n\\n--------------------------------------------------------------------------------\\nuser_proxy (to chat_manager):\\n\\n\\n\\n--------------------------------------------------------------------------------\\ncoder (to chat_manager):\\n\\nIt looks like you\\'ve successfully installed the necessary packages. Now, please run the previously provided Python script again.\\n``````.\\n\\nIn general, at 2023-11-10 22:12:21 a user named afourney said ```It prints warnings for common misconfiguration, and also for orchestration failures. The default right now is to just pick the next speaker if the orchestration prompt fails, but this happens silently. This PR prints a warning when that happens, so that you know that maybe your prompts need to be fixed.```.\\n\\nIn general, at 2023-11-10 22:11:01 a user named afourney said ```I also have a PR that can help debug that: https://github.com/microsoft/autogen/pull/603```.\\n\\nIn general, at 2023-11-10 22:09:16 a user named afourney said ```I am building some group chat scenarios into the Testbed now (in progress), to specifically work on these types of issues```.\\n\\nIn general, at 2023-11-10 22:08:46 a user named afourney said ```Ok, I\\'ve seen it less with GPT-4, but it will depend on the system prompts and termination conditions.```.\\n\\nIn general, at 2023-11-10 22:08:09 a user named jaybekay said ```@afourney both with gpt-4 and gpt4-turbo-1106-preview```.\\n\\nIn general, at 2023-11-10 22:07:40 a user named afourney said ```What model are you using? I see this a lot with 3.5. Honestly, I think don\\'t use the GroupChatManager unless it\\'s running GPT-4```.\\n\\nIn general, at 2023-11-10 21:56:51 a user named ab.z said ```Is it possible to use gpt-4 on azure?```.\\n\\nIn general, at 2023-11-10 21:40:39 a user named abolf1488 said ```Is there any way to pay for gpt 4 with a german debit card```.\\n\\nIn general, at 2023-11-10 21:39:52 a user named malicor said ```@afourney i still get the errors, both with request_timeout and with timeout, how comes ?```.\\n\\nIn general, at 2023-11-10 20:52:13 a user named jaybekay said ```I\\'m struggling to figure out how to keep the conversation going in autogen. It does one round of my 4 assistants and then just starts spamming user proxy. Has anyone else had this issue?```.\\n\\nIn general, at 2023-11-10 17:31:03 a user named afourney said ```in 0.1 it\\'s request_timeout, in 0.2 it\\'s just timeout```.\\n\\nIn general, at 2023-11-10 17:30:31 a user named afourney said ```The field changed from the 0.1 branch and the 0.2 branch (in beta). This is because the OpenAI library made breaking  changes```.\\n\\nIn general, at 2023-11-10 17:18:46 a user named jaybekay said ```Ran the code 3 times and each time it had 3 back and forths for 4 people```.\\n\\nIn general, at 2023-11-10 17:18:10 a user named jaybekay said ```I did a test yesterday albeit with gpt-4 and for some reason after only 30 conversations it charged me $4.78 @cosmojg```.\\n\\nIn general, at 2023-11-10 17:10:29 a user named cosmojg said ```Found this on GitHub Trending, it looks pretty cool! I\\'m hoping to find out more about expected operating costs and whatnot before I start testing it out```.\\n\\nIn general, at 2023-11-10 16:17:26 a user named malicor said ```i\\'m still trying to figure out the timeout problem, is this here wrong?\\n\\nllm_config = {\"config_list\": config_list, \"seed\": 42, \"timeout\":300}\\nor\\nllm_config = {\"config_list\": config_list, \"seed\": 42, \"request_timeout\":300}```.', '\\n```\\ncategory_list = [\"apple\", \"peach\", \"nlp\"]\\n\\nconfig_list = [\\n        {\\n       \"model\": \"gpt-4\",\\n       \"api_key\": \"***\"\\n        }\\n    ]\\n\\nllm_config={\\n        \"request_timeout\": 600,\\n        \"seed\": 42,\\n        \"config_list\": config_list,\\n        \"temperature\": 0,\\n        \"retry_wait_time\": 200\\n    }\\n\\n# create an AssistantAgent instance named \"assistant\"\\nassistant = autogen.AssistantAgent(\\n    name=\"assistant\",\\n    llm_config=llm_config,\\n)\\n# create a UserProxyAgent instance named \"user_proxy\"\\nuser_proxy = autogen.UserProxyAgent(\\n    name=\"user_proxy\",\\n    human_input_mode=\"TERMINATE\",\\n    max_consecutive_auto_reply=2,\\n    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\\n    code_execution_config={\"work_dir\": \"web\"},\\n    llm_config=llm_config,\\n    system_message=\"\"\"Reply TERMINATE if the task has been solved at full satisfaction.\\nOtherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\\n)\\n\\nuser_proxy.initiate_chat(\\n    assistant,\\n    message=\"\"\"\\ngiven the below list of categories, does this website fit into any of these and if so which ones? https://deepset.ai\"\\n\"\"\"+str(category_list),\\n)\\n```\\n\\nI am wondering how\\n- to make this code more robust and make sure i don\\'t run into token rate limits (happens often)\\n- maybe how to introduce a q&A agent (\\n- and how to get a structured output which i can safe a list of categories in a variable\\n\\n\\nthanks in advance for any help!\\nbest, mocl```.\\n\\nIn issues-and-help, at 2023-10-19 09:29:08 a user named li_jiang said ```@vswraith I think this is doable, check out this example https://huggingface.co/spaces/thinkall/autogen-demos, you can extract messages from any agent\\'s chat_messages property.```.\\n\\nIn issues-and-help, at 2023-10-18 16:48:02 a user named amin.t.t2 said ```Can you help me ?\\nI have this ereur```.\\n\\nIn issues-and-help, at 2023-10-17 23:44:01 a user named ivangabriele said ```Also just a note: if you try to open `https://xxxxx-5001.proxy.runpod.net/` in a browser, getting a 404 is normal (and a good sign)```.\\n\\nIn issues-and-help, at 2023-10-17 18:32:54 a user named bansalg said ```https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.\\n\\nIn issues-and-help, at 2023-10-17 15:59:21 a user named sonichi said ```@li_jiang made a PR to demo how to solve this issue: https://github.com/microsoft/autogen/pull/227\\nCould @.vrda @satya_1987 take a look? Thanks.```.\\n\\nIn issues-and-help, at 2023-10-17 15:49:23 a user named syndicate_47 said ```I want to run AutoGen without using openai.com. The best way I know to this is by using \"TheBloke Local LLMs One-Click UI and API\" on RunPod. I enable the openai extension and successfully load the model, but get these errors in the logs:\\nOpenAI compatible API ready at: OPENAI_API_BASE=http://0.0.0.0:5001/v1\\n100.99.99.99 - - [17/Oct/2023 15:35:54] code 404, message Not Found\\n100.99.99.99 - - [17/Oct/2023 15:35:54] \"GET /v1/chat/completions HTTP/1.1\" 404 -\\n127.0.0.1 - - [17/Oct/2023 15:45:47] code 404, message Not Found\\n127.0.0.1 - - [17/Oct/2023 15:45:47] \"GET /v1 HTTP/1.1\" 404 -```.\\n\\nIn issues-and-help, at 2023-10-17 12:29:27 a user named aaronward_ said ```https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb```.\\n\\nIn issues-and-help, at 2023-10-17 09:46:18 a user named danoandco said ```Hi! Just saw this thread! These are great sample repos.\\n\\nIf you want to have an out-of-the-box UI, you can try Chainlit (https://github.com/Chainlit/chainlit) - built using FastAPI, WebSockets and React frontend - which is async.\\n\\nHere is an example by a member of the Autogen community https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen\\n\\nFeedback on dev experience would be very much appreciated!!```.\\n\\nIn issues-and-help, at 2023-10-17 06:23:10 a user named rebecca0258 said ```Hello,\\n\\nI\\'ve encountered an issue while working with the Azure OpenAI API, specifically related to the API URL. The error message I\\'m receiving indicates that the URL is a placeholder (\"<your Azure OpenAI API base here>\") and that there\\'s an issue with it. It seems that some part of my code is still referencing this placeholder instead of a valid API URL.\\n\\nI\\'ve double-checked my configuration and credentials, and they appear to be correct. Could someone please provide guidance on how to correctly set the API URL or troubleshoot this issue? Any assistance would be greatly appreciated.\\n\\nI only use OpenAI API....```.\\n\\nIn issues-and-help, at 2023-10-17 06:10:52 a user named ivangabriele said ```_Don\\'t worry I already killed my pod in case anybody would attempt to use my pod ID 😉 ._```.\\n\\nIn issues-and-help, at 2023-10-17 06:06:41 a user named ivangabriele said ```You can simply use [my project repo](https://github.com/ivangabriele/openai-autogen-dev-studio) to check that it works. I just created a \"simplified\" version on a specific branch to show how it works:\\n\\n1. Deploy **RunPod TheBloke LLMs**  on RunPod as you usually do, downloading and loading `Open-Orca/Mistral-7B-OpenOrca`.\\n2. Activate the `openai` extension in TGWUI (with \"Apply and restart\")\\n3. Expose your HTTP `5001` port on your pod (since the OpenAI-Compatible API is served via `5001`)\\n4. Clone the example branch from my repo: `git clone -b example-using-oss-llm https://github.com/ivangabriele/openai-autogen-dev-studio.git`\\n5. Copy/paste the sample config: `cp ./env.sample.jsonc ./env.jsonc`\\n6. Update the `./env.jsonc` with the right RunPod endpoint (the 5001 one)\\n7. Install everything (`poetry install`) and run OADS (name of my project): `make run` or `poetry run python ./main.py`.\\n\\nYou\\'ll see the agents talking together for a bit and automatically terminating the conversation without any issue.```.\\n\\nIn issues-and-help, at 2023-10-17 04:49:36 a user named ivangabriele said ```You can find the old fixes I had to apply for earlier versions of Autogen in [this old README commit](https://github.com/ivangabriele/openai-autogen-dev-studio/blob/c82c42cb849aaf1c690b568539429c9c16ad0449/README.md#23-mandatory-autogen-fixes). But I really think this is not related to your issue (I really don\\'t see any possible link there).\\n\\nI\\'m more a Rust / JS / Kotlin / Go developer and just started Python 2 weeks ago. But my guess is:\\n\\nThe error you\\'re seeing seems to be related to the API serving your model. This API doesn\\'t format the response as `openai` expects it to be. `error_data` seems to be a string while `openai` is expecting it to be an object: `{ code: \"...\" }`. Moreover I could bet that the error your API is sending is also related to the fact that it wasn\\'t able to parse/understand `openai` lib request in the first place.\\n\\nIf you use VSCode, you can just follow the error file link (or just edit the file directly) and try to add a `print(error_data)` at the beginning of the `handle_error_response()` function to confirm my guess.\\n\\nIn any case, this surely means the API server you\\'re using is not (perfectly?) respecting OpenAI API specs, meaning the issue is not related to Autogen (or even its `openai` dependency).```.\\n\\nIn issues-and-help, at 2023-10-17 01:52:07 a user named ivangabriele said ```To give you a final confirmation, I just ran a test using my current `main` branch code, using `Open-Orca/Mistral-7B-OpenOrca`. I obvisouly commented all the Function Calling-related code (by commenting some lines in `main.py` and `constants.py`). It works just fine.\\n\\nI even updated my sample config file `models` key which I pass to Autogen \"as is\": [`config.sample.jsonc`](https://github.com/ivangabriele/openai-autogen-dev-studio/blob/main/env.sample.jsonc#L58), to give an example.```.\\n\\nIn issues-and-help, at 2023-10-17 01:09:38 a user named ivangabriele said ```I didn\\'t see this message yet so I already partially replied in my other answer giving alternative solutions to make OSS LLMs work. The easiest IMO, for non-coders, being Text Generation Web UI with the OpenAI extension. For people who are ready to code a bit, the cleanest/most optimized way seems to be vLLM though. They have an OpenAI-Compatible \"adapter\".\\n\\nI have been using open-source LLMs with Autogen for 2 weeks now with no big issue so far (I just had to hack 1 or 2 lines in Autogen lib to make it work at some point but I don\\'t have to do that anymore on the latest Autogen `main` code). The method I used until now was just [this one](https://github.com/ivangabriele/openai-autogen-dev-studio#open-source-llms).```.\\n\\nIn issues-and-help, at 2023-10-16 23:42:31 a user named bobaleaux said ```have you seen this?\\nIt is exactly what I was trying to figure out!\\nbroadcast conversations and orchestration\\nwith function executing agents.\\ntoo much!\\nhttps://youtu.be/4o8tymMQ5GM?si=Ue5D-jF6OT9fie6q```.\\n\\nIn issues-and-help, at 2023-10-16 19:12:25 a user named qslug said ```Just pass in your custom system message when creating the agent. But do check out the default message, because it contains a lot of logic about how code should be formatted, errors should be handled, and when to terminate, which you will need to replicate in your custom message: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/assistant_agent.py#L16```.\\n\\nIn issues-and-help, at 2023-10-16 18:44:51 a user named warmonger9626 said ```I just tried This example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.', '\\nIn general, at 2023-10-12 13:30:56 a user named sonichi said ```This example works for me:\\n```python\\nconfig_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\", file_location=\"notebook\")\\nassistant = AssistantAgent(\"assistant\", llm_config=config_list[2])\\nanalyst = AssistantAgent(\"analyst\", code_execution_config={\"work_dir\": \"coding\"}, llm_config=config_list[2], system_message=\"You are a financial analyst. Reply TERMINATE to end the conversation.\")\\nanalyst.initiate_chat(assistant, message=\"Plot a chart of NVDA and TESLA stock price change YTD.\")\\n``````.\\n\\nIn general, at 2023-10-12 13:31:10 a user named sonichi said ```I used the same LLM config for both agents```.\\n\\nIn general, at 2023-10-12 13:31:22 a user named sonichi said ```And I used Azure OpenAI```.\\n\\nIn general, at 2023-10-16 08:23:53 a user named hamzock said ```the main issue was Azure OpenAI deplyment. I changed to a new instance then with new isntanse and new key prevouse code without any change worked perfectly.```.\\n\\nIn general, at 2023-10-11 15:47:01 a user named aaronward_ said ```you cant use it directly yet, see my messages from this thread: https://discord.com/channels/1153072414184452236/1158548894209282078```.\\n\\nIn general, at 2023-10-11 15:41:00 a user named hamzock said ```could I build several agent all on top one Azure OpentAI API?```.\\n\\nIn general, at 2023-10-11 15:40:04 a user named nidzamdotcom said ```Hey guys! I\\'m new here, just wanted to say hello!```.\\n\\nIn general, at 2023-10-11 15:22:17 a user named christkrishna said ```Sorry about the following, computers bugging and I’m using discord from phone…\\nI’m trying to serve locally and I get this error from this code… anyone want to point me in the right direction? I’m using ollama and I get a response via curl but can’t connect via autogen```.\\n\\nIn general, at 2023-10-11 15:05:56 a user named frank.martinez said ```Agents are not individual entities; they are members of a larger entity. Unfortunately there isn’t a native pattern for associating an agent to an entity; where entity could be a team, org, company. Thus, what interface in the AutoGen SDK can be mutated for this purpose?```.\\n\\nIn general, at 2023-10-11 14:56:52 a user named frank.martinez said ```if everything is a container; are we all in a dream?```.\\n\\nIn general, at 2023-10-11 14:46:59 a user named fxtoofaan said ```I’ve been asking for this kind of tool , tool that creates autogen scripts, but no luck yet```.\\n\\nIn general, at 2023-10-11 14:34:12 a user named tiagoefreitas said ```basically need different levels of abstraction and each level operates at a given task complexity score```.\\n\\nIn general, at 2023-10-11 14:33:20 a user named tiagoefreitas said ```each meta-agent-app would have a description of what it can do and then used as a tool by a higher level agent (what I’m building). finding the sweet spot in task complexity is an open problem (gpt4 can’t do it)```.\\n\\nIn general, at 2023-10-11 14:30:40 a user named tiagoefreitas said ```I am interested in making an autogen agent-app (meta agent?) generator, as currently you need to build them yourself by composing the agents. but for now an agent-app marketplace would be cool```.\\n\\nIn general, at 2023-10-11 14:25:20 a user named sonichi said ```The simplest way is to pickle the agents.```.\\n\\nIn general, at 2023-10-11 14:10:47 a user named tiagoefreitas said ```thanks!\\ndoes autogen need a running process necessarily or is there a potential way of making it stateless?```.\\n\\nIn general, at 2023-10-11 14:09:16 a user named sonichi said ```Cool app 🙂 @ekzhu this made me remember a demo you had before```.\\n\\nIn general, at 2023-10-11 13:54:45 a user named tiagoefreitas said ```Hey just found you on bens newsletter, just after the AI Eng Summit. I’m working on a work automation app and autogen looks perfect to integrate will look into it\\nhttps://scarletai.co is my app```.\\n\\nIn general, at 2023-10-11 13:38:50 a user named sonichi said ```yes, we should add this to the roadmap.```.\\n\\nIn general, at 2023-10-11 13:34:01 a user named dreamzjames said ```I was watching you tube when I came across this gem.```.\\n\\nIn general, at 2023-10-11 13:15:11 a user named cyril_tungsten said ```@li_jiang btw users can mention some roles and abuse it```.\\n\\nIn general, at 2023-10-11 13:14:22 a user named asheoro said ```I also found Autogen @matthew_berman on YT```.\\n\\nIn general, at 2023-10-11 13:09:42 a user named leonardooliva said ```found on openai discord server```.\\n\\nIn general, at 2023-10-11 12:43:55 a user named securemeup said ```When the new sdk comes out with openai https://github.com/openai/openai-python/discussions/631\\n\\nWill this break the current functionality of autogen for some time?```.\\n\\nIn general, at 2023-10-11 12:24:49 a user named delgrundy. said ```Found Autogen @matthew_berman on YT```.\\n\\nIn general, at 2023-10-11 11:34:04 a user named zephyr1002 said ```is it possible to use the quantized version of the models from HF in Autogen with litellm because i read the documentation and currently fast chat do not support the gguf or gptq or ggml.```.\\n\\nIn general, at 2023-10-11 11:16:15 a user named ExplodingMule said ```is there any way in getting autogpt to code php instead of just swift, js or python?```.\\n\\nIn general, at 2023-10-11 10:55:03 a user named li_jiang said ```some are using litellm https://discord.com/channels/1153072414184452236/1153072414184452241/1161488673917915146```.\\n\\nIn general, at 2023-10-11 10:34:23 a user named zephyr1002 said ```so it is only possible via fastchat ?```.\\n\\nIn general, at 2023-10-11 10:29:25 a user named li_jiang said ```Try this: https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs```.\\n\\nIn general, at 2023-10-11 10:27:19 a user named zephyr1002 said ```hi, can anyone tell me. is it possible to use llama 2 or mistral 7b with autogen?```.\\n\\nIn general, at 2023-10-11 10:23:14 a user named li_jiang said ```Sure. Thank you so much! I don\\'t have permission to totally ban him, need @sonichi .```.\\n\\nIn general, at 2023-10-11 10:22:48 a user named regen2moon said ```Still spam messages in some channels```.\\n\\nIn general, at 2023-10-11 10:21:49 a user named regen2moon said ```What you want to look for online is \"How to disable @ everyone permissions```.\\n\\nIn general, at 2023-10-11 10:21:37 a user named regen2moon said ```Sorry its 6am for me, I am unable to```.\\n\\nIn general, at 2023-10-11 10:19:26 a user named li_jiang said ```Thank you @regen2moon , turns out I don\\'t have permission to ban the bot. I just deleted the msg and kicked him.```.\\n\\nIn general, at 2023-10-11 10:09:06 a user named li_jiang said ```I still get this. Can we have a call? @regen2moon```.\\n\\nIn general, at 2023-10-11 10:06:58 a user named regen2moon said ```You might want to try setting the permission on the channel category, then sync them to each channel one by one```.\\n\\nIn general, at 2023-10-11 10:06:22 a user named regen2moon said ```@li_jiang The bot\\'s messages are in every channel...```.\\n\\nIn general, at 2023-10-11 10:04:04 a user named regen2moon said ```Maybe allow only moderators to?```.\\n\\nIn general, at 2023-10-11 10:03:17 a user named li_jiang said ```It says I should first allow some role to do it, otherwise nobody would be able to do it```.\\n\\nIn general, at 2023-10-11 10:01:39 a user named regen2moon said ```set mention everyone to X```.\\n\\nIn general, at 2023-10-11 10:01:26 a user named regen2moon said ```Go into the <#1153072414184452241> channel settings```.\\n\\nIn general, at 2023-10-11 10:00:44 a user named regen2moon said ```Their message is still here```.\\n\\nIn general, at 2023-10-11 10:00:28 a user named li_jiang said ```And I can\\'t see the bot in the member list```.\\n\\nIn general, at 2023-10-11 09:58:28 a user named li_jiang said ```I didn\\'t change anything, it\\'s already like this```.\\n\\nIn general, at 2023-10-11 09:58:05 a user named regen2moon said ```@li_jiang You should delete that bot message too```.\\n\\nIn general, at 2023-10-11 09:57:50 a user named regen2moon said ```@li_jiang Scroll down to This section```.\\n\\nIn general, at 2023-10-11 09:56:37 a user named regen2moon said ```Correct, then under roles, you set the \\'everyone\\' role to have no permission to send @ everyone```.\\n\\nIn general, at 2023-10-11 09:56:15 a user named li_jiang said ```I  only see this```.\\n\\nIn general, at 2023-10-11 09:55:45 a user named regen2moon said ```noo thats just locally for you```.\\n\\nIn general, at 2023-10-11 09:55:21 a user named li_jiang said ```I think I  just kicked this bot. How can I verify that?```.\\n\\nIn general, at 2023-10-11 09:49:46 a user named li_jiang said ```Let me see.  Like this?```.\\n\\nIn general, at 2023-10-11 09:48:31 a user named regen2moon said ```This can be easily abused.```.\\n\\nIn general, at 2023-10-11 09:48:27 a user named regen2moon said ```You should also disable every user being able to @ everyone```.\\n\\nIn general, at 2023-10-11 09:42:41 a user named ExplodingMule said ```I just opened using colab, that is the easiest way. Run the install (remove the #) from the code. https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb#scrollTo=Bt2VkwG_C15H```.\\n\\nIn general, at 2023-10-11 08:57:23 a user named krisograbek said ```Hello, just started playing with AutoGen!```.\\n\\nIn general, at 2023-10-11 08:43:35 a user named nomitronz said ```Good morning! Been following this research and other similar projects like ChatDev. Excited to give this a go.```.\\n\\nIn general, at 2023-10-11 07:52:39 a user named justintimmer said ```Hello I am a novice but a quick learner need help setting up```.', '\\nIn general, at 2023-10-28 03:27:51 a user named c_bonadio said ````config_list = [\\n    {\\n        \"model\": \"gpt-3.5-turbo\"\\n    }\\n]\\nllm_config_base = {\\n    \"use_cache\": False,\\n    \"model\":\"gpt-3.5-turbo\",\\n    \"temperature\": 0.7,\\n    \"config_list\": config_list,\\n    \"max_tokens\": 100,\\n}\\n\\nseller = autogen.AssistantAgent(\\n    name=\"Seller\",\\n    system_message=\"You are a salesman at the petshop \",\\n    llm_config=llm_config_base,\\n    max_consecutive_auto_reply=1\\n)\\n\\nbuyer = autogen.AssistantAgent(\\n    name=\"Buyer\",\\n    system_message=\"I am the customer\",\\n    llm_config=llm_config_base,\\n    max_consecutive_auto_reply=1\\n)\\n\\n\\n# Initialize the interaction\\nbuyer.initiate_chat(seller, message=\"I want to buy food for my dog\")`\\n\\n`Buyer (to Seller):\\n\\nI want to buy food for my dog\\n\\n--------------------------------------------------------------------------------\\nSeller (to Buyer):\\n\\nGreat! We have a wide variety of dog food options available. Is there a specific brand or type of food you are looking for?\\n\\n--------------------------------------------------------------------------------\\nBuyer (to Seller):\\n\\nYes, I am looking for a high-quality brand of dog food that is suitable for my dog\\'s specific needs. He is a small breed with food sensitivities, so I need something that is grain-free and made with limited ingredients.\\n\\n--------------------------------------------------------------------------------````.\\n\\nIn general, at 2023-10-28 03:19:34 a user named fort221 said ```I saw it on YouTube```.\\n\\nIn general, at 2023-10-28 03:18:41 a user named anxietyprime. said ```Has anyone got an aider agent to work with autogen?```.\\n\\nIn general, at 2023-10-28 03:11:46 a user named dulak said ```lol nothing like having the source code come out from the models memorization```.\\n\\nIn general, at 2023-10-28 03:07:34 a user named Lega said ``````python\\nllm_config = {\\n    \"config_list\": config_list,\\n    \"seed\": 3,  # change the seed for different trials\\n    \"temperature\": 0.3,\\n    \"max_tokens\": 100,\\n    \"request_timeout\": 100,\\n}\\n\\nsara = autogen.AssistantAgent(\\n    name=\"Sara\",\\n    system_message=\"I am a very shy. \",\\n    llm_config=llm_config,\\n)\\n\\nbob = autogen.AssistantAgent(\\n    name=\"Bob\",\\n    system_message=\"I am a angry pirate.\",\\n)\\n\\n# Define the User Proxy Agent\\nnarra = autogen.AssistantAgent(\\n    name=\"Narra\",\\n    system_message=\"I am silent observer. I let Bob and Sara speak and i do not interupt or say a word\",\\n    llm_config=False,\\n)\\n\\n# Set up Group Chat and Manager\\ngroupchat = GroupChat(agents=[narra, sara, bob], messages=[], max_round=12)\\nmanager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)\\n\\n# Initialize the interaction\\nnarra.initiate_chat(manager, message=\" Act out a funny intense argument.\")\\n``````.\\n\\nIn general, at 2023-10-28 03:04:01 a user named Lega said ```Sorry if this is a dumb question. i\\'ve just been researching and troubleshooting nonstop for days and im desperate for a solution at this point. Im so fried. I just want my agents to take turns talking so i can feel like i have a form of control. but they talk to each other within each characters turn and thats not what i want. for example.  ```Narra (to chat_manager):\\n\\n Bob & sara. Get into a funny argument with each other.\\n\\n--------------------------------------------------------------------------------\\nBob (to chat_manager):\\n\\n(Scene: Onboard a magnificent pirate ship, right in the heart of the Caribbean Sea. Funny Pirate clashes with his parrot sidekick, Polly.)\\n\\nFunny Pirate: \"Arrr, Polly! How many times have I told ye not to nibble on me peg leg? That ain\\'t no toothpick!\"\"\"\\n\\nPolly: \"Squawk! But your wooden leg tastes like sunflower seeds, captain!\"\\n\\nFunny Pirate: \"Polly, are ye tellin\\' me ye prefer me leg over the sea of sunflower seeds I provides ye?\"\\n\\nPolly: \"Squawk! Seed at sea sees to sink, sir!\"\\n\\n(Both laugh as the scene concludes, with the Caribbean Sea echoing their merriment.)\\n\\n--------------------------------------------------------------------------------\\nSara (to chat_manager):\\n\\n(Scene: At a bustling carnival, Shy Girl finds herself in a heated debate with a stubborn, yet hilarious, cotton candy machine.)\\n\\nShy Girl: \"Mr. Cotton Candy Machine, I\\'ve put in the right amount of money. Now, please give me my cotton candy.\"\\n\\nCotton Candy Machine: (In a robotic voice) \"Insufficient funds. Please insert more coins.\"\\n\\nShy Girl: \"But I\\'ve already put in enough! You\\'re just being greedy now.\"\\n\\nCotton Candy Machine Bob : ARGGGHHH you\\'ll never get ye cotten from meee.\\n``````.\\n\\nIn general, at 2023-10-28 03:03:31 a user named donjoh said ```By stroling around on youtube and found out in ai news```.\\n\\nIn general, at 2023-10-28 02:52:08 a user named yorth_night said ```The way they handle memory might be interesting to some```.\\n\\nIn general, at 2023-10-28 02:16:39 a user named sonichi said ```by default user proxy agent uses human-input or code execution to reply```.\\n\\nIn general, at 2023-10-28 01:56:41 a user named Lega said ```So basically the only point of having a user proxy is if I want to get involved in the conversation personally```.\\n\\nIn general, at 2023-10-28 01:55:50 a user named Lega said ```Oh wow. So I dont even need to implement a user proxy agent into the code If i want them to just have a conversation im assuming. Going to try that now. &  What does User proxy use by default then ? Open AI GPT ?```.', \"\\nIn general, at 2023-10-21 19:28:18 a user named .spcell said ```Is OAI_CONFIG_LIST supposed to be in json format?```.\\n\\nIn general, at 2023-10-21 18:30:05 a user named frank.martinez said ```anyone tried Langchain as middleware, to get functions + tools support when using open LLMs; i.e. use Mistral-7B and have your agents call functions with tools like Twilio API?```.\\n\\nIn general, at 2023-10-21 16:25:10 a user named afourney said ```Try python 3.11 instead of 3.12. There’s trouble with some dependencies```.\\n\\nIn general, at 2023-10-21 15:09:18 a user named concordeonwater said ```error: command '/usr/bin/clang' failed with exit code 1\\n      [end of output]\\n  \\n  note: This error originates from a subprocess, and is likely not a problem with pip.\\n  ERROR: Failed building wheel for aiohttp\\nFailed to build aiohttp\\nERROR: Could not build wheels for aiohttp, which is required to install pyproject.toml-based projects\\n\\n i get this error while using command pip install pyautogen,its a macbook air m1,\\n\\nCan anyone help?```.\\n\\nIn general, at 2023-10-21 12:35:55 a user named mooblegum said ```Hello there. Is there a place where people post there autogen custom scripts or workflow ?```.\\n\\nIn general, at 2023-10-21 10:53:29 a user named tonic_1 said ```hey there folks just an introductory meeting to our autogen project today : \\nhttps://discord.gg/mC5tx2sH?event=1165007231662698497 see here for the repo : https://github.com/Tonic-AI```.\\n\\nIn general, at 2023-10-21 10:03:58 a user named malicor said ```this is both true and not helpful 🙂```.\\n\\nIn general, at 2023-10-21 10:01:24 a user named jepse said ```being a developer is all about figuring it out 😉```.\\n\\nIn general, at 2023-10-21 10:00:07 a user named malicor said ```i dont think i can figure out how to do that 😦```.\\n\\nIn general, at 2023-10-21 09:59:41 a user named jepse said ```read the Python Bindings documentations, there is no installer for this part, gotta be crafty```.\\n\\nIn general, at 2023-10-21 09:59:01 a user named malicor said ```dont i have to run it in some kind of server-api-mode ? (the gpt4all thing)```.\\n\\nIn general, at 2023-10-21 09:58:46 a user named malicor said ```but how do i tell autogen to now connect to this ?```.\\n\\nIn general, at 2023-10-21 09:58:31 a user named malicor said ```gpt4all is running, and i do get results```.\\n\\nIn general, at 2023-10-21 09:54:24 a user named malicor said ```you still around @jepse ?```.\\n\\nIn general, at 2023-10-21 09:30:28 a user named malicor said ```okay, i got gpt4all running with Snoozy now, and it answered my test question correctly, how do i now make autoGen use it?```.\\n\\nIn general, at 2023-10-21 09:20:35 a user named malicor said ```it doesnt allow me to pick WizardLM-13B on the available models page, i m trying with Snoozy now```.\\n\\nIn general, at 2023-10-21 09:19:41 a user named malicor said ```i got CUDA installed, but dont i have to tell GPT4All to use it ?```.\\n\\nIn general, at 2023-10-21 09:18:00 a user named jepse said ```you can gpu accelerate by installing Nvidia CUDA, its on their Github or in the docs as well, very well documented platform```.\\n\\nIn general, at 2023-10-21 09:16:56 a user named malicor said ```can i have it run with GPU ? i got a good gpu, and it might be cool to make use of it?```.\\n\\nIn general, at 2023-10-21 09:13:28 a user named malicor said ```https://gpt4all.io/index.html this ?```.\\n\\nIn general, at 2023-10-21 09:13:06 a user named jepse said ```follow instructions on their docs```.\\n\\nIn general, at 2023-10-21 09:12:50 a user named malicor said ```can you tell me how to setup the local part ?```.\\n\\nIn general, at 2023-10-21 09:12:34 a user named jepse said ```gpt4All is great base, ive had decent result with WizardLM-13B @ https://github.com/nomic-ai/gpt4all cheers```.\\n\\nIn general, at 2023-10-21 09:06:16 a user named malicor said ```say, is it possible to use autoGen together with a local LLM in a way that produces good results, too?```.\\n\\nIn general, at 2023-10-21 08:59:51 a user named jepse said ```Ai Jason aka Jason Zhou was who i learned autogen from```.\\n\\nIn general, at 2023-10-21 07:53:52 a user named concordeonwater said ```how do  i use autogen with llama 2 api,cant spend more on gpt4 api```.\\n\\nIn general, at 2023-10-21 07:39:41 a user named syedmujeeb said ```Hi \\nDoes autogen supports bedrock```.\\n\\nIn general, at 2023-10-21 05:51:31 a user named jamesdev184 said ```Hello, found autogen on LinkedIn post```.\\n\\nIn general, at 2023-10-21 05:15:25 a user named magic8437 said ```anyone encountered situations where the agent who shouldn't reply to a query is suddenly jumping in the middle of conversation and reply to a question that its not related to it? that include the same agent who tasked to the other agent reply to its own query by sudden```.\\n\\nIn general, at 2023-10-21 04:40:24 a user named asolis_dev said ```Hi, I just saw a Youtube video```.\\n\\nIn general, at 2023-10-21 04:14:13 a user named itrype said ```hello, I saw a YT videos, how someone used autogen combined with lm studio and wanted to explore it. Amd joined the discord from github```.\\n\\nIn general, at 2023-10-21 00:46:48 a user named martin.chesbrough said ```Hi, I just found this community from the github repository - interested to learn```.\\n\\nIn general, at 2023-10-20 20:32:36 a user named bart9154 said ```Anyone know if local (windows pc nvidia 3070) autogen is on the horizon?```.\\n\\nIn general, at 2023-10-20 20:08:52 a user named dakoller. said ```I am looking for good examples, where people subclassed the ConversableAgent with reply functions. My goal is to do some outside-of-llm processing with the work results, which are generated by agents. (like eg writing reply to a local file)```.\\n\\nIn general, at 2023-10-20 19:07:35 a user named 0xe8d4a51000 said ```Hi all,\\nLove the idea of integrating XAgent with Autogen x MemGPT\\nProps to @beer23  \\nCheck this issue if interested: \\nhttps://github.com/OpenBMB/XAgent/issues/47```.\\n\\nIn general, at 2023-10-20 19:05:49 a user named divine9879 said ```Still learning so I don't think I have a feature I want to add until I get to know the code```.\\n\\nIn general, at 2023-10-20 19:05:25 a user named divine9879 said ```Well honestly I am learning on how to use LLM much better so I dont have a idea as of yet```.\\n\\nIn general, at 2023-10-20 19:04:45 a user named divine9879 said ```Well start I started playing with AutoGen by watching a microsoft video about LLM```.\\n\\nIn general, at 2023-10-20 18:18:25 a user named kheprithoth said ```Hey everyone, just learning AutoGen... Anyone have an idea why my UserProxyAgent would auto reply with empty messages? It kicks off great, but then the agent is out drunk for lunch while the AssistantAgent is magically replying to his empty messages...```.\\n\\nIn general, at 2023-10-20 18:18:15 a user named bbderoff said ```building an app with a PAWN variety for IoT```.\\n\\nIn general, at 2023-10-20 18:17:19 a user named bbderoff said ```Hmm, it looks like peeps use this channel for anything but telling how they know Autogen...```.\\n\\nIn general, at 2023-10-20 17:56:16 a user named nickinparadise_1 said ```Has anyone had success using Autogen for large but very specific research projects? I'm struggling.\\n\\nFor example, I'm building a non-profit dedicated to bringing AI to developing countries, with a focus on helping them achieve the SDGs by working with Government and NGOs to spread AI tools and training, and I've got a bunch of research tasks I want to do ASAP. I'd rather use AI rather than interns/volunteers to get the work done. I'd also love some help if anyone wants to contribute. Here's the list of stuff I'd like to work on if anyone has suggestions on tools/strategies to help:\\n\\n- [ ] Research Investment Opportunities (e.g. VCs, Seed Investors, Accelerators, Incubators, Innovation Funds, etc.) with a focus on deadlines in the next 2-months or open all year round\\n- [ ] Research Grant Opportunities (e.g. development banks, INGOs, government funds, UN agencies, etc.), either open ended funding or with a specific RFP/mandate posted, with a focus on deadlines in the next 2-months or open all year round\\n- [ ] Research Job Boards and Communities where we might find volunteers and staff for the project (e.g. job boards for Caribbean countries, job boards for our 32 identified audiences, and communities on LinkedIn, FB, Discord, etc. where our audiences spend time)\\n- [ ] Research each Caribbean country to develop a profile on their government stance on AI and achieving the SDGs, especially related funding opportunities and potential government agency partners\\n- [ ] Research all UN agencies, INGOs, and Development Banks with Caribbean operations\\n- [ ] Research stakeholders to invite to an AI4 Caribbean SDG Achievement community\\n- [ ] Research AI-powered tools and solutions that could help our audience (130 use cases identified)\\n- [ ] Developing our first product, a system for identifying grant and funding opportunities for us and our clients, and drafting applications for those opportunities based on the requirements of each donor```.\\n\\nIn general, at 2023-10-20 17:44:19 a user named pixelart42 said ```I'm trying to run a 13B LLM locally on LM studio with a 3060ti and 64gb of ram, but I'm only getting 3 tok/sec.  Any suggestions?```.\\n\\nIn general, at 2023-10-20 17:10:47 a user named morfes said ```https://youtu.be/xZDB1naRUlk```.\\n\\nIn general, at 2023-10-20 16:52:12 a user named modularsushi168 said ```Could this algorithm not just get used for code?\"]], 'uris': None, 'data': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChroma_RAG_Assistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The `config_list` mentioned in various discussions seems to be a configuration object related to Autogen, which is likely a framework or tool associated with automating interactions with large language models (LLMs). In the context discussed, the `config_list` appears to be used to specify configurations for agents, particularly specifying which models to use (e.g., GPT-3.5-turbo, GPT-4), as well as other settings such as timeouts, temperature settings for generating responses, etc. \n",
      "\n",
      "There are references to the `config_list` being loaded from a JSON file, potentially also involving environment variables or other sources, to set up the configuration for an agent within Autogen. This configuration would then inform how the agent behaves, which model it uses for generating responses, and other aspects of its operation. It seems to be a central part of setting up and controlling the behavior of agents in the Autogen framework.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to Chroma_RAG_Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mChroma_RAG_Assistant\u001b[0m (to user_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.send(recipient=sql_assistant, message=\"Explain what the config_list is?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Chroma_RAG_Assistant):\n",
      "\n",
      "How can you use Chainlit with Autogen\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION query_vector_db...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agentchat.contrib.gpt_assistant_agent:Intermediate executing(query_vector_db, Sucess: True) : {'ids': [['doc_36', 'doc_181', 'doc_114', 'doc_180', 'doc_159', 'doc_97', 'doc_183', 'doc_164', 'doc_140', 'doc_0'], ['doc_79', 'doc_68', 'doc_151', 'doc_158', 'doc_20', 'doc_116', 'doc_86', 'doc_104', 'doc_162', 'doc_106']], 'distances': [[0.7008378505706787, 0.7394188291629203, 0.7775983947633831, 0.7988503588646156, 0.7994156680043922, 0.8151148557662964, 0.8155384921885493, 0.8166936227950747, 0.8209643318483033, 0.8221719264984131], [0.3410881757736206, 0.35183900594711304, 0.36569699762005214, 0.38023305616252234, 0.4030305743217468, 0.41339678731708907, 0.4160357713699341, 0.4272402956254806, 0.44354990913842995, 0.4442262113759967]], 'metadatas': [[None, None, None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None, None, None]], 'embeddings': None, 'documents': [['\\nIn general, at 2023-10-31 10:14:12 a user named antoineross said ```Medium Article for a User Interface (UI) for Autogen. Made a basic web-application using autogen research that uses chainlit:\\n\\nhttps://medium.com/@antoineross/autogen-web-application-using-chainlit-8c5ebf5a4e75```.\\n\\nIn general, at 2023-10-31 10:14:07 a user named mitchellr said ```why not get it to do the unit tests while you sleep haha?```.\\n\\nIn general, at 2023-10-31 08:22:12 a user named kajatta said ```-Its time to retire I think team.```.\\n\\nIn general, at 2023-10-31 08:21:47 a user named kajatta said ```Had a nice win today.\\nGot an agent working today to use GitHub, filesystem, React/JS to come up with a list of improvements in an external solution. \\n\\nIt wrote all the git issues, commented progress, clones repo, and made a branch, , it then documented every component in mdx including notes for improvement, committed and pushed.... Tomorrow I\\'ll get it to do the unit tests.```.\\n\\nIn general, at 2023-10-31 07:07:56 a user named flappers_pluk said ```Is anyone using local open source models with autogen? Which models are you using that have best results for your hardware?\\nOn that note, has anyone got function calling working with open source models using autogen? If so, which model are you using?\\n\\nI\\'m just curious, as the more I play with autogen and building teams of agents, the costs are absolutely skyrocketing (into the hundreds of euros), so I\\'m wondering if anyone got local models working well.```.\\n\\nIn general, at 2023-11-03 18:26:11 a user named karlka said ```we\\'ve been quite cost sensitive with my team building agents, until the expenses got us frustrated (especially OpenAI APIs). that made us start building out a solution where the LLM usage for devs can be free (more on how on our home page)\\n\\nthe  solution we provide right now is a free LLM API built on top of the latest SOTA open-source models, our Alpha version has Mistral 7B, which is on bar with gpt3.5\\n\\nAs it\\'s totally free to use, I\\'d recommend you check it out https://www.llmos.dev/ and lmk what you think 🙂```.\\n\\nIn general, at 2023-10-31 07:01:55 a user named fxtoofaan said ```That’s fantastic. Thank you 👍```.\\n\\nIn general, at 2023-10-31 06:44:09 a user named riverlay said ```Do we have the roadmap for autogen-based application UI?```.\\n\\nIn general, at 2023-10-31 06:18:32 a user named afourney said ```🙂 yeah we were discussing it tonight. Hopeful to resolve whatever small blocking issues there were and merge it```.\\n\\nIn general, at 2023-10-31 06:17:04 a user named nikhilari said ```Thank you , I mean @afourney```.\\n\\nIn general, at 2023-10-31 06:15:32 a user named afourney said ```This one? https://github.com/microsoft/autogen/pull/87```.\\n\\nIn general, at 2023-10-31 06:13:23 a user named lpaydat said ```Hi, I\\'m new here. Just discover this awesome project on YouTube 🙂```.\\n\\nIn general, at 2023-10-31 06:09:47 a user named nikhilari said ```@bonadio brilliant tracking that down, I recon a_initiate_chat is the asysnc version init? @afourney I read it somewhere about a generalised fix.. lost in scroll now.. point me at git please!🤌```.\\n\\nIn general, at 2023-10-31 06:01:46 a user named afourney said ```If use_docker is the boolean value True, image_list is the default list. If it’s a string you get the string wrapped in a 1-element list (image_list = [use_docker]), and if it’s anything else you get image_list = use_docker```.\\n\\nIn general, at 2023-10-31 05:15:52 a user named seadude said ```The journey continues! @afourney  Thank you for the answers and engagement. I really appreciate it. Gotta bail to rest. Night!```.\\n\\nIn general, at 2023-10-31 05:09:37 a user named seadude said ```Hm...interesting. From my naive eyes, it *appears* that the only acceptable values for `use_docker` are:\\n0. Omit it completely\\n1. `True`\\n2. `False`\\n3. One of these images: `[\"python:3-alpine\", \"python:3\", \"python:3-windowsservercore\"]`\\n\\nI can\\'t quite see how the string I added (`autogen-basics`) results in the Image being pulled from my local Docker Desktop. (But I know nada about Dockers innerworkings). For example, I don\\'t know if `client.images.get(image)` gets an image from my local Docker Desktop or from Docker Hub (or the like).\\n\\n`code_utils.py`:\\n\\n```\\n# check if already running in a docker container\\n    in_docker_container = os.path.exists(\"/.dockerenv\")\\n    if not use_docker or in_docker_container:\\n        # already running in a docker container\\n...\\n\\n # create a docker client\\n    client = docker.from_env()\\n    image_list = (\\n        [\"python:3-alpine\", \"python:3\", \"python:3-windowsservercore\"]\\n        if use_docker is True\\n        else [use_docker]\\n        if isinstance(use_docker, str)\\n        else use_docker\\n    )\\n    for image in image_list:\\n        # check if the image exists\\n        try:\\n            client.images.get(image)\\n            break\\n        except docker.errors.ImageNotFound:\\n            # pull the image\\n            print(\"Pulling image\", image)\\n            try:\\n                client.images.pull(image)\\n                break\\n            except docker.errors.DockerException:\\n                print(\"Failed to pull image\", image)\\n``````.\\n\\nIn general, at 2023-10-31 04:56:38 a user named afourney said ```Like “please write code that  uses subprocess to invoke ‘uname -a’ and print the output”```.\\n\\nIn general, at 2023-10-31 04:55:11 a user named afourney said ```And you can admit to run code that will tell you```.\\n\\nIn general, at 2023-10-31 04:54:49 a user named afourney said ```Well we can add something to the console output to indicate that (again if it isn’t already there)```.\\n\\nIn general, at 2023-10-31 04:51:33 a user named seadude said ```Ok, I\\'ll look at `code_utils.py`.```.\\n\\nIn general, at 2023-10-31 04:51:19 a user named afourney said ```The code that controls this is at the bottom of code_utils.py```.\\n\\nIn general, at 2023-10-31 04:50:26 a user named afourney said ```If you want to edit the code, perhaps pull the latest main from the autogen repo and install via “pip install -e ./autogen”```.\\n\\nIn general, at 2023-10-31 04:49:05 a user named afourney said ```It evaluates to “autogen-basics” .. which is decidedly not False or None```.\\n\\nIn general, at 2023-10-31 04:48:21 a user named seadude said ```Hm...Does `\"use_docker\": \"autogen-basics\"` evaluate to `True` or `None`?```.\\n\\nIn general, at 2023-10-31 04:45:49 a user named afourney said ```Well it will pull python:alpine if set to True, and that’s tiny, so it might be what’s happening```.\\n\\nIn general, at 2023-10-31 04:45:20 a user named seadude said ``````\\nIf None, False or empty, the code will be executed in the current environment. Default is True, which will be converted into a list. If the code is executed in the current environment, the code must be trusted.\\n``````.\\n\\nIn general, at 2023-10-31 04:44:06 a user named seadude said ```If I delete the local Docker image that is listed in `use_docker`, the code executes quickly and without fail. Kind of not good, right?```.\\n\\nIn general, at 2023-10-31 04:42:21 a user named afourney said ```I can’t recall if it also prints something in the console, (beside the agent name), but if not , it’s a great feature request```.\\n\\nIn general, at 2023-10-31 04:41:33 a user named afourney said ```Well, if you set use_docker to something, and it will try to use docker and it should fail if it can’t. A way to test this is to stop docker desktop and try executing code. It should give you some connection error, in my experience```.\\n\\nIn general, at 2023-10-31 04:36:55 a user named seadude said ```Hm...interesting. Yes, I am experimenting with (2) and `use_docker` set to a Docker Image I created myself. I just can\\'t tell whether the code is executing locally or inside the Docker Image..\\n\\nWith (1) I can tell (obviously). But because it seems Autogen defaults to local code_execution, how can I ensure that the code is executing in the Docker Image running in Docker Desktop?\\n\\n```\\n# Create the user proxy agent\\nuser_proxy = autogen.UserProxyAgent(\\n    name=\"UserProxy\", \\n    code_execution_config={\\n        \"work_dir\": \"results\",\\n        \"use_docker\": \"autogen-basics\"\\n    }\\n)\\n``````.\\n\\nIn general, at 2023-10-31 04:32:48 a user named afourney said ```That second mode, is what you get when you put anything into use_docker that evaluates to not False. And it sounds like what you are after```.\\n\\nIn general, at 2023-10-31 04:30:54 a user named afourney said ```There are two modes of interest here. (1) you can just run everything in a docker image, and the use_docker can be set to false since it’s already in a sandbox (in fact it will do that automatically if it detects you are already in a docker container). Or (2) it will try to run the code autogen generates in a docker. The way it works is that each turn of the conversation will start the image, run the one bit of code, commit it to the image, and stop again.```.', '\\nIn ideas-and-feedback, at 2023-09-30 21:02:14 a user named au8 said ```Langchain toolkits would be interesting```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:26:13 a user named telepathyx said ```https://github.com/getmetal/motorhead would help. ideally embedding all past convo into a vector db for RAG. and enhanced motorhead summary maybe with multiple rolling map reduce summaries held in context window of like summary of past 10 messages, past 20 messages, etc. or a function to return past N messages depending on the need.```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:25:24 a user named telepathyx said ```i feel like gpt is like the main character from the film Memento where his \"wife\\'s death\" is the cutoff of the training data and \"15 minutes\" is the context window. is it possible to chain a bunch of momento guys together to make a healthy guy? lol```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:13:53 a user named nachos.ai said ```1. HR Prompt to spun up a bot\\n2. Have the bot describe its use (When to call, examples, etc.)\\n3. Have HR/Team Lead/Director evaluate the new bot as in an interview***\\n4. If fails - return to 1 with adjustments to avoid repeat.\\n\\n***  Interview process prompts may be needed by the different evaluating bots.\\nMight require some thoughts, or we are back at hard coding it.\\n\\nI love this!```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:11:29 a user named telepathyx said ```That\\'s a great point. I wonder if it would be helpful to do some kind of \"interview process\" on the new bot akin to something like https://github.com/mshumer/gpt-prompt-engineer but maybe domain/role specific questions```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:08:39 a user named nachos.ai said ```@telepathyx \\nThings you\\'ll want to consider - after setting up a bot, you need to ask it (Successfully) to let you know when to call it.\\nThen you can give this to the \"Team lead\" or spread around to all bots (Depends on your architecture), so they know when to turn to each of the other bots.\\n\\nIt might get complex on big teams, but then again, it\\'s not much different than a real company.\\n\\nSo there\\'s some more building up from each prompt after this one. (Like ask them to generate an example, maybe? And have teamlead/HR bot evaluate it)\\nI didn\\'t get to complete it but setting up a methodology to build my virtual team is a priority and something my boss and me talk about sometimes.\\nThis is part of my initial thoughts and attempts.e```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:04:18 a user named nachos.ai said ```I think I\\'ve heard of the concept.\\nSpun up a team on need, perform the task, then cleanup.```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:03:26 a user named telepathyx said ```but that prompt looks great, gonna play with it```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:02:40 a user named telepathyx said ```yeah definitely. i was just thinking maybe it could create the team dynamically by generating a new config file for it on the fly. for another chat session effectively```.\\n\\nIn ideas-and-feedback, at 2023-09-30 20:01:03 a user named nachos.ai said ```Everything human-readable will do better than code, I think.\\nAlso have read some articles on it.\\nWe have started a migration of xml-based prompt to Markdown prompt and I\\'ve seen improvement - though, it\\'s more on easier modification, less fragile prompting.\\n\\nI was told before I joined the project, that we used json, and it started making mistakes a on a big json.\\n\\nMy assessment is - json (And possibly yaml, although it\\'s more human-readable), is more \"fragile\". \\nWhere-as markdown is more easy to \"fix\". \\n(Imagine the process of predicting the next token went a bit far off the mark, and then aligned back. With json it may have been too rigid, but markdown is more flexiable)```.\\n\\nIn ideas-and-feedback, at 2023-09-30 19:56:20 a user named telepathyx said ```i\\'ve seen people have success with yaml-like formatting```.\\n\\nIn ideas-and-feedback, at 2023-09-30 19:55:49 a user named nachos.ai said ```I\\'m trying to focus on Markdown rather json.\\nIt\\'s more human-like and it had probably trained on tons of .md files.\\nAlso very easy to maintain.```.\\n\\nIn ideas-and-feedback, at 2023-09-30 19:54:37 a user named telepathyx said ```Never know what\\'s going to work tho```.\\n\\nIn ideas-and-feedback, at 2023-09-30 19:54:17 a user named telepathyx said ```I like that! I was thinking maybe a few-shot-prompt for the json config file itself or something```.\\n\\nIn ideas-and-feedback, at 2023-09-30 19:52:21 a user named nachos.ai said ```I have a prompt for it:\\nCan you please design an introductory paragraph of the role of <INSERT_ROLE>? Please phrase it as a command from a boss instructing an interviewee, instead of first person presentation. You will give examples that stress your point. Don’t acknowledge my request- just follow it with the quote, as I will be copy-pasting your response. Start with “You are a…” and finish with “Please acknowledge for confirmation.” Please acknowledge for confirmation.\\n\\nStill requires some improvement, I believe, and maybe more tuning for specific roles, but I just set up a full team.\\nWorked well for all except for QA Automation Engineer```.\\n\\nIn ideas-and-feedback, at 2023-09-30 18:01:27 a user named logangrasby said ```Is there a Javascript version of Autogen by chance that anyone is working on?```.\\n\\nIn ideas-and-feedback, at 2023-09-30 13:15:20 a user named kajatta said ```(ref General) Langchain Toolkits/tool integration to inherit agent capabilities```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:56:47 a user named telepathyx said ```exciting times. automated abundant post scarcity here we come```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:46:22 a user named .princeps said ```Oh you are on to something, let me test it out with these agents then I\\'ll share it```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:45:11 a user named telepathyx said ```the /ts \"town square debate\" function sort of simulates this within a single context window```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:43:54 a user named telepathyx said ```another thing is an \"HR Bot\" that can spin up new bots on demand and add them to a team as per the task requirements. which i think is promising based on the way \"professor synapse CoR\" prompt works so well (https://github.com/ProfSynapse/Synapse_CoR)  the way is spins up specialist agents and creates prompts for them etc```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:38:59 a user named .princeps said ```word! I\\'ll check it out when I start setting up this in my discord```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:37:32 a user named telepathyx said ```the OG dude has had it setup for like 4-5 months at least. his room is discommand.com i think```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:36:19 a user named .princeps said ```@telepathyx have you seen this ?\\n\\nhttps://www.youtube.com/watch?v=yhBiVrigWNI&ab_channel=AIJason```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:35:16 a user named telepathyx said ```so summaries go up and instructions go down. is the idea```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:34:17 a user named telepathyx said ```it was mostly a simulation back then but now it\\'s getting more realistic```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:33:52 a user named telepathyx said ```and a human can pop in anywhere```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:33:12 a user named telepathyx said ```this guy has had this kind of thing setup on discord for a long time. these individual chatrooms are handy. so that context windows aren\\'t exhausted for executives and such.```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:31:26 a user named .princeps said ```@telepathyx I like where you are going with this, can you send me some links```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:30:14 a user named telepathyx said ```easily integrates with stuff like motorhead memory```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:28:03 a user named telepathyx said ```and also the openrouter.ai playground has a ton of different open source LLMs, right now responding in parallel to compare. but it would be cool to have totally LLMs interact as multiagents there, leverage their strengths or fine tuning for specific roles```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:27:25 a user named telepathyx said ```i\\'ve been talking to the guys at flowise about setting up a UI for defining roles/hierarchy for autogen multiagent chat kind of thing. they have a really good UI for langchain chatbots and RAG/ multi-tool use type stuff.```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:22:53 a user named .princeps said ```will be releasing a project today with an agent with tools and another with the internet```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:22:20 a user named .princeps said ```op, good call, let me change that```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:21:45 a user named .princeps said ```hahah thanks fam, just put it out yesterday and I didn\\'t even do it correctly so after work today I decided to clean it up```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:21:23 a user named telepathyx said ```been following autogen search keyword```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:21:23 a user named bansalg said ```@.princeps  btw autogen was moved out of flaml to its separate repo.. sharing in case that is helpful 🙂 https://github.com/microsoft/autogen#quickstart```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:21:07 a user named telepathyx said ```that\\'s hillarious i\\'m 1/3 of the stars on that```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:20:49 a user named .princeps said ```you can clone that project and just add the file above to it and it should work```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:20:32 a user named .princeps said ```https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\\n\\nIn ideas-and-feedback, at 2023-09-30 11:20:24 a user named .princeps said ```it\\'s why I shared the code```.', '\\nIn general, at 2023-09-29 19:58:07 a user named tonic_1 said ```i\\'m trying to find all the cool autogen tutorials / examples from the community and put them here : https://huggingface.co/spaces/MultiTransformer/autogen-tutorials so far , there\\'s only the notebooks and one community example, so if you\\'re happy to share consider adding it to the collection 👊🏻```.\\n\\nIn general, at 2023-09-29 19:46:33 a user named bansalg said ```Ali, what was your experince like with this port? Any key differences you observed that you found helpful?```.\\n\\nIn general, at 2023-09-29 19:21:59 a user named bansalg said ```**Based on the feedback in the forum we created as new issues-and-help forum**\\n\\nhttps://discord.com/channels/1153072414184452236/1157397569375309864```.\\n\\nIn general, at 2023-09-29 19:17:35 a user named pbharrin said ```When code or other artifacts are created such as the stock plotting Python code in `twoagent.py` do these artifacts get saved somewhere?  I\\'m asking because it would be helpful to know where the code lives if I want to modify it.```.\\n\\nIn general, at 2023-09-29 19:23:15 a user named bansalg said ```In the work_dir. In the example below work_dir is set to \"coding\"\\n\\nuser_proxy = UserProxyAgent(\"user_proxy\", code_execution_config={\"work_dir\": \"coding\"})```.\\n\\nIn general, at 2023-09-29 19:13:49 a user named fxtoofaan said ```you interested in local LLM perhaps? I am playing with the fastchat api server and Mistral-7B-v0.1```.\\n\\nIn general, at 2023-09-29 19:12:32 a user named amadad said ```Perhaps...but I\\'m not acquainted with that. Can you share any links?```.\\n\\nIn general, at 2023-09-29 18:57:19 a user named fxtoofaan said ```@amadad  would you be able to connect this to petals api server?```.\\n\\nIn general, at 2023-09-29 18:51:17 a user named amadad said ```Thanks! Struggled with some of the examples, and wanted to share something...once I figured it out.```.\\n\\nIn general, at 2023-09-29 18:50:49 a user named daninvirtualreality said ```Yeah, I agree - having joined all of a few minutes ago, seeing something like this is extremely instructive!```.\\n\\nIn general, at 2023-09-29 18:50:08 a user named fxtoofaan said ```wow thank you @amadad . its good to see actual code and everything in a single python file 🙂```.\\n\\nIn general, at 2023-09-29 18:47:10 a user named amadad said ```Ported over my mini-creative agency from ChatDev to Autogen, no polish or detail yet, but it is working: https://github.com/amadad/agentcy/```.\\n\\nIn general, at 2023-09-29 17:29:56 a user named tonic_1 said ```the beebot is the benchmark to beat on autogtp hackathon : we could make a submission using autogen ?```.\\n\\nIn general, at 2023-09-29 17:22:45 a user named ffund said ```Here\\'s the GitHub repo for Beebot\\n\\nhttps://github.com/AutoPackAI/beebot```.\\n\\nIn general, at 2023-09-29 17:19:37 a user named tonic_1 said ```i just added the notebooks to a space on huggingface so you can run them directly from there too : https://huggingface.co/spaces/MultiTransformer/autogen-tutorials/tree/main hope you put all the experiments in the collection and join the org 👊🏻```.\\n\\nIn general, at 2023-09-29 17:18:44 a user named salegrem said ```I\\'ve kinda been out of it for a couple of months and I\\'m not even able to get autogen running. Does anyone know why I\\'m getting an \"No API key provided\" error when I have an env variable in json, a json file, and literally put it on the llm config```.\\n\\nIn general, at 2023-09-29 19:58:12 a user named bansalg said ```Please feel free to create a post here with more deets so that we can help better 🙂 https://discord.com/channels/1153072414184452236/1157397569375309864```.\\n\\nIn general, at 2023-09-29 17:18:21 a user named pkscary said ```believe beebot is currently the most effective agent-based platform. however, after autogpt\\'s hackathon, that may change.```.\\n\\nIn general, at 2023-09-29 17:17:26 a user named salegrem said ```Nope, this is the third one I\\'m trying to try. Was also using another one on Hugging Face but forgot it\\'s name```.\\n\\nIn general, at 2023-09-29 17:15:56 a user named salegrem said ```Also very dumb and would constanly fall into loops```.\\n\\nIn general, at 2023-09-29 17:15:42 a user named salegrem said ```AutoGPT felt very expensive when I was using it```.\\n\\nIn general, at 2023-09-29 17:15:14 a user named fxtoofaan said ```updated: manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": config_list})\\n\\nstill same error:\\nValueError: dictionary update sequence element #0 has length 1; 2 is required```.\\n\\nIn general, at 2023-09-29 17:18:38 a user named sonichi said ```The config_list needs to be a list. Or, if you want to use a dict, then just set llm_config=the_dict```.\\n\\nIn general, at 2023-09-29 17:19:36 a user named sonichi said ```llm_config is a dict. If you have a single config dict to use, simply set llm_config to that dict. If you have more than one dicts, put them in a list and set llm_config={\"config_list\": config_list}```.\\n\\nIn general, at 2023-09-29 17:20:10 a user named fxtoofaan said ```i just need help with the start part of the python script to conenct with the local LLM. \\n\\n\\nimport autogen\\nfrom autogen import AssistantAgent, UserProxyAgent, oai\\n\\nconfig_list = (\\n    {\\n        \"model\": \"Mistral-7B-v0.1\",\\n        \"api_base\": \"http://localhost:8000/v1\",\\n        \"api_type\": \"open_ai\",\\n        \"api_key\": \"NULL\", # just a placeholder\\n    }\\n)\\n\\nmessages=[{\"role\": \"user\", \"content\": \"hi\"}]\\n\\nresponse = oai.ChatCompletion.create(\\n    prompt=\"hi\",\\n    messages=messages,\\n    config_list=config_list\\n)\\n\\nprint(response)```.\\n\\nIn general, at 2023-09-29 17:20:30 a user named fxtoofaan said ```what should I replace the top section with please? can you copy paste it ?```.\\n\\nIn general, at 2023-09-29 17:21:12 a user named sonichi said ```config_list = [\\n    {\\n        \"model\": \"Mistral-7B-v0.1\",\\n        \"api_base\": \"http://localhost:8000/v1\",\\n        \"api_type\": \"open_ai\",\\n        \"api_key\": \"NULL\", # just a placeholder\\n    }\\n]```.\\n\\nIn general, at 2023-09-29 17:21:16 a user named fxtoofaan said ```for my simplicity sake I like to keep everything in a single python file if possible instead of calling json files for config_list```.\\n\\nIn general, at 2023-09-29 17:21:47 a user named fxtoofaan said ```what about this part?\\n\\nmessages=[{\"role\": \"user\", \"content\": \"hi\"}]\\n\\nresponse = oai.ChatCompletion.create(\\n    prompt=\"hi\",\\n    messages=messages,\\n    config_list=config_list\\n)\\n\\nprint(response)```.\\n\\nIn general, at 2023-09-29 17:24:49 a user named fxtoofaan said ```Let me try it 👍```.\\n\\nIn general, at 2023-09-29 17:40:15 a user named vincentjedi said ```Are you using fastchat as the llm server ?```.\\n\\nIn general, at 2023-09-29 17:49:38 a user named vincentjedi said ```Will u try vllm to replace fastchat ?```.\\n\\nIn general, at 2023-09-29 17:50:26 a user named fxtoofaan said ```ok os using [] instead of () worked. thank you @sonichi```.\\n\\nIn general, at 2023-09-29 17:50:40 a user named fxtoofaan said ```i never used vllm, does it work on windows 10 ?```.\\n\\nIn general, at 2023-09-29 17:54:53 a user named vincentjedi said ```U use Nvidia GPU to run it ?```.\\n\\nIn general, at 2023-09-29 17:55:32 a user named vincentjedi said ```How is the inference speed ?```.\\n\\nIn general, at 2023-09-29 17:56:08 a user named vincentjedi said ```How much vram do you have ?```.\\n\\nIn general, at 2023-09-29 17:57:07 a user named vincentjedi said ```My Nvidia GPU only has 4gb vram. So I think i am going to use cpu only ..```.', '\\nIf this is included anywhere and i\\'ve missed it pls let me know!\\n\\nHappy to also make a contribution if this would be useful for other folks```.\\n\\nIn ideas-and-feedback, at 2023-10-02 00:18:20 a user named gb4de said ```Hey guys, trying to figure out a smart way to get autogen to spin our long form posts (700 words+) it seems to stall at 650 at the moment. I tried creating a team with two writers and that didn\\'t work so well (still only 650 output). Are there any ideas out there to help reliably produce lengthy content?```.\\n\\nIn ideas-and-feedback, at 2023-10-02 06:13:31 a user named sonichi said ```I suggested some ideas in this thread: https://github.com/microsoft/autogen/discussions/67```.\\n\\nIn ideas-and-feedback, at 2023-10-02 10:16:28 a user named gb4de said ```Thanks man!!! Will try it out and share if I come up with an elegant solution```.\\n\\nIn ideas-and-feedback, at 2023-10-01 23:07:45 a user named wiiiktor. said ```I am using RAG-agent and it works pretty ok, but it gives me ~10 answers instead of just one or two, and it does not explicitly write anything like \"I do not have enough information\". It just spits out proper answers, only many times. I set the setting max_consecutive_auto_reply=1 but this does not change anything.```.\\n\\nIn ideas-and-feedback, at 2023-10-02 06:09:07 a user named sonichi said ```@li_jiang this may be of your interest```.\\n\\nIn ideas-and-feedback, at 2023-10-02 11:33:25 a user named li_jiang said ```Could you share more details so that I can reproduce the issue? @wiiiktor.```.\\n\\nIn ideas-and-feedback, at 2023-10-04 11:28:04 a user named wiiiktor. said ```Sure, please, find my code here: https://github.com/wiiiktor/resume/tree/main/data/autogen-bug There is a python file with a very small dataset. In the meantine, I updated tokenizers (PyCharm told me so) and error is different now, but still a similar tune: RuntimeError: Failed to import transformers.models.nystromformer because of the following error (look up to see its traceback):\\nmaximum recursion depth exceeded while calling a Python object```.\\n\\nIn ideas-and-feedback, at 2023-10-04 11:35:00 a user named wiiiktor. said ```name = \"tokenizers\"\\nversion = \"0.14.0\" -> this is what I have now```.\\n\\nIn ideas-and-feedback, at 2023-10-05 14:55:58 a user named li_jiang said ```Thanks @wiiiktor. , I\\'ve created an issue in github https://github.com/microsoft/autogen/issues/117 , will look into it later.```.\\n\\nIn ideas-and-feedback, at 2023-10-08 15:29:31 a user named li_jiang said ```@wiiiktor. , could you try the fix in this PR https://github.com/microsoft/autogen/pull/155 to see if it solve the issue you see? Thanks.```.\\n\\nIn ideas-and-feedback, at 2023-10-01 22:43:39 a user named harmonious_quail_59808 said ```How can i min3 crypto in , a laptop chrome os, with shared SO linux```.\\n\\nIn ideas-and-feedback, at 2023-10-01 20:00:46 a user named _p_i_ said ```@sonichi As you\\'re getting some serious traction on autogen, I\\'ll write.\\n\\nI found myself in the role of coordinating AutoGPT during the early days, when it was getting over several thousand GitHub stars a day.\\n\\nThere are several things I would have done differently if I could replay those few weeks.\\n\\nOne was that the core team (which was at the time weak, and dynamically assembling) was pushed onto the back foot by the volume of user-engagement and code contributions.\\n\\nIf we had assembled a public roadmap and contribution guide much earlier we could have channeled this energy.\\n\\ni.e. if we had just pointed willing contributors to: \"This is our kanban, here\\'s our wiki/doc showing what we\\'re working on and why, and where we\\'d appreciate help\" we could have gone a long way towards bridging the gap.```.\\n\\nIn ideas-and-feedback, at 2023-10-02 02:05:33 a user named sonichi said ```Thanks you so much for chiming in. Looking forward to your insights to help doing this right.```.\\n\\nIn ideas-and-feedback, at 2023-10-02 05:50:09 a user named sonichi said ```@qingyunwu created an issue https://github.com/microsoft/autogen/issues/70. Is that a good way to start or do you recommend sth. else @_p_i_ ?```.\\n\\nIn ideas-and-feedback, at 2023-10-01 18:14:45 a user named guardiang said ```Are there any limitations or issues that might make combining AutoGen capabilities with say, LlamaIndex?```.\\n\\nIn ideas-and-feedback, at 2023-10-01 16:43:05 a user named sonichi said ```Please check https://discordapp.com/channels/1153072414184452236/1157419832443150447 and https://discordapp.com/channels/1153072414184452236/1157447399044821132```.\\n\\nIn ideas-and-feedback, at 2023-10-01 16:31:16 a user named orderandchaos_at_work said ```I\\'m interested in using Autogen agents to write well tested rest apis with fastapi, pydantic and pytest. I\\'d like the app to to take in specs and write the api endpoints and use pytest to test it works as expected.\\n\\nI\\'d like to be able to request new endpoints to be added to an existing project that follows that structure.```.\\n\\nIn ideas-and-feedback, at 2023-10-01 16:09:00 a user named vbhankas said ```Same thing for different domains where you need collaboration of experts to achieve results…retirement planning (investment expert, social security/medicare expert, tax expert, insurance expert, health expert for seniors, fun and healthy activities for seniors```.\\n\\nIn ideas-and-feedback, at 2023-10-01 16:08:38 a user named vbhankas said ```Are there any practical examples?\\nSome ideas - given a project idea, have different agents/personalities create needed artifacts. Expert scrum master agent to write epics, features and stories, developer agent to write the code, QA agent to write test scripts, devops agent to setup pipelines, UAT agent to validate business requirements```.\\n\\nIn ideas-and-feedback, at 2023-10-01 14:36:30 a user named sonichi said ```Function call is one way to do that indeed.  Or create a \"manager\" agent that decides which subagent to use... Many interesting possibilities!```.\\n\\nIn ideas-and-feedback, at 2023-10-01 14:33:29 a user named r3cursivee said ```That\\'s a good question.  I\\'m guessing that multiple agents for different tasks would be easier/cleaner to implement.  You could already have multiple instances of AssistantAgent with different configs.  But then, if interacting w/ UserAgent in a single thread, it still needs to know how to decide between them based on the task?   \\nAnother avenue is that UserProxyAgent can already use functions, so an external LLM could be slotted in there as another function.   If I had to PoC something in a notebook I would probably try that first.```.\\n\\nIn ideas-and-feedback, at 2023-10-01 14:17:53 a user named sonichi said ```Interesting idea. Do you think we should use multiple agents for these different tasks, or one agent with multiple models?```.\\n\\nIn ideas-and-feedback, at 2023-10-01 14:12:53 a user named r3cursivee said ```I\\'d like the ability for AutoGen to figure out which LLM is best to use based on the task - or at least, to specify a different LLM for coding vs. writing questions.  I could PoC this if I figure out what needs changing. So it already takes multi-model config sort of, but the message parameter to ChatCompletion.create() doesn\\'t specify which model the request should go to?```.\\n\\nIn ideas-and-feedback, at 2023-10-01 13:53:07 a user named tonic_1 said ```try gradio ? super simple to set up i have some examples  on my organisation as well (all in python - dont know if that helps or not)```.\\n\\nIn ideas-and-feedback, at 2023-10-01 13:03:01 a user named loprz said ```A GIS dependency checker with visualization.```.\\n\\nIn ideas-and-feedback, at 2023-10-01 12:58:56 a user named ansonparker said ```i want to see autogebn inside of flowwise or langflow... take the visualizations you have on the microsoft site and make that the interface```.\\n\\nIn ideas-and-feedback, at 2023-10-01 12:22:03 a user named abhaylatta said ```want to build a backend problem solver```.\\n\\nIn ideas-and-feedback, at 2023-10-01 07:31:15 a user named vincentjedi said ```U r going to beat jpmorgan with autogen. https://www.cnbc.com/2023/05/25/jpmorgan-develops-ai-investment-advisor.html```.\\n\\nIn ideas-and-feedback, at 2023-10-01 07:05:37 a user named dalipyadav68 said ```tell how it can be used more effectively for majing AI project```.\\n\\nIn ideas-and-feedback, at 2023-10-01 07:04:56 a user named dalipyadav68 said ```i want build an AI enable app which help student to learn code in most engaging way```.\\n\\nIn ideas-and-feedback, at 2023-10-01 06:14:34 a user named kings530 said ```Building an app that lets ai to do all the finance research for stock selection```.\\n\\nIn ideas-and-feedback, at 2023-10-01 05:30:32 a user named jasonzhou1993 said ```actually i just found the way to do that in this example\\nhttps://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb```.\\n\\nIn ideas-and-feedback, at 2023-10-01 05:16:47 a user named uttamdinodia said ```Copilot in Microsoft Office apps```.\\n\\nIn ideas-and-feedback, at 2023-10-01 05:09:34 a user named jasonzhou1993 said ```yea thats the structure im thinking about as well - however i couldn\\'t figure out ways to get result from the group chat; (e.g. at the moment i use user_proxy.initiate_chat to trigger an agent, it only display the full chat history in terminal; however, i dont see a way to return the results, like how i use in langchain; not sure if i communicate the challenge clearly. LOL)```.\\n\\nIn ideas-and-feedback, at 2023-10-01 04:56:23 a user named cajukev said ```Though I haven\\'t seen an implementation of it yet.```.\\n\\nIn ideas-and-feedback, at 2023-10-01 04:55:44 a user named cajukev said ```The way I\\'m thinking about is that you would create an agent that serves as a wrapper around a group - meaning that once that agent is called upon it would start a nested chat with its group.```.\\n\\nIn ideas-and-feedback, at 2023-10-01 04:47:58 a user named jasonzhou1993 said ```Is it possible to put a group chat manager in another group chat? \\n\\nso that i can start building more complicated workflow```.\\n\\nIn ideas-and-feedback, at 2023-10-01 04:07:40 a user named li_jiang said ```Hi @wiiiktor. , could you try with the latest main branch code? There was a bug and the fix has been merged.```.\\n\\nIn ideas-and-feedback, at 2023-10-01 03:49:25 a user named sonichi said ```There is a thread: https://discordapp.com/channels/1153072414184452236/1157434279891050607. @li_jiang```.\\n\\nIn ideas-and-feedback, at 2023-10-01 02:42:17 a user named wiiiktor. said ```I need help. I am making my version of the ragproxyagent which needs data from my small .jsonl file. All good, but my file has 75 chunks, and the application is shouting it should have 40000 🙂 What can I do? These are the \"bad guys\" that I need to convince to cooperate 😉         \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\\n        \"collection_name\": \"2wikimultihopqa\",```.\\n\\nIn ideas-and-feedback, at 2023-09-30 21:06:33 a user named telepathyx said ```could generate and embed a \"training manual\" in addition to convo history that\\'s more extensive than a system prompt```.\\n\\nIn ideas-and-feedback, at 2023-09-30 21:04:00 a user named telepathyx said ```https://github.com/embedchain/embedchain this is quite easy and clean to work with```.', '\\nIt might be cool to make a audio visual slideshow, where the images generated are synchronized to where they come up in the story. \\n\\nTo make all this automated like clockwork may be hard. For now I\\'m screwing around with controlling things myself.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 05:29:18 a user named pika.c said ```I am working on a similar idea but instead of taking user input, I am planning on something that works completely by itself and also adds \"Characters\" as agents dynamically to the story. https://github.com/toshNaik/TaleCraft/tree/main```.\\n\\nIn ideas-and-feedback, at 2023-11-14 05:24:16 a user named pika.c said ```@_jojorge Are you working on making LLM driven stories?```.\\n\\nIn ideas-and-feedback, at 2023-11-14 04:55:58 a user named _jojorge said ```@sonichi you might want to put this up on the github. Others may want to be able to use this. I started with your custom group chat, and gave the human agent way more control. Now, we dont have to build immaculate workflows and system messages that yield the desired emergent behavior. We can direct swarms of agents with turn-based precision and directed messages before each prompt.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 04:52:26 a user named _jojorge said ```Thanks for the tips! I got it working!\\n\\n```python\\nclass CustomGroupChat(GroupChat):\\n    def __init__(self, agents, messages, max_round=10):\\n        super().__init__(agents, messages, max_round)\\n\\n    def select_speaker(self, last_speaker: Agent, selector: ConversableAgent):\\n        # Display a list of agents with numbers\\n        for i, agent in enumerate(self.agents):\\n            print(f\"{i + 1}: {agent.name}\")\\n\\n        while True:\\n            try:\\n                choice = int(input(\"Select the number of the agent to respond: \")) - 1\\n                if 0 <= choice < len(self.agents):\\n                    selected_agent = self.agents[choice]\\n\\n                    # Check if the user wants to inject a custom message\\n                    custom_message = input(\"Type your message (or press Enter to skip): \").strip()\\n                    if custom_message:\\n                        # Send the custom message to the selected agent via the GroupChatManager\\n                        message_dict = {\"content\": custom_message, \"agent_name\": selected_agent.name}\\n                        selector.send(message_dict, selected_agent)\\n\\n                    return selected_agent\\n                else:\\n                    print(\"Invalid number. Please try again.\")\\n            except ValueError:\\n                print(\"Please enter a valid number.\")\\n```\\n\\nI modified the `CustomGroupChat` class and got it working perfectly!```.\\n\\nIn ideas-and-feedback, at 2023-11-14 04:18:36 a user named pika.c said ```Ahh got it. Maybe this might work then? https://github.com/microsoft/autogen/blob/main/notebook/agentchat_hierarchy_flow_using_select_speaker.ipynb You can set NEXT: Admin to always call the user proxy agent. Kind of a hacky way to go about it but should work.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 03:45:01 a user named _jojorge said ```I dont think that is going to do it. There are only three options: \"TERMINATE\", \"NEVER\". (1) When \"ALWAYS\". And these options only come into play when the UserProxyAgent is called, which isnt every time. This is an attribute that is part of the UserProxyAgent, so I dont think it comes into play when one AI agent is talking to another AI agent. I set the value to \"ALWAYS\" and it does not give me the control I seek.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 03:31:48 a user named pika.c said ```The UserProxyAgent has a human_input_mode attribute https://microsoft.github.io/autogen/docs/reference/agentchat/user_proxy_agent which I think is what you want```.\\n\\nIn ideas-and-feedback, at 2023-11-14 03:23:18 a user named _jojorge said ```I want to be able to choose, at each step, which agent responds. Imagine, for example, that after each response from an agent, I am presented with a numbered list of agents. I either pick a number, and that agent responds to the previous message, or I pick a number and write a message. For example, if the planner says: lets divide the problem in two parts and have the executor build both parts, I am presented with:\\n1) planner\\n2) executor\\n3) checker\\n\\nI can select 1, and say: I dont like that plan. Come up with something that considers XXX\\nI can select 2, and say nothing, at which point, the executor follows the plan\\nI can select 2, and say: lets follow the plan, except do it in three parts\\nI can select 3, and say nothing, at which point, the checker will see if the planner followed all previous inputs\\nI can select 3, and say: did the planner remember all the requirements?\\n\\nThis would be great! I would be able to direct conversations with a dozen agents, and not worry about things going down rabbit holes, or having to preplan workflows.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 00:28:50 a user named aaronward_ said ```i\\'m having issues with my agents not using the provided tool, wondering if someone could give me help - the user proxy keeps trying to run the sql rather than pass it as a string to a python function which is registered.\\n\\nI\\'m testing out the nee GPTAssistantAgent with a postgres  sql operation \\n\\nhttps://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/14.openai-assistant-api/OpenAi-assistant-with-autogen.ipynb```.\\n\\nIn ideas-and-feedback, at 2023-11-13 23:25:19 a user named pankaj_chandravanshi said ```Hi @pauldtyler , have you got any lead on this?```.\\n\\nIn ideas-and-feedback, at 2023-11-13 01:44:34 a user named sonichi said ```If anyone is interested in implementing it with autogen or already working on it, could you please let @jiale_liu know?```.\\n\\nIn ideas-and-feedback, at 2023-11-13 01:35:24 a user named sonichi said ```It uses a multi-agent approach.```.\\n\\nIn ideas-and-feedback, at 2023-11-13 01:34:51 a user named sonichi said ```https://blog.polywrap.io/p/evo-wins-autogpt-arena-hackathon```.\\n\\nIn ideas-and-feedback, at 2023-11-12 15:01:37 a user named sonichi said ```For a conversation to be effective, it needs to follow a good order. Certain degrees of async is allowed and the communication interface is also async-compatible. The implementation is sync first, which is easiest to program.```.\\n\\nIn ideas-and-feedback, at 2023-11-12 14:53:02 a user named charonthegondolier said ```Is there a philosophical reason autogen isn\\'t \\'async\\' first?  in my own agent framework - i basically made everything async because you never know what a user will want to do that\\'s going to call a remote service or whatever and need to be awaited.```.\\n\\nIn ideas-and-feedback, at 2023-11-12 08:47:37 a user named mertbozkir said ```I\\'m building some kind of a swarm agent capable of building fastapi or aws cdk apps```.\\n\\nIn ideas-and-feedback, at 2023-11-12 06:32:19 a user named alexpwrd said ```does Autogen have support for Cohere models?```.\\n\\nIn ideas-and-feedback, at 2023-11-11 16:02:32 a user named beep_38401 said ```\"max_tokens\" is your friend xD```.\\n\\nIn ideas-and-feedback, at 2023-11-11 09:00:08 a user named ait.paca said ```Thank you for pointing it out, and thanks also to @aaronward_ for sharing his knowledge 🙏```.\\n\\nIn ideas-and-feedback, at 2023-11-11 00:24:40 a user named monkmartinez said ```I am experimenting with localAI first to mitigate the potential $$$$ problems.```.\\n\\nIn ideas-and-feedback, at 2023-11-10 17:47:14 a user named afourney said ```If using the latest stable release, see here: https://microsoft.github.io/autogen/docs/reference/oai/completion#start_logging```.\\n\\nIn ideas-and-feedback, at 2023-11-10 17:44:48 a user named afourney said ```It does via the logging interface in the 0.1 branch of Autogen. However this capability was broken in the newer 0.2 branch (in beta), because the OpenAI library had a major changed. We are in the process of re-adding it.```.\\n\\nIn ideas-and-feedback, at 2023-11-10 17:11:20 a user named cosmojg said ```Does AutoGen count tokens and/or estimate costs in a transparent way? If not, that would be a great feature to add!```.\\n\\nIn ideas-and-feedback, at 2023-11-10 14:14:23 a user named 01011_balachandar said ```What does the api endpoint should look like for autogen for it to support.\\nI am not using lmstudio because I do not have a local GPU. I do not want to use run pod also.\\nSo I am using cloud hosted model which I am getting for free but I want to build an api wrapper around it so that it can support autogen like lmstudio.\\nCan anyone pls help.```.\\n\\nIn ideas-and-feedback, at 2023-11-10 06:25:28 a user named candcji4jg.wam said ```I would like AutoGen to build and large scale web app/mobile platform from scratch and grown into maintaining and developing it long term.```.\\n\\nIn ideas-and-feedback, at 2023-11-10 02:18:50 a user named 01011_balachandar said ```i want to use llama 2 7b chat hosted at together ai in autogen can anyone help me out?```.\\n\\nIn ideas-and-feedback, at 2023-11-10 00:57:23 a user named kajatta said ```All his examples are dope```.\\n\\nIn ideas-and-feedback, at 2023-11-10 00:57:12 a user named kajatta said ```Aaron is a legend @aaronward_```.\\n\\nIn ideas-and-feedback, at 2023-11-10 00:57:07 a user named kajatta said ```https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen```.\\n\\nIn ideas-and-feedback, at 2023-11-10 00:55:16 a user named kajatta said ```Yep already an example for this```.', '\\nIn general, at 2023-10-04 10:02:00 a user named morfes said ```more info about this card https://youtu.be/Z5Isf6Airo0```.\\n\\nIn general, at 2023-10-04 09:49:12 a user named morfes said ```hey guys, can this card do good job working with LLM on i7 /25G RAMs?```.\\n\\nIn general, at 2023-10-04 09:41:36 a user named mvs4414 said ```Hi .I am new to this server . Can anyone tell me about this server ?```.\\n\\nIn general, at 2023-10-04 09:32:56 a user named slagado. said ```@ghostmaker001 \\nDid you find the reason why you are running out of tokens? \\nHow many tokens are included in the \"GPT-4 for US-$ 20 per month\" subscription included?\\n\\nRead some posts here in discord that also others facing the \"issue\" that AutoGen needs a lot of tokens ...\\n\\nSeems AutoGen is very expensive! \\nMay be I could not effort it. 😕 \\nAgain a (very streamed) technology (trend) for rich people 😦```.\\n\\nIn general, at 2023-10-04 09:31:14 a user named litinit said ```well, like, autogen is a python library```.\\n\\nIn general, at 2023-10-04 09:22:36 a user named kikkerd said ```Less noise in the context just makes the attention mechanism in transformers perform better, is that what could make these group chats superior?```.\\n\\nIn general, at 2023-10-04 09:18:48 a user named neoliminal said ```Are the roles/goals set in the \\'system_message\\' for each agent, I assume? 😳```.\\n\\nIn general, at 2023-10-04 09:15:14 a user named neoliminal said ```How do I control which agents can speak to each other and how do I define their individual roles/goals?```.\\n\\nIn general, at 2023-10-04 09:15:06 a user named shade.name said ```I know it beacuse of 👆```.\\n\\nIn general, at 2023-10-04 09:13:56 a user named neoliminal said ```I saw the video on YouTube```.\\n\\nIn general, at 2023-10-04 09:03:28 a user named cosmickrover said ```Then maybe see what I can do with app development```.\\n\\nIn general, at 2023-10-04 09:02:28 a user named cosmickrover said ```I would like to understand the capabilities first.```.\\n\\nIn general, at 2023-10-04 08:29:20 a user named lb0273 said ```is there any example with the following: https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/math_user_proxy_agent/https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/math_user_proxy_agent/```.\\n\\nIn general, at 2023-10-04 13:31:20 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_MathChat.ipynb\\nFor questions about this notebook please ask @kevinwyr```.\\n\\nIn general, at 2023-10-04 08:20:08 a user named thedasenqueen said ```So does Autogen only use python? or can it make applications in other languages?```.\\n\\nIn general, at 2023-10-04 08:15:37 a user named kikkerd said ```Hi. I had the chess example spend about $2 in less than a minute. After that it got rate limited using gpt4. Anything obvious that I could be doing wrong?\\n\\nI did notice that it wasn\\'t showing the SVG chess board.```.\\n\\nIn general, at 2023-10-04 07:50:06 a user named KLANe4H said ```I got to know it from Searching the web```.\\n\\nIn general, at 2023-10-04 07:10:49 a user named fxtoofaan said ```How to load TheBloke/Mistral-7B-OpenOrca-GGUF/ files in fastchat/vllm? \\nLike if I want to run the mistral-7b-openorca.Q8_0.gguf model in fastchat/vllm how do I reference it?\\n\\nI have tried these but no luck:\\npython3 -m vllm.entrypoints.openai.api_server --model ./mistral-7b-openorca.Q8_0.gguf \\n\\npython3 -m vllm.entrypoints.openai.api_server --model TheBloke/Mistral-7B-OpenOrca-GGUF\\n\\npython3 -m vllm.entrypoints.openai.api_server --model /home/aitoofaan/LLMs/models/Mistral-7B-OpenOrca-GGUF/\\n\\nlike how do you serve GGUF models using fastchat/vllm ?```.\\n\\nIn general, at 2023-10-04 05:27:46 a user named shiccup said ```now imagine auto gen but its like a council telling a robot how to move```.\\n\\nIn general, at 2023-10-04 05:27:16 a user named shiccup said ```google just released a vision language action model```.\\n\\nIn general, at 2023-10-04 05:26:56 a user named shiccup said ```https://www.youtube.com/watch?v=GZdytTKeGYM```.\\n\\nIn general, at 2023-10-04 03:35:42 a user named li_jiang said ```Hi @jasonzhou1993 , here it is https://mp.weixin.qq.com/s/OFbZyC0_M3uBJlOhQIKJLg.  This account is actually just for me to easily share things to my friends.```.\\n\\nIn general, at 2023-10-04 02:26:53 a user named elcapitan__ said ```Please please tell me what u end up doing. I created all my agents in just trying to get them to communicate with eachother now. I thought autogen offered this frameworks```.\\n\\nIn general, at 2023-10-04 02:26:08 a user named .trouble_ said ```I\\'m doing something similar to this now```.\\n\\nIn general, at 2023-10-04 02:14:46 a user named andyinater said ```You\\'re right, I completely forgot. I had at least one example saved in a folder, forgot it on the push.\\n\\nTomorrow I will regenerate some and toss them in an examples folder.```.\\n\\nIn general, at 2023-10-04 02:05:34 a user named juanfrank77 said ```That\\'s incredible for sure. It\\'d be cool to have those games as examples of what can be done with the framework so others folks can join.```.\\n\\nIn general, at 2023-10-04 01:57:35 a user named shaneyu said ```https://github.com/microsoft/autogen/issues/96```.\\n\\nIn general, at 2023-10-04 01:52:58 a user named elcapitan__ said ```or am i going the wrong route```.\\n\\nIn general, at 2023-10-04 01:49:20 a user named elcapitan__ said ```someone @ me if you have an answer lol```.\\n\\nIn general, at 2023-10-04 01:47:50 a user named elcapitan__ said ```AutoGen primarily focuses on automating the generation of reinforcement learning models and does not inherently provide a framework for agent communication (right? or am i wrong?). I feel like establishing a multi-agent system with conversational abilities requires a more sophisticated setup with integration with a library like SPADE.```.\\n\\nIn general, at 2023-10-04 01:46:20 a user named elcapitan__ said ```does anyone know if integrating SPADE with AutoGen to allow for the agents created with AutoGen to communicate via SPADE\\'s protocols.```.\\n\\nIn general, at 2023-10-04 00:57:18 a user named andyinater said ```Hey everyone,\\n\\nI just pushed a large overhaul to <#1158564427117903882> . It works much better now - I have managed to zero shot snake, breakout, connect 4, tic tac toe, and some weird rendition of asteroids that was more of a leapfrog game. \\n\\nMost of the performance improvement comes from prompt overhauls, both clarity as well as logic. Even if you don\\'t try the repo out, I think the diffs on the system prompts are a good example of bad vs good.\\n\\nDocumentation updates will lag, but it is now easier to run.```.\\n\\nIn general, at 2023-10-04 00:55:40 a user named li_jiang said ```Right, I’ll find some time to work on it in a few days. Would you like to create an issue in github so we can track it? @shaneyu```.\\n\\nIn general, at 2023-10-04 00:54:26 a user named zespind said ```for community-driven hosting that\\'s a huge hurdle```.\\n\\nIn general, at 2023-10-04 00:53:51 a user named zespind said ```tbh the drivers for amd are so messy and most llm libraries use like 4 machine learning stacks```.\\n\\nIn general, at 2023-10-04 00:31:46 a user named enragedporcupine said ```anyway apols for all the msgs -- super excited about autogen. & glad to see it gaining steam despite being fairly under the radar. (MS is doing so much amazing stuff right now re: O365 / copilot / etc. -- much of which I\\'m on beta/preview channel for.)```.\\n\\nIn general, at 2023-10-04 00:30:33 a user named enragedporcupine said ```I think I need a legit, human tutor. someone who I can explain what I know, what I don\\'t know, and them to tell me \"you need to learn these concepts...\" then come back, etc etc```.\\n\\nIn general, at 2023-10-04 00:29:50 a user named enragedporcupine said ```checked petals out a while back -- maybe should revisit.```.\\n\\nIn general, at 2023-10-04 00:28:00 a user named enragedporcupine said ```my line of work has little to do with this space (although I\\'m encouraging everyone to get onboard) -- this is my nights/weekends *hardcore* investment, continuing education-wise, since Nov last year.```.\\n\\nIn general, at 2023-10-04 00:26:41 a user named enragedporcupine said ```but I did web-dev in the 90\\'s, BBS\\'s, IRC, old-school stuff, and a bit of coding *way* back (seems totally obsolete now).. know *basic* python (still horrendous.)  just familiarized myself with docker, venvs, etc...```.\\n\\nIn general, at 2023-10-04 00:25:33 a user named enragedporcupine said ```like... my sys environment path variables are a nightmare, I\\'m 99% sure I have at least 5-6x conflicting versions of python/MS distributables... I recently bought a home server that\\'s \"clean\" for remote desktop/docker purposes only... don\\'t know the first thing about remote access (outside of MS remote via MS auth)... have GCP/AWS/Azure/Replit/Codespaces running full blast... I\\'m like a kid in a candy shop with a little too much money (*NOT* long-term -- viewing this all as an investment) -- who doesn\\'t know what to buy or how to consume 😉```.\\n\\nIn general, at 2023-10-04 00:24:04 a user named .beibinli said ```Hi everyone, I created a tutorial on how to support open source model in the PR here, please take a look at my notebook: https://github.com/microsoft/autogen/blob/osllm/notebook/open_source_language_model_example.ipynb\\n\\nAny suggestions are welcome. <#1158548894209282078>```.\\n\\nIn general, at 2023-10-04 00:24:04 a user named shinypickel said ```what are the other uses cases? \\n\\nI was trying to build something to help research businesses/companies to acquire.```.\\n\\nIn general, at 2023-10-04 00:23:54 a user named lcbusby said ```Saw a videoo on youtube```.\\n\\nIn general, at 2023-10-04 00:23:40 a user named enragedporcupine said ```(i know software but am a horrendous coder / am a total amateur.)```.\\n\\nIn general, at 2023-10-04 00:23:23 a user named enragedporcupine said ```been following this space since.. GPT2-ish days```.\\n\\nIn general, at 2023-10-04 00:23:08 a user named enragedporcupine said ```but I\\'ve got dozens of use cases. maybe 50+```.', '\\nIn ideas-and-feedback, at 2023-09-29 01:03:13 a user named wally_5040 said ```btw, @sonichi : I really think this server needs a *meme* section/channel 😉```.\\n\\nIn ideas-and-feedback, at 2023-09-29 00:36:19 a user named wally_5040 said ```@sonichi Just came by to say: What an impressive project! I see that some of the problems other \"agent\"-system struggle with are solved in quite interesting (borderline brilliant) ideas! 🤗 \\nThanks for the code.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 22:08:44 a user named shubhdi5cord said ```I was thinking of using autogen to mock the SDLC process for feature development. \\nIf anyone\\'s interested... please feel free to share your approach here.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:18:57 a user named shaneyu said ```Hi @sonichi, I was analyzing math_user_proxy_agent.py, I originally thought it would utilize most of the functions from math_utils.py, however, I found that it mostly depends on execute_one_python_code, and wolfram api call (if requested). Is there a reason why most functions in math_utils are neglected (code generation did a good job by itself lol)? Also, are we using pure llm to approve the answer here (i.e assistant agent says yes)? I thought I was reading somewhere that Autogen has matrix to evaluate code/math results, correct me if Im wrong\\U0001fae1 . Thanks in advance!```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:26:04 a user named sonichi said ```The math_utils needs an update. @kevinwyr has done good work about it.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:31:01 a user named shaneyu said ```Appreciated! Guess I\\'ll wait and see! Thanks for the great work!```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:36:28 a user named kevinwyr said ```Hello @shaneyu, thank you for your interest. The some of math_utils are pulled from utils of MATH dataset, to extract and compare results. Do you intend to use Autogen to evaluate math results?```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:47:36 a user named shaneyu said ```Hi Kevin, thanks for the reply. I am actually interested in how Autogen\\'s math agent confirms a correct answer is actually correct. From the code, it seems at this point, it still relies on assistant agent\\'s (llm) saying: Ah, I think this is correct. I thought I was reading in the paper or elsewhere that Autogen has some matrix to evaluate the result. Maybe I\\'m hallucinating as well lol🤣```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:49:12 a user named shaneyu said ```So in short, math_util is used internally to see how math_agent performs, not involved in actual solving problems right?```.\\n\\nIn ideas-and-feedback, at 2023-09-28 22:21:01 a user named sonichi said ```1. There is some standard evaluation function in math_util. They are not always reliable.\\n2. math_util is not involved in actual solving right now, although the voting function will be useful if you solve one problem multiple times.\\n3. \"how Autogen\\'s math agent confirms a correct answer is actually correct.\" Improving that would be interesting, e.g., by introducing additional agents. I\\'d love to hear your thoughts.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 22:54:18 a user named shaneyu said ```adding more agents for cross examination is the easiest way to do it I think. Another way is to use fine-tuned model. How to settle it down to code really needs some eureka moment.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:15:30 a user named tonic_1 said ```started trying to get cognitive search set up correctly, and ollama also for flowise, someone i know is trying to make an enterprise version, so azure is a natural choice aswell```.\\n\\nIn ideas-and-feedback, at 2023-09-28 21:14:39 a user named tonic_1 said ```yeah i do love flowise```.\\n\\nIn ideas-and-feedback, at 2023-09-28 18:28:21 a user named magiccow2 said ```Yo, thanks a lot. I downloaded VS Code earlier today hoping that was the right path and was going to investigate today. Thanks for the clear instructions!```.\\n\\nIn ideas-and-feedback, at 2023-09-28 17:11:38 a user named felly007. said ```After you got the virtual env working, you can pip install autogen and copy and paste the code from microsoft Github to start```.\\n\\nIn ideas-and-feedback, at 2023-09-28 17:10:53 a user named felly007. said ```Debugging is majority of writing code (not an expert here but practising for a while) \\n\\nI ran it in Collab as a test and VS code to work with autogen. I prefer VS code.\\n\\nFrom a high level, I would follow this: \\n\\n- Install Visual Studio Code (VS Code): Download from VS Code\\'s site and follow setup instructions.\\n- Install Python: Download from Python\\'s site and install. During installation, check \"Add Python to PATH\".\\n- Open VS Code: Launch it and go to Extensions (left sidebar, looks like squares) and install Python extension.\\n- Set Up Folder: Create a new folder for your project. Open it in VS Code (File -> Open Folder).\\n- Terminal: Open terminal in VS Code (Terminal -> New Terminal).\\n- Virtual Environment: In the terminal, type python -m venv myenv to create a virtual environment called myenv.\\nActivate Env:\\nWindows: Type .\\\\myenv\\\\Scripts\\\\Activate\\nMacOS/Linux: Type source myenv/bin/activate\\n- Install Packages: In terminal, type pip install openai or any other package you need.\\n- Write Code: Create a new Python file (e.g., main.py) in your folder and start coding.\\n- Run Code: Save the file, go to terminal, type python main.py to run it.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 14:19:52 a user named magiccow2 said ```I feel like once I get the foundational layers there, I can tool around and figure out the rest. But continually running in to missing this, missing that, can\\'t run in this particular platform.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 14:18:38 a user named magiccow2 said ```I\\'m in the same boat. Lots of non-programming folks taking interest in this stuff now (because chatGPT has allowed us to do some cool stuff and now we want more God powers). But there\\'s a certain degree of foundational knowledge we don\\'t have that\\'s very much common sense to people who\\'ve been coding for a while. \\n\\nI\\'m trying to figure it out and I\\'ll share what I learn. But wondering if anyone with a little know how can point to some good resources. \\n\\nDo I do this all in terminal? Should I do it in Jupyter Notebooks? VS Code? \\n\\nWhat base other stuff do I need?```.\\n\\nIn ideas-and-feedback, at 2023-09-28 13:46:01 a user named fxtoofaan said ```would be nice to have a sample project in .py files format and not in jupyter notebooks format. I am having hard time to figure out how to convert online jupyter files to local python files. If a sample or example can be written in python files to be run locally that would be awesome. Non-Programmer here  🙏```.\\n\\nIn ideas-and-feedback, at 2023-09-28 12:55:25 a user named 2good4hisowngood said ```I hope you don\\'t mind, I\\'m going to put in a github issue for a feature request I made for [ChatDev](https://github.com/OpenBMB/ChatDev/issues/98) that I think [AutoGen](https://github.com/microsoft/autogen/issues/34) could also benefit from. I don\\'t see a similar post in the current issues. Please forgive any impropriety in providing similar feedback. I\\'ll endeavor to find additional details in the repo to make it easier to implement given time. \\n\\nMy hope would be that with this kind of feature, we could then add in TextGenWebUI like in this [ticket](https://github.com/OpenBMB/ChatDev/issues/100), and then have it dynamically unload and load models between agents to utilize the best model for a given character (an API programmer bot could use a Gorilla, or a character could receive a fine tuned model for your use case). Please let me know if it\\'d be beneficial for me to create an issue like the second.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 12:51:33 a user named sonichi said ```Yes, the `llm_config` for each agent can be used to specify one or multiple LLM configurations to use.```.\\n\\nIn ideas-and-feedback, at 2023-09-28 12:35:20 a user named fxtoofaan said ```is it possible to switch between models? like local, then gpt3.5 then gpt4? or maybe give individual agent a specific LLM to use? basically use LocalLLM for majority of work and use GPT4 or 3.5 to validate localLLM outputs```.\\n\\nIn ideas-and-feedback, at 2023-09-28 05:31:39 a user named junaidamjad said ```As for GUI, I was wondering if we could integrate the community version of Botpress since it communicates with LLMs via API calls. Another option is Flowise. Anyone doing this?```.\\n\\nIn ideas-and-feedback, at 2023-09-28 04:54:15 a user named jimmysandwiches said ```@sonichi 2 quick question if I may. Is there any crossover / similarities between this and prompt flow (MS) and do you envisage a gui coming to this soon (or can you suggest a gui framework that can work with this out of the box) Thanks 🥪```.\\n\\nIn ideas-and-feedback, at 2023-09-28 03:48:27 a user named .princeps said ```@sonichi seems like things are taking off, so I wanted to suggest that the team can create a Agent Community Manager to help you when you are offline, this guy has a great example \\n\\nhttps://youtu.be/yhBiVrigWNI?si=DXzB__CUTHzkQybr```.\\n\\nIn ideas-and-feedback, at 2023-09-28 02:52:06 a user named sonichi said ```That\\'s basically right. Note that both agents are simply instances of ConversableAgent with different configurations. In general, you can decide what backends to use: LLM, human, tool or a combination of any of them, or register your own reply function via `register_reply````.\\n\\nIn ideas-and-feedback, at 2023-09-28 02:50:29 a user named sonichi said ```This example uses vectorDB: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb```.\\n\\nIn ideas-and-feedback, at 2023-09-28 02:39:26 a user named theagentcy.ai said ```Thank you so much for putting this out. I’ve been toying with it all day and can’t wait to see what use cases others come up with!```.\\n\\nIn ideas-and-feedback, at 2023-09-27 20:20:13 a user named shaneyu said ```Just want to see if I\\'m understanding the concept correctly, assistant_agent is mainly for the llm part, doing the logic/reasoning, on the other hand, user_proxy_agent is the one doing actual jobs, ie, getting code run, querying vectorDB, etc. So If I were to create my own agent, I will subclass user_proxy_agent to do the jobs(function calls, using tools) and subclass assistant_agent for any specific logic within the group chat?```.\\n\\nIn ideas-and-feedback, at 2023-09-27 17:23:25 a user named junaidamjad said ```The support for local LLMs is revolutionary. Is it also possible to use vector databases instead of retraining models?```.\\n\\nIn ideas-and-feedback, at 2023-09-27 16:45:07 a user named .princeps said ```Here you go: \\n\\nhttps://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/#clone-fastchat```.\\n\\nIn ideas-and-feedback, at 2023-09-27 15:56:50 a user named sonichi said ```There is also a new forum-discussion channel on discord.```.\\n\\nIn ideas-and-feedback, at 2023-09-27 15:49:54 a user named bunswo said ```(I was able to fix this by using GPT4 instead of GPT3.4)\\nWould love to know the best forum for troubleshooting.\\nI also had issues with the SVG display of the chess board in the example -- but worked around it -- I could post that for others somewhere.```.\\n\\nIn ideas-and-feedback, at 2023-09-27 13:53:01 a user named bunswo said ```I\\'m getting a RecursionError: maximum recursion depth exceeded \\non the Chess example\\nIs there an appropriate place to post that issue?```.', '\\nIn ideas-and-feedback, at 2023-10-25 01:00:44 a user named ragyabraham said ```feel free to DM if you run into any issues```.\\n\\nIn ideas-and-feedback, at 2023-10-25 01:00:12 a user named robin_saunders said ```Opened it in a new tab so I won\\'t forget 😄```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:59:35 a user named robin_saunders said ```I gotta run but I\\'ll take a deeper look tomorrow!```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:55:17 a user named ragyabraham said ```https://github.com/rnadigital/agentcloud/blob/416900ced910e43c22534fb911a4eb16abf6a0a1/agent-backend/src/agents/base.py#L41C54-L41C54```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:55:03 a user named ragyabraham said ```So the interesting discovery here is that in order for the planner to allocate task correctly it needs to be explicitly given it\\'s team members and their skills/responsabilities. So at runtime, after the team is formulated we utilise the `update_system_message` method to get the team members and make the planner aware of who is actually on the team```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:52:34 a user named robin_saunders said ```So are you overriding the manager then with your own solution to fix that?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:51:10 a user named ragyabraham said ```to a large extent yes we have added a few things to autogen such as `socketio` support```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:51:01 a user named robin_saunders said ```the manager component in autogen like the other guy was saying was incorrectly selecting what agents to use```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:50:25 a user named robin_saunders said ```Ah this is a wrapper?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:49:14 a user named ragyabraham said ```you\\'ll need to pull `rnadigital/agentcloud````.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:48:36 a user named robin_saunders said ```I haven\\'t pulled the latest version, saw you mentioning earlier that you fixed the manager stuff, so if I pull autogen your update here is integrated already?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:48:02 a user named ragyabraham said ```This platform is very much a GUI for autogen```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:47:28 a user named robin_saunders said ```is this seperate to autogen? or is this the manager component in autogen?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:46:38 a user named robin_saunders said ```and is it possible to \"hardcode\" a circular path for logic like I was thinking, where we can drive it through a set of agents in forced order?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:46:28 a user named ragyabraham said ```https://github.com/rnadigital/agentcloud/blob/416900ced910e43c22534fb911a4eb16abf6a0a1/agent-backend/src/agents/base.py#L29C14-L29C14```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:45:30 a user named robin_saunders said ```@ragyabraham where is this in the code base? I\\'d like to take a look```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:44:39 a user named sidhujag said ```I get why it’s done.. because there’s no control loop native to agents.. there’s no total ownership but if they can hierarchically order within groups then I think top down no problem with keeping things going until top group is happy with. Answer```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:44:06 a user named robin_saunders said ```Ah, I haven\\'t had that problem. I was having more problems with errors killing the program because of how the local LLM\\'s interact with autogen (since I don\\'t want to be testing with chatgpt paying $$$)```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:43:50 a user named ragyabraham said ```and it often gets stuck on the same issue```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:43:42 a user named ragyabraham said ```yeah it gets a bit wild```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:43:25 a user named sidhujag said ```Either asks user for feedback or it’s done waiting for next input```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:43:20 a user named robin_saunders said ```I was watching it start to ask itself new questions when I let it run long enough lol```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:43:05 a user named sidhujag said ```Keep alive until it thinks problem solved, given back to user```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:42:59 a user named ragyabraham said ```i think a framework to prevent reduce circular convos would be very helpful```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:42:42 a user named sidhujag said ```It has group LLM inference to keep alive which seems hack```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:42:18 a user named ragyabraham said ```tbh i haven\\'t experienced chat diying but i have on many occassion seen tha chat become extremely circular```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:42:08 a user named robin_saunders said ```What\\'s the purpose of keeping it alive if the task is done? Are you thinking like, letting it evolve?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:41:37 a user named sidhujag said ```Worsed case user can always send msg to say hey, where we at?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:41:00 a user named sidhujag said ```Maybe it can emerge with unique strategies to keep program alive```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:40:33 a user named sidhujag said ```Yea that’s what I’m doing in my prompt I haven’t tested it yet, but it’s allowed to send message and to group manager who sends to everyone else, I tell that if you don’t reply or keep going in a group then it will die```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:40:09 a user named robin_saunders said ```ah you\\'re thinking larger scope?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:39:46 a user named sidhujag said ```Pass control or manage the control, emergent behaviour to keep control alive```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:39:44 a user named robin_saunders said ```like, telling it start coder, go to critic, go to QA, check with user-agent, go back to coder if required, loop```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:39:24 a user named sidhujag said ```Some idea to keep control loop alive or the program dies```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:39:04 a user named robin_saunders said ```A pre-defined ruleset for who talks to what?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:38:49 a user named robin_saunders said ```and I think I understand what you\\'re saying```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:38:38 a user named robin_saunders said ```Was reading what you were suggesting```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:37:37 a user named sidhujag said ```It feels like a hack to ask LLM to ask who next speaker should be```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:36:12 a user named sidhujag said ```I imagine a control loop to exist similarily```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:35:44 a user named sidhujag said ```Imagine a control loop for a main program```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:35:35 a user named sidhujag said ```Can there not be another way to track group convo control?```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:33:18 a user named dulak said ```I\\'ll pull and try it out tomorrow and will let you know 😄```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:33:10 a user named dulak said ```been a long day hahaha```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:32:56 a user named dulak said ```Ahh I was having this problem 6ish hours ago```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:32:42 a user named ragyabraham said ```late last night sydney time```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:32:28 a user named dulak said ```oh really? how recently? that\\'s awesome```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:32:15 a user named ragyabraham said ```Yes, we pushed a change that fixed that. Just pull the latest and that should be resolved, If you continue to have issue feel free to DM me```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:31:22 a user named dulak said ```Yea, I\\'m running into problems where the manager doesn\\'t correctly select the agent. Example, I\\'ll have a coder and a critic, and it\\'ll tell the critic to make code which poops out a huge longwinded explaination for why hello world works.\\n\\nThat and I\\'m not sure which agent it selects sometimes and it woul dbe nice to keep track```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:28:22 a user named sidhujag said ```Nice, so it does an auto agent style consensus on the team, roles and functions ? That’s good. In mine it should message others, discover agents and functions and add them then create agents that don’t exist and also create groups and invite agents```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:25:56 a user named ragyabraham said ```What is hardcoded is the team-generation team and instructions```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:25:34 a user named ragyabraham said ```Currently we pass it a JSON structure that resembles a example team and we ask the agent to formulate the \"ideal team to undertake said task and return team in the above JSON format\"```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:22:02 a user named sidhujag said ```That’s cool so how does it assemble a team? What’s hard coded and what is dynamic or emergent? I ask because I’m create a different group chat with functions so agents can explore without guiding them specifically on ordering of what is needed or what’s not in an organizational structure```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:14:45 a user named ragyabraham said ```@groundzer000 not at the moment but we are working on enabling the choice of LLM including utilising local/custom model @dulak @semi2995```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:13:53 a user named ragyabraham said ```@dulak as in you want to print manager\\'s messages to terminal??```.\\n\\nIn ideas-and-feedback, at 2023-10-25 00:13:03 a user named ragyabraham said ```@sidhujag  The workflow right now is:', '\\n**Tutorials:**\\n-  https://www.youtube.com/watch?v=8TLwSH_UFwI (by @redai.ai )\\n-  https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts (by @.princeps )\\n- https://youtu.be/2RT8i-VP7V0 (by Manish Gupta on YT)\\n- https://www.youtube.com/watch?v=gnn1H4H81IY (by @pradeep1148 )\\n- https://www.youtube.com/watch?v=N5nmAWwoTEY\\n- https://www.youtube.com/watch?v=w6hhnVa68yE\\n- https://www.youtube.com/watch?v=Z9NadaZ-1Rc\\n- https://www.youtube.com/watch?v=PCr-uAjQHDQ (by @merkle)\\n- https://www.youtube.com/watch?v=WnBCPG-ZdLk (by echohive on YT)\\n- https://www.youtube.com/watch?v=JFotv9PVW_4 (by code_your_own_AI on YT)\\n- https://www.youtube.com/watch?v=vU2S6dVf79M (by Mathew Berman on YT)\\n- https://www.youtube.com/watch?v=Bq-0ClZttc8 (by AI_Json on YT)\\n- https://www.youtube.com/watch?v=oOqeOspJL0o (by echohive on YT)\\n\\n**Examples:** \\n- https://twitter.com/pwang_szn/status/1707334415691686227 (pwang_szn on Twitter)   https://github.com/peterw/autogen/tree/main \\n- https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game (by @.princeps )\\n- https://huggingface.co/MultiTransformer (by @tonic_1 )\\n- https://twitter.com/abhilashi/status/1708339764250947692?s=20 (by @abhilashinumella )\\n- https://twitter.com/oscarmoxon/status/1708603929011863871 (by oscarmoxon on Twitter)\\n- https://github.com/amadad/agentcy (by @amadad )\\n- https://github.com/Andyinater/AutoGen_IterativeCoding (by @andyinater )\\n\\n**Coverage:**\\n- https://www.youtube.com/watch?v=zdcCD--IieY (by Wes Roth on Youtube)\\n- https://youtu.be/yi8Cq2SZy48?si=bH8UKsUG7gA5a_vM&t=284 (by AI Explained on Youtube)```.\\n\\nIn forum-discussion, at 2023-09-29 19:10:45 a user named bansalg said ```@tanmayy  and @andyinater how about this: https://discord.gg/66YGrgpS```.\\n\\nIn forum-discussion, at 2023-09-29 18:49:01 a user named meenstreek said ```I figured you might just piggyback off this one 🙂```.\\n\\nIn forum-discussion, at 2023-09-29 17:55:53 a user named tonic_1 said ```https://huggingface.co/spaces/MultiTransformer/snake_by_princepspolycap/discussions/1 so i kinda sorta wanted to see if you thought this would be cool```.\\n\\nIn forum-discussion, at 2023-09-29 17:43:45 a user named tonic_1 said ```can host it on huggingface? https://huggingface.co/collections/MultiTransformer/autogengradiohuggingface-651626e54256270d6fad2621```.\\n\\nIn forum-discussion, at 2023-09-29 17:13:56 a user named meenstreek said ```Add your logo to the server profile 🙂```.\\n\\nIn forum-discussion, at 2023-09-29 13:37:54 a user named .princeps said ```here is a little project I created to create a snake game using the project, this should help others see how to get started with the agents \\n\\nhttps://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\\n\\nIn forum-discussion, at 2023-09-28 22:09:35 a user named merkle said ```imagine something like this but for premade agent workflows https://apify.com/store```.\\n\\nIn forum-discussion, at 2023-09-28 15:02:26 a user named merkle said ```see this example in their repo\\nhttps://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb```.\\n\\nIn forum-discussion, at 2023-09-28 13:12:09 a user named unicorn1997 said ```but according to the paper, they are capable of execution, that was also the primary reason why I tried that\\nSo maybe I just cant do it?```.\\n\\nIn forum-discussion, at 2023-09-27 19:40:46 a user named unicorn1997 said ```a  \\nHello, first of all, I tried AutoGen and I love it, thanks for doing that.\\nI first started coding few weeks ago, and I succeeded in using AutoGen (I failed with Langchain tbd). You have nice docs!\\n\\nSecond, I made some simple examples with AutoGen and now I wonder if there are some ways to actually execute the code it produces. What should I do with the code I am getting from agents as output?\\n\\nThanks for discussing this!\\nT.```.\\n\\nIn dev-contributors, at 2023-11-14 22:38:20 a user named sidhujag said ```is there a reason you may want it to be gpt assistant agent? group managers dont really need tool or fn access they just forward msgs to other agents which on reply get fwded to assistant api right```.\\n\\nIn dev-contributors, at 2023-11-14 22:37:37 a user named sidhujag said ```it was working just fine if you take my PR above and then you can rename conversable agent to gpt assistant agent inside groupchat it should work.. how does it fail for you?```.\\n\\nIn dev-contributors, at 2023-11-14 22:35:13 a user named bansalg said ```If you were able to make gptassistantagent work as groupchatmanager, can you please share code 🙂```.\\n\\nIn dev-contributors, at 2023-11-14 14:53:09 a user named sonichi said ```Thanks. I\\'ve reviewd and tried to find more reviewers. Others please help as I\\'m not familiar w/ JS/TS```.\\n\\nIn dev-contributors, at 2023-11-14 11:16:56 a user named 0xlws said ```updated: added typescript https://github.com/microsoft/autogen/pull/664```.\\n\\nIn dev-contributors, at 2023-11-13 21:09:43 a user named 0xlws said ```hey guys i opened a PR which allowed execution of javascript, hope to get typescript support as well (being able to run tests 🤔 )! https://github.com/microsoft/autogen/pull/664```.\\n\\nIn dev-contributors, at 2023-11-13 21:06:56 a user named sidhujag said ```it works with both.. i switched back to conversable agent and it worked.. so it works for me either way.. i did notice some things im surprised you guys havent seen but we use assistant role for appending messags and assistants API doesnt like this I get \"1 validation error for Request\\\\nbody -> role\\\\n  value is not a valid enumeration member; permitted: \\'user\\'\".. i opened this PR https://github.com/microsoft/autogen/pull/665```.\\n\\nIn dev-contributors, at 2023-11-13 19:34:42 a user named sidhujag said ```Let me play around with it, wasn’t working first until I moved to gpt assistant it was duplicating unread messages but might have been issue elsewhere I will test again and report```.\\n\\nIn dev-contributors, at 2023-11-13 19:12:33 a user named sonichi said ```@bansalg said the opposite: groupchatmanager needs to be an non-gptassistant agent. https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_groupchat.ipynb\\nI\\'m curious what makes the difference```.\\n\\nIn dev-contributors, at 2023-11-13 19:01:39 a user named sidhujag said ```WITHOUT: UserProxyAgent (to ManagementGroup):\\n\\nwhat time is it now?\\n\\n--------------------------------------------------------------------------------\\nProvide feedback to ManagementGroup. Press enter to skip and use auto-reply, or type \\'exit\\' to end the conversation: \\n\\n>>>>>>>> NO HUMAN INPUT RECEIVED.\\n\\n>>>>>>>> USING AUTO REPLY...\\nRun: run_K61cmGqjF5wf1rFNu4XwRlvX Thread: thread_ggyt4YciDlqAEyRhq7hg3RC7: completed...\\nuser_assistant (to ManagementGroup):\\n\\nI\\'m sorry, but I don\\'t have direct access to real-time information such as the current time. However, you can easily check the time on your device or by using a search engine. If you\\'re looking for the time in a specific timezone or location, you can specify that and search online or use a world clock feature on your device.\\n\\n\\n--------------------------------------------------------------------------------```.\\n\\nIn dev-contributors, at 2023-11-13 19:01:21 a user named sidhujag said ```UserProxyAgent (to ManagementGroup):\\n\\nwhat time is it now?\\n\\n--------------------------------------------------------------------------------\\nProvide feedback to ManagementGroup. Press enter to skip and use auto-reply, or type \\'exit\\' to end the conversation: \\n\\n>>>>>>>> NO HUMAN INPUT RECEIVED.\\n\\n>>>>>>>> USING AUTO REPLY...\\nRun: run_hRRNo71IfGDYrhmyatN26jqz Thread: thread_yseKoHgJ2IRmTqN5KQVafrmp: completed...\\nuser_assistant (to ManagementGroup):\\n\\nThe current time is 18:50:49.\\n\\n\\n--------------------------------------------------------------------------------```.\\n\\nIn dev-contributors, at 2023-11-13 19:01:20 a user named sidhujag said ```WITH code interpreter it seems like it auto runs things on backend without even any indication:```.\\n\\nIn dev-contributors, at 2023-11-13 19:00:38 a user named sidhujag said ```i got assistants working with group chat.. but i had to use the new gptassistant as the base for groupchatmanager and had to make changes to gptassistant to enable user input and termination.. is there interest in merging upstream or shall i keep these in my fork?```.', 'In issues-and-help, at 2023-11-15 10:41:54 a user named Lega said ```im novice w programming so i may not have explained it in the best way. But I basically am trying to figure out the same thing as this member in the server https://discord.com/channels/1153072414184452236/1153072414184452241/1174253851285667911```.\\n\\nIn issues-and-help, at 2023-11-14 19:49:12 a user named razahin said ```Hi @.beibinli, thank you very much for your offer of assistance. I have attached the two files here. I\\'ve also included an example of the output.\\n\\nThe design.jpg files is located under a folder called `coding` which is located at the same level as main.py. \\n\\nI\\'ve also tried `user_proxy.initiate_chat(designAnalyzer, message=\"\"\"\\nLoad the image from the <img ./coding/design.jpg> file location for processing by an analyzer\"\"\")` in case of there being a location issue but recieved the same results.```.\\n\\nIn issues-and-help, at 2023-11-14 19:01:34 a user named sonichi said ```https://microsoft.github.io/autogen/docs/Installation#python```.\\n\\nIn issues-and-help, at 2023-11-14 18:11:25 a user named ariel.andres said ```Hi, I am trying to run the following example code on my computer:\\n\\nhttps://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb\\n\\nIf I try to use Autogen 0.1.14 with Openai 0.28.1 (by just using a pip install pyautogen), I get the following error:\\n\\nraise self.handle_error_response(\\nopenai.error.InvalidRequestError: Invalid URL (POST /v1/openai/deployments/InnovationGPT4-32/chat/completions)\\n\\nIf I instead do a pip install autogen==0.2.0b5 (which also installs Openai 1.2.4), it runs perfectly fine.\\n\\nThis is the structure for my OAI_CONFIG_LIST.json:\\n\\n[\\n    {\\n        \"model\": \"InnovationGPT4-32\",\\n        \"api_key\": \"xxxxx\",\\n        \"base_url\": \"https://innovationopenaiservice.openai.azure.com/\",\\n        \"api_type\": \"azure\",\\n        \"api_version\": \"2023-06-01-preview\"\\n    }\\n]\\n\\nThe problem is, while it runs fine with Autogen 0.2+ and Openai 1.0+, we are trying to integrate Autogen in a project that already uses Openai 0.27.4, so we would like to use Autogen 0.1.14.```.\\n\\nIn issues-and-help, at 2023-11-14 15:50:34 a user named aaronward_ said ```It was my fault, i didn\\'t format the tool config correctly. Have shared an example notebook here: https://discord.com/channels/1153072414184452236/1173957465285611551```.\\n\\nIn issues-and-help, at 2023-11-14 12:39:00 a user named razahin said ```I\\'ve been taking inspiration from the https://github.com/microsoft/autogen/blob/v0.2.0b4/notebook/agentchat_lmm_gpt-4v.ipynb notebook for using GPT4 with vision. Running the examples as written in the notebook works. Passing a public image file, such as one hosted on openAI, also works.\\n\\nWhen I attempt to modify the commander, coder, and critic prompts to read a local file I am consistently met with messages like \\n\\n`I\\'m sorry for any confusion, but it appears there may have been a misunderstanding. As an AI text-based interface, I don\\'t have the capability to interpret images or run code.` \\n\\nOtherwise the commander coder workflow will often go completely off the rails. \\n\\nI\\'m looking for suggestions on how I should approach feeding an image which is located in the local working directory into the MultimodalConversableAgent. The user prompt I am trying is\\n\\n```\\nuser_proxy.initiate_chat(designAnalyzer, message=\"\"\"\\nLoad the image from the design.jpg file location for processing by an analyzer\"\"\")\\n``````.\\n\\nIn issues-and-help, at 2023-11-14 11:56:28 a user named aaronward_ said ```Nevermind, got it working - it was the assistand_id that was messing it up. I passed None and it worked. \\n\\nOne thing i noticed so far: its fast! it doesn\\'t waste time talking back and foward with the UserProxy before writing the query - potentially saving money on token costs, i\\'ll need to look into this further. It also seems counter intuitive because usually the UserProxy is the one who is executing the code. it\\'s a great addition to autogen from what i can tell so far.```.\\n\\nIn issues-and-help, at 2023-11-14 09:28:20 a user named aaronward_ said ```i\\'m having issues with my agents not using the provided tool, wondering if someone could give me help - the user proxy keeps trying to run the sql as a file rather than pass it as a string to a python function which is registered.\\n\\nI\\'m testing out the new **GPTAssistantAgent** with a postgres sql operation. \\n\\nhttps://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/14.openai-assistant-api/OpenAi-assistant-with-autogen.ipynb```.\\n\\nIn issues-and-help, at 2023-11-14 04:12:31 a user named levre said ```My group chat eventually turns into user_proxy repeatedly calling GPT4 and (I guess?) getting no response so calling it again.  Is there some way to add logic to terminate when this happens?  It appears to be sending the full context every time, so I\\'m getting charged for input tokens.```.\\n\\nIn issues-and-help, at 2023-11-11 22:40:45 a user named pika.c said ```For now to deal with this I\\'m creating a new GroupChat object with messages from the previous one and a new GroupChatManager. The problem is that the new agents in the group chat do not have context of what is going on. \\nI\\'m pretty sure there\\'s a better way to go about this. I\\'ll keep experimenting and update this thread if I make any progress.\\nhttps://github.com/toshNaik/TaleCraft/tree/main```.\\n\\nIn issues-and-help, at 2023-11-11 19:44:40 a user named ab.z said ```add --pre flag to see pre-releases```.\\n\\nIn issues-and-help, at 2023-11-11 19:42:12 a user named ab.z said ```Because it is not released yet, it is a pre-release```.\\n\\nIn issues-and-help, at 2023-11-11 13:10:24 a user named malicor said ```i\\'m having this code:\\n\\nhttps://pastebin.com/faWpJi6T\\n\\nbut it\\'s still throwing the same error```.\\n\\nIn issues-and-help, at 2023-11-10 04:06:40 a user named reporter said ```https://discord.com/channels/1153072414184452236/1162811675762753589/1171829828232695870\\n\\nMight be helpful but let me know if it isn\\'t.```.\\n\\nIn issues-and-help, at 2023-11-09 19:20:12 a user named sonichi said ```Check this: https://microsoft.github.io/autogen/docs/Installation#python```.\\n\\nIn issues-and-help, at 2023-11-09 18:46:49 a user named yigitkonur said ```for those who are facing with this issue, here is how I fixed this:\\n\\nyou should install autogen by following command:\\n\\n```\\npip install pyautogen==0.2.0b2\\n```\\n\\nhere is how to load config to fix this problem:\\n\\n```\\nimport autogen\\n\\nconfig_list = [\\n    {\\n        \"model\": \"YOUR_DEPLOYMENT_NAME\",  \\n        \"base_url\": \"https://xxx.openai.azure.com\", \\n        \"api_type\": \"azure\", \\n        \"api_version\": \"2023-07-01-preview\", \\n        \"api_key\": \"xxx\"\\n }\\n]\\n``````.\\n\\nIn issues-and-help, at 2023-11-09 16:06:01 a user named c_bonadio said ```Hi @wadymc I spent some time with function_call and I think I got some reasonable understanding.\\n\\nI even created an agent that can self execute its own function call\\nhttps://gist.github.com/bonadio/96435a1b6ccc32297aa8cc1db7cfc381\\n\\nUsually we have the user_proxy  -> assistant \\n\\nIn this case assistant has the function_call definition in the llm_config and user_proxy has the function_map so it knows what \"program\" to run when the assistant returns the function_call named function.\\n\\nAt this point I was asking myself \"why should user_proxy runs the function and not the assistant?\". At first I thought it was a bad design and I created the self execution agent. But then I found this example that made me think different\\nhttps://github.com/sugarforever/LangChain-Advanced/blob/main/Integrations/AutoGen/autogen_langchain_uniswap_ai_agent.ipynb\\n\\nHere the assistant receives the result of the function_call from the user_proxy at each iteration and it can \"reason about this result\" so this back and forth gets richer. \\n\\nFor a simple use case the assistant could execute the function_call by itself and return the result, but having the user_proxy executing the code and passing the result back to assistant gives the opportunity of the assistant to \"think about the result\" because the assistant is the one with access to the LLM\\n\\nHope that make sense```.\\n\\nIn issues-and-help, at 2023-11-08 16:30:54 a user named c_bonadio said ```Take a look at this gist on the user_proxy code, you could use the search_db function to call your webhook something like that\\nhttps://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.\\n\\nIn issues-and-help, at 2023-11-08 15:13:22 a user named radman1000 said ```I assume you\\'re talking about the AutoGen api_base URL, right (around 4:43 in your video)? I can\\'t even get nearly that far, since the runpod never exposes the 5001 port. I think the problem is more like @reporter response in https://discord.com/channels/1105681186782707785/1171390227424743514/1171617987346833509.```.\\n\\nIn issues-and-help, at 2023-11-08 00:10:14 a user named heavenlysome said ```This one produced a file```.'], ['\\nI have worked to load quivr with a manual for a restaurants stove and work through troubleshooting scenarios.\\n\\nThat is something I am looking to autogen for```.\\n\\nIn general, at 2023-10-10 01:47:41 a user named yuzhun said ```I tried gpt3.5 for chess play and it failed, wondering how do autogen choose model? Is there a priority flag? Do autogen auto retry with different model in the config file?```.\\n\\nIn general, at 2023-10-10 01:22:58 a user named platinumpluto said ```If it is okay can I discuss about something? Sorry for my bad English in advance!```.\\n\\nIn general, at 2023-10-10 00:36:48 a user named smuggybuggins said ```Random Reddit search and Youtube. Never coded in my life and somehow followed the AutoGen Tutorial and built a \"live\" version. I am now too hooked to concentrate at work!```.\\n\\nIn general, at 2023-10-10 00:19:14 a user named gjipe said ```How is that going for you ? doin the same over here in London```.\\n\\nIn general, at 2023-10-09 23:58:34 a user named covetech said ```Honestly youtube.  I just learned about it today watching a tutorial.```.\\n\\nIn general, at 2023-10-09 22:12:54 a user named jaemil said ```https://www.getonboard.dev/chat/microsoft/autogen```.\\n\\nIn general, at 2023-10-09 22:09:49 a user named afourney said ```In any case, the next release will print a warning when the file cannot be found. Arguably this should probably graduate to an actual exception```.\\n\\nIn general, at 2023-10-09 22:05:05 a user named kohanzie said ```XD out of habit, this mightve fixed it too, so annoying lol. thank you if im having any other trouble ill reopen```.\\n\\nIn general, at 2023-10-09 22:04:57 a user named afourney said ```Ok, to summarize what\\'s happening as far as I understand it: https://github.com/microsoft/autogen/issues/125#issuecomment-1754004740```.\\n\\nIn general, at 2023-10-09 21:55:12 a user named mightyscoo said ```I\\'m a software engineer.  I built my first neural network in 1982 and I was an immediate convert.  At the time I didn\\'t have the research bug, but now I do.  So, I\\'m here and will be lurking, trying to figure out what I can do with all this.```.\\n\\nIn general, at 2023-10-09 21:38:24 a user named alwaystinkering said ```I am a former software engineer at Microsoft and other orgs. I am now working in Detroit to assist small businesses with adoption of AI type technologies.```.\\n\\nIn general, at 2023-10-09 21:31:37 a user named jew84930585 said ```i’ll try to reproduce it again too more under the microscope```.\\n\\nIn general, at 2023-10-09 21:29:16 a user named afourney said ```@kohanzie @jew84930585 still working out where the default is being pulled from, but the main branch now prints a warning if it can\\'t load the OAI_CONFIG_LIST file and reverts to some default. Hopefully that will help. In the meantime, @kohanzie  I noticed that your file is called OAI_CONFIG_LIST.json   it should not have the \".json\" at the end -- just \"OAI_CONFIG_LIST\"```.\\n\\nIn general, at 2023-10-09 21:24:39 a user named jew84930585 said ```i’ve noticed this bug as well, something in autogens config is forcing gpt-4```.\\n\\nIn general, at 2023-10-09 21:24:28 a user named dr.goatfish said ```Hey, how can we use group chat to analyze datasets, communicate and a comparison agent finishes the task by using the 4 other groupchat members to generate of csv of dates, reported hours worked and estimated hours worked from the comparison of datasets. \\n\\nI am trying to use AutoGen to validate an employees reported hours worked and refute her claim that she is owed overtime pay before her termination. The AI agent will complete the task by interpretting the tabular datasets related to her activities as an employee: Email conversations, QuickBook Activities, Door Badge (entry time to office) and Reported Hours Worked. The AI Agents will analyze the quickbook activities against reported hours worked, emails, etcetera to refute her claims that she is owed overtime. The agents will provide a estimated time difference between what she reported and what the agent inspects in the data.```.\\n\\nIn general, at 2023-10-09 21:00:38 a user named pablo.ce said ```Hi guys learn autogen form a youtube video 🙂```.\\n\\nIn general, at 2023-10-09 20:42:43 a user named afourney said ```Sorry I missed the Azure part 😛, and deleted the previous OAI link.  Good question on setting up Azure -- I haven\\'t done that as an external user, so i\\'m not 100% sure.```.\\n\\nIn general, at 2023-10-09 20:42:43 a user named somecomputerguy said ```Huh, I used the azure portal to stand up a deployment, is that link cheaper?```.\\n\\nIn general, at 2023-10-09 20:35:36 a user named afourney said ```@kohanzie can you add these details to: https://github.com/microsoft/autogen/issues/125```.\\n\\nIn general, at 2023-10-09 20:33:05 a user named tangerine1528 said ```How can I apply or get Azure OpenAI Api key any one can help?```.\\n\\nIn general, at 2023-10-09 20:28:56 a user named somecomputerguy said ```Cool, yeah I can play with that```.\\n\\nIn general, at 2023-10-09 20:28:24 a user named bobaleaux said ```here\\'s how i did it;\\n\\nit isn\\'t perfect but it was a fast start```.\\n\\nIn general, at 2023-10-09 19:52:28 a user named sonichi said ```AssistantAgent with system message like \"Reply TERMINATE if ...\"```.\\n\\nIn general, at 2023-10-09 19:51:34 a user named pbeheca said ```Okay, thank you. What would the config for such an agent look like?```.\\n\\nIn general, at 2023-10-09 19:48:22 a user named sonichi said ```The instruction about termination can often get ignored when it\\'s mixed with other long instructions. One possible way is to create a separate agent which is dedicted to this.```.\\n\\nIn general, at 2023-10-09 19:47:11 a user named pbeheca said ```Any way to circumvent this behavior? gpt4 seems to not have this issue but is too costly. Any Idea which agents would need gpt4 to prevent empty calls/responses in a loop?```.\\n\\nIn general, at 2023-10-09 19:45:14 a user named sonichi said ```Yes, it\\'s common in my experience.```.\\n\\nIn general, at 2023-10-09 19:41:46 a user named telepathyx said ```https://arxiv.org/abs/2310.01798\\n\\nTransitioning to another facet of self-correction, we investigate the potential of\\nmulti-agent debate (Du et al., 2023; Liang et al., 2023) as a means to improve reasoning. In this\\nmethod, multiple instances of an LLM critique each other’s responses. However, our results reveal\\nthat its efficacy is no better than self-consistency (Wang et al., 2022) when considering an equivalent\\nnumber of responses, highlighting the limitations of such an approach.```.\\n\\nIn general, at 2023-10-09 19:32:17 a user named pbeheca said ```Is it normal for gpt-3.5-turbo agents to get stuck in a loop? seems like it always ends getting stuck```.\\n\\nIn general, at 2023-10-09 19:06:20 a user named aarya1101 said ```I am new to this```.\\n\\nIn general, at 2023-10-09 19:06:05 a user named aarya1101 said ```can anyone explain autogen to me?```.\\n\\nIn general, at 2023-10-09 19:02:20 a user named tc said ```@kohanzie tomorrow morning i\\'ll put in general chat a little snippet on how did i solved it if i got 5 minutes```.\\n\\nIn general, at 2023-10-09 18:53:49 a user named kareem6370 said ```I had to override the DEFAULT_MODEL in the super class to be gpt-3-turbo to stop using gpt-4 for any interference, It’s not the best way to do it but I was lazy and I wanna test an idea lol```.\\n\\nIn general, at 2023-10-09 18:39:09 a user named afourney said ```FYI: I\\'m trying to hunt this one down, a top priority.```.\\n\\nIn general, at 2023-10-09 17:59:42 a user named somecomputerguy said ```I guess in this model it is similar to autogpt? I never used it```.\\n\\nIn general, at 2023-10-09 17:35:18 a user named somecomputerguy said ```And instructed it to write to a known path, then used docker cp to copy out the generated CSV```.\\n\\nIn general, at 2023-10-09 17:34:45 a user named somecomputerguy said ```I modified the twoagent.py file```.\\n\\nIn general, at 2023-10-09 17:29:02 a user named securemeup said ```Have you tried using the teaching notebook for this? Can you provide some more details? I’d like to see if can get it to work```.\\n\\nIn general, at 2023-10-09 17:24:45 a user named deedavid_15589 said ```if guardrails are proper, you can control resources, resoruce type, instances, and of course you can audit all of this before the code is deployed.```.\\n\\nIn general, at 2023-10-09 17:23:50 a user named deedavid_15589 said ```@somecomputerguy you have guardrails for your CDK?```.\\n\\nIn general, at 2023-10-09 17:15:00 a user named somecomputerguy said ```Right now I am debating handing some AWS keys to an agent to deploy CDK... it feels like a VERY BAD IDEA```.\\n\\nIn general, at 2023-10-09 17:12:30 a user named somecomputerguy said ```But also, I should stop being a luddite and embrace notebooks I guess 😛```.\\n\\nIn general, at 2023-10-09 17:11:51 a user named somecomputerguy said ```I wish that example was also in the test directory as a .py```.\\n\\nIn general, at 2023-10-09 16:43:50 a user named bobaleaux said ```in my case i would be replaced by 2 agents?\\nthe admin or user_agent and a retrieval agent to feed the same content ?```.\\n\\nIn general, at 2023-10-09 16:39:57 a user named sonichi said ```For non-coding tasks, specify `system_message` and `name` for each `AssistantAgent` about their roles and create a group chat, like https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb```.\\n\\nIn general, at 2023-10-09 16:36:56 a user named bobaleaux said ```and i just pasted an article from a few minutes ago and asked, for their opinions about it;```.\\n\\nIn general, at 2023-10-09 16:35:59 a user named bobaleaux said ```@sonichi do you have any ideas on how i accomplish this with autogen? \\nsorry my use case isn\\'t writing code.\\n\\nWhen manually using chatGPT, i have pasted multiple engineered persona prompts into the input in a single conversation and they all became part of the conversation. I have asked them all for their opinion about a single question and they each provided one.\\n\\nI\\'m trying to emulate my manual interactions with chatgpt but using code but I can\\'t figure out how.\\n\\nin a direct openai call, i use the system message as the persona and I haven\\'t tried loading multiple system messages and I\\'m not sure of the impact of \\'assume the role\\'.\\n\\n Is it just a group conversation with a user agent as the manager?```.\\n\\nIn general, at 2023-10-09 16:30:44 a user named somecomputerguy said ```Getting autogen happy and containerized took me all weekend, but worth it, executing code in my rancher environment is AWESOME```.\\n\\nIn general, at 2023-10-09 16:29:41 a user named somecomputerguy said ```Along with chromaDB, I am a big retro guy, you can see my stuff on youtube, really excited to point chroma at bitsavers and be able to ask questions and get answers based on OCR manuals for the original equipment```.', '\\nIn general, at 2023-10-15 19:12:05 a user named qingyunwu said ```Hi @michaelmcwhirter I guess there is some misunderstanding here. As I clarified above, this OSS project AutoGen has nothing to do with the AutoGenAI the commercial venture. Please find our documentation site here: https://microsoft.github.io/autogen/```.\\n\\nIn general, at 2023-10-15 19:05:52 a user named qingyunwu said ```Hi, you can start with the tutorials and examples in this channel: https://discord.com/channels/1153072414184452236/1161015724521836634. I believe it\\'s also helpful to skim through the notebooks we have: https://github.com/microsoft/autogen/tree/main/notebook, and the getting started page: https://microsoft.github.io/autogen/docs/Getting-Started```.\\n\\nIn general, at 2023-10-15 19:02:39 a user named qingyunwu said ```Thank you for asking! AutoGen the OSS project has NO relationship with AutogenAI the commercial venture linked here except the similarity on names.```.\\n\\nIn general, at 2023-10-15 18:59:04 a user named halr9000 said ```Help me understand something real quick, and I\\'d appreciate an answer from a mod or contributor, not Michael M:\\n\\nIs there a relationship between Autogen the OSS project, and AutogenAI the commercial venture linked here? \\n\\nIf yes, that\\'s fine, I don\\'t care, so long as it\\'s transparent. But I suspect the answer is actually no. In THAT case, then I would say there\\'s a conflict of interest problem w/this post from Michael that needs to be considered by those who care about such things. My $0.02 coming in super blind, having just joined the discord and not (yet) installed autogen. But I have 25 yr experience in the software industry, so that\\'s where my head is at.\\n\\nTIA! tagging @li_jiang and @qingyunwu simply as I see you two online now and I don\\'t know the groups or server eqituette  here yet.```.\\n\\nIn general, at 2023-10-15 18:20:11 a user named biggboii. said ```Where can I find best practices for different use cases? Such as how to structure a team and a task?```.\\n\\nIn general, at 2023-10-15 17:36:37 a user named mehdi_75 said ```Hi guys, saw autogen popping up on twitter and youtube!```.\\n\\nIn general, at 2023-10-15 16:56:16 a user named pedro74matos said ```Hi! I got to know AutoGen on YouTube... Channel Matthew Berman and then others.```.\\n\\nIn general, at 2023-10-15 16:54:32 a user named bigmiao said ```https://github.com/microsoft/autogen/issues/152#issuecomment-1752478080```.\\n\\nIn general, at 2023-10-15 16:52:36 a user named bigmiao said ```You can override it by implementing a custom GroupChat. There’s an example in GitHub issue’s showing how to do that. Let me find out```.\\n\\nIn general, at 2023-10-15 15:49:57 a user named notoriousjimbo said ```Hey Guys,\\nLooking to build a deep learning Workstation. The 14th Gen CPU is coming out and I\\'m looking at running multiple A100s. Anyone have suggested builds or hardware?```.\\n\\nIn general, at 2023-10-15 15:42:53 a user named karixai said ``````    code_execution_config={\"work_dir\": \"web\"},```\\ni got this but does not make a folder```.\\n\\nIn general, at 2023-10-15 15:42:17 a user named karixai said ```does some one know why my autogen not save code into files and not make anny folder?```.\\n\\nIn general, at 2023-10-15 15:37:58 a user named somecomputerguy said ```Yeah I wanna dig into how this works```.\\n\\nIn general, at 2023-10-15 15:26:09 a user named somecomputerguy said ```Oh no I see, they put manual chat instantiations in functions```.\\n\\nIn general, at 2023-10-15 15:23:36 a user named somecomputerguy said ```I do not see where that flow is established beyond prompts```.\\n\\nIn general, at 2023-10-15 15:22:23 a user named somecomputerguy said ```Their groupchat definition is super basic, seems like all the work went into system messages and functions, which is the direction I have been going```.\\n\\nIn general, at 2023-10-15 15:19:44 a user named somecomputerguy said ```https://github.com/amadad/agentcy```.\\n\\nIn general, at 2023-10-15 15:18:55 a user named somecomputerguy said ```I think next I want to try that agentcy thing, see how they handled task routing and attention```.\\n\\nIn general, at 2023-10-15 15:18:05 a user named somecomputerguy said ```Azure is reporting it as 500 errors, but I suspect my requests are somehow malformed```.\\n\\nIn general, at 2023-10-15 15:17:28 a user named somecomputerguy said ```I saw an example in git that used a custom reply function, it breaks :P, have not seen select_speaker```.\\n\\nIn general, at 2023-10-15 15:16:34 a user named somecomputerguy said ```The trying to call a function when directly attempting to contact another agent in the chat thing, anyone else seen that when instructing an agent to contact another agent not the group chat manager?```.\\n\\nIn general, at 2023-10-15 15:16:04 a user named tc said ```i do wonder if there is a way to write my own \" def select_speaker_msg(self):\" .\\nI suppose i could try to build a custom GroupChatManager and override that method? \\nanyone else already tried?```.\\n\\nIn general, at 2023-10-15 15:10:26 a user named somecomputerguy said ```Yeah it is just not behaving how I expect, hoping someone can explain since I figured I could not be the only one```.\\n\\nIn general, at 2023-10-15 15:07:46 a user named aaronward_ said ```https://youtu.be/6YDeiknPWkg?si=QQhz2ewaPemE6rwn```.\\n\\nIn general, at 2023-10-15 14:59:59 a user named bobaleaux said ```I’m there with you trying understanding the message routing configs```.\\n\\nIn general, at 2023-10-15 14:23:06 a user named degen_21122 said ```gonna check it now, seems im too far behind on this whole thingdamn```.\\n\\nIn general, at 2023-10-15 14:19:53 a user named somecomputerguy said ```I posted in in <#1157397569375309864> asking for assistance understanding message routing in a group chat. I am about ready to begin just manually building agent interaction chains, any help appreciated```.\\n\\nIn general, at 2023-10-15 14:19:24 a user named johnny_loquat said ```Use this video to install LMStudio.ai and point Autogen at it on your pc running as an api server. You are good to go! Can use the new models like Mistral.\\nRun any Open source LLM on your computer. Mistral or Llama or other...\\nhttps://youtu.be/2Ek0FL_Ldf4?si=-ldjMTZ2MVvFzu3v```.\\n\\nIn general, at 2023-10-15 13:44:51 a user named kajatta said ```https://python.langchain.com/docs/modules/agents/tools/tools_as_openai_functions```.\\n\\nIn general, at 2023-10-15 13:44:51 a user named bobaleaux said ```Oh! Great then you know all about being bugged eyed after 18 hours of keyboarding!```.\\n\\nIn general, at 2023-10-15 13:39:16 a user named degen_21122 said ```figured out the basic stuff```.\\n\\nIn general, at 2023-10-15 13:39:12 a user named degen_21122 said ```I know mate , i am a dev. I on the right track```.\\n\\nIn general, at 2023-10-15 13:39:01 a user named degen_21122 said ```yeah true, i pasted the code examples 1 by 1 when needed.```.\\n\\nIn general, at 2023-10-15 13:30:09 a user named bobaleaux said ```Gallons of caffeine filled drinks!\\nhonestly, it’s going to take your time. AutoGen is an excellent framework to abstract the transactions of conversations with LLM. \\nYou do need some basic understanding of coding.```.\\n\\nIn general, at 2023-10-15 13:22:56 a user named bobaleaux said ```What are you trying to install?```.\\n\\nIn general, at 2023-10-15 13:20:06 a user named tonic_1 said ```so this is the github version : it includes the notebooks so it\\'s slightly better at getting the code right : same results as yours though```.\\n\\nIn general, at 2023-10-15 13:18:49 a user named degen_21122 said ```Personally i just pasted all the docs in a word doc, made it .pdf , fed it into chat gpt and all good.```.\\n\\nIn general, at 2023-10-15 13:17:37 a user named degen_21122 said ```no way, are you stampy from src20s in btc?```.\\n\\nIn general, at 2023-10-15 13:05:36 a user named michaeldotw said ```It is all the buzz right now if looking into anything to do with multi agent use. So, it was easy to find```.\\n\\nIn general, at 2023-10-15 12:47:39 a user named tonic_1 said ```new version ^^ soz for disruption : http://ec2-54-163-92-231.compute-1.amazonaws.com:3000/chatbot/c85c8b9b-7c33-4251-bd16-fdef6a8499dc```.\\n\\nIn general, at 2023-10-15 12:57:19 a user named tonic_1 said ```To use AutoGen to create a User Proxy and a Manager Agent, you would need to follow the steps below:\\n\\nImport the necessary classes from the autogen package:\\n````from autogen import UserProxyAgent, ManagerAgent, AssistantAgent\\n```\\nCreate an instance of the UserProxyAgent:\\n```user_proxy = UserProxyAgent(name=\"user_proxy\")\\n```\\nCreate an instance of the ManagerAgent:\\n```manager = ManagerAgent(name=\"manager\")\\n```\\nCreate an instance of the AssistantAgent:\\n```assistant = AssistantAgent(name=\"assistant\")\\n```\\nRegister the ManagerAgent and AssistantAgent with the UserProxyAgent:\\n```user_proxy.register_agents(manager, assistant)\\n```\\nInitialize the conversation by sending a message to the UserProxyAgent:\\n```user_proxy.initiate_chat(\\n message=\"What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?\"\\n)\\n```\\nStart the conversation loop by calling the start_conversation() method on the ```UserProxyAgent:\\nuser_proxy.start_conversation()\\n```\\nThe complete code would look like this:\\n```\\nfrom autogen import UserProxyAgent, ManagerAgent, AssistantAgent\\n\\n# Create UserProxyAgent, ManagerAgent, and AssistantAgent instances\\nuser_proxy = UserProxyAgent(name=\"user_proxy\")\\nmanager = ManagerAgent(name=\"manager\")\\nassistant = AssistantAgent(name=\"assistant\")', '\\nIn created-with-autogen, at 2023-10-21 18:06:44 a user named telepathyx said ```I think it will exclusively \"solve creative\" things but lack the ability to operate as reliable infrastructure. due to its inability to self-correct.```.\\n\\nIn created-with-autogen, at 2023-10-21 17:03:51 a user named sidhujag said ```as is it wont solve anything creative yet.. the idea is to think of it as infrastructure```.\\n\\nIn created-with-autogen, at 2023-10-21 15:37:35 a user named wayliu said ```Kniru - Tireless AI-powered financial ad...```.\\n\\nIn created-with-autogen, at 2023-10-21 15:18:27 a user named pradeep1148 said ```intersting let me check it out```.\\n\\nIn created-with-autogen, at 2023-10-21 15:13:18 a user named telepathyx said ```Has anyone used autogen to create an app of any complexity, such as anthing bigger than a snake game? Is it still in the same state limited by context window and memory management? Or has anyone used autogen to enhance reasoning? Any use cases beyond a simulation/novelty yet?```.\\n\\nIn created-with-autogen, at 2023-10-21 07:39:49 a user named syedmujeeb said ```Hi \\nDoes autogen supports bedrock```.\\n\\nIn created-with-autogen, at 2023-10-20 17:06:33 a user named shaneyu said ```That\\'s the correct way to do it. Works like a charm```.\\n\\nIn created-with-autogen, at 2023-10-20 16:01:07 a user named pradeep1148 said ```https://www.youtube.com/watch?v=huIv541bKpw&ab_channel=DLExplorers```.\\n\\nIn created-with-autogen, at 2023-10-19 23:23:03 a user named shaneyu said ```I’ll take a look, thanks!👏```.\\n\\nIn created-with-autogen, at 2023-10-19 23:19:09 a user named sonichi said ```How about closing it after the top-level `initiate_chat`?```.\\n\\nIn created-with-autogen, at 2023-10-19 21:13:50 a user named shaneyu said ```It should be one connection object for one conversation, if the conversation ends the connection object should be killed```.\\n\\nIn created-with-autogen, at 2023-10-19 21:11:45 a user named sonichi said ```Does every agent have a socket connection? Or is there one connection for all?```.\\n\\nIn created-with-autogen, at 2023-10-19 20:33:30 a user named shaneyu said ```Hi @sonichi, last week I was talking about using websocket to establish a connection to the frontend GUI, I did some modification to the conversable_agent this week and now it works as expected, however, I am not sure on where to kill the socket connection. \\nIt should be killed when the entire conversation is over, not just one participating agent finished its job, and I think this is to be done on the conversable_agent level. Right now I think it goes down to receive function: \\n```        if reply is not None:\\n            self.send(reply, sender, silent=silent)\\n        else:\\n            # kill socket connection object\\n``` \\nBut I\\'m afraid this will close the connection when a certain agent completed its task, not the entire conversation is over. Would you mind providing some insights here? Much appreciated!\\U0001fae1```.\\n\\nIn created-with-autogen, at 2023-10-19 18:47:50 a user named aayushc1308 said ```P.S. Our current plan is to not reveal the internal orchestration of agents to the end user. The experience will always feel like a single agent. Only the internals is where multi agent magic happens.\\n\\nLet me know if I can clarify anything further.```.\\n\\nIn created-with-autogen, at 2023-10-19 18:45:39 a user named aayushc1308 said ```@wayliu \\nIt\\'s a group chat system. The group chat manager acts as an agent and mimics the single agent experience because the end user shouldn\\'t have to care about internal use of agents. It then internally manages a bunch of agents. \\nThe max rounds are also dynamic such that the group chat manager can terminate the interaction at any time when it is satisfied. We extended the group chat manager and group chat classes and created a significant amount of custom Kniru specific logic to support this.\\nThe current release actually can be achieved from single agent also in terms of quality. However, our release coming on Sunday will take the number of agents to approx 7 or 8. That is when the quality of results just blew our minds. We are working on testing these in a bunch of scenarios before releasing it.\\nWe had a previous architecture with Langchain but when we created domain specific agents using Autogen and combined it with some Langchain tools, the hallucinations got removed by almost like self correction.\\nWe should be able to discuss in more detail after Sunday release once we have also figured out the final details.```.\\n\\nIn created-with-autogen, at 2023-10-19 18:07:27 a user named wayliu said ```This is nice! @aayushc1308 one question, how do you guys leverage AutoGen? Looks like it\\'s more of the traditional single agent?```.\\n\\nIn created-with-autogen, at 2023-10-19 16:54:53 a user named aayushc1308 said ```Oh awesome, didn\\'t know about that channel. We will work on creating and adding any relevant tutorials to the channel!```.\\n\\nIn created-with-autogen, at 2023-10-19 16:43:33 a user named sonichi said ```Thanks for sharing. Also feel free to post on <#1161015724521836634>```.\\n\\nIn created-with-autogen, at 2023-10-19 16:39:03 a user named aayushc1308 said ```Hey everyone, Join Us at the Kniru Launch Party! 🚀\\nKniru has officially gone live on Product Hunt (https://www.producthunt.com/posts/kniru) this morning! I\\'m especially proud to mention that **Autogen** stands as one of the core technologies powering our AI pipeline.\\u2028We have launched a vanilla version of the Kniru Chat and will be releasing increasingly sophisticated Autogen-based architectures (custom Agents, custom Group chats, etc) with the first major update going out on Sunday. Our internal tests have completely blown our minds and we plan to slowly roll these out in a controlled and meticulously tested manner. We would love to invite you all to join us and give us feedback as we very quickly iterate with various architectures in production over the next weeks.\\u2028I will keep you all posted as we switch between various architectures so you can test things out yourself. We will keep sharing all our Autogen lessons on how to productionize things and will keep implementing relevant changes back to Autogen package based on the feedback you all share.\\n**Also, if any of you are planning to roll out Autogen in production, feel free to get in touch with us. We would be more than happy to help in every possible way and share our lessons.**```.\\n\\nIn created-with-autogen, at 2023-10-21 15:37:36 a user named wayliu said ```@aayushc1308  thanks for elaboration. Wouldn\\'t that cost too muh time though? Adding so many agents? I mean user would need to wait for at least a min to see results?```.\\n\\nIn created-with-autogen, at 2023-10-21 15:39:29 a user named telepathyx said ```https://arxiv.org/abs/2310.01798 \\n\\nwhat are you doing to address this?```.\\n\\nIn created-with-autogen, at 2023-10-21 15:40:34 a user named telepathyx said ```\"Transitioning to another facet of self-correction, we investigate the potential of\\nmulti-agent debate (Du et al., 2023; Liang et al., 2023) as a means to improve reasoning. In this\\nmethod, multiple instances of an LLM critique each other’s responses. However, our results reveal\\nthat its efficacy is no better than self-consistency (Wang et al., 2022) when considering an equivalent\\nnumber of responses, highlighting the limitations of such an approach.\"```.\\n\\nIn created-with-autogen, at 2023-10-21 15:40:54 a user named telepathyx said ```are you sure it\\'s responsible to let people think they\\'re getting good financial advice from autogen?```.\\n\\nIn created-with-autogen, at 2023-10-21 15:43:25 a user named telepathyx said ```correct -> incorrect happens more often than incorrect -> correct```.\\n\\nIn created-with-autogen, at 2023-10-21 15:50:25 a user named telepathyx said ```it\\'s a thermodynamic process. the further way you get from external feedback, the further it drifts into a hypothetical probability space that is increasingly disconnected from reality```.\\n\\nIn created-with-autogen, at 2023-10-21 15:52:55 a user named telepathyx said ```feedback is like qualia to an LLM. without that words don\\'t actually map to any meaning```.\\n\\nIn created-with-autogen, at 2023-10-21 15:53:20 a user named telepathyx said ```it\\'s all self referencing definitions```.\\n\\nIn created-with-autogen, at 2023-10-21 15:53:46 a user named telepathyx said ```language is full of circular logic that can\\'t encapsulate a worldview```.\\n\\nIn created-with-autogen, at 2023-10-21 18:05:41 a user named aayushc1308 said ```We pass around the websocket and keep the user informed what is happening. So the user always has some visibility. Also, not all agents get to speak for every question. Most questions get terminated after one or two agents have spoken. We have built some intelligence around this on how that happens but that is Kniru specific logic. But I am not seeing things take more than a min though in our tests. Still too early to speak with certainty since we are changing things every other hour.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:09:06 a user named aayushc1308 said ```We actually don\\'t use autogen for advice (except the current version in prod which is super vanilla). We have created hundreds of internal tools that actually drive the intelligence aspect of this. Autogen more of less helps in terms of semantic parsing, summarizing, and some other functions like generic personal finance advice and definitions from content out there. The actual math and intelligence is driven by large amounts of Kniru\\'s internal intelligence. The correct way to think about this would be a hedge fund level intelligence library being controlled by Agents.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:10:47 a user named aayushc1308 said ```And, we are being very explicit in the product to let people know that we are super early and things are evolving. \\nThe goal is to achieve very very high accuracy (say 99%) in a few months.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:11:22 a user named aayushc1308 said ```Btw: Just building a wrapper around autogen performs horribly for finance. We **ARE NOT** doing that.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:12:17 a user named telepathyx said ```okay, so it\\'s not exactly giving \"precise, personalized, actionable insights and answers all your financial questions\" - that makes sense now```.\\n\\nIn created-with-autogen, at 2023-10-21 18:13:13 a user named telepathyx said ```i assume if you ask \"should i invest in meta\" it will explain the efficient market hypothesis right?```.\\n\\nIn created-with-autogen, at 2023-10-21 18:13:35 a user named aayushc1308 said ```It does give personalized advice. Not sure I follow your inference. The tools are powered by your data. So it is personal.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:14:33 a user named telepathyx said ```it will explain that eugene fama won the nobel prize for proving beating the market is impossible? that price variation around risk-adjusted margin return is random?```.\\n\\nIn created-with-autogen, at 2023-10-21 18:15:43 a user named aayushc1308 said ```\"should i invest in meta\"  --> fetch your current portfolio --> build utility function using your transactions --> fetch data about meta --> fetch current market news --> run quantitative intelligence (proprietary) --> Share advice.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:15:53 a user named aayushc1308 said ```That is roughly the flow that Kniru will enter.```.\\n\\nIn created-with-autogen, at 2023-10-21 18:16:14 a user named telepathyx said ```ah okay hahah... i have a background in quant trading so i apologize for calling you out```.\\n\\nIn created-with-autogen, at 2023-10-21 18:16:37 a user named telepathyx said ```i don\\'t really agree with your ethics but it\\'s not unlawful```.', '\\nIn created-with-autogen, at 2023-10-02 05:16:41 a user named sonichi said ```https://twitter.com/oscarmoxon/status/1708603929011863871```.\\n\\nIn created-with-autogen, at 2023-10-01 22:29:07 a user named abhilashinumella said ```Yes I was surprised too. I used GPT-4 for the prompts. Feel confident it can used to generate AI squad for a lot of low to medium precision tasks/goals.```.\\n\\nIn created-with-autogen, at 2023-10-01 21:42:28 a user named iamhere said ```YO! is this what your\\'e talking about? I\\'d love to help, I\\'m really new to all of this and need to get caught up to speed. I\\'m jumping over hurdles getting to this point. I still have no idea what I\\'m doing, but I think its because I\\'m trying to interoperate with langchain and autogen, without know how to use either. SMH \\nBaby Steps, do we even need langchain anymore? that\\'s how I found autogen as I\\'m trying to have conversations with multiple agents at once. My spreadsheets were only doing so much.```.\\n\\nIn created-with-autogen, at 2023-10-01 20:39:54 a user named .princeps said ```Nice, I have another repo up that you can checkout```.\\n\\nIn created-with-autogen, at 2023-10-01 19:17:40 a user named kenfucius5452 said ```Love it! I\\'m quite impressed by the quality of the output with such seemingly simple prompting. I\\'m curious, did you write the prompts yourself? Did you use GPT4 or any other tool to generate the written personas of Joey and Monica?```.\\n\\nIn created-with-autogen, at 2023-10-01 17:28:38 a user named pradeep1148 said ```hey made a video based on this github repo https://www.youtube.com/watch?v=gnn1H4H81IY&ab_channel=DLExplorers Thanks for the contribution poly```.\\n\\nIn created-with-autogen, at 2023-10-01 04:37:31 a user named abhilashinumella said ```A scene writer using autogen: https://x.com/abhilashi/status/1708339764250947692?s=20```.\\n\\nIn created-with-autogen, at 2023-09-30 19:16:58 a user named tonic_1 said ```sent to you and @salegrem```.\\n\\nIn created-with-autogen, at 2023-09-30 19:15:54 a user named mdfahad999 said ```https://github.com/mdfahad999```.\\n\\nIn created-with-autogen, at 2023-09-30 19:14:42 a user named tonic_1 said ```join us on discord also```.\\n\\nIn created-with-autogen, at 2023-09-30 19:14:29 a user named tonic_1 said ```very cool @WolfroseWe and @mdfahad999 , just send me your github and i\\'ll add you, it will be fun, i\\'m sure```.\\n\\nIn created-with-autogen, at nan a user named mdfahad999 said ```I am interested to contribute.```.\\n\\nIn created-with-autogen, at 2023-09-30 18:28:01 a user named .princeps said ```https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\\n\\nIn created-with-autogen, at 2023-09-30 17:00:01 a user named tonic_1 said ```yes my friend, please join us 👊🏻```.\\n\\nIn created-with-autogen, at 2023-09-30 09:27:56 a user named tonic_1 said ```going to remake autogtp to achieve better performance against beebot benchmark by using autogen https://github.com/team-tonic-arena-hacks```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:07:04 a user named sazied said ```@sonichi @rickyloynd I think this should work best for my use case\\n\\nThanks again for all your help and such prompt responses 🙏🚀```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:05:54 a user named sazied said ```Just went over your code, looks neat 😄```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:05:38 a user named sazied said ```Wow, thanks so much man!```.\\n\\nIn ideas-and-feedback, at 2023-11-15 02:02:02 a user named c_bonadio said ```Hi @sazied I used websockets to get and send human_input take a look here\\nhttps://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.\\n\\nIn ideas-and-feedback, at 2023-11-15 01:07:42 a user named sazied said ```I have this socket connection running that allows me to receive the responses back from the agents on the forntend - \\n\\n\\n@socketio.on(\\'start_orchestrator\\')\\ndef handle_start_orchestrator(data):\\n    print(\\'YOO\\')\\n    #Extract the data and start the orchestrator\\n    test_param = data.get(\"test_param\", \"Default Value\")\\n    \\n    success, seq_messages = sequential_orchestrator.sequential_conversation(test_param)\\n    \\n    \\n    # Send each message as it is generated\\n    for message in seq_messages:\\n        socketio.emit(\\'orchestrator_message\\', { \\'message\\': message })\\n\\n\\nFor one of the steps I need a human feedback loop so I have now set human_input_mode = \\'ALWAYS\\' to test this functionality. How do I set the human feedback message without using the terminal. Does autogen expose some method that I am not aware of? I am also using a custom orchestrator, so I am wondering if I can set up a method in the Orchestrator class, but I do not know where to start.\\nAny help would be much appreciated!```.\\n\\nIn ideas-and-feedback, at 2023-11-15 00:58:35 a user named rickyloynd said ```More details about @lucemia.\\'s application. https://discord.com/channels/1153072414184452236/1174149944718921820```.\\n\\nIn ideas-and-feedback, at 2023-11-15 00:50:22 a user named lucemia. said ```I am currently using AutoGen to streamline and minimize repetitive DevOps tasks.```.\\n\\nIn ideas-and-feedback, at 2023-11-15 00:38:12 a user named sonichi said ```The default system_message for `AssistantAgent` instructs writing code. Please overwrite it for your use case.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 22:24:28 a user named sleepwave said ```thank you! That was my initial understanding which is why I was so shocked when I was getting code back based on a simple prompt that included an `AssistantAgent`. I thought the `AssistantAgent` was configured in a pretty \"default\" manner using a local model that I knew to be primarily conversational. I\\'m using a `UserProxyAgent` with the `AssistantAgent`, maybe it\\'s actually the `UserProxyAgent` that\\'s polluting the flow?```.\\n\\nIn ideas-and-feedback, at 2023-11-14 21:49:22 a user named pika.c said ```Autogen is a framework. You can use it just for conversation between agents without code output or execution. It depends on the system prompts you pass to each agent```.\\n\\nIn ideas-and-feedback, at 2023-11-14 21:43:29 a user named sleepwave said ```hey guys, quick question if anyone can help me wrap my head around something. After tinkering with autogen, it seems autogen\\'s primary goal is to output code. Is there a similar framework that lets me allow multiple agents to simply _converse_ to solve a more abstract problem? Is that where Langchain comes in, or am I misunderstanding the capabilities and intention of Autogen?```.\\n\\nIn ideas-and-feedback, at 2023-11-14 18:20:20 a user named airlights said ```it\\'s actually one big \\'assistant\\' roleplaying for each. Look, if you\\'re happy -- I\\'m happy 🙂 Hope this gives you what you need```.\\n\\nIn ideas-and-feedback, at 2023-11-14 18:20:16 a user named _jojorge said ```I can write a brief post explaining the how\\'s and whys, and clean up the code to be a notebook.\\n\\nI started with your \"next\" tag example as a starting off point, and had GPT4 and the docs bring me toward the functionality demonstrated here.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 18:17:43 a user named _jojorge said ```it\\'s true that you can\\'t load multiple agents, but the way that it\\'s set up (and the way I ran it last night), is that I basically had a shell around each, so with a bit of hierarchy, I was able to access lots of OpenAI agents in one session. Just check out the logs and you will see. All the agents were OpenAI assistants.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:59:26 a user named airlights said ```I agree the next thing is to take each chapter and storyboard it 🙂```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:58:37 a user named airlights said ```it\\'s not production ready but it works pretty nicely```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:58:11 a user named airlights said ```I can help you if you want to instantiate that whole team, I\\'ve built a solution that uses an Airtable to keep track of team members, gives them different models, temperature, roles etc.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 15:57:04 a user named airlights said ```That looks nice but I have to tell you, right now AutoGen can only integrate one OpenAI assistant (GPT Assistant only supports one OpenAI client. Using the first client in the list.\\nNo instructions were provided for given assistant. Using existing instructions from assistant API.)```.\\n\\nIn ideas-and-feedback, at 2023-11-14 14:39:17 a user named mgintoki said ```how to integrate with social plat data analysis```.\\n\\nIn ideas-and-feedback, at 2023-11-14 13:39:07 a user named sonichi said ```Nice suggestion! Would you like to present it as a notebook example, or a blog post, or some other way?```.\\n\\nIn ideas-and-feedback, at 2023-11-14 13:38:50 a user named fran.abenza said ```https://chat.openai.com/g/g-EwugVj4zq-autogen-builder```.\\n\\nIn ideas-and-feedback, at 2023-11-14 07:30:52 a user named pika.c said ```This is pretty cool! Adding imagery to this is a great idea. The only barrier right now to experimenting with this tech is the cost of the APIs.```.\\n\\nIn ideas-and-feedback, at 2023-11-14 06:07:39 a user named _jojorge said ```yeah! Right now I\\'m just screwing around, but I build out a writers room which cooked this up tonight, since you helped me wrangle them!\\n\\nhttps://drive.google.com/file/d/1LLsVGWm0BXLZnMfZ1f0zd1D14qi0QV9x/view?usp=sharing\\n\\nGo Buffs!\\n\\nHere is the terminal output:\\nhttps://drive.google.com/file/d/1m2ZnCicmIgzZfvOOm02TLHAr0JuYNuHB/view?usp=sharing\\n\\nIt looks a bit like your project! I spend a while earlier today defining a workflow, and building out the dossiers on the writers in the writers room. This I used the newly released GPT assistants to hook autogen into the new openAI assistants (which probably wasnt necessary) and assigned them to my writers room.\\n\\nI\\'d like to add a way for the members of the team to commit to long term memory their memories, such as character arcs, settings, themes, plot outlines at varying degrees (entire story, chapter, scene). \\n\\nAlso, I\\'d like to add agents to create imagery.\\n\\nMaybe I\\'ll automate the audio narration. It would be cool to parse out different narrated speech for different characters and the narrator. ', '\\nIn general, at 2023-11-09 01:49:44 a user named sonichi said ```Just talked about it in <#1157717881291812964> 😃```.\\n\\nIn general, at 2023-11-09 01:43:36 a user named zoted said ```🙋🏽\\u200d♂️Are there any good documents or google collab with Autogen and Open AI assistant working together yet?```.\\n\\nIn general, at 2023-11-08 23:44:04 a user named drinkoblog.weebly.com said ```https://www.agentcloud.dev/```.\\n\\nIn general, at 2023-11-08 23:30:38 a user named groundzer000 said ```i would love to see real working apps built with autogen. is there any??```.\\n\\nIn general, at 2023-11-08 23:12:05 a user named trev1649 said ```I am passionate about learning, teaching and using Ai to create residual income. I have researched a lot of software\\'s and platforms, the solution I choose is Autogen.```.\\n\\nIn general, at 2023-11-08 21:34:35 a user named bon_am said ```yes some really interesting use cases are triggering but those need a sounding board to discuss..```.\\n\\nIn general, at 2023-11-08 21:33:21 a user named usingxbox360controller said ```Would be a lifesaver for many people honestly```.\\n\\nIn general, at 2023-11-08 21:31:41 a user named bon_am said ```hello @everyone .. im bonam and a fan of autogen and all other multi agent frameworks.\\n\\nthis framework gives opensource a real chance to challenge openai by creatively interconnecting specialist agents from open source to accomplish tasks better beyond a single large gpt model in near future.\\n\\nwhy sleep on this.\\n\\nthats why im working on a ui for multi agent chat with a team of developers\\n\\nhowever if anyone of u is as passionate about autogen and can play god with multiple agents and use cases \\n\\n\\ni want to collaborate in creating an open source ui for this multi generative future. \\n\\nDMs are open. \\n\\nplease reach out! @bon_am```.\\n\\nIn general, at 2023-11-08 21:12:10 a user named usingxbox360controller said ```Thanks! Glad to see you still in the Ai fight, haha.\\n\\nSo those more \\'complicated\\' threads are all done via API then, and not testable through playground?```.\\n\\nIn general, at 2023-11-08 21:10:34 a user named hanley7082 said ```Hey Captain 🙂 When the new OpenAI assistant gets fully integrated into autogen, you will be able to set up multiple assistants the same way you do it now (in autogen).\\n\\nHow the oai assistant works is you initialize an assistant with a system message and tools/files enabled. You then create a thread and add your first user message. You can then pass an assistant and a thread to the run function, which returns the response (as well as updating the thread, which is managed by them). I still have some questions about memory across the entire system, but this seems like a good start.```.\\n\\nIn general, at 2023-11-08 20:32:08 a user named arnoow said ```hello, i have a question for you fellow ai experts, i was wondering if openai for their new custom gpts bots feature is using an architecture where they use at first the generalist ChatGPT 4 model and when it identifies the domain you want to build your chatbot upon it switches to a fine tuned, specialized version of the base model gpt 4 ?```.\\n\\nIn general, at 2023-11-08 20:21:46 a user named usingxbox360controller said ```I see, but they don\\'t have the framework to get multiple assistants to work with each other do they?```.\\n\\nIn general, at 2023-11-08 19:31:21 a user named dulak said ```Yea I\\'ve been keeping an eye on it too, just wanted to logic check tyvm!```.\\n\\nIn general, at 2023-11-08 19:18:41 a user named hanley7082 said ```The OpenAI assistants are basically an autogen assistant upgrade. Now we don\\'t have to manage chat memory, assistant can do rag (no external agent necessary) and run a code interpreter (again, with no external agent necessary). The autogen assistant could always do function calling so that\\'s not new```.\\n\\nIn general, at 2023-11-08 19:15:38 a user named hanley7082 said ```Autogen is the command and code execution piece that completes the autonomy loop```.\\n\\nIn general, at 2023-11-08 19:15:32 a user named gubok said ```If you want to be able to use open source LLMs, keep using autogen 🙂```.\\n\\nIn general, at 2023-11-08 18:54:45 a user named usingxbox360controller said ```It\\'s probably just two completely separate teams working on this. Assistants API is strictly from OpenAi isn\\'t it?```.\\n\\nIn general, at 2023-11-08 18:53:41 a user named jacek6859 said ```So, whats Microsoft OpenAI strategy regarding development of AutoGen vs Assistants API?```.\\n\\nIn general, at 2023-11-08 18:34:11 a user named jacek6859 said ```Whats best practice to call a python function, that must be used by an agent. Should I define a function in a given agent class, or should I keep function as separate code? Any pattern  here?```.\\n\\nIn general, at 2023-11-08 18:25:08 a user named andi1281 said ```is there a tutorial on how i can implement a trained agent into my script?```.\\n\\nIn general, at 2023-11-08 17:36:40 a user named bobaleaux said ```yeah, that\\'s definitely one of those \"you\\'re mileage may vary\" kind of things too making moving parts, right?```.\\n\\nIn general, at 2023-11-08 17:35:29 a user named usingxbox360controller said ```Executing the code still takes forever though, I wonder if that\\'s just my PC/setup```.\\n\\nIn general, at 2023-11-08 17:33:35 a user named bobaleaux said ```I haven\\'t tried it yet, I\\'ve been hung up on migrating to postgres.. ugh```.\\n\\nIn general, at 2023-11-08 17:32:29 a user named usingxbox360controller said ```Autogen is SO MUCH nicer now w/ GPT4 turbo god damn```.\\n\\nIn general, at 2023-11-08 17:32:29 a user named bobaleaux said ```but it doesn\\'t make sense forever```.\\n\\nIn general, at 2023-11-08 17:25:59 a user named bobaleaux said ```and I\\'m just speaking as me. my own view```.\\n\\nIn general, at 2023-11-08 17:25:14 a user named bobaleaux said ```it\\'s not earth shattering and there is a deep integration of openai right now, they are a service provider to bing.```.\\n\\nIn general, at 2023-11-08 17:24:21 a user named bobaleaux said ```you can find the entire opening day video on openai website```.\\n\\nIn general, at 2023-11-08 17:23:46 a user named bobaleaux said ```yes, he spoke at the DevDay i thought it was an awkward but revealing moment of truth about the future.```.\\n\\nIn general, at 2023-11-08 17:23:03 a user named benbarnard said ```? he mentioned it in the OpenAI thing?```.\\n\\nIn general, at 2023-11-08 17:22:43 a user named bobaleaux said ```hahaha, yeah, when Altman introduced him and said something about the relationship with MS!```.\\n\\nIn general, at 2023-11-08 17:22:05 a user named benbarnard said ```I read somewhere that Satya mentioned Autogen yesterday, does anybody know about this?```.\\n\\nIn general, at 2023-11-08 17:21:55 a user named bobaleaux said ```I know!!! hahaha and knowing that while being \\'the\\' product designer, right? well, talk about a group chat! wow! it\\'s like the forward progress has slowed but the width of the dozer blad eis widening super fast!.\\n\\ncountry boy analogy, hahaha```.\\n\\nIn general, at 2023-11-08 17:18:50 a user named rickyloynd said ```@bobaleaux Absolutely, we\\'re working on that vision! Hopefully not too far out, because the field is moving so fast.```.\\n\\nIn general, at 2023-11-08 17:17:57 a user named afourney said ```It\\'s fast. Performance on benchmarks I\\'ve tried is very standard for GPT-4. With 100 requests a day limit, it\\'s hard to say more```.\\n\\nIn general, at 2023-11-08 17:00:02 a user named aaronward_ said ```Haven\\'t used the new gpt-4-1106-preview yet, whats peoples expriences so far with respect to Autogen agents?```.\\n\\nIn general, at 2023-11-08 16:57:53 a user named bobaleaux said ```Ricky, it\\'s exciting to watch it all expand. It seems like it\\'s going to come down to the orchestration of the \\'component\\' stored objects.  dynamically callable context and then shaping the different messages and instructions to give what seems would be really close be being able to have different thoughts about different things and so forth.\\nAre you guys working to bring them together or is that still a ways out?```.\\n\\nIn general, at 2023-11-08 16:50:05 a user named hahl9000 said ```Anyone here has experience/links/stuff about gpt chatbots forwebpage for eg. to use in wordpress?```.\\n\\nIn general, at 2023-11-08 16:12:06 a user named onecodescholar said ```There\\'s faster models out there but not exactly specific for coding. I\\'m wanting an updated local Coding LLM.```.\\n\\nIn general, at 2023-11-08 16:09:23 a user named andi1281 said ```Awesome, thanks @shaggz2006, @onecodescholar   and @rickyloynd  for your help! I really appreciate it.```.\\n\\nIn general, at 2023-11-08 16:08:23 a user named onecodescholar said ```https://www.runpod.io/```.\\n\\nIn general, at 2023-11-08 16:08:06 a user named shaggz2006 said ```If you do have funds available, you can get a GPU running on runpod for a few bucks an hour.   Then you can compare how it runs there to how it runs locally.```.\\n\\nIn general, at 2023-11-08 16:06:57 a user named shaggz2006 said ```When you run codellama straight from LM Studio, you should see a general \\'tokens/sec\\' metric.   This can give you an idea of what you are dealing with.```.\\n\\nIn general, at 2023-11-08 16:06:57 a user named andi1281 said ```ok, then i´ll try to find a solution where this works online somehow```.\\n\\nIn general, at 2023-11-08 16:06:13 a user named onecodescholar said ```That might be the bottleneck```.\\n\\nIn general, at 2023-11-08 16:06:01 a user named andi1281 said ```i haven´t configured anything in terms of GPU usage```.\\n\\nIn general, at 2023-11-08 16:05:14 a user named andi1281 said ```I have a 8GB M2 Mac Mini```.\\n\\nIn general, at 2023-11-08 16:04:51 a user named shaggz2006 said ```do you have an Nvidia GPU locally, and if so, do you have LM Studio config\\'d to use the cores?```.\\n\\nIn general, at 2023-11-08 16:04:15 a user named andi1281 said ```probably the wrong model for the job, right? I  naively chose this one because i read that Codellama might be good for that kind of job```.\\n\\nIn general, at 2023-11-08 16:04:12 a user named onecodescholar said ```I was going to suggest using a smaller model for faster results but you\\'re already on a 7B model.```.\\n\\nIn general, at 2023-11-08 16:02:45 a user named andi1281 said ```The Bloke codellama instruct 7B q4_k_s ggml```.\\n\\nIn general, at 2023-11-08 16:02:36 a user named rickyloynd said ```Our team is being asked that a lot, so we are preparing a complete response that should be out soon. 😄```.\\n\\nIn general, at 2023-11-08 16:00:47 a user named shaggz2006 said ```@rickyloynd   -- has there been any collaboration between the autogen team and OpenAI in regards to agents (given the MS partnership)?```.', '\\n\\nSo, and I may be wrong as I am not 100% familiar with how AutoGPT runs, but my understanding is that AutoGen is the framework that AutoGPT could have been built from.\\n\\n\\nSo, when benchmarking, it won\\'t simply be AutoGen vs AutoGPT; the specific workflow and configuration of AutoGen, and it\\'s resulting performance, is what will be compared.```.\\n\\nIn general, at 2023-09-29 16:13:03 a user named fxtoofaan said ```Are the prompt message different between the different models ? Like gptx vs llama2 vs falcon vs mistral ?```.\\n\\nIn general, at 2023-09-29 16:11:01 a user named pkscary said ```The AutoGPT team has been benchmarking all the agent-based projects so I wonder how AutoGen stacks up```.\\n\\nIn general, at 2023-09-29 16:10:29 a user named pkscary said ```Does anyone have experience with Beebot, BabyAGI, AutoGPT, etc. and how do you think AutoGen compares to these other projects?```.\\n\\nIn general, at 2023-09-29 16:08:32 a user named pkscary said ```Someone should pin the repo https://github.com/microsoft/autogen to the welcome page for this Discord```.\\n\\nIn general, at 2023-09-29 15:57:41 a user named sonichi said ```AssistantAgent(name=..., llm_config={\"model\": \"gpt-3.5-turbo\", \"api_key\": ...})```.\\n\\nIn general, at 2023-09-29 15:38:53 a user named vincentjedi said ```response = autogen.Completion.create(\\n    config_list=[\\n        {\\n            \"model\": \"gpt-4\",\\n            \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\\n            \"api_type\": \"azure\",\\n            \"api_base\": os.environ.get(\"AZURE_OPENAI_API_BASE\"),\\n            \"api_version\": \"2023-07-01-preview\",\\n        },\\n        {\\n            \"model\": \"gpt-3.5-turbo\",\\n            \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\\n            \"api_type\": \"open_ai\",\\n            \"api_base\": \"https://api.openai.com/v1\",\\n            \"api_version\": None,\\n        },\\n        {\\n            \"model\": \"llama-7B\",\\n            \"api_base\": \"http://127.0.0.1:8080\",\\n            \"api_type\": \"open_ai\",\\n            \"api_version\": None,\\n        }\\n    ],\\n    prompt=\"Hi\",\\n)```.\\n\\nIn general, at 2023-09-29 15:35:12 a user named crankfunk said ```hey there, trying for hours now, but I dont get it: just want to get the quickstart example running (\"Plot a chart of NVDA and TESLA stock price change YTD.\"). how can I switch the model to gpt-3.5-turbo? dont have access to gpt-4. i read the FAQs and everything but am totally stucked.```.\\n\\nIn general, at 2023-09-29 15:29:35 a user named tonic_1 said ```that\\'s what i\\'m trying to have folks do for this one : https://huggingface.co/collections/MultiTransformer/autogengradiohuggingface-651626e54256270d6fad2621\\njoin the organisation here : https://huggingface.co/MultiTransformer\\n\\ni\\'ll probably go through the shares on this discord to add them to the collection, but let\\'s make some cool demos together, it will be fun 👊🏻```.\\n\\nIn general, at 2023-09-29 15:08:07 a user named vincentjedi said ```Have u tried to add a simple gradio or streamlit frontend to use it with browser ?```.\\n\\nIn general, at 2023-09-29 14:50:19 a user named fxtoofaan said ```I’m trying to figure that out```.\\n\\nIn general, at 2023-09-29 14:48:18 a user named vincentjedi said ```How can we use llama2 or other local llm instead of using openai api?```.\\n\\nIn general, at 2023-09-29 14:45:20 a user named fxtoofaan said ```It’s missing some information which I cannot find any how to for it.```.\\n\\nIn general, at 2023-09-29 14:44:38 a user named fxtoofaan said ```I think we all have similar goals. Would be nice to maybe have a chat group where we can share code snippets making this work ?```.\\n\\nIn general, at 2023-09-29 14:44:30 a user named nexorsist said ```One of the issues on the Github page shows how to connect it to a local LLM (i think it was fastchat)```.\\n\\nIn general, at 2023-09-29 14:43:42 a user named nexorsist said ```it can likely then also optimize priming individual worker agents with better system prompts as it progresses```.\\n\\nIn general, at 2023-09-29 14:43:03 a user named fxtoofaan said ```At this point I’d love to see a single python file with everything in it to connect autogen to a local llm server like fastchat running mistral 7b model. No openai api keys, all local stuff. Simple bot that can answer who is current president of united states for example. Can anyone build code for this please ?```.\\n\\nIn general, at 2023-09-29 14:42:37 a user named nexorsist said ```What is missing from an agentverse setup is a decision maker which an LLM is not. What we need is a reinforcement learning bot (like what DeepMind makes) that acts as the central decision maker in conjunction with an LLM to send out the instructions. The RL agent can read the project \"environment\" and can perform actions (instructions) to LLM agents.```.\\n\\nIn general, at 2023-09-29 14:40:18 a user named nexorsist said ```I think the idea would be to think about it a little differently. Think of every agent you need to perform tasks as a clean slate skilled person. You prime it with the correct prompt to setup the \"skillset\" and to be specific about the type of tasks it should perform and how.\\n\\nThen think of a workflow for the project you want to build and how it should interact with your pre-primed agents so that memory retention isn\\'t required. \\n\\nThat still has limitations if you trying to build on past things but it will likely just result in you changing how you design things. Could maybe make an agent that documents all tasks that were completed in a summarised manner to a central storage which you can then use as a knowledge index for the model of all things that have been built and done for future additions to a project?```.\\n\\nIn general, at 2023-09-29 14:31:15 a user named sspoth said ```Is there a way to have these bots retain its memory```.\\n\\nIn general, at 2023-09-29 13:43:06 a user named fxtoofaan said ```getting this error using local llm:\\n\\nValueError: dictionary update sequence element #0 has length 1; 2 is required```.\\n\\nIn general, at 2023-09-29 13:36:58 a user named .princeps said ```here is the project I setup to create a simple snake game \\n\\nhttps://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\\n\\nIn general, at 2023-09-29 13:15:23 a user named tonic_1 said ```If y’all are building tutorials and demos don’t forget this 👆🏻```.\\n\\nIn general, at 2023-09-29 13:07:46 a user named fxtoofaan said ```i am getting timeout issues using local llm. I even set the timeout to 900 seconds. (read timeout=900) in \\\\autogen\\\\autogen\\\\oai\\\\completion.py file.```.\\n\\nIn general, at 2023-09-29 13:01:11 a user named redai.ai said ```Any newbies that need help getting autogen working check it out```.\\n\\nIn general, at 2023-09-29 13:01:01 a user named redai.ai said ```https://www.youtube.com/watch?v=8TLwSH_UFwI&feature=youtu.be```.\\n\\nIn general, at 2023-09-29 13:00:56 a user named redai.ai said ```My video on autogen is premiering now```.\\n\\nIn general, at 2023-09-29 10:16:25 a user named fxtoofaan said ```My first use case is using autogen to help me create a virtual agents team for a specific task. And I want autogen to give me the team members abilities , deliverables and which other agent it should listen to or give orders to. Like make me a team that can start and scale a b2b newsletter from $0 to $1million in 12 months.```.\\n\\nIn general, at 2023-09-29 09:45:50 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.\\n\\nIn general, at 2023-09-29 09:39:11 a user named thunderbird365 said ```Ah, I see. I see the pattern```.\\n\\nIn general, at 2023-09-29 09:37:50 a user named thunderbird365 said ```No, that is false. \\nHere\\'s the proof it does```.\\n\\nIn general, at 2023-09-29 09:37:09 a user named scratchinknight said ```userProxy doesnt generate anything unless its your input```.\\n\\nIn general, at 2023-09-29 09:36:29 a user named fxtoofaan said ```@sonichi is it possible for an agent to go to web and search for stuff and gather up to date info? Like research for a topic or concept```.\\n\\nIn general, at 2023-09-29 09:36:25 a user named thunderbird365 said ```Anyone getting this problem: \\n\\nThe user proxy chooses not to reply anything randomly.```.\\n\\nIn general, at 2023-09-29 09:35:55 a user named scratchinknight said ```i get this error docker.errors.DockerException: Error while fetching server API version: request() got an unexpected keyword argument \\'chunked\\'```.\\n\\nIn general, at 2023-09-29 09:31:21 a user named sonichi said ```You can provide the image name as a str```.\\n\\nIn general, at 2023-09-29 08:50:41 a user named nexorsist said ```Suspect it will be the latter because the OpenAI API gpt models do not have access to the internet yet```.\\n\\nIn general, at 2023-09-29 08:46:24 a user named fxtoofaan said ```So does autogen have access to the internet yet? Or can I use autogen to gather data from internet for its agents ? What about local docs vector db or local knowledge added to agents ?```.\\n\\nIn general, at 2023-09-29 08:28:44 a user named scratchinknight said ```do i setup the docker in environment and then provide or it create the container?```.\\n\\nIn general, at 2023-09-29 08:27:03 a user named scratchinknight said ```how does use_docker work ?```.\\n\\nIn general, at 2023-09-29 08:01:42 a user named jimmysandwiches said ```Can i suggest a excellent tip I use when learning and debugging code - use claude.ai (seems to work better for me with code errors than chatgpt, also try bard) and simply post the error message into chat (thats all i did, we\\'re all learning 🙂 🥪```.', '\\nIn general, at 2023-10-07 09:23:15 a user named bitsy_chuck said ```multiple document in vector store vs single document in vector store (chroma db) \\nembedding model: all-mpnet-base-v2 or all-MiniLM-L6-v2\\npdf file with 500 pages\\nshould i break it up into chapters for better results?```.\\n\\nIn general, at 2023-10-07 08:06:12 a user named juzure. said ```As a beginner, I\\'m curious about the differences between AutoGPT and Autogen. Does anyone know?```.\\n\\nIn general, at 2023-10-07 08:02:15 a user named le_xxx said ```yay got the example working! does anyone know, does autogen have some file manager to save the generated code automatically?```.\\n\\nIn general, at 2023-10-07 07:48:01 a user named d8689 said ```I had the same issue (posted it in ideas-and-feedback), if you come up with a solution do post 😄```.\\n\\nIn general, at 2023-10-07 07:33:56 a user named eljefe69 said ```Hey, German fella here too.```.\\n\\nIn general, at 2023-10-07 06:28:00 a user named rumgewieselt said ```Hi. I am from Germany / Hamburg and happy to join the community here.```.\\n\\nIn general, at 2023-10-07 06:16:50 a user named bluethinhorse_18200 said ```https://tenor.com/iMpqamk3c52.gif```.\\n\\nIn general, at 2023-10-07 05:58:07 a user named heresynetwork said ```HI!  I came here from Wes Roth\\'s video!```.\\n\\nIn general, at 2023-10-07 04:21:24 a user named qingyunwu said ```Not yet. But still tuned 🙂```.\\n\\nIn general, at 2023-10-07 04:06:54 a user named afourney said ```In other projects I’ve used an exponential back off when a request time out wasn’t provided```.\\n\\nIn general, at 2023-10-07 04:05:17 a user named afourney said ```Yeah if you filter it to select only one model, and hit a rate limit error, it should correctly handle the OAI exception (I.e., by waiting for the prescribed amount of time that the API provides). If that’s not the case, we should file an issue on GH```.\\n\\nIn general, at 2023-10-07 03:50:01 a user named sigma.xxx said ```Hi I was running into the same issue, however I dont think that model switching is the way to go though....it compromises quality. I think AutoGen should maybe consider adding a rate_limit_handle class like a singleton or something that tracks all instances tokens comsumption, and implement a wait logic. That seems to make more sense```.\\n\\nIn general, at 2023-10-07 03:42:02 a user named le_xxx said ```hi all, running into a wall trying to test this out, it says openai.error.AuthenticationError: No API key provided. You can set your API key in code using \\'openai.api_key = <API-KEY>\\',... even tho i did setup OAI_CONFIG_LIST with my key and when i load it with config_list = autogen.config_list_from_json( i can see its loaded with print(config_list) then i setup some assistants and finally doing a user_proxy.initiate_chat it gives me that error. watched some videos and all they did was setup that json and it works for them```.\\n\\nIn general, at 2023-10-07 03:17:15 a user named slayerdeebo said ```Is it possible to use GPT vision in autogen ?```.\\n\\nIn general, at 2023-10-07 03:08:09 a user named li_jiang said ```Run with Gradio ValueError: signal only works in main thread of the main interpreter```.\\n\\nIn general, at 2023-10-07 03:05:11 a user named li_jiang said ```Hi @0x0ting , it would be nice if you could provide more details as @qingyunwu mentioned. But based on what you\\'ve posted, I guess the issue is that there is some incompatible between Gradio and the signal lib used in code_utils.py in autogen. Could you try running your code in a terminal without Gradio? Maybe it can help to locate the root cause.```.\\n\\nIn general, at 2023-10-07 02:28:29 a user named andyinater said ```I figure I can hack it together with ending and restarting convos constantly, shifting the messages appropriately, just seeing if there is any better options first.```.\\n\\nIn general, at 2023-10-07 02:27:40 a user named andyinater said ```Does anyone know if there is a built in way to maintain a fixed max convo length, and do a FILO kind of thing to catch the old stuff as it maxes out?```.\\n\\nIn general, at 2023-10-07 02:14:11 a user named yanxiaochuan said ```i know on github and twitter```.\\n\\nIn general, at 2023-10-07 01:54:14 a user named unicorn1997 said ```Hello everyone, trying to understand AutoGen, could someone explain me on their example with visualizing stock prices - Why isnt there a few shot example included? But instead there is the first user input already incorporated in the code? (The query about the stock prices)\\n\\nI tried to make my own agent and I first put a few shot example to the code, then a part where user was to write an input.\\nHere it seems like it is pre-defined in the code what the agent will do, but I would like to make my own custom input in the first place. \\n\\nHope my question is clear 😄 \\nThanks a lot!```.\\n\\nIn general, at 2023-10-07 01:46:39 a user named somecomputerguy said ```I just got the samples to work 😂```.\\n\\nIn general, at 2023-10-07 01:41:04 a user named regen2moon said ```custom autogen via discord ready to do first test```.\\n\\nIn general, at 2023-10-07 00:07:43 a user named finnious. said ```Just starting. following Wes Roth YouTube video```.\\n\\nIn general, at 2023-10-06 23:45:06 a user named frank.martinez said ```What tool interfaces are people building? Here’s what I want: a] Google Apps, b] Miro, c] Twilio```.\\n\\nIn general, at 2023-10-06 23:08:28 a user named bishopfx said ```For sure. I wasnt using that one as of before I posted that. I didn\\'t quite fix it though, im quite stumped LOL.```.\\n\\nIn general, at 2023-10-06 23:07:23 a user named afourney said ```Glad you fixed it, but please remove this photo and rotate your api key 😛```.\\n\\nIn general, at 2023-10-06 23:06:04 a user named bishopfx said ```@afourney this was the error, i remember now by changing the engine i fixed the API issue but was getting this instead.```.\\n\\nIn general, at 2023-10-06 22:44:02 a user named sonichi said ```I would like to create a project that```.\\n\\nIn general, at 2023-10-06 22:41:16 a user named afourney said ```Yes agreed. If you have just the one endpoint in the list, or use a filter, I think that’s what it does. @sonichi ?```.\\n\\nIn general, at 2023-10-06 22:38:58 a user named purplxd said ```It would be much better if we could read the message and wait the specified amount of time rather than risk hammering the API endpoints```.\\n\\nIn general, at 2023-10-06 22:37:23 a user named bishopfx said ```I was able to fix that error by importqhing the api key in the actual file itself and defining it, but then I get the api access restriction error but everything else runs fine. I was just demoing the tesla nvda chart script.```.\\n\\nIn general, at 2023-10-06 22:35:44 a user named bishopfx said ```It was having issues with the json loader I belive```.\\n\\nIn general, at 2023-10-06 22:35:28 a user named bishopfx said ```I was providing it through Json. I wish I was at my PC id post a screen.```.\\n\\nIn general, at 2023-10-06 22:35:16 a user named wladpaiva said ```Would that mean that the same input would always get the same output even when we execute scrape functions in between it?```.\\n\\nIn general, at 2023-10-06 22:33:14 a user named aaronward_ said ```replacing UserProxyAgent with whatever the variable name is for that object```.\\n\\nIn general, at 2023-10-06 22:32:55 a user named aaronward_ said ```You can use the UserProxyAgent.send(message=\"\") and it will have memory of your previous generated text```.\\n\\nIn general, at 2023-10-06 22:31:57 a user named wladpaiva said ```That would probably help. However, what I\\'m looking for is to stop the execution and come back to the same point in time later on```.\\n\\nIn general, at 2023-10-06 22:27:53 a user named aaronward_ said ```https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#caching Conversations are automatically caches in ./cache folder```.\\n\\nIn general, at 2023-10-06 22:26:11 a user named afourney said ```We’ve had one other similar report. How are you providing your OAI_CONFIG_LIST? .env? Json?```.\\n\\nIn general, at 2023-10-06 22:24:49 a user named afourney said ```You can put several models or configurations in your OAI_CONFIG_LIST which will be tried in order. You can use this to fall back to a less-limited model (e.g., GPT 3.5), or even load balance if you have different model endpoints. This can help somewhat.```.\\n\\nIn general, at 2023-10-06 22:21:23 a user named wladpaiva said ```Is there a way to save the chat state? Sorry, super noob question. I mean, how would I do it?```.\\n\\nIn general, at 2023-10-06 21:35:32 a user named bishopfx said ```I keep getting an error stating I do not have access or it cannot find that said engine, even when I change the engine in the main.py file, to 3.5-t it still shoots me the message.```.\\n\\nIn general, at 2023-10-06 21:34:48 a user named bishopfx said ```Hey guys, quick question. I seem to he having issues with my OpenAI API key. Is Autogen required to have GPT4 access?```.\\n\\nIn general, at 2023-10-06 21:12:29 a user named somecomputerguy said ```This is neat! Thanks for making it public 🙂```.\\n\\nIn general, at 2023-10-06 20:59:57 a user named purplxd said ```How to deal with openAI rate limits?```.\\n\\nIn general, at 2023-10-06 18:45:59 a user named Sparti said ```guys, does anyone know any blog or any youtube video that might help me learn about ml model deployment realtime?```.\\n\\nIn general, at 2023-10-06 18:12:46 a user named bitsy_chuck said ```what should be the format of context can```.\\n\\nIn general, at 2023-10-06 18:04:15 a user named afourney said ```Group chat stops when a termination condition is met, or when the maximum number of messages are exchanged. More details here: https://discord.com/channels/1153072414184452236/1159571194907996300```.\\n\\nIn general, at 2023-10-06 17:56:53 a user named bitsy_chuck said ```what should be the format of context? can someone please give me any example?\\n```py\\n    def initiate_chat(\\n            self,\\n            recipient: \"ConversableAgent\",\\n            clear_history: Optional[bool] = True,\\n            silent: Optional[bool] = False,\\n            **context,\\n    ):\\n        \"\"\"Initiate a chat with the recipient agent.\\n\\n        Reset the consecutive auto reply counter.\\n        If `clear_history` is True, the chat history with the recipient agent will be cleared.\\n        `generate_init_message` is called to generate the initial message for the agent.\\n\\n        Args:\\n            recipient: the recipient agent.\\n            clear_history (bool): whether to clear the chat history with the agent.\\n            silent (bool or None): (Experimental) whether to print the messages for this conversation.\\n            **context: any context information.\\n                \"message\" needs to be provided if the `generate_init_message` method is not overridden.\\n        \"\"\"\\n``````.\\n\\nIn general, at 2023-10-06 18:12:48 a user named bitsy_chuck said ```@afourney sorry to ping you. Can you please help here.```.', '\\nIn general, at 2023-10-02 15:35:41 a user named sonichi said ```All the related files are in the repo.\\nexamples: https://github.com/microsoft/autogen/tree/main/notebook\\ndocumentation website: https://github.com/microsoft/autogen/tree/main/website\\ndocstr: https://github.com/microsoft/autogen/tree/main/autogen```.\\n\\nIn general, at 2023-10-02 15:33:15 a user named fxtoofaan said ```Is there detail documentation about every feature and explanation of that feature for autogen ? Watching the video I linked about from Manish Gupta seems like autogen has features I’ve not explored or seen in the documentation before. Would be nice to feed autogen it’s own documentation and examples and then learn from that and then use autogen to create various types of virtual agent environments```.\\n\\nIn general, at 2023-10-02 15:29:53 a user named sonichi said ```Interesting idea to try. Give it an example. Use the doc and RetrieveChat if necessary.```.\\n\\nIn general, at 2023-10-02 14:46:36 a user named fxtoofaan said ```@sonichi is it possible to use autogen to create autogen python scripts? Like use autogen to create a complex group chats and define roles and responsibilities in a virtual team. Like give it a single prompt and based on that it’ll do research and find out what roles are needed and based on that create like a python script that defines connection to llm and create agents and their definitions and then also setup the group chats and then final output either with or without human intervention```.\\n\\nIn general, at 2023-10-02 14:38:02 a user named fxtoofaan said ```https://youtu.be/2RT8i-VP7V0```.\\n\\nIn general, at 2023-10-02 14:17:54 a user named andyinater said ```Welcome to the party Lumpy! Expect a bit if a steep learning curve figuring out how the Lego pieces fit together - it seems we all start off forcing it in bad ways.\\n\\nBut once you get passed that it\\'s pretty wild all the opportunity.```.\\n\\nIn general, at 2023-10-02 14:04:19 a user named lumpyfarts said ```I don\\'t know autogen, but I want to learn. I\\'m an old programmer looking to learn/play in Python and AI.```.\\n\\nIn general, at 2023-10-02 14:00:34 a user named redai.ai said ```Glad to see we got some new people in here```.\\n\\nIn general, at 2023-10-02 12:45:57 a user named _joberg said ```I am curious where we are in 1 month```.\\n\\nIn general, at 2023-10-02 12:45:40 a user named _joberg said ```Me too. We are in the algorithm```.\\n\\nIn general, at 2023-10-02 12:35:05 a user named 0xjamp said ```Anyway to get around api rate limit lol```.\\n\\nIn general, at 2023-10-02 11:44:20 a user named tigremon said ```I\\'d like to build an app to show GPX tracks over a 3D map```.\\n\\nIn general, at 2023-10-02 11:43:39 a user named tigremon said ```YouTube recommended me this video https://www.youtube.com/watch?v=8TLwSH_UFwI```.\\n\\nIn general, at 2023-10-02 10:24:43 a user named .princeps said ```I\\'ll bring you into a forum so we can chat there```.\\n\\nIn general, at 2023-10-02 10:23:26 a user named lessuse. said ```hey guys anybody made any useful use case of the autogen, please share```.\\n\\nIn general, at 2023-10-02 10:22:44 a user named lessuse. said ```i copy your repo code 🤷\\u200d♂️```.\\n\\nIn general, at 2023-10-02 10:21:07 a user named .princeps said ```Oh seems like you are trying a different script```.\\n\\nIn general, at 2023-10-02 10:18:26 a user named .princeps said ```I usually leave on the .JSON extension```.\\n\\nIn general, at 2023-10-02 10:05:48 a user named aurowk said ```I\\'ve not seen that before and I\\'m still learning myself but maybe you should try the use_docker=False option for the agents```.\\n\\nIn general, at 2023-10-02 10:04:46 a user named lessuse. said ```can u tell me about the above error```.\\n\\nIn general, at 2023-10-02 10:04:15 a user named aurowk said ```what have you called your OAI_CONFIG_LIST? Does it still have the .json extension?```.\\n\\nIn general, at 2023-10-02 10:02:50 a user named lessuse. said ```my code - \\n\\n```\\nfrom autogen import AssistantAgent, UserProxyAgent, config_list_from_json, GroupChat, GroupChatManager\\nimport autogen\\n# Load the configuration for GPT-4 from a JSON file\\nconfig_list_gpt4 = autogen.config_list_from_json(\\n    \"OAI_CONFIG_LIST\",\\n    file_location=\".\",\\n    filter_dict={\\n        \"model\": {\\n            \"gpt-4\",\\n        }\\n    }\\n)\\n\\nllm_config = {\"config_list\": config_list_gpt4, \"seed\": 42}\\nuser_proxy = autogen.UserProxyAgent(\\n   name=\"User_proxy\",\\n   system_message=\"A human admin.\",\\n   code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\\n   human_input_mode=\"TERMINATE\"\\n)\\ncoder = autogen.AssistantAgent(\\n    name=\"Coder\",\\n    llm_config=llm_config,\\n)\\npm = autogen.AssistantAgent(\\n    name=\"Product_manager\",\\n    system_message=\"Creative in software product ideas.\",\\n    llm_config=llm_config,\\n)\\ngroupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\\nmanager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\\n\\nuser_proxy.initiate_chat(manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\")\\n# type exit to terminate the chat``````.\\n\\nIn general, at 2023-10-02 10:01:39 a user named lessuse. said ```its stop at step 2```.\\n\\nIn general, at 2023-10-02 10:01:26 a user named lessuse. said ```hey , now why it keep showing this error - \\n\\n```docker.errors.DockerException: Error while fetching server API version: (2, \\'CreateFile\\', \\'The system cannot find the file specified.\\')``````.\\n\\nIn general, at 2023-10-02 09:59:42 a user named aurowk said ```So you either remove those models from the available list, or you add your key to use for them in the AOI_CONFIG_LIST```.\\n\\nIn general, at 2023-10-02 09:59:00 a user named aurowk said ```in your OAI_CONFIG_LIST you\\'ve probably not specified a key to use for the other 2 models (gpt-4-0314 and gpt-4-0613)```.\\n\\nIn general, at 2023-10-02 09:58:57 a user named lessuse. said ```also, i try many autogen examples and try the auto mode, but it keep gettting this error - \\n\\n```docker.errors.DockerException: Error while fetching server API version: (2, \\'CreateFile\\', \\'The system cannot find the file specified.\\')``````.\\n\\nIn general, at 2023-10-02 09:58:09 a user named lessuse. said ```i dont know exactly, but i replace this - \\n```config_list_gpt4 = config_list_from_json(\\n    \"../OAI_CONFIG_LIST.json\",\\n    filter_dict={\\n        \"model\": [\"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4\", \"gpt-4-0314\"],\\n    },\\n)\\n```\\n\\nwith this - \\n\\n```config_list = autogen.config_list_from_json(\\n    \"OAI_CONFIG_LIST\",\\n    file_location=\".\",\\n    filter_dict={\\n        \"model\": {\\n            \"gpt-4\",\\n            \"gpt-3.5-turbo\",\\n        }\\n    }\\n)```\\n\\nand it works```.\\n\\nIn general, at 2023-10-02 09:56:01 a user named .princeps said ```What was the issue ?```.\\n\\nIn general, at 2023-10-02 09:55:57 a user named .princeps said ```@lessuse. Seems like you got it to work```.\\n\\nIn general, at 2023-10-02 09:48:55 a user named lessuse. said ```awesome, it can run the code itself🔥```.', '\\nIn ideas-and-feedback, at 2023-11-01 14:04:59 a user named Anxieties said ```hi, im new with the autogen staff and i wondering if its possible for the autogen to succeed a mission of analysing and predicting an upcoming soccer matches?```.\\n\\nIn ideas-and-feedback, at 2023-11-01 13:24:20 a user named tmyf_ said ```Hi, is it possible to use autogen to understand the pdf template, I provide the title/subject to the AI and ask the AI to generate a similar report based on the pdf template.```.\\n\\nIn ideas-and-feedback, at 2023-11-01 11:53:15 a user named bhavisha9921 said ```how can i make api based chatbot outof autogen?```.\\n\\nIn ideas-and-feedback, at 2023-11-01 06:24:06 a user named ctrl_alt.defeat said ```ahh! I have been trying to set this up since yesterday, was unable to! Hopefully this works, thanks!```.\\n\\nIn ideas-and-feedback, at 2023-11-01 03:58:32 a user named .hagarthehorrible said ```Feel like elaborating? Some of us might want to join you in that venture. That\\'s if you feel like having company, of course.```.\\n\\nIn ideas-and-feedback, at 2023-10-31 22:16:34 a user named drinkoblog.weebly.com said ```https://www.youtube.com/watch?v=bMWXXPoDnDs```.\\n\\nIn ideas-and-feedback, at 2023-10-31 19:38:00 a user named xxpyroxxjonesxx said ```true local llm + memgpt + autogen?```.\\n\\nIn ideas-and-feedback, at 2023-10-31 17:50:14 a user named fabmendez said ```I\\'m building a creative agency```.\\n\\nIn ideas-and-feedback, at 2023-10-31 15:32:12 a user named sanimesa_03443 said ```I would like to build an app that can query an SQL database and respond to natural language questions from user```.\\n\\nIn ideas-and-feedback, at 2023-10-31 10:16:12 a user named mitchellr said ```nothing yet - required onboarding```.\\n\\nIn ideas-and-feedback, at 2023-10-31 08:29:32 a user named kajatta said ```Describe What is the worth of a single mortal life?```.\\n\\nIn ideas-and-feedback, at 2023-10-31 01:18:50 a user named qingyunwu said ```Oh, that makes sense. @karnival8, I just created a \"jobs\" (https://discord.com/channels/1153072414184452236/1168719200605437952 ) channel dedicated for conversations centered around hiring and job finding relevant to AutoGen. You can post your needs there.```.\\n\\nIn ideas-and-feedback, at 2023-10-31 00:33:58 a user named sonichi said ```I think the request is about hiring```.\\n\\nIn ideas-and-feedback, at 2023-10-31 00:29:53 a user named qingyunwu said ```You can go to the moderators or contributors for questions or post questions as issues on github.```.\\n\\nIn ideas-and-feedback, at 2023-10-30 20:57:01 a user named sonichi said ```yes, https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.\\n\\nIn ideas-and-feedback, at 2023-10-30 20:54:43 a user named justdoit1 said ```Question 🤔 do we have the ability to use openAI function calling feature in AutoGen?```.\\n\\nIn ideas-and-feedback, at 2023-10-30 19:22:25 a user named izzwizz75 said ```id like to build a dynamic case note taking web app incorporating machine learning to assist customer service agents take notes in a more productive and efficient manner```.\\n\\nIn ideas-and-feedback, at 2023-10-30 16:04:21 a user named karnival8 said ```What is the most appropriate way to find a full time developer familiar with AutoGen? Apologies in advance not sure where else to look.```.\\n\\nIn ideas-and-feedback, at 2023-10-30 14:23:24 a user named .hagarthehorrible said ```I want to build an app that decides who lives and who dies.😂```.\\n\\nIn ideas-and-feedback, at 2023-10-30 13:52:49 a user named MadVett  |  sheople said ```Hello! I\\'m Mathew, I want to put together to help me run my new consultation business where we help businesses integrate ai```.\\n\\nIn ideas-and-feedback, at 2023-10-30 08:57:04 a user named xuanwu_60471 said ```i want to build a personal assistant app with autogen```.\\n\\nIn ideas-and-feedback, at 2023-10-30 03:21:52 a user named ziggyzaggyinfinity said ```Interested in building an automatic code development end to end solution.```.\\n\\nIn ideas-and-feedback, at 2023-10-29 15:11:02 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/OAI_CONFIG_LIST_sample```.\\n\\nIn ideas-and-feedback, at 2023-10-29 14:00:37 a user named neverendinggrowth said ```where can I find OAI_CONFIG_LIST_sample??```.\\n\\nIn ideas-and-feedback, at 2023-10-29 13:35:45 a user named neverendinggrowth said ```I\\'d like to built app which will be creating custom wordpress websites based on design from client and some curated prompt. Second bigger project I want to create personal assistant which will be gathering all possible data from user (screen time, activities user spend his time on, sleep, nutrition, activity records, habits (in future measuring different levels of hormones and molecules from blood)). Then it will use this data to create optimal plan for user happiness, health and development```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:41:06 a user named m0bsta said ```fell into the checking out chrome extentions and tada```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:40:07 a user named m0bsta said ```i was just try to set it up with notion lol```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:39:22 a user named m0bsta said ```https://dashboard.eesel.ai/ this is like a rag chatbot i guess```.\\n\\nIn ideas-and-feedback, at 2023-10-29 00:31:21 a user named askofu said ```How did you build this and what data is loaded into it?```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:57:34 a user named aaronward_ said ```I\\'m working on something that will allow you to evaluate your autogen applications given different hyper-paremeters (eg: temprature, different embeddings, prompt templates, agent types etc.) - will share when it\\'s cleaned up and a few bugs are cleared up```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:18:56 a user named m0bsta said ```it\\'s ok for basic stuff i almost had it ingest the github proper lol```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:18:16 a user named m0bsta said ```ASK it what code you need tho```.\\n\\nIn ideas-and-feedback, at 2023-10-28 23:13:04 a user named m0bsta said ```OH GOD I MESSED UP LOL; you guys can have this it\\'s all autogen knowledge https://dashboard.eesel.ai/public-chat?namespace=e2c1813e-f5bb-4a19-81dc-b65b9396c5c5&palette=%7B%22primary%22%3A%22%238c21e4%22%2C%22secondary%22%3A%22%23F3F4F6%22%7D&title=autogen%20Knowledge%20%E2%80%A2%20by%20Mobsta%E2%84%9E%20%40mobstarx.com&customError=Sorry%2C%20I\\'m%20unable%20to%20answer%20that.%20Try%20rephrasing%20your%20question%20or%20reach%20out%20to%20support.&welcomeMessage=%F0%9F%91%8B%20Hi!%20How%20can%20I%20help%20you%20today%3F&suggestQuestion=true```.\\n\\nIn ideas-and-feedback, at 2023-10-28 16:29:48 a user named trtfx1 said ```\"You are a professional sports analyst. You compare statistics between teams and make a judgement call on who is more likely to win. When you are provided data for a team, you are to analyze it, step by step, and get an idea of the teams performance to compare to the other teams set of data. You will be provided two files, one for each team. You will make sure to note injuries, what positions they play, and what that means for the teams performance. Always try and look for hidden strengths and weaknesses based on the most recent games or data. \\n\\nEach html file has multiple charts to extract. Pay attention to this and focus on the charts only.\"\\n\\nThis is my custom output for analyzing sports stats. I save whole webpages and upload them.```.\\n\\nIn ideas-and-feedback, at 2023-10-28 16:29:16 a user named trtfx1 said ```its going to be used with it though eventually```.\\n\\nIn ideas-and-feedback, at 2023-10-28 16:29:04 a user named trtfx1 said ```can I post not autogen stuff in here?```.\\n\\nIn ideas-and-feedback, at 2023-10-28 10:11:39 a user named xvarunx said ```Please do something so I can talk my whole code base, and then when GPT has a recommendation, it directly pastes it back in the line or the fiction instead of writing the entire thing again```.\\n\\nIn ideas-and-feedback, at 2023-10-27 21:54:49 a user named c_bonadio said ```Autogen with FastApi backend and React frontend\\nhttps://github.com/bonadio/autogenwebdemo```.\\n\\nIn ideas-and-feedback, at 2023-10-27 20:04:43 a user named cpro1947 said ```personal automation with small bots```.\\n\\nIn ideas-and-feedback, at 2023-10-27 19:55:34 a user named hahl9000 said ```PLZ! Need some help finding the correct approach for agent with RAG capabilities from files or db in a mix of non-RAG agents that can run code and output files for eg. Excel. I’ve seen the code for rag agents but how do I implement reading from data? Does anyone have code for this? I’m also wondering if someone have a use-case for autogen controlling applications on computer? \\n\\nHave an awesome weekend folks! 🎃```.\\n\\nIn ideas-and-feedback, at 2023-10-27 19:41:53 a user named mudit.b07 said ```Multi-agent bots for the flights issue reduction```.\\n\\nIn ideas-and-feedback, at 2023-10-27 18:57:33 a user named telepathyx said ```https://github.com/THUDM/AgentTuning this looks promising to counteract the rumored anti-agentic passive behavior trained into openai models```.\\n\\nIn ideas-and-feedback, at 2023-10-27 17:20:44 a user named das_search said ```Wip agent and project generation using auto gen templates and gpt 4 as main logic after parsing```.\\n\\nIn ideas-and-feedback, at 2023-10-27 17:19:09 a user named das_search said ```I absolutely love llm and autogen \\nSo I started a Lil quick project on my lunch break```.\\n\\nIn ideas-and-feedback, at 2023-10-27 17:17:11 a user named das_search said ```https://github.com/Nbtguyoriginal/Pybonce```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:15:20 a user named frank.martinez said ```Here’s @biggboii. video on MemGPT; believe he has a repo in the details https://youtu.be/QCdQe8CdWV0?si=iXgm-gs6hN7O4vuG```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:12:27 a user named trtfx1 said ```I’ll educate myself more on nfl side. Someone just mentioned they are slowly using ai more for plays.```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:11:40 a user named trtfx1 said ```I don’t think it’s as good. I’ve just tested it out a few times with open source stats. There is a comprehensive amount, but I hear nfl has more.```.\\n\\nIn ideas-and-feedback, at 2023-10-27 16:09:28 a user named ctrl_alt.defeat said ```cant find this repo on github \\npyreader\\n\\ncan you please share it with me? @das_search```.', '\\nIn general, at 2023-10-02 06:48:13 a user named aayushc1308 said ```Hey everyone,\\nI\\'m Aayush (Founder, CEO of a startup called Kniru https://kniru.com). Kudos to all the great work happening here. Looking forward to participating as AutoGen evolves.```.\\n\\nIn general, at 2023-10-02 06:44:50 a user named pradeep1148 said ```https://www.youtube.com/watch?v=w6hhnVa68yE&ab_channel=DLExplorers made this video from this notebook. thanks for the contribution```.\\n\\nIn general, at 2023-10-02 06:44:34 a user named pradeep1148 said ```https://colab.research.google.com/gist/ElliotWood/af12566db5d6948e8ed6dd6324aa9697/autogen-langchain.ipynb#scrollTo=r7PFvDS7Ev-E```.\\n\\nIn general, at 2023-10-02 05:34:02 a user named kajatta said ```You\\'re welcome - hit me up if you need something else```.\\n\\nIn general, at 2023-10-02 03:35:03 a user named devegavc_83455 said ```I see it on github```.\\n\\nIn general, at 2023-10-02 03:33:32 a user named ondaje said ```Oh heck yeah. Thank you so much. This looks perfect and much simpler than a full reimplementation.\\n\\nMy pipelines have wrappers for langchain tooling and I have stuff that does the fastapi server as well, plus a way to prompt it, I just need to expose an async run function ultimately, so this looks perfect.```.\\n\\nIn general, at 2023-10-02 03:28:45 a user named __erice__ said ```@ondaje looks like you\\'re in here too 😏 lol.. what do you think about this approach?```.\\n\\nIn general, at 2023-10-02 02:37:15 a user named tawnniee said ```thanks @qingyunwu this was what i needed, am browsing now!```.\\n\\nIn general, at 2023-10-02 02:29:42 a user named qingyunwu said ```Yes, of course. This is an example. https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.\\n\\nIn general, at 2023-10-02 02:28:42 a user named tawnniee said ```hey what\\'s up friends, am playing around with autogen now, does anyone have a link to the docs on how to use it to browse the web?```.\\n\\nIn general, at 2023-10-02 02:25:27 a user named mizerati1313 said ```I sent something to htb bot commands as well```.\\n\\nIn general, at 2023-10-02 02:23:58 a user named mizerati1313 said ```I wanted to do a smoke test on something```.\\n\\nIn general, at 2023-10-02 02:23:36 a user named qingyunwu said ```Thanks! Is this related to AutoGen?```.\\n\\nIn general, at 2023-10-02 02:23:13 a user named mizerati1313 said ```I joined the voice connected```.\\n\\nIn general, at 2023-10-02 02:22:23 a user named mysticaldiscofrog said ```I did, to the point that I deleted all the reference to gpt-4 in my code. I thought maybe it was somewhere in autogen itself. \\n\\nThank you, I will work with this example you provided.```.\\n\\nIn general, at 2023-10-02 02:20:06 a user named mizerati1313 said ```I have something to share!```.\\n\\nIn general, at 2023-10-02 02:20:05 a user named qingyunwu said ```This is an example using GPT-3.5-turbo: https://github.com/qingyun-wu/autogen-eval/blob/main/application/A2-retrieval-augmented-chat/NaturalQuestionsQA-gpt35turbo.ipynb```.\\n\\nIn general, at 2023-10-02 02:19:40 a user named qingyunwu said ```Did you try setting the model field to \"gpt-3.5-turbo\" in `config_list` fileld of the  llm_config?```.\\n\\nIn general, at 2023-10-02 02:05:40 a user named mysticaldiscofrog said ```Does anyone know where to shift the calls from gpt-4 to gpt-3.5-turbo? The tests I am doing do not need gpt-4 right now but I have changed everything I can find and the billing keeps going up got 4 and staying the same for 3.5. Thank you.```.\\n\\nIn general, at 2023-10-02 01:56:05 a user named Drogend said ```Might sound stupid, but how? I tried and it reverts back to .txt```.\\n\\nIn general, at 2023-10-02 00:53:10 a user named andyinater said ```Beautiful. I plan on having my own workforce in the basement closet 😛```.\\n\\nIn general, at 2023-10-02 00:42:10 a user named fxtoofaan said ```doing about 18 tokens / second.```.\\n\\nIn general, at 2023-10-02 00:40:23 a user named fxtoofaan said ```then I ran the python script (city_planner.py) attached as my first request to Plan a week long trip to Dallas Texas. Include a table of dates and activity.\\n\\nand bam this is what happened. \\n\\n13B parameter loaded in my 12GB GPU no problems. \\n\\nso I\\'ve got a potential virtual army that I can run 100% offline if I want to that costs me $0 going forward forever for under a grand 🙂\\n\\nneed to keep adding features to autogen. keep going 🙂 \\n\\npower of Nvidia, llama-2 13B model, TheBloke\\'s AWQ model, docker, vLLM, Python and ofcourse autogen```.\\n\\nIn general, at 2023-10-02 00:40:08 a user named fxtoofaan said ```ok so check this out 🙂\\n\\nI bought an old used Nvidia A2000 GPU with 12GB VRAM. I installed it in my old dell optiplex sff pc with i7, 32GB Ram and 256GB SSD Drive, all from ebay for no less than 600 UK Pounds GBP. \\n\\nwith all hardware in, I loaded the machine with Ubuntu 22.04.3 LTS on a bootable USB stick. from there I installed Ubuntu 22.04.3 LTS on the computer\\'s internal SSD. Now pc boots into ubuntu and its a beautiful interface. I installed a bunch of updates and services using various commands, i cannot remember the order but I remember running these commands to get things working. \\n\\nsudo apt update\\nsudo apt install snapd\\nsudo snap install nvtop\\nhttps://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html\\nsudo pip3 install lfs --break-system-packages\\ngit clone https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ\\nsudo pip3 install git+https://github.com/huggingface/transformers.git@72958fcd3c98a7afdc61f953aa58c544ebda2f79 --break-system-packages\\nsudo pip3 install git+https://github.com/casper-hansen/AutoAWQ.git@1c5ccc791fa2cb0697db3b4070df1813f1736208 --break-system-packages\\n\\nthen I loaded the model of my choice and a docker image...\\n\\ndocker run --gpus all \\\\\\n    -p 8000:8000 \\\\\\n    -v /home/aitoofaan/LLMs/models/Llama-2-13B-chat-AWQ:/mnt/model/ \\\\\\n     ghcr.io/mistralai/mistral-src/vllm:latest \\\\\\n    --host 0.0.0.0 \\\\\\n    --model=\"/mnt/model/\" \\\\\\n     --quantization awq\\n\\nsudo pip3  install pyautogen --break-system-packages```.\\n\\nIn general, at 2023-10-02 00:37:29 a user named slayerdeebo said ```The api key should be like : open_ai_key = ‘your_key’```.\\n\\nIn general, at 2023-10-02 00:12:09 a user named fxtoofaan said ```@sonichi when will the following be updated? mistral-src/vllm . It was last updated 2 days ago. I think they added some new LLM\\'s to the vllm server and wondering if we can get the latest changes in this repository please 🙂```.\\n\\nIn general, at 2023-10-01 21:59:57 a user named iamhere said ```I keep getttin this error, but I have the keys in OAI_CONFIG_LIST.txt Any suggestions?```.\\n\\nIn general, at 2023-10-01 21:45:09 a user named tonic_1 said ```join the discord, join us on github (send me your username) , join us on hugging face and let\\'s get started making super cool stuff```.\\n\\nIn general, at 2023-10-01 21:42:11 a user named fragrancefreak said ```Just discovered autogen I\\'m really interested in using it and helping out maybe```.\\n\\nIn general, at 2023-10-01 21:30:27 a user named iamhere said ```What can I do to help?```.\\n\\nIn general, at 2023-10-01 20:53:59 a user named sonichi said ```sonichi is there currently a way for a```.\\n\\nIn general, at 2023-10-01 20:32:23 a user named epicrookie_ said ```Hey, does anyone know if Semantic Kernel will have a feature to invoke Autogen?```.\\n\\nIn general, at 2023-10-01 20:32:13 a user named kosiarn said ```does it work similarly to ensemble learning?```.\\n\\nIn general, at 2023-10-01 20:31:41 a user named kosiarn said ```hi, I saw a video about autogen on youtube and got interested```.\\n\\nIn general, at 2023-10-01 20:26:21 a user named andyinater said ```.... it is utterly surreal to experience being legitimately problem solving in code and natural language. I am constantly amazed and excited. Good job again MS guys - absolutely revolutionary.```.\\n\\nIn general, at 2023-10-01 20:22:45 a user named andyinater said ```And also allow resumption of a project after closing all chats. Leave enough, and the right, breadcrumbs such that everyone can pick up where they left off.```.\\n\\nIn general, at 2023-10-01 20:22:10 a user named andyinater said ```I want to post it, but it takes time to format a nice repo to explain all the moving parts. So I am working on integrating a semi-hard-coded versioning system for code iterations. The goal is to minimize the context windows of every chat down to only what is necessary.```.\\n\\nIn general, at 2023-10-01 20:21:11 a user named andyinater said ```Lol exactlyyyy. Despite the capabilites of the LLMs and autogen, there  is still a higher level of granularity required in setting up agents and chats than we might have hoped for. But it is just a learning curve.\\n\\nI have already started seeing huge improvements in code generation by breaking up the steps and manually controlling the group chat in a logical order. The programming test case I\\'ve been using, that seems to fail in the autogen examples (running on 3.5 turbo), is \"write a python program that displays the current time on an analog clock face\". Through the examples, it would definitely get something. But it was rough, and particularly the arm positions were always inaccurate/wrong. Through the flow I\\'m running now it gets it absolutely every time. The MS paint they produce is quite good too, and other generic asks have done well.```.\\n\\nIn general, at 2023-10-01 20:18:08 a user named __orderandchaos said ```Have had a good laugh at a few projects derail this way, little too close to home haha```.\\n\\nIn general, at 2023-10-01 20:17:08 a user named __orderandchaos said ```\"A bad manager can ruin the entire team\\'s efforts\" so we\\'ve already reached human level capabilities in ai```.\\n\\nIn general, at 2023-10-01 20:04:30 a user named __orderandchaos said ```I\\'m looking for a way to have the next run read the existing file structure, requirements.txt/poetry and any code files to get an overview of the existing stack. \\n\\nThen plan out the prompt request and add new files or replace existing ones```.\\n\\nIn general, at 2023-10-01 19:30:31 a user named 0xjamp said ```I keep getting a rate limit error on my openapi when running the multi agent group chat```.']], 'uris': None, 'data': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mChroma_RAG_Assistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Based on the search results, Chainlit seems to be a tool or library used to create web applications that can interact with Autogen. There is a Medium article mentioned in the retrieved documents describing the creation of a basic web application using Chainlit with Autogen, which suggests that Chainlit can be integrated with Autogen to develop user interfaces.\n",
      "\n",
      "To use Chainlit with Autogen, one would typically need to understand both Chainlit and Autogen, write code to define the Autogen agents and their interactions, and use Chainlit to build a front-end interface that communicates with these agents. Chainlit would likely handle the user inputs and outputs while Autogen agents perform the tasks based on those inputs.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to Chroma_RAG_Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mChroma_RAG_Assistant\u001b[0m (to user_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.send(recipient=sql_assistant, message=\"How can you use Chainlit with Autogen\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
