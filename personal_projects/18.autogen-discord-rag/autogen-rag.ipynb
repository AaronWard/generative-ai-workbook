{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autogen Discord QA\n",
    "\n",
    "I want to develop a LLM Application that will let me ask any question with regards to Autogen. The application should be able to:\n",
    "1. Search discord history for answers\n",
    "2. Multi model capabilities to retrieve images also.\n",
    "3. Search the internet to get additional information if needed.\n",
    "\n",
    "To pull message history, I am using an extension called [Discrub](https://chrome.google.com/webstore/detail/discrub/plhdclenpaecffbcefjmpkkbdpkmhhbj/related) as i had issues setting up the Discord API. <br>\n",
    "Data pull is up until `15th November 2023`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "sys.path.append('./')\n",
    "\n",
    "import openai\n",
    "import autogen\n",
    "import chromadb\n",
    "\n",
    "config_list = autogen.config_list_from_dotenv(dotenv_file_path='../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "\n",
    "# Create an instance of RetrieveAssistantAgent\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "path = Path(os.getcwd(), 'docs')\n",
    "client = chromadb.PersistentClient(path=f\"{os.getcwd()}/chromadb\")\n",
    "\n",
    "# Create an instance of RetrieveUserProxyAgent\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"task\": \"default\",\n",
    "        \"docs_path\": str(path), \n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": client, \n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Delete dir each instantiation\n",
    "client.delete_collection('autogen-docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.retrieve_utils:Found 281 chunks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_159', 'doc_241', 'doc_205', 'doc_244', 'doc_135', 'doc_213', 'doc_12', 'doc_166', 'doc_141', 'doc_181', 'doc_106', 'doc_233', 'doc_195', 'doc_61', 'doc_229', 'doc_49', 'doc_152', 'doc_48', 'doc_93', 'doc_214']]\n",
      "\u001b[32mAdding doc_id doc_159 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_241 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_205 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_244 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "If user's intent is code generation, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "If user's intent is question answering, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: How can chainlit be used with Autogen? Provide a code snippet example in your response.\n",
      "\n",
      "Context is: \n",
      "I think that it has something to do with the parallel execution of agent requests , Does anyone know how can i send the requests sequantially?```.\n",
      "\n",
      "In general, at 2023-10-02 15:51:03 a user named aurowk said ```Autogen within autogen making an autogen solution üòÑ```.\n",
      "\n",
      "In general, at 2023-10-02 15:35:41 a user named sonichi said ```All the related files are in the repo.\n",
      "examples: https://github.com/microsoft/autogen/tree/main/notebook\n",
      "documentation website: https://github.com/microsoft/autogen/tree/main/website\n",
      "docstr: https://github.com/microsoft/autogen/tree/main/autogen```.\n",
      "\n",
      "In general, at 2023-10-02 15:33:15 a user named fxtoofaan said ```Is there detail documentation about every feature and explanation of that feature for autogen ? Watching the video I linked about from Manish Gupta seems like autogen has features I‚Äôve not explored or seen in the documentation before. Would be nice to feed autogen it‚Äôs own documentation and examples and then learn from that and then use autogen to create various types of virtual agent environments```.\n",
      "\n",
      "In general, at 2023-10-02 15:29:53 a user named sonichi said ```Interesting idea to try. Give it an example. Use the doc and RetrieveChat if necessary.```.\n",
      "\n",
      "In general, at 2023-10-02 14:46:36 a user named fxtoofaan said ```@sonichi is it possible to use autogen to create autogen python scripts? Like use autogen to create a complex group chats and define roles and responsibilities in a virtual team. Like give it a single prompt and based on that it‚Äôll do research and find out what roles are needed and based on that create like a python script that defines connection to llm and create agents and their definitions and then also setup the group chats and then final output either with or without human intervention```.\n",
      "\n",
      "In general, at 2023-10-02 14:38:02 a user named fxtoofaan said ```https://youtu.be/2RT8i-VP7V0```.\n",
      "\n",
      "In general, at 2023-10-02 14:17:54 a user named andyinater said ```Welcome to the party Lumpy! Expect a bit if a steep learning curve figuring out how the Lego pieces fit together - it seems we all start off forcing it in bad ways.\n",
      "\n",
      "But once you get passed that it's pretty wild all the opportunity.```.\n",
      "\n",
      "In general, at 2023-10-02 14:04:19 a user named lumpyfarts said ```I don't know autogen, but I want to learn. I'm an old programmer looking to learn/play in Python and AI.```.\n",
      "\n",
      "In general, at 2023-10-02 14:00:34 a user named redai.ai said ```Glad to see we got some new people in here```.\n",
      "\n",
      "In general, at 2023-10-02 12:45:57 a user named _joberg said ```I am curious where we are in 1 month```.\n",
      "\n",
      "In general, at 2023-10-02 12:45:40 a user named _joberg said ```Me too. We are in the algorithm```.\n",
      "\n",
      "In general, at 2023-10-02 12:35:05 a user named 0xjamp said ```Anyway to get around api rate limit lol```.\n",
      "\n",
      "In general, at 2023-10-02 11:44:20 a user named tigremon said ```I'd like to build an app to show GPX tracks over a 3D map```.\n",
      "\n",
      "In general, at 2023-10-02 11:43:39 a user named tigremon said ```YouTube recommended me this video https://www.youtube.com/watch?v=8TLwSH_UFwI```.\n",
      "\n",
      "In general, at 2023-10-02 10:24:43 a user named .princeps said ```I'll bring you into a forum so we can chat there```.\n",
      "\n",
      "In general, at 2023-10-02 10:23:26 a user named lessuse. said ```hey guys anybody made any useful use case of the autogen, please share```.\n",
      "\n",
      "In general, at 2023-10-02 10:22:44 a user named lessuse. said ```i copy your repo code ü§∑‚Äç‚ôÇÔ∏è```.\n",
      "\n",
      "In general, at 2023-10-02 10:21:07 a user named .princeps said ```Oh seems like you are trying a different script```.\n",
      "\n",
      "In general, at 2023-10-02 10:18:26 a user named .princeps said ```I usually leave on the .JSON extension```.\n",
      "\n",
      "In general, at 2023-10-02 10:05:48 a user named aurowk said ```I've not seen that before and I'm still learning myself but maybe you should try the use_docker=False option for the agents```.\n",
      "\n",
      "In general, at 2023-10-02 10:04:46 a user named lessuse. said ```can u tell me about the above error```.\n",
      "\n",
      "In general, at 2023-10-02 10:04:15 a user named aurowk said ```what have you called your OAI_CONFIG_LIST? Does it still have the .json extension?```.\n",
      "\n",
      "In general, at 2023-10-02 10:02:50 a user named lessuse. said ```my code - \n",
      "\n",
      "```\n",
      "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json, GroupChat, GroupChatManager\n",
      "import autogen\n",
      "# Load the configuration for GPT-4 from a JSON file\n",
      "config_list_gpt4 = autogen.config_list_from_json(\n",
      "    \"OAI_CONFIG_LIST\",\n",
      "    file_location=\".\",\n",
      "    filter_dict={\n",
      "        \"model\": {\n",
      "            \"gpt-4\",\n",
      "        }\n",
      "    }\n",
      ")\n",
      "\n",
      "llm_config = {\"config_list\": config_list_gpt4, \"seed\": 42}\n",
      "user_proxy = autogen.UserProxyAgent(\n",
      "   name=\"User_proxy\",\n",
      "   system_message=\"A human admin.\",\n",
      "   code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
      "   human_input_mode=\"TERMINATE\"\n",
      ")\n",
      "coder = autogen.AssistantAgent(\n",
      "    name=\"Coder\",\n",
      "    llm_config=llm_config,\n",
      ")\n",
      "pm = autogen.AssistantAgent(\n",
      "    name=\"Product_manager\",\n",
      "    system_message=\"Creative in software product ideas.\",\n",
      "    llm_config=llm_config,\n",
      ")\n",
      "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
      "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
      "\n",
      "In created-with-autogen, at 2023-10-02 05:16:41 a user named sonichi said ```https://twitter.com/oscarmoxon/status/1708603929011863871```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 22:29:07 a user named abhilashinumella said ```Yes I was surprised too. I used GPT-4 for the prompts. Feel confident it can used to generate AI squad for a lot of low to medium precision tasks/goals.```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 21:42:28 a user named iamhere said ```YO! is this what your'e talking about? I'd love to help, I'm really new to all of this and need to get caught up to speed. I'm jumping over hurdles getting to this point. I still have no idea what I'm doing, but I think its because I'm trying to interoperate with langchain and autogen, without know how to use either. SMH \n",
      "Baby Steps, do we even need langchain anymore? that's how I found autogen as I'm trying to have conversations with multiple agents at once. My spreadsheets were only doing so much.```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 20:39:54 a user named .princeps said ```Nice, I have another repo up that you can checkout```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 19:17:40 a user named kenfucius5452 said ```Love it! I'm quite impressed by the quality of the output with such seemingly simple prompting. I'm curious, did you write the prompts yourself? Did you use GPT4 or any other tool to generate the written personas of Joey and Monica?```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 17:28:38 a user named pradeep1148 said ```hey made a video based on this github repo https://www.youtube.com/watch?v=gnn1H4H81IY&ab_channel=DLExplorers Thanks for the contribution poly```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 04:37:31 a user named abhilashinumella said ```A scene writer using autogen: https://x.com/abhilashi/status/1708339764250947692?s=20```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:16:58 a user named tonic_1 said ```sent to you and @salegrem```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:15:54 a user named mdfahad999 said ```https://github.com/mdfahad999```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:14:42 a user named tonic_1 said ```join us on discord also```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:14:29 a user named tonic_1 said ```very cool @WolfroseWe and @mdfahad999 , just send me your github and i'll add you, it will be fun, i'm sure```.\n",
      "\n",
      "In created-with-autogen, at nan a user named mdfahad999 said ```I am interested to contribute.```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 18:28:01 a user named .princeps said ```https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 17:00:01 a user named tonic_1 said ```yes my friend, please join us üëäüèª```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 09:27:56 a user named tonic_1 said ```going to remake autogtp to achieve better performance against beebot benchmark by using autogen https://github.com/team-tonic-arena-hacks```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:07:04 a user named sazied said ```@sonichi @rickyloynd I think this should work best for my use case\n",
      "\n",
      "Thanks again for all your help and such prompt responses üôèüöÄ```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:05:54 a user named sazied said ```Just went over your code, looks neat üòÑ```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:05:38 a user named sazied said ```Wow, thanks so much man!```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:02:02 a user named c_bonadio said ```Hi @sazied I used websockets to get and send human_input take a look here\n",
      "https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 01:07:42 a user named sazied said ```I have this socket connection running that allows me to receive the responses back from the agents on the forntend - \n",
      "\n",
      "\n",
      "@socketio.on('start_orchestrator')\n",
      "def handle_start_orchestrator(data):\n",
      "    print('YOO')\n",
      "    #Extract the data and start the orchestrator\n",
      "    test_param = data.get(\"test_param\", \"Default Value\")\n",
      "    \n",
      "    success, seq_messages = sequential_orchestrator.sequential_conversation(test_param)\n",
      "    \n",
      "    \n",
      "    # Send each message as it is generated\n",
      "    for message in seq_messages:\n",
      "        socketio.emit('orchestrator_message', { 'message': message })\n",
      "\n",
      "\n",
      "For one of the steps I need a human feedback loop so I have now set human_input_mode = 'ALWAYS' to test this functionality. How do I set the human feedback message without using the terminal. Does autogen expose some method that I am not aware of? I am also using a custom orchestrator, so I am wondering if I can set up a method in the Orchestrator class, but I do not know where to start.\n",
      "Any help would be much appreciated!```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 00:58:35 a user named rickyloynd said ```More details about @lucemia.'s application. https://discord.com/channels/1153072414184452236/1174149944718921820```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 00:50:22 a user named lucemia. said ```I am currently using AutoGen to streamline and minimize repetitive DevOps tasks.```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 00:38:12 a user named sonichi said ```The default system_message for `AssistantAgent` instructs writing code. Please overwrite it for your use case.```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 22:24:28 a user named sleepwave said ```thank you! That was my initial understanding which is why I was so shocked when I was getting code back based on a simple prompt that included an `AssistantAgent`. I thought the `AssistantAgent` was configured in a pretty \"default\" manner using a local model that I knew to be primarily conversational. I'm using a `UserProxyAgent` with the `AssistantAgent`, maybe it's actually the `UserProxyAgent` that's polluting the flow?```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 21:49:22 a user named pika.c said ```Autogen is a framework. You can use it just for conversation between agents without code output or execution. It depends on the system prompts you pass to each agent```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 21:43:29 a user named sleepwave said ```hey guys, quick question if anyone can help me wrap my head around something. After tinkering with autogen, it seems autogen's primary goal is to output code. Is there a similar framework that lets me allow multiple agents to simply _converse_ to solve a more abstract problem? Is that where Langchain comes in, or am I misunderstanding the capabilities and intention of Autogen?```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 18:20:20 a user named airlights said ```it's actually one big 'assistant' roleplaying for each. Look, if you're happy -- I'm happy üôÇ Hope this gives you what you need```.\n",
      "\n",
      "In forum-discussion, at 2023-10-10 12:45:10 a user named aaronward_ said ```https://docs.litellm.ai/docs/proxy_server```.\n",
      "\n",
      "In forum-discussion, at 2023-10-10 12:44:17 a user named tomexmachina said ```It would be nice to instantly have a bunch of new APIs integrated, and I really like the LiteLLM project. However, it's no small thing to add such a dependency. Personally, I hope autogen avoids as much added dependency as possible, and doesn't implement solutions that cause negative scaling issues in the future. I will try to make time to contribute to the PR but I have a lot of catching up to do, and many people seem to be begging to merge it. Convenience is almost always our enemy.\n",
      "\n",
      "Never forget Jurassic Park (and langchain)\n",
      "\n",
      "An engineering-focused inquiry: https://github.com/microsoft/autogen/discussions/189\n",
      "Related Issue: https://github.com/microsoft/autogen/issues/46\n",
      "The PR: https://github.com/microsoft/autogen/pull/95```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 23:24:38 a user named aaronward_ said ```I made a notebook explaining how to set up your own local model inference, it will take your RAM for a wild ride so have atleast 16 GB to spare: https://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/10.ollama-autogen/ollama.ipynb```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 22:26:38 a user named aaronward_ said ```Using LiteLLM with locally hosted quantized mistral model with Ollama + autogen = money saver```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 19:17:09 a user named bansalg said ```Moving this thread to its own forum : https://discord.com/channels/1153072414184452236/1161015724521836634```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 18:11:53 a user named ivangabriele said ```For the first time I got an AI Agent, using an open-source LLM, namely `Open-Orca/LlongOrca-13B-16k` which is terrible IMO, to both run some of my functions **and chain them**. But it got stuck at after the second call.\n",
      "\n",
      "I attached my current sandbox agent code.\n",
      "\n",
      "```sh\n",
      "--------------------------------------------------------------------------------\n",
      "OADS Configuration\n",
      "\n",
      "brave_search_api_key:            BSA*************************cB6\n",
      "current_model:                   Open-Orca/LlongOrca-13B-16k\n",
      "\n",
      "...\n",
      "\n",
      "    api_base:                htt**************************************net\n",
      "    api_key:                 sk-*********************************************111\n",
      "    api_type:                open_ai\n",
      "    api_version:             None\n",
      "    model:                   Open-Orca/LlongOrca-13B-16k\n",
      "\n",
      "user_proxy_agent:                {'current_model': 'Open-Orca/LlongOrca-13B-16k'}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "CEO (to Assistant):\n",
      "\n",
      "What are the best Ubuntu features?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant (to CEO):\n",
      "\n",
      "SEARCH Best Ubuntu Features\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CEO (to Assistant):\n",
      "\n",
      "{\"search_results\": [{\"title\": \"Desktop features | Ubuntu\", \"description\": \"Learn about all the great...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Assistant (to CEO):\n",
      "\n",
      "OPEN https://itsfoss.com/ubuntu-20-04-release-features/\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CEO (to Assistant):\n",
      "\n",
      "[üì∞ News Portal](https://news.itsfoss.com/) [üéí Resources](https://itsfoss.com/resources/)...\n",
      "``````.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 18:01:05 a user named ivangabriele said ```I added a section in my README for that: https://github.com/ivangabriele/openai-autogen-dev-studio#open-source-llms\n",
      "\n",
      "It's a similar LLM config in Autogen.```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 17:08:19 a user named rhokstar said ```https://www.youtube.com/watch?v=JjVvYDPVrAQ&ab_channel=IndyDevDan```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 16:56:13 a user named flaiwheel said ```Hi, did you already checked the examples? https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 16:52:36 a user named flaiwheel said ```Hi there, some people seem to work on it https://discord.com/channels/1153072414184452236/1159815963076730921, but would be great to hear your ideas!```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 16:05:47 a user named brad_10154 said ```@andyinater I may not be using it correctly. I ran main.py and passed it \"Document the code at https://github.com/Andyinater/AutoGen_EnhancedAgents/blob/main/EnhancedAgents.py\". I used the default llm of gpt-3.5-turbo with my api key.  I was thinking maybe it would write the web scraping code, execute the code, pass results back up to gpt for summarizing.  I cant seem to paste in whole dialog as limit on length here but it did not seem to summarize the code getting stopped at various points in the process - either creating code or executing code or reading executed code results to send back up. Am I using it how you intended? Thanks, Brad\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------```.\n",
      "\n",
      "In forum-discussion, at 2023-10-09 14:10:16 a user named kevinwyr said ```Hey @andyinater  Great work! I am also creating a similar PR in https://github.com/microsoft/autogen/pull/131. There is also a roadmap here to handle context overflow: https://github.com/microsoft/autogen/issues/156.\n",
      "It would be great if you can take a look!```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-10 00:57:07 a user named kajatta said ```https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-10 00:55:16 a user named kajatta said ```Yep already an example for this```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 20:37:50 a user named ai.reseach said ```ü§î Put it in the task for Groupchat automated code notebook? üòâüòâü§£ü´£```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 20:26:00 a user named ssvfx said ```great idea, thank you for the advice!```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 19:20:09 a user named hanley7082 said ```an autogen program needs to live in a python file. Maybe you could connect those machines via api into a third machine that is running the autogen code?```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 19:19:10 a user named hanley7082 said ```assistant is not yet officially available in autogen```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 18:08:04 a user named ssvfx said ```id like to set up my first autogen project using 2 separate ubuntu machines working together. where is the best place to start?```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 17:41:42 a user named ai.reseach said ```Is there any difference in the using assistant API when it comes to the config_oai file```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 17:41:01 a user named .basie. said ```It has been requested already: Work with local LLMs```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 14:03:12 a user named cncgeorge said ```#autogen is amazing, looking forward to combining teachable agent to RAG. Current work around is passing last good response to teachable agent. Thoughts‚Ä¶```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-09 08:16:31 a user named warmonger9626 said ```Anyone tried processing very long discussions? I'd like to scrap entire Discord channel and extract Q&A from it. Of course it won't fit in a context window, but maybe agent can process it step by step?```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-08 14:50:24 a user named shullp said ```creating a full dev team```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-08 14:27:58 a user named dhifafathiyahz said ```To connect with local llm seamlessly```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-08 13:31:12 a user named uknowwhoab1r said ```Embedded system datasheet checker ( Anyone would like to join me ?)```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-08 10:44:22 a user named stefan_str said ```Code Security Testing Agents üôÇ```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-08 08:28:47 a user named nikolkox said ```web page optimizaiton for SEO```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-07 22:16:59 a user named diogenesbr said ```I would like to create a Code Generator that can be used in maintenance of a legacy codebase```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-07 18:10:17 a user named char79 said ```Is something like this possible?\n",
      "Here's what I cooked up so far. I know changes are necessary.\n",
      "from autogen import AssistantAgent, UserProxyAgent\n",
      "import autogen\n",
      "\n",
      "Represents the project manager or team lead with continuous oversight\n",
      "team_lead = autogen.UserProxyAgent(\n",
      "    name=\"Team_Lead\",\n",
      "    system_message=\"A human team lead providing continuous oversight and dynamic task assignment based on project needs.\",\n",
      "    code_execution_config=False,\n",
      ")\n",
      "\n",
      "Represents the software developer specializing in UI/UX, adaptable to changes\n",
      "ui_ux_developer = autogen.AssistantAgent(\n",
      "    name=\"UI_UX_Developer\",\n",
      "    llm_config=gpt4_config,\n",
      "    system_message=\"UI/UX Developer. Adapt design practices to feedback and iterate on user interface elements for optimal user experience across updates.\",\n",
      ")\n",
      "\n",
      "Represents the back-end developer with a focus on scalable and maintainable code\n",
      "backend_developer = autogen.AssistantAgent(\n",
      "    name=\"Backend_Developer\",\n",
      "    llm_config=gpt4_config,\n",
      "    system_message=\"Backend Developer. Focus on creating scalable and maintainable back-end systems, with the flexibility to adjust to new requirements as they emerge.\",\n",
      ")\n",
      "\n",
      "Represents the front-end developer who ensures continuous integration\n",
      "frontend_developer = autogen.AssistantAgent(\n",
      "    name=\"Frontend_Developer\",\n",
      "    llm_config=gpt4_config,\n",
      "    system_message=\"Frontend Developer. Ensure the application's frontend is responsive and functional, with continuous integration of new features and fixes.\",\n",
      ")\n",
      "\n",
      "Represents the DevOps engineer who manages the deployment pipeline\n",
      "devops_engineer = autogen.AssistantAgent(\n",
      "    name=\"DevOps_Engineer\",\n",
      "    system_message=\"DevOps Engineer. Manage and improve the CI/CD pipeline for regular code integration and seamless deployment across environments.\",\n",
      "    llm_config=gpt4_config,\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "Based on your context, it seems Chainlit might be miscommunicated because there isn't any notable tool or library named \"Chainlit\" associated with Autogen or in general.\n",
      "\n",
      "Moreover, chainlit might be a context-specific term used in some discussions but it isn't globally recognized or linked with any specific functionality in Autogen package. With the existing context, I cannot provide a code snippet example on how to use the Chainlit with Autogen. \n",
      "\n",
      "Kindly provide more context or correct information regarding Chainlit.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# From a txt document \n",
    "user_question = \"How can Langchain be used with Autogen? Provide a code snippet example in your response.\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=user_question, clear_history=True) \n",
    "# ragproxyagent.send(recipient=assistant, message=user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print documents retrieved from Query\n",
    "ragproxyagent.retrieve_docs(\"Chainlit\")\n",
    "ragproxyagent._results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print documents retrieved from Query\n",
    "ragproxyagent.retrieve_docs(\"Langchain\")\n",
    "ragproxyagent._results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
