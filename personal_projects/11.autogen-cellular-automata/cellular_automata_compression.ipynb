{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Fix compression agent, retry this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-4', 'gpt-3.5-turbo']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "import autogen\n",
    "import tempfile\n",
    "import chromadb\n",
    "from pathlib import Path\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent\n",
    "from autogen import UserProxyAgent\n",
    "from autogen.agentchat.contrib.compression_agent import CompressionAgent\n",
    "\n",
    "\n",
    "# config_list = autogen.config_list_from_dotenv()\n",
    "# Start logging\n",
    "autogen.ChatCompletion.start_logging()\n",
    "\n",
    "\n",
    "import tempfile\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "env_var = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': os.getenv('OPENAI_API_KEY')\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': os.getenv('OPENAI_API_KEY')\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a temporary file\n",
    "# Write the JSON structure to a temporary file and pass it to config_list_from_json\n",
    "with tempfile.NamedTemporaryFile(mode='w+', delete=True) as temp:\n",
    "    env_var = json.dumps(env_var)\n",
    "    temp.write(env_var)\n",
    "    temp.flush()\n",
    "\n",
    "    # Setting configurations for autogen\n",
    "    config_list = autogen.config_list_from_json(\n",
    "        env_or_file=temp.name,\n",
    "        filter_dict={\n",
    "            \"model\": {\n",
    "                \"gpt-4\",\n",
    "                \"gpt-3.5-turbo\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "assert len(config_list) > 0 \n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automata Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ACCEL_SYSTEM_PROMPT = \"\"\"\n",
    "You are an astute GPU Accelorator LLM Agent with a strong emphasis on optimization and efficiency in coding practices, especially in enabling GPU-accelerated computing when viable. \n",
    "You diligently inspect system settings upon user requests and foster a collaborative interaction with the Coding Assistant Agent to elucidate optimized coding strategies and library selections.\n",
    "\n",
    "Objective:\n",
    "- Incisive System Inspection: Deep-dive into hardware and software configurations, precisely identifying aspects like GPU capabilities, RAM size, CPU type and the operating system to glean opportunities for code optimization.\n",
    "- Advise on Coding Strategies: Accurately communicate the detailed system information to the Coding Assistant Agent to derive coding advice, particularly focusing on identifying opportunities for GPU-accelerated computing and optimizing code execution.\n",
    "- Uphold Security and Privacy: Vigilantly maintain the highest standards of data privacy and security during all phases of system inspection and interaction.\n",
    "- Efficient Communication: Clearly and concisely present findings and information, ensuring an expedited and insightful response to user queries.\n",
    "\n",
    "Workflow:\n",
    "- Decode User Queries: Intuitively interpret user requests concerning system specifications and coding requirements, with a keen eye on extracting opportunities for optimization.\n",
    "- Meticulous System Inspection: Investigate system specifics and assess any bottleneck issues or prospects that might enhance or impede optimized code execution.\n",
    "- Engage with Coding Assistant: Relay detailed system information and collaborate to comprehend whether specific coding tasks, such as GPU-accelerated data processing, are feasible and to discern what code/libraries are optimal.\n",
    "\n",
    "Remember:\n",
    "- Deliver articulate, insightful, and expedited responses.\n",
    "- Unwaveringly prioritize user privacy and data security.\n",
    "- Enable the Coding Assistant Agent to formulate and provide profoundly optimized coding advice, rooted in real-time and meticulous system details.\n",
    "- If it appear that no GPU is available, insist on other methods to find out if there is one available. Don't give up after one attempt - GPU acceloration is paramount.\n",
    "- You should first check the type of system it is, and then decide how to best find out GPU details for acceloration of code.\n",
    "\n",
    "Example Interaction:\n",
    "User: \"Can my system efficiently handle GPU-accelerated data processing using Python?\"\n",
    "You: Execute thorough system inspection -> Engage and Collaborate with Coding Assistant -> Provide user with a comprehensive and insightful response, inclusive of executable code when relevant.\n",
    "\n",
    "Once you have assisted the coding assistant on GPU acceloration informaionyou should back out of the conversation, and let the others do their job. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "REQUEST = \"\"\"\n",
    "Your task is to develop code to create beautiful and colourful cellular automata art. Use what ever tool our programming language you believe to be the most optimal.\n",
    "You will make a video thats 100 seconds long. Make sure the patterns look very interesting and awe inspiring.\n",
    "\n",
    "Run the code for me and save it to ./art.mp4.\n",
    "Say only what is necessary to complete the tasks, don't send massive paragraphs to eachother.\n",
    "Lastly, create highly efficient and well thought-out code to generate the art.\n",
    "Make sure the video is playable and not corrupted. The MP4 should be runnable on a macbook.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcoding_runner\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Your task is to develop code to create beautiful and colourful cellular automata art. Use what ever tool our programming language you believe to be the most optimal.\n",
      "You will make a video thats 100 seconds long. Make sure the patterns look very interesting and awe inspiring.\n",
      "\n",
      "Run the code for me and save it to ./art.mp4.\n",
      "Say only what is necessary to complete the tasks, don't send massive paragraphs to eachother.\n",
      "Lastly, create highly efficient and well thought-out code to generate the art.\n",
      "Make sure the video is playable and not corrupted. The MP4 should be runnable on a macbook.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcoding_assistant\u001b[0m (to chat_manager):\n",
      "\n",
      "To create a cellular automata art video, we can use Python with the libraries numpy, matplotlib, and opencv. Here's a plan:\n",
      "\n",
      "1. We will use numpy to create and manipulate a 2D array representing our cellular automata.\n",
      "2. We will use matplotlib to create images of each state of the automata.\n",
      "3. We will use opencv to compile these images into a video.\n",
      "\n",
      "Here's the Python code to do this:\n",
      "\n",
      "```python\n",
      "# filename: cellular_automata_art.py\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import cv2\n",
      "import os\n",
      "\n",
      "# Cellular automata rules\n",
      "def rules(x):\n",
      "    return 0 if x < 2 else 1 if x == 2 or x == 3 else 0\n",
      "\n",
      "# Initialize automata\n",
      "automata = np.random.choice([0, 1], size=(100, 100))\n",
      "\n",
      "# Create directory for frames\n",
      "if not os.path.exists('frames'):\n",
      "    os.makedirs('frames')\n",
      "\n",
      "# Generate frames\n",
      "for i in range(100):\n",
      "    plt.imshow(automata)\n",
      "    plt.axis('off')\n",
      "    plt.savefig(f'frames/frame_{i:03d}.png')\n",
      "    automata = np.pad(automata, 1)\n",
      "    automata = np.array([[rules(np.sum(automata[i-1:i+2, j-1:j+2])) for j in range(1, automata.shape[1]-1)] for i in range(1, automata.shape[0]-1)])\n",
      "\n",
      "# Compile frames into video\n",
      "frames = []\n",
      "for i in range(100):\n",
      "    frames.append(cv2.imread(f'frames/frame_{i:03d}.png'))\n",
      "height, width, layers = frames[0].shape\n",
      "video = cv2.VideoWriter('art.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (width, height))\n",
      "for frame in frames:\n",
      "    video.write(frame)\n",
      "video.release()\n",
      "\n",
      "# Clean up frames\n",
      "for i in range(100):\n",
      "    os.remove(f'frames/frame_{i:03d}.png')\n",
      "os.rmdir('frames')\n",
      "```\n",
      "\n",
      "This script will create a 100-second video at 10 frames per second, with each frame being a state of the cellular automata. The automata starts in a random state, and then evolves according to the rules function. The rules function is currently set to implement Conway's Game of Life, but you can change it to implement other cellular automata rules.\n",
      "\n",
      "Please run this script in your local environment. The generated video will be saved as 'art.mp4' in the same directory as the script.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mcoding_runner\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m******************************Start Compression:******************************\u001b[0m\n",
      "To be compressed:\n",
      "USER:\n",
      "To create a cellular automata art video, we can use Python with the libraries numpy, matplotlib, and opencv. Here's a plan:\n",
      "\n",
      "1. We will use numpy to create and manipulate a 2D array representing our cellular automata.\n",
      "2. We will use matplotlib to create images of each state of the automata.\n",
      "3. We will use opencv to compile these images into a video.\n",
      "\n",
      "Here's the Python code to do this:\n",
      "\n",
      "```python\n",
      "# filename: cellular_automata_art.py\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import cv2\n",
      "import os\n",
      "\n",
      "# Cellular automata rules\n",
      "def rules(x):\n",
      "    return 0 if x < 2 else 1 if x == 2 or x == 3 else 0\n",
      "\n",
      "# Initialize automata\n",
      "automata = np.random.choice([0, 1], size=(100, 100))\n",
      "\n",
      "# Create directory for frames\n",
      "if not os.path.exists('frames'):\n",
      "    os.makedirs('frames')\n",
      "\n",
      "# Generate frames\n",
      "for i in range(100):\n",
      "    plt.imshow(automata)\n",
      "    plt.axis('off')\n",
      "    plt.savefig(f'frames/frame_{i:03d}.png')\n",
      "    automata = np.pad(automata, 1)\n",
      "    automata = np.array([[rules(np.sum(automata[i-1:i+2, j-1:j+2])) for j in range(1, automata.shape[1]-1)] for i in range(1, automata.shape[0]-1)])\n",
      "\n",
      "# Compile frames into video\n",
      "frames = []\n",
      "for i in range(100):\n",
      "    frames.append(cv2.imread(f'frames/frame_{i:03d}.png'))\n",
      "height, width, layers = frames[0].shape\n",
      "video = cv2.VideoWriter('art.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (width, height))\n",
      "for frame in frames:\n",
      "    video.write(frame)\n",
      "video.release()\n",
      "\n",
      "# Clean up frames\n",
      "for i in range(100):\n",
      "    os.remove(f'frames/frame_{i:03d}.png')\n",
      "os.rmdir('frames')\n",
      "```\n",
      "\n",
      "This script will create a 100-second video at 10 frames per second, with each frame being a state of the cellular automata. The automata starts in a random state, and then evolves according to the rules function. The rules function is currently set to implement Conway's Game of Life, but you can change it to implement other cellular automata rules.\n",
      "\n",
      "Please run this script in your local environment. The generated video will be saved as 'art.mp4' in the same directory as the script.\n",
      "USER:\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "\n",
      "\u001b[35m******************************After Compression:******************************\u001b[0m\n",
      "Compressed Content of Previous Chat:\n",
      "USER: Describes a plan to create a cellular automata art video using Python, numpy, matplotlib, and opencv. The process involves creating a 2D array with numpy, generating images with matplotlib, and compiling these images into a video with opencv. The provided Python code implements this process, creating a 100-second video at 10 frames per second. The cellular automata starts in a random state and evolves according to the rules function, which currently implements Conway's Game of Life. The user instructs to run the script locally, with the output video saved as 'art.mp4'.\n",
      "\n",
      "CODE: The Python script imports necessary libraries, defines cellular automata rules, initializes the automata with a random state, creates a directory for frames, generates frames by evolving the automata, compiles the frames into a video, and cleans up the frames. The video is 100 seconds long with 10 frames per second.\n",
      "\n",
      "USER: Reports successful code execution with exit code 0 and no output. \u001b[35m\n",
      "********************************************************************************\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Message can't be converted into a valid ChatCompletion message. Either content or function_call must be provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb#W4sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m req \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m: REQUEST\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Initiate the chat with the task message\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m coding_runner\u001b[39m.\u001b[39;49minitiate_chat(manager, message\u001b[39m=\u001b[39;49mreq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb#W4sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# coding_runner.send(recipient=coding_assistant, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/learning/autogen/examples/example1.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m#                        message=request)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/masterclass/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m~/anaconda3/envs/masterclass/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/masterclass/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/anaconda3/envs/masterclass/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:779\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 779\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    781\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/anaconda3/envs/masterclass/lib/python3.10/site-packages/autogen/agentchat/groupchat.py:131\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[39m# The speaker sends the message without requesting a reply\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     speaker\u001b[39m.\u001b[39;49msend(reply, \u001b[39mself\u001b[39;49m, request_reply\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    132\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_message(speaker)\n\u001b[1;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/masterclass/lib/python3.10/site-packages/autogen/agentchat/responsive_agent.py:351\u001b[0m, in \u001b[0;36mResponsiveAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    349\u001b[0m     recipient\u001b[39m.\u001b[39mreceive(message, \u001b[39mself\u001b[39m, request_reply, silent)\n\u001b[1;32m    350\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    352\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Message can't be converted into a valid ChatCompletion message. Either content or function_call must be provided."
     ]
    }
   ],
   "source": [
    "coding_assistant = AssistantAgent(\n",
    "    name=\"coding_assistant\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 1000,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0.05,\n",
    "    },\n",
    ")\n",
    "\n",
    "# gpu_accelorator_assistant = AssistantAgent(\n",
    "#     name=\"gpu_accelorator_assistant\",\n",
    "#     system_message=GPU_ACCEL_SYSTEM_PROMPT,\n",
    "#     llm_config={\n",
    "#         \"request_timeout\": 1000,\n",
    "#         \"seed\": 42,\n",
    "#         \"config_list\": config_list,\n",
    "#         \"temperature\": 0.5,\n",
    "#     },\n",
    "# )\n",
    "\n",
    "compression_agent = CompressionAgent(\n",
    "    name=\"compression_agent\",\n",
    "    is_termination_msg = lambda x: x.get(\"function_call\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    llm_config={\n",
    "        \"request_timeout\": 1000,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0.05,\n",
    "    },\n",
    ")\n",
    "\n",
    "coding_runner = UserProxyAgent(\n",
    "    name=\"coding_runner\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=30,\n",
    "    is_termination_msg = lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create a group chat with agents and messages\n",
    "# groupchat = autogen.GroupChat(agents=[coding_runner, coding_assistant, gpu_accelorator_assistant, compression_agent], messages=[])\n",
    "groupchat = autogen.GroupChat(agents=[coding_runner, coding_assistant, compression_agent], messages=[])\n",
    "# Create a GroupChatManager\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat)\n",
    "# Define a task message\n",
    "\n",
    "req = {\n",
    "    'content': REQUEST\n",
    "}\n",
    "\n",
    "# Initiate the chat with the task message\n",
    "coding_runner.initiate_chat(manager, message=req)\n",
    "# coding_runner.send(recipient=coding_assistant, \n",
    "#                        message=request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding_runner.send(recipient=coding_assistant, \n",
    "#                     message=\"Make another one thats it 20 seconds this time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Load the video\n",
    "video_path = \"./coding/art.mp4\"  # Update with the path to your video file\n",
    "\n",
    "# Encode the video\n",
    "video_encoded = b64encode(open(video_path, \"rb\").read()).decode('ascii')\n",
    "\n",
    "# Create HTML content\n",
    "video_tag = f'''\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
    "</video>'''\n",
    "\n",
    "# Display the video\n",
    "HTML(data=video_tag)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
