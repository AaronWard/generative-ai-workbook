{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph RAG using Groq\n",
    "\n",
    "In this notebook i will be using CrewAI to showcase how you can do RAG on a graphQL representation of your obsidian notes.<br>\n",
    "This example will be using grow for better inference speeds\n",
    "\n",
    "```bash\n",
    "pip install langchain-groq\n",
    "```\n",
    "\n",
    "\n",
    "I am exposing the notes as a local GraphQL server using this [plugin](https://github.com/TwIStOy/obsidian-local-graphql). <br>\n",
    "Access the Apollo client UI by going to this link [http://localhost:28123/](http://localhost:28123/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pprint as pp\n",
    "from langchain.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import load_tools\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv('.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObsidianGraphTool:\n",
    "    @tool(\"get_documents\")\n",
    "    def get_documents(query: str) -> str:\n",
    "        \"\"\"Get Documents from obsdiain graph and parse them.\"\"\"\n",
    "\n",
    "        def define_query_string(search_type):\n",
    "            # Define your query with the variable\n",
    "            string = f\"\"\" \\\n",
    "            query ExampleQuery($query: String!) {{\n",
    "                vault {{\n",
    "                {search_type}(query: $query) {{\n",
    "                    file {{\n",
    "                    name\n",
    "                    readContent\n",
    "                    stat {{\n",
    "                        size\n",
    "                    }}\n",
    "                    }}\n",
    "                    score\n",
    "                }}\n",
    "                }}\n",
    "            }}\n",
    "            \"\"\"\n",
    "            return gql(string)\n",
    "\n",
    "\n",
    "        def filter_results(result, min_neg_score, search_type, top_n):\n",
    "            \"\"\"\n",
    "            Filter results based on min_neg_score threshold and sort by score descending (closest to 0)\n",
    "            \"\"\"\n",
    "            result_string = \"\"\n",
    "            top_items = sorted(\n",
    "                (item for item in result[\"vault\"][search_type] if item[\"score\"] > min_neg_score),\n",
    "                key=lambda x: x[\"score\"], \n",
    "                reverse=True\n",
    "            )\n",
    "\n",
    "            # Get top N results\n",
    "            if top_n != -1:\n",
    "                top_items = top_items[:top_n]\n",
    "\n",
    "            for item in top_items:\n",
    "                file_name = item[\"file\"][\"name\"]\n",
    "                score = item[\"score\"]\n",
    "                read_content = item['file']['readContent']\n",
    "\n",
    "                file_string = f\"File Name: {file_name}\\nScore: {score}\\nContent:\\n{read_content}\"        \n",
    "                result_string += file_string + \"\\n\"\n",
    "\n",
    "            return result_string\n",
    "\n",
    "        # Configure the client\n",
    "        transport = RequestsHTTPTransport(\n",
    "            url='http://localhost:28123/',  # Make sure this URL is correct\n",
    "            use_json=True,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            verify=True,\n",
    "            retries=3,\n",
    "        )\n",
    "\n",
    "        client = Client(transport=transport, fetch_schema_from_transport=True)\n",
    "\n",
    "        SIMPLE_SEARCH_TYPE = \"simpleSearch\"\n",
    "        FUZZY_SEARCH_TYPE = \"fuzzySearch\"\n",
    "        MIN_NEG_SCORE = -3\n",
    "        TOP_N = 3\n",
    "\n",
    "        # simple_search_query = define_query_string(SIMPLE_SEARCH_TYPE)\n",
    "        fuzzy_search_query = define_query_string(FUZZY_SEARCH_TYPE)\n",
    "\n",
    "        # Execute the query with variables\n",
    "        variables = {\n",
    "            \"query\": query\n",
    "        }\n",
    "\n",
    "        result = client.execute(fuzzy_search_query, variable_values=variables)\n",
    "        result = filter_results(result, MIN_NEG_SCORE, FUZZY_SEARCH_TYPE, TOP_N)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Crew\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_crew(question):\n",
    "    \"\"\"Setup a crew to extract keywords and search a database based on a question\"\"\"\n",
    "\n",
    "    # llm = Ollama(model=model_name, base_url=api_base)\n",
    "    llm = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\", groq_api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "    # ------ Agents ------ \n",
    "    extract_agent = Agent(\n",
    "        role=\"Extractor\",\n",
    "        goal=\"Extract a single entity within the query, and boil it down to a single word to search for.\",\n",
    "        backstory=\"Skilled in identifying a single key word from complex questions.\",\n",
    "        llm=llm,\n",
    "        # tools=human_tools,\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "    )\n",
    "\n",
    "    # Agent to perform a search in the graph database using ObsidianGraphTool\n",
    "    search_agent = Agent(\n",
    "        role=\"Answerer\",\n",
    "        goal=\"Search the graph database using the extracted search term and use that information to ANSWER the users query.\",\n",
    "        backstory=\"Helpful assistant who uses get_documents tools to get answers and provides clear explanations\",\n",
    "        llm=llm,\n",
    "        tools=[ObsidianGraphTool.get_documents],  # Assuming the tool is correctly implemented as a class method\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "        memory=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # Agent to use the search results to answer the user's original question\n",
    "    answer_agent = Agent(\n",
    "        role=\"Answerer\",\n",
    "        goal=\"Provide a concise answer using information from the graph database.\",\n",
    "        backstory=\"Adept at synthesizing information to craft clear, accurate answers.\",\n",
    "        llm=llm,\n",
    "        verbose=False,\n",
    "        allow_delegation=False,\n",
    "    )\n",
    "\n",
    "    # ------ Tasks ------ \n",
    "\n",
    "    # Define the tasks\n",
    "    extract_task = Task(\n",
    "        description=f\"Extract a search term from this question: {question}\\n\\n DO NOT include spaces in your. DO NOT try to infer acronyms, just use them as is.\",\n",
    "        expected_output=\"A single word to search for within a fuzzy search\",\n",
    "        agent=extract_agent,\n",
    "    )\n",
    "\n",
    "    search_task = Task(\n",
    "        description=\"\"\"\n",
    "        1. Pass the extracted search term to provided get_documents tool to search the graph database.\n",
    "        2. Answer the user's question using the search results\n",
    "\n",
    "        Rules:\n",
    "        - You MUST only use the provided get_documents tool once\n",
    "        - You MUST use the information from the search as \n",
    "\n",
    "        This is the users question:{question}\\n\n",
    "        \"\"\",\n",
    "        expected_output=\"An informative answer to the question\",\n",
    "        agent=search_agent,\n",
    "        context=[extract_task]  # Pass the output of the extract_task as context\n",
    "    )\n",
    "\n",
    "    # Create the crew\n",
    "    graph_search_crew = Crew(\n",
    "        agents=[extract_agent, search_agent],\n",
    "        tasks=[extract_task, search_task],\n",
    "        process=Process.sequential,\n",
    "        manager_llm=llm\n",
    "    )\n",
    "\n",
    "    return graph_search_crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe question is asking about measuring bias in a Machine Learning (ML) project. The key term here is \"bias\" as it is the main subject of the question. The task is to extract a single word to search for, so the answer should be \"bias\".\n",
      "\n",
      "Thought: I now can give a great answer\n",
      "\n",
      "Final Answer: bias\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the user's question, I need to first use the `get_documents` tool to search the graph database for information related to the search term \"bias\". Then, I will use this information to provide an informative answer to the user's question.\n",
      "\n",
      "Action: get_documents\n",
      "Action Input: {\"query\": \"bias\"}\u001b[0m\u001b[93m \n",
      "\n",
      "File Name: 8. Aequitas.md\n",
      "Score: -0.14600000000000002\n",
      "Content:\n",
      "---\n",
      "tags:\n",
      "  - data\n",
      "  - ml\n",
      "  - model-bias\n",
      "  - mlops\n",
      "  - model-testing\n",
      "---\n",
      "> [[Model Evaluation]], [[ML Pipelines]], [[Model Bias (Fairness)]], [[7.  Model Bias]]\n",
      "### Aequitas\n",
      "\n",
      "Aequitas is an open-source bias audit toolkit that allows users to evaluate their machine learning models for fairness. It can be used both as a Python library or via a web interface. Aequitas offers various fairness metrics and visualizations to help you understand and address bias in your model. Here are the requirements for using Aequitas:\n",
      "- Model score\n",
      "- Label\n",
      "- Binary classification only\n",
      "- At least one categorical feature OR a numerical feature\n",
      "\n",
      "There are 3 reports generated:\n",
      "- Create cross-tabulation using Group() class(this is the basis for all analysis)\n",
      "- After the cross tab we compute bias using Bias() class\n",
      "- Then we compute fairness using Fairness() class\n",
      "- This can result in a beefy data frame \n",
      "\n",
      "\n",
      "\n",
      "[http://aequitas.dssg.io/](http://aequitas.dssg.io/) \n",
      "### Other Tools:\n",
      "- What-IF tool\n",
      "- Fairlearn\n",
      "- FairML\n",
      "File Name: 7.  Model Bias.md\n",
      "Score: -0.173\n",
      "Content:\n",
      "---\n",
      "tags:\n",
      "  - data\n",
      "  - ml\n",
      "  - mlops\n",
      "  - model-testing\n",
      "  - model-bias\n",
      "---\n",
      "> [[Machine Learning]], [[ML Operations]], [[ML Pipelines]], [[Model Evaluation]], \n",
      "### Model Bias\n",
      "- Bias is multifaceted, and isn’t as concrete as model performance metrics\n",
      "- More accurately: data bias\n",
      "\t- Note the same as bias-variance tradeoff\n",
      "- Slice performance may help indicate bias\n",
      "- Bias is distinct, but occasionally related to model explainabilty \n",
      "\n",
      "### Types of data bias:\n",
      "- **Human error**\n",
      "\t- Sampling error: mismatch between same and intended population (too small)\n",
      "\t- Exclusion bias: group excluded from survey/data\n",
      "\t- Recall bias: Unreliability of getting people to recall events from the past\n",
      "- **Society error**\n",
      "\t- Implicit bias\n",
      "\t- Unjust policy\n",
      "\n",
      "### When bias can appear:\n",
      "- Collection stage\n",
      "\t- Ex: images from web not match user input\n",
      "- Annotation\n",
      "\t- Labeler bias\n",
      "- Preprocessing\n",
      "\t- Data cleaning \n",
      "\t- example: truncating something for memory issues\n",
      "\n",
      "**Bias can creep in at any part of the process**\n",
      "\n",
      "\n",
      "File Name: Bias vs Variance.md\n",
      "Score: -0.31689999999999996\n",
      "Content:\n",
      "---\n",
      "tags:\n",
      "  - ml\n",
      "  - data-science\n",
      "  - data\n",
      "---\n",
      "> [[Machine Learning]], [[Data Science]], [[Data]]\n",
      "### Bias\n",
      "- If a straight line can’t fit the relationship of the true curve, this is known as bias\n",
      "- Calculating distances (residuals) from the line to the datapoint to see how well the model fit:\n",
      "\t- In a straight line vs a overfitted line the overfitted line wins, but only on the training data\n",
      "\t- Given a test set this won’t be able to give good results\n",
      "\n",
      "### Variance\n",
      "- The difference between in fits between datasets is called variance\n",
      "- variance is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting).”\n",
      "- Variance refers to an algorithm’s sensitivity to specific sets of the training set occurs when an algorithm has limited flexibility to learn the true signal from the dataset.\n",
      "\n",
      "### 3 methods to find the sweet spot are:\n",
      "- Regualarization \n",
      "- Boosting \n",
      "- Bagging\n",
      "\n",
      "![[download 14.png]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Statistical Bias vs Societal Bias\n",
      "The term \"bias\" in the context of the bias-variance tradeoff and the term \"bias\" in the context of racial or societal bias in ML models refer to two different concepts, even though they share the same name. It's important to distinguish between them:\n",
      "### 1. Statistical Bias (Bias-Variance Tradeoff):\n",
      "- This refers to the error introduced by approximating a real-world problem, which may be complex, by a too-simplistic model.\n",
      "- In the bias-variance tradeoff, \"bias\" quantifies how much on average the predictions of a model differ from the true values.\n",
      "### 2. Societal Bias (e.g., Racial Bias):\n",
      "- This refers to the presence of unfair and often systematic values or prejudices in a model's predictions.\n",
      "- It can arise from various factors, including biased training data, biased labeling, or inherent biases in the design of algorithms.\n",
      "- Models that are biased in this sense can perpetuate or amplify societal inequalities, leading to unfair or discriminatory outcomes.\n",
      "\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought:\n",
      "Now that I have the information from the graph database related to the search term \"bias\", I can use this information to provide an informative answer to the user's question. The information I have includes descriptions of different types of bias, such as human error, societal error, and data bias, as well as a tool called Aequitas that can be used to evaluate machine learning models for fairness.\n",
      "\n",
      "Final Answer:\n",
      "Bias in the context of machine learning can refer to both statistical bias and societal bias. Statistical bias, as it relates to the bias-variance tradeoff, is the error introduced by approximating a real-world problem with a simplistic model. Societal bias, on the other hand, refers to the presence of unfair and often systematic values or prejudices in a model's predictions. This can arise from biased training data, biased labeling, or inherent biases in the design of algorithms. Models that are biased in this sense can perpetuate or amplify societal inequalities, leading to unfair or discriminatory outcomes. To help address bias in machine learning models, tools like Aequitas can be used to evaluate models for fairness. Aequitas is an open-source bias audit toolkit that allows users to evaluate their machine learning models for fairness and offers various fairness metrics and visualizations to help understand and address bias in the model.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('Bias in the context of machine learning can refer to both statistical bias '\n",
      " 'and societal bias. Statistical bias, as it relates to the bias-variance '\n",
      " 'tradeoff, is the error introduced by approximating a real-world problem with '\n",
      " 'a simplistic model. Societal bias, on the other hand, refers to the presence '\n",
      " \"of unfair and often systematic values or prejudices in a model's \"\n",
      " 'predictions. This can arise from biased training data, biased labeling, or '\n",
      " 'inherent biases in the design of algorithms. Models that are biased in this '\n",
      " 'sense can perpetuate or amplify societal inequalities, leading to unfair or '\n",
      " 'discriminatory outcomes. To help address bias in machine learning models, '\n",
      " 'tools like Aequitas can be used to evaluate models for fairness. Aequitas is '\n",
      " 'an open-source bias audit toolkit that allows users to evaluate their '\n",
      " 'machine learning models for fairness and offers various fairness metrics and '\n",
      " 'visualizations to help understand and address bias in the model.')\n"
     ]
    }
   ],
   "source": [
    "# Execute the crew\n",
    "question = \"How should i measure bias in an ML project?\"\n",
    "\n",
    "graph_search_crew = define_crew(question)\n",
    "result = graph_search_crew.kickoff()\n",
    "pp.pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
