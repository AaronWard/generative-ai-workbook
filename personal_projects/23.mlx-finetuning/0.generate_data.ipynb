{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLX Apple Silicon LLM Finetuning\n",
    "\n",
    "Need to create a dataset in format it within a `jsjonl` representation to fine tune Mistral 7B\n",
    "\n",
    "`{\"text\":\"<s>[INST] Instruction[/INST] Model answer</s>[INST] Follow-up instruction[/INST]\"}`\n",
    "\n",
    "I've going to reuse the QA dataset i made for the autogen discord RAG from a previous project, \n",
    "\n",
    "**Useful Links:**\n",
    "- [Building your training data for fine-tuning](https://apeatling.com/articles/part-2-building-your-training-data-for-fine-tuning/)\n",
    "- [Documentation for the JSON Lines text file format](https://jsonlines.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in QA pairs to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I handle an invalid URL error when usi...</td>\n",
       "      <td>To fix an invalid URL error, ensure you're usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How should I approach feeding a local image in...</td>\n",
       "      <td>When you want to feed a local image into the M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I use the `--pre` flag in pip?</td>\n",
       "      <td>Use the `--pre` flag in pip to include pre-rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What do you do if you're charged for input tok...</td>\n",
       "      <td>You could modify the logic to terminate the op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I install a package from a pre-release...</td>\n",
       "      <td>To install pre-release versions of a package t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>What is the current state of support for integ...</td>\n",
       "      <td>According to a user's statement, Llama2 and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>How does one decide between using Autogen and ...</td>\n",
       "      <td>The provided text does not give a specific ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Are the developers of Autogen and Semantic Ker...</td>\n",
       "      <td>The text implies that there was some awareness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Can I use any AI model, like Llama2, or am I l...</td>\n",
       "      <td>There is no clear answer provided in the text;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>What should I do if I have ideas for the setup...</td>\n",
       "      <td>Though there is no direct answer in the text, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    How can I handle an invalid URL error when usi...   \n",
       "1    How should I approach feeding a local image in...   \n",
       "2                How do I use the `--pre` flag in pip?   \n",
       "3    What do you do if you're charged for input tok...   \n",
       "4    How can I install a package from a pre-release...   \n",
       "..                                                 ...   \n",
       "882  What is the current state of support for integ...   \n",
       "883  How does one decide between using Autogen and ...   \n",
       "884  Are the developers of Autogen and Semantic Ker...   \n",
       "885  Can I use any AI model, like Llama2, or am I l...   \n",
       "886  What should I do if I have ideas for the setup...   \n",
       "\n",
       "                                                Answer  \n",
       "0    To fix an invalid URL error, ensure you're usi...  \n",
       "1    When you want to feed a local image into the M...  \n",
       "2    Use the `--pre` flag in pip to include pre-rel...  \n",
       "3    You could modify the logic to terminate the op...  \n",
       "4    To install pre-release versions of a package t...  \n",
       "..                                                 ...  \n",
       "882  According to a user's statement, Llama2 and mo...  \n",
       "883  The provided text does not give a specific ans...  \n",
       "884  The text implies that there was some awareness...  \n",
       "885  There is no clear answer provided in the text;...  \n",
       "886  Though there is no direct answer in the text, ...  \n",
       "\n",
       "[887 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_qa(text):\n",
    "    \"\"\"Parse the text to extract questions and answers.\"\"\"\n",
    "    qa_pairs = re.findall(r'Question: (.*?)\\nAnswer: (.*?)\\n', text, re.DOTALL)\n",
    "    return qa_pairs\n",
    "\n",
    "def create_dataframe(filepath):\n",
    "    \"\"\"Read the text file and create a pandas DataFrame.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    qa_pairs = parse_qa(content)\n",
    "    df = pd.DataFrame(qa_pairs, columns=['Question', 'Answer'])\n",
    "    return df\n",
    "\n",
    "\n",
    "data_path = \"./data/22112023_qa.txt\"\n",
    "qa_df = create_dataframe(data_path)\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      <s>[INST] How can I handle an invalid URL erro...\n",
       "1      <s>[INST] How should I approach feeding a loca...\n",
       "2      <s>[INST] How do I use the `--pre` flag in pip...\n",
       "3      <s>[INST] What do you do if you're charged for...\n",
       "4      <s>[INST] How can I install a package from a p...\n",
       "                             ...                        \n",
       "882    <s>[INST] What is the current state of support...\n",
       "883    <s>[INST] How does one decide between using Au...\n",
       "884    <s>[INST] Are the developers of Autogen and Se...\n",
       "885    <s>[INST] Can I use any AI model, like Llama2,...\n",
       "886    <s>[INST] What should I do if I have ideas for...\n",
       "Length: 887, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_for_mistral(row):\n",
    "    # Formatting the question-answer pair with the required Mistral format\n",
    "    return f\"<s>[INST] {row['Question']} [/INST] {row['Answer']}</s>\"\n",
    "\n",
    "# Apply the formatting function to each row of the DataFrame\n",
    "formatted_data = qa_df.apply(format_for_mistral, axis=1)\n",
    "formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the formatted data to a JSONL file\n",
    "with open('./data/instructions.json', 'w') as file:\n",
    "    for entry in formatted_data:\n",
    "        json.dump({\"text\": entry}, file)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in to train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_valid_file(formatted_data):\n",
    "    # Calculate 20% of the total lines for validation\n",
    "    twenty_percent = int(len(formatted_data) * 0.2)\n",
    "    validation_lines = formatted_data[:twenty_percent]\n",
    "    training_lines = formatted_data[twenty_percent:]\n",
    "\n",
    "    with open('./data/train.jsonl', 'w') as file:\n",
    "        for entry in training_lines:\n",
    "            json.dump({\"text\": entry}, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "    with open('./data/valid.jsonl', 'w') as file:\n",
    "        for entry in validation_lines:\n",
    "            json.dump({\"text\": entry}, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "create_valid_file(formatted_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning with MLX\n",
    "\n",
    "- Install mlx: `pip install mlx`\n",
    "- I've imported the code from the examples to the `./models` folder.\n",
    "- The `adapters.npz` file will be outputted to the directory where the command was run.\n",
    "- [LORA - MLX Documentation](https://github.com/ml-explore/mlx-examples/tree/main/lora)\n",
    "\n",
    "\n",
    "\n",
    "```bash\n",
    "python lora.py --train --model mistralai/Mistral-7B-Instruct-v0.2 --data ./data/ --batch-size 2 --lora-layers 8 --iters 1000\n",
    "\n",
    ". . .\n",
    "\n",
    "Iter 900: Train loss 2.438, It/sec 0.464, Tokens/sec 69.842\n",
    "Iter 900: Saved adapter weights to adapters.npz.\n",
    "Iter 910: Train loss 2.326, It/sec 0.146, Tokens/sec 20.943\n",
    "Iter 920: Train loss 2.328, It/sec 0.310, Tokens/sec 43.160\n",
    "Iter 930: Train loss 2.280, It/sec 0.232, Tokens/sec 33.151\n",
    "Iter 940: Train loss 2.454, It/sec 0.588, Tokens/sec 76.523\n",
    "Iter 950: Train loss 2.238, It/sec 0.579, Tokens/sec 79.892\n",
    "Iter 960: Train loss 2.457, It/sec 0.515, Tokens/sec 76.947\n",
    "Iter 970: Train loss 2.419, It/sec 0.563, Tokens/sec 81.282\n",
    "Iter 980: Train loss 2.276, It/sec 0.511, Tokens/sec 76.844\n",
    "Iter 990: Train loss 2.332, It/sec 0.532, Tokens/sec 72.286\n",
    "Iter 1000: Train loss 2.536, It/sec 0.498, Tokens/sec 73.649\n",
    "Iter 1000: Val loss 2.187, Val took 82.108s\n",
    "Iter 1000: Saved adapter weights to adapters.npz.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Mistral-7B-Instruct-v0.2 to our Finetuned Version\n",
    "\n",
    "First we will query the regular Mistral model to see what kind of response it gives.<br>\n",
    "Then, we will ask the fine tuned model the same question to verify the affectiveness of the finetune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "python lora.py --model mistralai/Mistral-7B-Instruct-v0.2 --max-tokens 1000 --prompt \"What are some ways you can use open sourced models with Autogen?\"\n",
    "```\n",
    "\n",
    "**response:**\n",
    "```\n",
    "Open sourced models can be used with Autogen for different purposes, such as improving realism, adding new features, and extending the coverage of different use cases. This is done by deploying the open sourced models as plugins or custom controls.\n",
    "\n",
    "Split the answer into some possible applications:\n",
    "\n",
    "1. Improving realism:\n",
    "   - Open sourced models can be used to enhance existing features within Autogen.\n",
    "   - Examples include adding additional textures using new models to pinpoint locations like parking lots, gates, fences, or even trees.\n",
    "\n",
    "2. Extending feature coverage:\n",
    "   - Open sourced models can be used to enhance the range of Autogen's capabilities by adding new types to the library.\n",
    "   - For example, adding open sourced models of power stations, wind turbines, or antennas.\n",
    "\n",
    "3. Custom controls or applications:\n",
    "   - Scripts can be written to interact with the models, creating new custom controls or applications.\n",
    "   - For example, using open sourced LIDAR data to create new methods of terrain modeling or even using open sourced satellite data to generate accurate 3D models of the terrain.\n",
    "\n",
    "\n",
    "Remember that you would need to check the license of the open sourced model before importing to Autogen.\n",
    "==========\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
