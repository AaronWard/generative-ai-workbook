{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSPY Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv('../../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy is configured to use DeepSeek's 'deepseek-chat'!\n"
     ]
    }
   ],
   "source": [
    "lm = dspy.LM(\n",
    "    'openai/deepseek-chat',      # The 'openai/' prefix indicates an OpenAI-compatible model\n",
    "    api_key=os.getenv('DEEPSEEK_API_KEY'),\n",
    "    api_base='https://api.deepseek.com',\n",
    "    model_type='chat'            # 'chat' because the endpoint expects Chat-style messages.\n",
    ")\n",
    "\n",
    "# Let DSPy know we want to use this LM globally\n",
    "dspy.configure(lm=lm)\n",
    "print(\"DSPy is configured to use DeepSeek's 'deepseek-chat'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here \"\n",
      " 'and ready to help you with whatever you need. How are you doing today? 😊')\n"
     ]
    }
   ],
   "source": [
    "result = lm(\"Hello, how are you?\")\n",
    "pprint(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Loading Data with DSPy DataLoaders\n",
    "\n",
    "DSPy provides convenient utilities to load data from CSVs, HuggingFace Datasets, or a raw Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5028c2e447a4f7eb6cb7a75863211a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/195 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4976131d017a4d1db45828fc7fccd2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/756 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e157b8b4d43848328c7d107556ab06e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.01M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db20b24417d14ad68210cd6d9ebb5cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/336k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2834d5fec36c4a12b76ab5c342e31c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18019 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a6b78f4b124814aa696c02dea0588f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits in CodeAlpaca: dict_keys(['train', 'test'])\n",
      "Number of train examples: 18019\n",
      "Number of test examples: 2003\n"
     ]
    }
   ],
   "source": [
    "from dspy.datasets import DataLoader\n",
    "\n",
    "dl = DataLoader()\n",
    "\n",
    "# Example 1: Load from HuggingFace\n",
    "# (Ensure you have 'datasets' library installed via `pip install datasets`)\n",
    "code_alpaca = dl.from_huggingface(\"HuggingFaceH4/CodeAlpaca_20K\", split=[\"train\", \"test\"])\n",
    "print(\"Splits in CodeAlpaca:\", code_alpaca.keys())\n",
    "print(\"Number of train examples:\", len(code_alpaca['train']))\n",
    "print(\"Number of test examples:\", len(code_alpaca['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce2c29163c34e83b25e5b2c1c70c029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the csv: 13\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Load from CSV\n",
    "# Suppose you have a CSV with columns: instruction, context, response\n",
    "example_csv = dl.from_csv(\"../_resources/test.csv\", fields=(\"example_header\", \"value\"))\n",
    "print(\"Number of examples in the csv:\", len(example_csv ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 10\n",
      "test dataset size: 3\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Splitting a Python list of Examples\n",
    "splits = dl.train_test_split(example_csv, train_size=0.8)\n",
    "train_dataset = splits['train']\n",
    "test_dataset = splits['test']\n",
    "print(\"train dataset size:\", len(train_dataset))\n",
    "print(\"test dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Creating a Simple DSPy Program\n",
    "\n",
    "DSPy organizes your “AI logic” into modules using OOP (classes and objects)\n",
    "\n",
    "A module has an input signature and an output signature. \n",
    "Here’s a very simple classification example that classifies text into “positive,” “negative,” or “neutral.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: I absolutely love this new phone, but it's a bit expensive.\n",
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "import dspy\n",
    "\n",
    "# 1) Define a signature. This is effectively your structured “prompt+response” contract.\n",
    "class SentimentSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Classify a given sentence as positive, negative, or neutral.\n",
    "    \"\"\"\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal['positive','negative','neutral'] = dspy.OutputField()\n",
    "\n",
    "# 2) Create a DSPy module that implements the signature with a simple approach:\n",
    "sentiment_classifier = dspy.Predict(SentimentSignature)\n",
    "\n",
    "# 3) Try it out:\n",
    "sample_text = \"I absolutely love this new phone, but it's a bit expensive.\"\n",
    "result = sentiment_classifier(sentence=sample_text)\n",
    "\n",
    "print(f\"Input Sentence: {sample_text}\")\n",
    "print(f\"Predicted Sentiment: {result.sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Opinion about DSPy\n",
    "\n",
    "\n",
    "- Known as the \"pytorch for llm programs\", instead of relying on chains like LangChain, it implements graphs. \n",
    "- I don't like how it relies on implicit functionality that isn't clear what is actually happening\n",
    "- For example: equating the LLM workflow to a neural network code with functions named `forward()` seems like an ML engineers approach to over engineer an LLM powered application.\n",
    "- I guess some of the utilities are good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
