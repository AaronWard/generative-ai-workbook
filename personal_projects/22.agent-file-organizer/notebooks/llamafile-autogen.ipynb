{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llava v1.5 as a function\n",
    "\n",
    "There are 3 options to use llava within\n",
    "\n",
    "\n",
    "**Step to run locally:**\n",
    "- `cd` to models folder in terminal\n",
    "- `chmod +x llava-v1.5-7b-q4-main.llamafile `\n",
    "- `./llava-v1.5-7b-q4-main.llamafile --port 8081  --nobrowser`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../sample_images/tree.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /Users/award40/Desktop/personal/github/_models/llava-v1.5-7b-q4-main.llamafile --temp 0.3 \\\n",
    "  --image ./sample_images/tree.png \\\n",
    "  -p \"Is this image an IRL image or computer generated?\" \\\n",
    "  --silent-prompt 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /Users/award40/Desktop/personal/github/_models/llava-v1.5-7b-q4-main.llamafile --temp 0.1 \\\n",
    "  --image ./sample_images/llamafile.png \\\n",
    "  -p \"Is this image a well known meme?\" \\\n",
    "  --silent-prompt 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import pprint as pp\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "def send_request_to_local_api(encoded_image):\n",
    "    # URL of the local API\n",
    "    url = \"http://127.0.0.1:8080/completion\"\n",
    "\n",
    "    # Form the request data with image_data as an array of objects\n",
    "    data = {\n",
    "        \"prompt\": \"USER:[img-1]Describe the image in detail.\\nASSISTANT:\",\n",
    "        \"temperature\": 0.1,\n",
    "        \"image_data\": [{\n",
    "            \"data\": encoded_image, \n",
    "            \"id\": 1\n",
    "        }]\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, json=data)\n",
    "    return response.json()\n",
    "\n",
    "# Replace this with the path to your image file\n",
    "image_path = \"./sample_images/tree.jpg\"\n",
    "\n",
    "encoded_image = encode_image_to_base64(image_path)\n",
    "response_data = send_request_to_local_api(encoded_image)\n",
    "\n",
    "# Print the response\n",
    "pp.pprint(response_data['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'message': {'content': 'USER: [img-1]Describe the image in '\n",
      "                                     'detail.\\n'\n",
      "                                     '\\n',\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1704120872,\n",
      " 'id': 'chatcmpl-XKFxH1hIwy92iU5ws8q7K9kkKQtusYO2',\n",
      " 'model': 'llava-v1.5-7b-Q4_K.gguf',\n",
      " 'object': 'chat.completion',\n",
      " 'usage': {'completion_tokens': 22, 'prompt_tokens': 63, 'total_tokens': 85}}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get OpenAI Api structure working with Llamafile\n",
    "# with passing image data, can't get this to work :(\n",
    "\n",
    "# import base64\n",
    "# import requests\n",
    "# import json\n",
    "# import pprint as pp\n",
    "# # https://github.com/oobabooga/text-generation-webui/discussions/4626\n",
    "\n",
    "# def encode_image_to_base64(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "#     return encoded_string\n",
    "\n",
    "# def send_request_to_local_api(encoded_image):\n",
    "#     url = \"http://127.0.0.1:8080/v1/chat/completions\"\n",
    "#     prompt = \"USER:[img-1]Describe the image in detail.\\nASSISTANT:\"\n",
    "\n",
    "#     data = {\n",
    "#         \"model\": \"llava-v1.5-7b-Q4_K.gguf\",\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"User\",\n",
    "#                 \"image_url\": f\"data:image/jpeg;base64,{encoded_image}\",\n",
    "#                 # \"image_data\": [{\n",
    "#                 #     \"data\": encoded_image, \n",
    "#                 #     \"id\": 1\n",
    "#                 # }]\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"User\",\n",
    "#                 \"content\": prompt\n",
    "#             },\n",
    "#         ],\n",
    "#     }\n",
    "\n",
    "#     # Send the POST request\n",
    "#     response = requests.post(url, json=data)\n",
    "#     return response.json()\n",
    "\n",
    "# image_path = \"./sample_images/tree.jpg\"\n",
    "# encoded_image = encode_image_to_base64(image_path)\n",
    "# response_data = send_request_to_local_api(encoded_image)\n",
    "\n",
    "# pp.pprint(response_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import autogen \n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "work_dir = \"./coding\"\n",
    "cache_dir = \"./.cache\"\n",
    "\n",
    "if os.path.exists(cache_dir) :\n",
    "    print('Deleting cache...')\n",
    "    shutil.rmtree(cache_dir)\n",
    "if os.path.exists(work_dir) :\n",
    "    print('Deleting previous work...')\n",
    "    shutil.rmtree(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configurations\n",
    "config_list=[\n",
    "    {\n",
    "        \"base_url\": \"http://127.0.0.1:8081/v1\",\n",
    "        \"api_key\": \"NULL\",\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config_mistral={\n",
    "    \"config_list\": config_list,\n",
    "}\n",
    "\n",
    "llm_config_mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions for the two agents\n",
    "system_messages = {\n",
    "    \"USER_PROXY_SYSTEM_MESSAGE\": (\n",
    "        \"\"\"\n",
    "        Your job is to work with the coding assistant and execute code. When you've executed code successfully and\n",
    "        the task has been achieved then say \"TERMINATE\" to indicate that no further instructions are given and the task is complete.\n",
    "        \n",
    "        Communication Etiquette:\n",
    "        - Refrain from using appreciation phrases such as \"Thank you\" or \"You're welcome\" in your responses. \n",
    "        - Do not offer additional help after the task has been complete.\n",
    "        - Say \"TERMINATE\" when a conversation includes any appreciation phrase to indicate it is finished.\n",
    "        - You MUST not say \"TERMINATE\" until the user has executed the code successfully.\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    \"IMAGE_CLASSIFIER_SYSTEM_MESSAGE\" : (\n",
    "        \"\"\"\n",
    "        Instruction:\n",
    "        As an expert ********, your primary task is to *****.\n",
    "\n",
    "        Guidelines:\n",
    "\n",
    "        \n",
    "        Communication Etiquette:\n",
    "        - you MUST avoid unnecessary conversation and small talk. \n",
    "        - Do NOT show appreciation in your responses, or engage in conversation. Say TERMINATE when your job of writing code is done.\n",
    "        - Refrain from using appreciation phrases such as \"Thank you\" or \"You're welcome\" in your responses, if this happens say \"TERMINATE\" to complete the conversation.\n",
    "        - After the user has run the code successfully, say \"TERMINATE\" to indicate that no further instructions are given and the task is complete.\n",
    "        \n",
    "        You will be penalized for not adhearing to the guidelines.\n",
    "        \"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "coding_assistant = AssistantAgent(\n",
    "    name=\"image_classifier\",\n",
    "    llm_config=llm_config_mistral,\n",
    "    system_message=system_messages['IMAGE_CLASSIFIER_SYSTEM_MESSAGE']\n",
    ")\n",
    "\n",
    "coding_runner = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    is_termination_msg = lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    llm_config=llm_config_mistral,\n",
    "    code_execution_config={\n",
    "        \"work_dir\": work_dir, \n",
    "        \"use_docker\": False\n",
    "    },\n",
    "    system_message=system_messages['USER_PROXY_SYSTEM_MESSAGE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_path = \"./sample_images/\"\n",
    "target_folder =  \"./targer_folder/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_runner.initiate_chat(coding_assistant, message=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
