{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TaskWeaver\n",
    "\n",
    "This notebook aims to condence all requirements needed for coding up a taskweaver project.\n",
    "\n",
    "Firstly, you need to make a project folder. this is a prerequisite to running TaskWeaver. \n",
    "\n",
    "Then we need to make a session:\n",
    "> TaskWeaver supports a basic session management to keep different users' <br>\n",
    "> data separate. The code execution is separated into different processes <br>\n",
    "> in order not to interfere with each other.\n",
    "\n",
    "See [starter_project](\"../_starter_projects/\")\n",
    "\n",
    "We also need to enable modules that the code interpreter can use and code verification.\n",
    "> Code verification - TaskWeaver is designed to verify the generated code before execution. <br>\n",
    "> It can detect potential issues in the generated code and provide suggestions to fix them.\n",
    "\n",
    "Add this to the `taskweaver_config.json`\n",
    "\n",
    "```\n",
    "\"code_verification.allowed_modules\": [\"pandas\", \"matplotlib\", \"numpy\", \"sklearn\", \"scipy\", \"seaborn\", \"datetime\", \"typing\"],\n",
    "\"code_verification.code_verification_on\": true,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Optional\n",
    "\n",
    "import pprint as pp\n",
    "from taskweaver.app.app import TaskWeaverApp\n",
    "\n",
    "# Create a session\n",
    "# would prefer if the expected folder structure was autogenerated\n",
    "app_dir = \"../_starter_projects/\"\n",
    "app = TaskWeaverApp(app_dir=app_dir)\n",
    "session = app.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add customer configurations programatically by adding\n",
    "# something like the following to taskweaver_config.json\n",
    "# \"session.max_internal_chat_round_num\": 5\n",
    "# or  session.config.max_internal_chat_round_num = 5\n",
    "session.config.max_internal_chat_round_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.config.max_internal_chat_round_num = 30\n",
    "session.config.max_internal_chat_round_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where the configurations from taskweaver_config.json are stored\n",
    "#\n",
    "# Categories of keys within the config\n",
    "# - session_manager\n",
    "# - llm\n",
    "# - workspace\n",
    "# - logging\n",
    "# - session\n",
    "# - planner\n",
    "# - plugin\n",
    "# - round_compressor\n",
    "# - code_generator\n",
    "# - embedding_model\n",
    "# - code_verification\n",
    "# - code_interpreter\n",
    "session.config.src.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple test message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a message to the session\n",
    "user_query = \"hello, what can you do?\"\n",
    "response_round = session.send_message(\n",
    "                            user_query,\n",
    "                            event_handler=lambda _type, _msg: print(f\"{_type}:\\n{_msg}\")\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heres what that looks like in JSON\n",
    "pp.pprint(response_round.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The classic stock market agent benchmark\n",
    "\n",
    "> protip: make sure `llm.response_format` is `text` because when working with `json` i found it crashed when using the code interpreter.\n",
    "> üí° Up to 11/30/2023, the json_object and text options of `llm.response_format` is only supported by the OpenAI models later than `1106`. If you are using an older version of OpenAI model, you need to set the llm.response_format to null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Write code to plot the price of tesla stock YTD and save it to the current working directory\"\n",
    "response_round = session.send_message(user_query,\n",
    "                                      event_handler=lambda _type, _msg: print(f\"{_type}:\\n{_msg}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../_starter_projects/workspace/sessions/20231212-200217-2ba37e82/cwd/tesla_stock_price_ytd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plugins\n",
    "\n",
    "A plugin is the equivalent to a function call in Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from injector import Injector\n",
    "\n",
    "from taskweaver.config.config_mgt import AppConfigSource\n",
    "from taskweaver.logging import LoggingModule\n",
    "from taskweaver.memory import Memory, Post, Round\n",
    "from taskweaver.memory.plugin import PluginModule, PluginRegistry\n",
    "from taskweaver.planner import Planner\n",
    "from taskweaver.plugin import Plugin, register_plugin, test_plugin\n",
    "\n",
    "# Plugin definition\n",
    "@register_plugin\n",
    "class DataAnalysisPlugin(Plugin):\n",
    "    def __call__(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Performs a simple analysis on the DataFrame and returns a description.\n",
    "        \"\"\"\n",
    "        row_count = len(df)\n",
    "        column_count = len(df.columns)\n",
    "        description = f\"The DataFrame has {row_count} rows and {column_count} columns.\"\n",
    "        return df, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TaskWeaver environment\n",
    "app_injector = Injector([PluginModule, LoggingModule])\n",
    "app_config = AppConfigSource(config={\n",
    "    \"plugin.base_path\": os.path.join(app_dir, \"plugins\"),\n",
    "    \"llm.api_key\": \"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\",\n",
    "})\n",
    "\n",
    "# app.\n",
    "app_injector.binder.bind(AppConfigSource, to=app_config)\n",
    "\n",
    "plugin_registry = app_injector.get(PluginRegistry)\n",
    "planner = app_injector.create_object(Planner)\n",
    "\n",
    "# Create a memory object for the session\n",
    "memory = Memory(session_id=\"session-1\")\n",
    "\n",
    "def send_message_to_session(query):\n",
    "    # Create a new round with the user query\n",
    "    round1 = Round.create(user_query=query, id=\"round-1\")\n",
    "    post1 = Post.create(message=query, send_from=\"User\", send_to=\"Planner\", attachment_list=[])\n",
    "    round1.add_post(post1)\n",
    "\n",
    "    # Add the round to the memory and compose the prompt\n",
    "    memory.conversation.add_round(round1)\n",
    "    prompt = planner.compose_prompt(rounds=memory.conversation.rounds)\n",
    "\n",
    "    # Here you should process the prompt using the appropriate plugin or logic\n",
    "    # For demonstration, I'm just printing the prompt\n",
    "    print(\"Processing:\", prompt)\n",
    "\n",
    "    # Process the result and print the response (This is where your plugin logic will go)\n",
    "    # Assuming a response is generated\n",
    "    response = \"Processed response for: \" + query\n",
    "    print(\"Response:\\n\", response)\n",
    "\n",
    "    # Update the conversation with the response\n",
    "    response_post = Post.create(message=response, send_from=\"Planner\", send_to=\"User\", attachment_list=[])\n",
    "    round1.add_post(response_post)\n",
    "\n",
    "    return round1\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Tell me about the data\"\n",
    "round  = send_message_to_session(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing a plugin\n",
    "# @test_plugin(name=\"test DataAnalysisPlugin\", description=\"test\")\n",
    "# def test_call(api_call):\n",
    "#     question = \"Tell me about the data\"\n",
    "#     result, description = api_call(query=question)\n",
    "#     assert result is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Autogen\n",
    "\n",
    "User(Human) input mode:\n",
    "- Autogen ‚úÖ (`human_input_mode` with `UserProxyAgent`)\n",
    "- TaskWeaver ‚úÖ (Planner can ask User)\n",
    "\n",
    "Compression:\n",
    "- Autogen ‚úÖ (Compressible Agent)\n",
    "- TaskWeaver ‚úÖ (Built in compression mechanism)\n",
    "\n",
    "Custom Agent Types:\n",
    "- Autogen  ‚úÖ\n",
    "- TaskWeaver ‚ùå\n",
    "\n",
    "Predefined Code Tools:\n",
    "- Autogen  ‚úÖ (with function calling)\n",
    "- TaskWeaver  ‚úÖ (with Plugins)\n",
    "\n",
    "Session Management:\n",
    "- Autogen ‚ùå (need to use different seed for cache)\n",
    "- TaskWeaver ‚úÖ \n",
    "\n",
    "Stateful Code Execution:\n",
    "- Autogen ‚ùå\n",
    "- TaskWeaver ‚úÖ\n",
    "\n",
    "Parallel Code Execution:\n",
    "- Autogen ‚ùå\n",
    "- TaskWeaver ‚úÖ\n",
    "\n",
    "Code Execution Security Measures:\n",
    "- Autogen ‚úÖ (through containers)\n",
    "- TaskWeaver ‚úÖ (through predefined rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extendibility?\n",
    "\n",
    "In [taskweaver.memory.post](https://github.com/microsoft/TaskWeaver/blob/4e9b71518c98bde20dbc87e6441ff1d84197dc48/taskweaver/memory/post.py#L13) it states that a post can only be one of these roles.\n",
    "> A post is the message used to communicate between two roles. <br>\n",
    "> It should always have a text_message to denote the string message,  <br>\n",
    ">while other data formats should be put in the attachment. <br>\n",
    "> The role can be either a User, a Planner, or a CodeInterpreter. <br>\n",
    "\n",
    "And in `type_vars.py`:\n",
    "```python\n",
    "RoleName = Literal[\"User\", \"Planner\", \"CodeInterpreter\"]\n",
    "```\n",
    "\n",
    "So it differs from autogen in that you don't create a number of agents that have different roles, with TaskWeaver it seems you use these three roles to do one specific type of task very well: **natural language to executable code**. In the paper they even state that multi-agent systems is \n",
    "\n",
    ">*The first approach involves one agent (powered by TaskWeaver) calling other agents via its plugins.\n",
    ">Fig. 4 (a) depicts a simple example, although this can be extended to a more complex network <br> where multiple agents form a mesh network.\n",
    "> he second approach involves embedding TaskWeaverpowered agents into an existing multi-agent framework, such as AutoGen [1], as demonstrated in Fig.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes in the paper:\n",
    "\n",
    "https://export.arxiv.org/pdf/2311.17541\n",
    "\n",
    "> TaskWeaver gets the LLM to condense tasks into larger tasks to that it doesn't go back and forward executing the code and reduces costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE TO SELF:\n",
    "\n",
    "- Autogen as a plugin/example generator for TaskWeaver:\n",
    "    - Plugins:\n",
    "        - \"I need a plugin to do ____\" --> save it in Plugin store\n",
    "    - Examples:\n",
    "        - Domain specific code base -> llm to make examples -> store as examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
