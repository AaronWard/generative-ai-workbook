{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agentchat.user_proxy_agent.UserProxyAgent\n",
    "The `UserProxyAgent` class is a specialized agent that acts as a proxy for the user, allowing the execution of code and enabling interactions with other agents. It is a subclass of ConversableAgent.\n",
    "\n",
    "Properties and Initialization:\n",
    "\n",
    "- `name (str)`: Name of the agent.\n",
    "- `is_termination_msg (Optional[Callable[[Dict], bool]])`: Function to determine if a received message is a termination message, based on its content.\n",
    "- `max_consecutive_auto_reply (Optional[int])`: Maximum number of consecutive auto replies.\n",
    "- `human_input_mode (Optional[str])`: Strategy to determine when to ask for human inputs. It has three possible values:\n",
    "\"ALWAYS\": Prompts for human input every time a message is received.\n",
    "\"TERMINATE\": Only prompts for human input when a termination message is received or the number of auto replies reaches max_consecutive_auto_reply.\n",
    "\"NEVER\": Never prompts for human input.\n",
    "- `function_map (Optional[Dict[str, Callable]])`: Mapping of function names to callable functions.\n",
    "- `code_execution_config (Optional[Union[Dict, bool]])`: Configuration for code execution. If False, code execution is disabled.\n",
    "- `default_auto_reply (Optional[Union[str, Dict, None]])`: Default auto-reply message when no code execution or LLM based reply is generated.\n",
    "- `llm_config (Optional[Union[Dict, bool]])`: Configuration for LLM inference. If False, LLM-based auto reply is disabled.\n",
    "- `system_message (Optional[str])`: System message for ChatCompletion inference, used only when llm_config is not False.\n",
    "Key Features and Behaviors:\n",
    "- `Code Execution`: Allows the execution of code blocks, single code lines, or function calls, customizable through overrideable methods.\n",
    "- `Human Input Mode`: Configures the strategy to obtain human inputs based on the human_input_mode parameter.\n",
    "- `LLM-Based Auto Reply`: Can perform auto replies based on LLM (Language Learning Model) inferences if configured through llm_config.\n",
    "\n",
    "--- \n",
    "\n",
    "**Workflow:**\n",
    "1. Initialization: Create an instance of `UserProxyAgent` with the desired configuration.\n",
    "2. Integration: Integrate the `UserProxyAgent` within a chat system or multi-agent environment.\n",
    "3. Interaction: The agent can receive and process messages, execute code, provide feedback to other agents, and prompt for human input based on its configuration.\n",
    "\n",
    "\n",
    "**Customization**: \n",
    "- The behavior of `UserProxyAgent` regarding human input acquisition, code execution, and initial messaging can be customized by overriding the corresponding methods, allowing for flexible adaptations to different chat scenarios and user interactions.\n",
    "\n",
    "**Use Cases:**\n",
    "- Proxying User in Multi-Agent Systems: Acts as a user representative in a system with multiple interacting agents, enabling user interventions and feedback.\n",
    "- Code Execution Agent: Can execute code and return results in response to received messages, useful in interactive coding environments or chat-based programming interfaces.\n",
    "- Adaptive Response Generation: With LLM-based auto replies and customizable human input strategies, it can adapt responses based on the chat context and user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.user_proxy_agent import UserProxyAgent\n",
    "\n",
    "# Initialize a UserProxyAgent\n",
    "proxy_agent = UserProxyAgent(\n",
    "    name='user_proxy',\n",
    "    human_input_mode='ALWAYS',\n",
    "    code_execution_config={'timeout': 10}\n",
    ")\n",
    "\n",
    "# To use this agent, you would typically integrate it within a chat system, where it can receive messages and interact with other agents.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
