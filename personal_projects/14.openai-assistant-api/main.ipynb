{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Assistant API\n",
    "\n",
    "The OpenAI Assistants API is a framework for building AI assistants within applications, leveraging OpenAI models like GPT-3.5 and GPT-4. These assistants can perform a variety of tasks, supported by tools like Code Interpreter, Retrieval, and Function calling. It's currently in beta, with ongoing development and feedback collection.\n",
    "\n",
    "[Docs](https://platform.openai.com/docs/assistants/overview)\n",
    "\n",
    "#### Components\n",
    "\n",
    "- **Assistant**: The top-level entity, configured with specific instructions, a chosen model, and tools.\n",
    "- **Thread**: Each thread is a unique conversation session with the Assistant, containing the dialogue history.\n",
    "- **Message**: Individual components of a Thread, representing communication from either the user or the Assistant.\n",
    "- **Run**: An instance where the Assistant processes a Thread to generate responses, guided by its configuration.\n",
    "- **Run Step:** Detailed breakdown of actions taken during a Run, including message creation and tool invocations.\n",
    "\n",
    "```bash\n",
    "OpenAI Assistants API\n",
    "│\n",
    "├── Assistant\n",
    "│   ├── Model (e.g., GPT-3.5 or GPT-4)\n",
    "│   ├── Instructions (Defines behavior and response guidelines)\n",
    "│   ├── Tools (Code Interpreter, Retrieval, Function Calling)\n",
    "│   └── Files (Optional, for file-based interactions)\n",
    "│\n",
    "├── Thread (Represents a conversation session)\n",
    "│   ├── Message 1 (User or Assistant generated)\n",
    "│   │   ├── Text\n",
    "│   │   └── Files (Optional)\n",
    "│   ├── Message 2\n",
    "│   ├── Message 3\n",
    "│   └── ...(Additional Messages as needed)\n",
    "│\n",
    "└── Run (Invocation of an Assistant on a Thread)\n",
    "    ├── Run Step 1 (Details of each action taken)\n",
    "    │   ├── Message Creation\n",
    "    │   └── Tool Calls (if any)\n",
    "    ├── Run Step 2\n",
    "    └── ...(Additional Run Steps as needed)\n",
    "```\n",
    "\n",
    "\n",
    "#### Tools\n",
    "\n",
    "**Code Interpreter:** Enables Assistants to write and execute Python code, processing and generating diverse data formats, including images and CSV files.\n",
    "**Knowledge Retrieval**: Augments Assistants with external knowledge, like proprietary information or user-provided documents. It implements vector search for content retrieval.\n",
    "**Function Calling**: Similar to the Chat Completions API, this allows Assistants to call defined functions and use their results in ongoing Runs.\n",
    "\n",
    "\n",
    "#### File Handling\n",
    "- Assistants can interact with various file formats, with a maximum size of 512MB per file.\n",
    "- File citations and paths are included in Messages, allowing for referencing and downloading generated files.\n",
    "\n",
    "\n",
    "#### Limitations\n",
    "- Limitations include absence of support for image files in user Messages, streaming output, and notifications for object status updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "from typing import List, Callable\n",
    "\n",
    "sys.path.append('./')\n",
    "\n",
    "from modules import llm\n",
    "from modules import rand\n",
    "from turbo4 import Turbo4\n",
    "from modules import embeddings\n",
    "from data_types import Chat, TurboTool, FactStoringTool\n",
    "from instruments import PostgresAgentInstruments\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "DB_URL = os.environ.get(\"POSTGRES_CONNECTION_URL\")\n",
    "POSTGRES_TABLE_DEFINITIONS_CAP_REF = \"TABLE_DEFINITIONS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_function_tool_config = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"store_fact\",\n",
    "        \"description\": \"A function that stores a fact.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"fact\": {\"type\": \"string\"}},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "run_sql_tool_config = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"run_sql\",\n",
    "        \"description\": \"Run a SQL query against the postgres database\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sql\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The SQL query to run\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"sql\"],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prompt = \"Get the mean age of everyone who had covid.\"\n",
    "prompt = f\"Fulfill this database query: {raw_prompt}. \"\n",
    "tools = []\n",
    "\n",
    "assistant_name = \"Turbo4\"\n",
    "assistant = Turbo4()\n",
    "session_id = rand.generate_session_id(assistant_name + raw_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_or_create_assistant(Turbo4, gpt-4-1106-preview)\n",
      "set_instructions()\n",
      "equip_tools([TurboTool(name='run_sql', config={'type': 'function', 'function': {'name': 'run_sql', 'description': 'Run a SQL query against the postgres database', 'parameters': {'type': 'object', 'properties': {'sql': {'type': 'string', 'description': 'The SQL query to run'}}, 'required': ['sql']}}}, function=<bound method PostgresAgentInstruments.run_sql of <instruments.PostgresAgentInstruments object at 0x106e46f50>>)], False)\n",
      "make_thread()\n",
      "add_message(Fulfill this database query: Get the mean age of everyone who had covid..  Use these TABLE_DEFINITIONS to satisfy the database query.\n",
      "\n",
      "TABLE_DEFINITIONS\n",
      "\n",
      "CREATE TABLE patients (\n",
      "id integer,\n",
      "patient_id character varying(255),\n",
      "state character varying(2),\n",
      "fips integer,\n",
      "diagnosed_covid boolean,\n",
      "diagnoses_date date,\n",
      "current_age integer,\n",
      "age_at_diagnosis double precision\n",
      ");\n",
      "\n",
      "CREATE TABLE patient_medical_history (\n",
      "id integer,\n",
      "patient_id character varying(255),\n",
      "has_diabetes boolean,\n",
      "has_heart_disease boolean,\n",
      "has_lung_disease boolean,\n",
      "smoker_status character varying(10),\n",
      "bmi double precision,\n",
      "last_checkup_date date\n",
      ");)\n",
      "run_thread(None)\n",
      "add_message(Use the run_sql function to run the SQL you've just generated.)\n",
      "run_thread(['run_sql'])\n",
      "run_thread() Calling run_sql({'sql': 'SELECT AVG(current_age) AS mean_age FROM patients WHERE diagnosed_covid = true;'})\n",
      "run_validation(validate_run_sql)\n",
      "✅ Turbo4 Assistant finished.\n"
     ]
    }
   ],
   "source": [
    "with PostgresAgentInstruments(DB_URL, session_id) as (agent_instruments, db):\n",
    "    database_embedder = embeddings.DatabaseEmbedder(db)\n",
    "\n",
    "    table_definitions = database_embedder.get_similar_table_defs_for_prompt(\n",
    "        raw_prompt\n",
    "    )\n",
    "\n",
    "    prompt = llm.add_cap_ref(\n",
    "        prompt,\n",
    "        f\"Use these {POSTGRES_TABLE_DEFINITIONS_CAP_REF} to satisfy the database query.\",\n",
    "        POSTGRES_TABLE_DEFINITIONS_CAP_REF,\n",
    "        table_definitions,\n",
    "    )\n",
    "\n",
    "    # CUSTOM TOOLS WITH CLASS\n",
    "    tools = [\n",
    "        TurboTool(\"run_sql\", run_sql_tool_config, agent_instruments.run_sql),\n",
    "    ]\n",
    "\n",
    "    res = (\n",
    "        assistant.get_or_create_assistant(assistant_name)\n",
    "        .set_instructions(\n",
    "            \"You're an elite SQL developer. You generate the most concise and performant SQL queries.\"\n",
    "        )\n",
    "        .equip_tools(tools)\n",
    "        .make_thread()\n",
    "        .add_message(prompt)\n",
    "        .run_thread()\n",
    "        .add_message(\n",
    "            \"Use the run_sql function to run the SQL you've just generated.\",\n",
    "        )\n",
    "        .run_thread(toolbox=[tools[0].name])\n",
    "        .run_validation(agent_instruments.validate_run_sql)\n",
    "        .spy_on_assistant(agent_instruments.make_agent_chat_file(assistant_name))\n",
    "        .get_costs_and_tokens(\n",
    "            agent_instruments.make_agent_cost_file(assistant_name)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Turbo4 Assistant finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Message from Assistant: The SQL query to get the mean age of everyone who had COVID has been successfully executed. The result has been delivered to a JSON file.\n"
     ]
    }
   ],
   "source": [
    "# Check if there are chat messages\n",
    "if res.chat_messages:\n",
    "    # Retrieve the last chat message\n",
    "    final_message = res.chat_messages[0].message\n",
    "    print(\"Final Message from Assistant:\", final_message)\n",
    "else:\n",
    "    print(\"No chat messages found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompt Solution \n",
    "\n",
    "- Same thing, only 2 api calls instead of 8+\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = rand.generate_session_id(assistant_name + raw_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the mean age of all patients who had been diagnosed with COVID-19, you can use the following SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT AVG(current_age) AS mean_age\n",
      "FROM patients\n",
      "WHERE diagnosed_covid = TRUE;\n",
      "```\n",
      "\n",
      "This SQL query selects the average (mean) of the `current_age` column from the `patients` table but only includes rows where `diagnosed_covid` is set to `TRUE`, meaning only the patients who had been diagnosed with COVID-19 will be considered in the calculation. The result will be labeled as `mean_age`.\n",
      "['Successfully delivered results to json file']\n",
      "sql validation result: (True, '')\n"
     ]
    }
   ],
   "source": [
    "with PostgresAgentInstruments(DB_URL, session_id) as (agent_instruments, db):\n",
    "    database_embedder = embeddings.DatabaseEmbedder(db)\n",
    "\n",
    "    table_definitions = database_embedder.get_similar_table_defs_for_prompt(\n",
    "        raw_prompt\n",
    "    )\n",
    "\n",
    "    prompt = f\"Fulfill this database query: {raw_prompt}.\"\n",
    "\n",
    "    prompt = llm.add_cap_ref(\n",
    "        prompt,\n",
    "        f\"Use these {POSTGRES_TABLE_DEFINITIONS_CAP_REF} to satisfy the database query.\",\n",
    "        POSTGRES_TABLE_DEFINITIONS_CAP_REF,\n",
    "        table_definitions,\n",
    "    )\n",
    "\n",
    "    # CUSTOM TOOLS WITH CLASS\n",
    "    tools = [\n",
    "        TurboTool(\"run_sql\", run_sql_tool_config, agent_instruments.run_sql),\n",
    "    ]\n",
    "\n",
    "    sql_response = llm.prompt(\n",
    "        prompt,\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        instructions=\"You're an elite SQL developer. You generate the most concise and performant SQL queries.\",\n",
    "    )\n",
    "\n",
    "    print(sql_response)\n",
    "\n",
    "    # Chaining\n",
    "    final_response = llm.prompt_func(\n",
    "        \"Use the run_sql function to run the SQL you've just generated: \"\n",
    "        + sql_response,\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        instructions=\"You're an elite SQL developer. You generate the most concise and performant SQL queries.\",\n",
    "        turbo_tools=tools,\n",
    "    )\n",
    "\n",
    "    print(final_response)\n",
    "    print(f\"sql validation result: {agent_instruments.validate_run_sql()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool\n",
    "def store_fact(fact: str, folder: str = \"./agent_results/facts\"):\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Define a file name. You might want to customize this to avoid overwriting files.\n",
    "    file_name = f\"fact_{int(time.time())}.txt\"\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "\n",
    "    # Store the fact in the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(fact)\n",
    "        print(f\"Fact stored in {file_path}\")\n",
    "\n",
    "    return \"Fact stored.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_name = \"Turbo4_facts\"\n",
    "assistant = Turbo4()\n",
    "session_id = rand.generate_session_id(assistant_name + raw_prompt)\n",
    "tools.append(FactStoringTool(name=\"store_fact\", config=custom_function_tool_config, function=store_fact))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_or_create_assistant(Turbo4_facts, gpt-4-1106-preview)\n",
      "make_thread()\n",
      "equip_tools([TurboTool(name='run_sql', config={'type': 'function', 'function': {'name': 'run_sql', 'description': 'Run a SQL query against the postgres database', 'parameters': {'type': 'object', 'properties': {'sql': {'type': 'string', 'description': 'The SQL query to run'}}, 'required': ['sql']}}}, function=<bound method PostgresAgentInstruments.run_sql of <instruments.PostgresAgentInstruments object at 0x2c08e3040>>), FactStoringTool(name='store_fact', config={'type': 'function', 'function': {'name': 'store_fact', 'description': 'A function that stores a fact.', 'parameters': {'type': 'object', 'properties': {'fact': {'type': 'string'}}}}}, function=<function store_fact at 0x2920f4700>)], False)\n",
      "add_message(Generate 10 random facts about LLM technology.)\n",
      "run_thread(None)\n",
      "add_message(Use the store_fact function to 1 fact.)\n",
      "run_thread(['store_fact'])\n",
      "run_thread() Calling store_fact({'fact': \"LLM stands for 'Large Language Model,' which refers to AI models that are trained on vast amounts of text data to understand and generate human-like text.\"})\n",
      "Fact stored in ./agent_results/facts/fact_1699914107.txt\n"
     ]
    }
   ],
   "source": [
    "# ----------- Example use case of Turbo4 and the Assistants API ------------\n",
    "res = (\n",
    "    assistant.get_or_create_assistant(assistant_name)\n",
    "    .make_thread()\n",
    "    .equip_tools(tools)\n",
    "    .add_message(\"Generate 10 random facts about LLM technology.\")\n",
    "    .run_thread()\n",
    "    .add_message(\"Use the store_fact function to 1 fact.\")\n",
    "    .run_thread(toolbox=[\"store_fact\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Message from Assistant: The fact about LLMs has been successfully stored. If you need any more assistance or have more facts to store, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "# Check if there are chat messages\n",
    "if res.chat_messages:\n",
    "    # Retrieve the last chat message\n",
    "    final_message = res.chat_messages[0].message\n",
    "    print(\"Final Message from Assistant:\", final_message)\n",
    "else:\n",
    "    print(\"No chat messages found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
