{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLX LLM Finetuning\n",
    "\n",
    "MLX is an array library that is similar to Numpy, It contains an python API for Apply Silicon. The focus of this notebook is to for LLM finetuning, which a capability of MLX. \n",
    "\n",
    "- `pip install mlx`\n",
    "- `pip install mlx-lm`\n",
    "\n",
    "`mlx-lm` is an abstraction library for interacting with language models using mlx.\n",
    "\n",
    "To view compute resource usage:\n",
    "- `pip install asitop` \n",
    "\n",
    "Note: MLX currently doesn't support Apple Neural Engine(ANE) which is a component within Apple devices, specifically designed for efficiently executing deep neural network operations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import load, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =\"s3nh/Mistral_Sonyichi-7B-slerp\"\n",
    "\n",
    "model, tokenizer = load(model_name)\n",
    "response = generate(model, tokenizer, prompt=\"Who are you?\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model, tokenizer, prompt=\"Bill gates is a:\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"<s>[INST] Who are you? [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path of where the model is stored locally\n",
    "from mlx_lm.utils import get_model_path\n",
    "\n",
    "get_model_path(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lh /Users/award40/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  ls /Users/award40/.cache/huggingface/hub/models--s3nh--Mistral_Sonyichi-7B-slerp/snapshots/a749122da3653ed7133197687f84e25961372f48/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  ls /Users/award40/.cache/huggingface/hub/models--s3nh--Mistral_Sonyichi-7B-slerp/snapshots/a749122da3653ed7133197687f84e25961372f48/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize and save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm.utils import save_weights\n",
    "from mlx_lm import convert\n",
    "\n",
    "mlx_path = f\"/Volumes/Extreme\\ Pro/models/mlx/{model_name}\"\n",
    "\n",
    "convert(\n",
    "    hf_path=model_name,\n",
    "    mlx_path = mlx_path,\n",
    "    # quantize = True,\n",
    "    # dtype = \"float16\",\n",
    "    upload_repo = None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize models from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import convert\n",
    "\n",
    "upload_repo = \"mlx-community/My-Mistral-7B-v0.1-4bit\"\n",
    "\n",
    "convert(\"mistralai/Mistral-7B-v0.1\", quantize=True, upload_repo=upload_repo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
