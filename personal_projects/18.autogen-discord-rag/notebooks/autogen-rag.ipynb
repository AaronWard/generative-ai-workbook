{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autogen Discord QA\n",
    "\n",
    "I want to develop a LLM Application that will let me ask any question with regards to Autogen. The application should be able to:\n",
    "1. Search discord history for answers\n",
    "2. Multi model capabilities to retrieve images also.\n",
    "3. Search the internet to get additional information if needed.\n",
    "\n",
    "To pull message history, I am using an extension called [Discrub](https://chrome.google.com/webstore/detail/discrub/plhdclenpaecffbcefjmpkkbdpkmhhbj/related) as i had issues setting up the Discord API. <br>\n",
    "Data pull is up until `15th November 2023`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "sys.path.append('./')\n",
    "\n",
    "import openai\n",
    "import autogen\n",
    "import chromadb\n",
    "\n",
    "config_list = autogen.config_list_from_dotenv(dotenv_file_path='../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "\n",
    "# Create an instance of RetrieveAssistantAgent\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "path = Path(os.getcwd(), 'docs')\n",
    "client = chromadb.PersistentClient(path=f\"{os.getcwd()}/chromadb\")\n",
    "\n",
    "# Create an instance of RetrieveUserProxyAgent\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"task\": \"default\",\n",
    "        \"docs_path\": str(path), \n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": client, \n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Delete dir each instantiation\n",
    "client.delete_collection('autogen-docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_167', 'doc_241', 'doc_125', 'doc_91', 'doc_49', 'doc_78', 'doc_41', 'doc_204', 'doc_211', 'doc_130', 'doc_188', 'doc_235', 'doc_174', 'doc_213', 'doc_172', 'doc_65', 'doc_261', 'doc_208', 'doc_178', 'doc_71']]\n",
      "\u001b[32mAdding doc_id doc_167 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_241 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_125 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "If user's intent is code generation, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "If user's intent is question answering, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: Langchain\n",
      "\n",
      "Context is: \n",
      "In general, at 2023-10-01 06:17:06 a user named kajatta said ```Nah not a replacement Langchain is more of an interoperability framework that happens to have agents, one of them is CAMEL architecture which can be compared to AutoGen.\n",
      "\n",
      "My goal was to enable the tools from Langchain to work with Autogen agents so we have the best of both```.\n",
      "\n",
      "In general, at 2023-10-01 06:13:11 a user named kings530 said ```Learn from watching some ai YT video```.\n",
      "\n",
      "In general, at 2023-10-01 06:10:13 a user named steevek_62832 said ```I just read about the paper, I wander if Autogen is the replacement of Langchain?```.\n",
      "\n",
      "In general, at 2023-10-01 06:01:55 a user named steevek_62832 said ```Wow, looks like you really excited about autogen.```.\n",
      "\n",
      "In general, at 2023-10-01 05:40:06 a user named kajatta said ```There is a PR on AutoGen for the notebook also FYI```.\n",
      "\n",
      "In general, at 2023-10-01 05:39:24 a user named .princeps said ```@kajatta thanks man, was hard to sleep last night , so excited, so thanks for this gift, I'll work on it today```.\n",
      "\n",
      "In general, at 2023-10-01 05:16:16 a user named uttamdinodia said ```I found it on youtube while going through Github Copilot.```.\n",
      "\n",
      "In general, at 2023-10-01 04:47:57 a user named steevek_62832 said ```And, I think that the agent have to verify what it generate.```.\n",
      "\n",
      "In general, at 2023-10-01 04:44:57 a user named steevek_62832 said ```I think that should be hard to achieve, because some tasks require more tokens than others.```.\n",
      "\n",
      "In general, at 2023-10-01 04:39:52 a user named felly007. said ```chat history so it can refer back to previous conversations. Potentially we could make an memory agent. or we can follow @andyinater example```.\n",
      "\n",
      "In general, at 2023-10-01 04:28:18 a user named Drogend said ```I just read the paper. Someone correct me if I‚Äôm wrong but I think you can adjust your stop setting to determine how many tokens get used```.\n",
      "\n",
      "In general, at 2023-10-01 04:23:52 a user named steevek_62832 said ```It feels like autogen is token-consumed.```.\n",
      "\n",
      "In general, at 2023-10-01 03:58:25 a user named kajatta said ```This will give your AutoGen agent the callability to use this toolkit to solve the problem or query```.\n",
      "\n",
      "In general, at 2023-10-01 03:57:44 a user named kajatta said ```try my example https://colab.research.google.com/gist/ElliotWood/af12566db5d6948e8ed6dd6324aa9697/autogen-langchain.ipynb\n",
      "with the SQLDatabaseToolkit from Langchain\n",
      "https://api.python.langchain.com/en/latest/_modules/langchain/agents/agent_toolkits/sql/toolkit.html#SQLDatabaseToolkit```.\n",
      "\n",
      "In general, at 2023-10-01 03:48:32 a user named Drogend said ```How would you go about that?```.\n",
      "\n",
      "In general, at 2023-10-01 03:46:13 a user named mdfahad999 said ```Can we add SQL agent in autogen , which can connect with sqldb and we can do complex queries on it.```.\n",
      "\n",
      "In general, at 2023-10-01 03:43:16 a user named vincentjedi said ```U can ask your skynet to build you a trading algorithm and do backtesting for you ?```.\n",
      "\n",
      "In general, at 2023-10-01 03:32:15 a user named steevek_62832 said ```What is \"multi-agent conversations\" in  `AutoGen enables complex LLM-based workflows using multi-agent conversations.` . Do you mean that multiple LLM-based robots talk to each other to solve problem?```.\n",
      "\n",
      "In general, at 2023-10-01 03:29:10 a user named steevek_62832 said ```Can I say autogen is something like agentGPT?```.\n",
      "\n",
      "In general, at 2023-10-01 03:21:26 a user named iamhere said ```I feel so good right now, biggest accomplishment all week ü§£```.\n",
      "\n",
      "In general, at 2023-10-01 02:41:37 a user named andyinater said ```Hey everyone, just dropped a thing https://discord.com/channels/1153072414184452236/1157869584901226586\n",
      "\n",
      "Let me know what you think. I hope it inspires you to try using the method.```.\n",
      "\n",
      "In general, at 2023-10-01 01:58:38 a user named nikoma said ```If you are using vllm sometimes timeouts are shown when the context is too large. Also, do you run it in openai compatible mode like this? python -m vllm.entrypoints.openai.api_server --model Xwin-LM/Xwin-LM-70B-V0.1```.\n",
      "\n",
      "In general, at 2023-10-01 01:53:07 a user named kajatta said ```Note if you use the custom_tool the type error throws for non strings to do internal AutoGen Schema to function call. Should be easy to fix.```.\n",
      "\n",
      "In general, at 2023-10-01 01:50:58 a user named kajatta said ``````Read the file with the path 'Test.txt', then calculate the circumference of a circle that has a radius of that files contents.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "chatbot (to user_proxy):\n",
      "\n",
      "***** Suggested function Call: read_file *****\n",
      "Arguments: \n",
      "{\n",
      "  \"file_path\": \"Test.txt\"\n",
      "}\n",
      "**********************************************\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> EXECUTING FUNCTION read_file...\n",
      "user_proxy (to chatbot):\n",
      "\n",
      "***** Response from calling function \"read_file\" *****\n",
      "7.81mm\n",
      "******************************************************\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "chatbot (to user_proxy):\n",
      "\n",
      "***** Suggested function Call: circumference_calculator *****\n",
      "Arguments: \n",
      "{\n",
      "  \"radius\": 7.81\n",
      "}\n",
      "*************************************************************\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "In created-with-autogen, at 2023-10-02 05:16:41 a user named sonichi said ```https://twitter.com/oscarmoxon/status/1708603929011863871```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 22:29:07 a user named abhilashinumella said ```Yes I was surprised too. I used GPT-4 for the prompts. Feel confident it can used to generate AI squad for a lot of low to medium precision tasks/goals.```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 21:42:28 a user named iamhere said ```YO! is this what your'e talking about? I'd love to help, I'm really new to all of this and need to get caught up to speed. I'm jumping over hurdles getting to this point. I still have no idea what I'm doing, but I think its because I'm trying to interoperate with langchain and autogen, without know how to use either. SMH \n",
      "Baby Steps, do we even need langchain anymore? that's how I found autogen as I'm trying to have conversations with multiple agents at once. My spreadsheets were only doing so much.```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 20:39:54 a user named .princeps said ```Nice, I have another repo up that you can checkout```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 19:17:40 a user named kenfucius5452 said ```Love it! I'm quite impressed by the quality of the output with such seemingly simple prompting. I'm curious, did you write the prompts yourself? Did you use GPT4 or any other tool to generate the written personas of Joey and Monica?```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 17:28:38 a user named pradeep1148 said ```hey made a video based on this github repo https://www.youtube.com/watch?v=gnn1H4H81IY&ab_channel=DLExplorers Thanks for the contribution poly```.\n",
      "\n",
      "In created-with-autogen, at 2023-10-01 04:37:31 a user named abhilashinumella said ```A scene writer using autogen: https://x.com/abhilashi/status/1708339764250947692?s=20```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:16:58 a user named tonic_1 said ```sent to you and @salegrem```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:15:54 a user named mdfahad999 said ```https://github.com/mdfahad999```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:14:42 a user named tonic_1 said ```join us on discord also```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 19:14:29 a user named tonic_1 said ```very cool @WolfroseWe and @mdfahad999 , just send me your github and i'll add you, it will be fun, i'm sure```.\n",
      "\n",
      "In created-with-autogen, at nan a user named mdfahad999 said ```I am interested to contribute.```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 18:28:01 a user named .princeps said ```https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 17:00:01 a user named tonic_1 said ```yes my friend, please join us üëäüèª```.\n",
      "\n",
      "In created-with-autogen, at 2023-09-30 09:27:56 a user named tonic_1 said ```going to remake autogtp to achieve better performance against beebot benchmark by using autogen https://github.com/team-tonic-arena-hacks```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:07:04 a user named sazied said ```@sonichi @rickyloynd I think this should work best for my use case\n",
      "\n",
      "Thanks again for all your help and such prompt responses üôèüöÄ```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:05:54 a user named sazied said ```Just went over your code, looks neat üòÑ```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:05:38 a user named sazied said ```Wow, thanks so much man!```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 02:02:02 a user named c_bonadio said ```Hi @sazied I used websockets to get and send human_input take a look here\n",
      "https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 01:07:42 a user named sazied said ```I have this socket connection running that allows me to receive the responses back from the agents on the forntend - \n",
      "\n",
      "\n",
      "@socketio.on('start_orchestrator')\n",
      "def handle_start_orchestrator(data):\n",
      "    print('YOO')\n",
      "    #Extract the data and start the orchestrator\n",
      "    test_param = data.get(\"test_param\", \"Default Value\")\n",
      "    \n",
      "    success, seq_messages = sequential_orchestrator.sequential_conversation(test_param)\n",
      "    \n",
      "    \n",
      "    # Send each message as it is generated\n",
      "    for message in seq_messages:\n",
      "        socketio.emit('orchestrator_message', { 'message': message })\n",
      "\n",
      "\n",
      "For one of the steps I need a human feedback loop so I have now set human_input_mode = 'ALWAYS' to test this functionality. How do I set the human feedback message without using the terminal. Does autogen expose some method that I am not aware of? I am also using a custom orchestrator, so I am wondering if I can set up a method in the Orchestrator class, but I do not know where to start.\n",
      "Any help would be much appreciated!```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 00:58:35 a user named rickyloynd said ```More details about @lucemia.'s application. https://discord.com/channels/1153072414184452236/1174149944718921820```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 00:50:22 a user named lucemia. said ```I am currently using AutoGen to streamline and minimize repetitive DevOps tasks.```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-15 00:38:12 a user named sonichi said ```The default system_message for `AssistantAgent` instructs writing code. Please overwrite it for your use case.```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 22:24:28 a user named sleepwave said ```thank you! That was my initial understanding which is why I was so shocked when I was getting code back based on a simple prompt that included an `AssistantAgent`. I thought the `AssistantAgent` was configured in a pretty \"default\" manner using a local model that I knew to be primarily conversational. I'm using a `UserProxyAgent` with the `AssistantAgent`, maybe it's actually the `UserProxyAgent` that's polluting the flow?```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 21:49:22 a user named pika.c said ```Autogen is a framework. You can use it just for conversation between agents without code output or execution. It depends on the system prompts you pass to each agent```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 21:43:29 a user named sleepwave said ```hey guys, quick question if anyone can help me wrap my head around something. After tinkering with autogen, it seems autogen's primary goal is to output code. Is there a similar framework that lets me allow multiple agents to simply _converse_ to solve a more abstract problem? Is that where Langchain comes in, or am I misunderstanding the capabilities and intention of Autogen?```.\n",
      "\n",
      "In ideas-and-feedback, at 2023-11-14 18:20:20 a user named airlights said ```it's actually one big 'assistant' roleplaying for each. Look, if you're happy -- I'm happy üôÇ Hope this gives you what you need```.\n",
      "\n",
      "In general, at 2023-10-09 02:27:12 a user named mysticmarks1 said ```this year is going to be good folks, very good```.\n",
      "\n",
      "In general, at 2023-10-09 02:12:33 a user named rastrol7 said ```Found through the Microsoft press release!```.\n",
      "\n",
      "In general, at 2023-10-09 01:38:40 a user named jpakjr said ```Learned about this through YouTube AI channels```.\n",
      "\n",
      "In general, at 2023-10-09 01:29:58 a user named frank.martinez said ```https://microsoft.github.io/autogen/```.\n",
      "\n",
      "In general, at 2023-10-09 01:26:53 a user named Deep Warren Buffet Value said ```Anyone have a getting started guide for someone w extremely limited coding experience```.\n",
      "\n",
      "In general, at 2023-10-09 01:12:14 a user named Dr.Inc said ```I scrolled through tiwtter I saw this```.\n",
      "\n",
      "In general, at 2023-10-09 00:53:39 a user named elcapitan__ said ```Like what benefits does langchain allow for that autogen doesn‚Äôt```.\n",
      "\n",
      "In general, at 2023-10-09 00:52:52 a user named elcapitan__ said ```I‚Äôm trying to figure out if I shud use langchain with autogen or simply just use gpt. I don‚Äôt have much experience in langchain.```.\n",
      "\n",
      "In general, at 2023-10-09 00:52:05 a user named elcapitan__ said ```All I‚Äôm saying is this community is on fire right now```.\n",
      "\n",
      "In general, at 2023-10-08 23:58:17 a user named sonichi said ```doc about logging: https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logging-experimental```.\n",
      "\n",
      "In general, at 2023-10-08 23:45:13 a user named c_bonadio said ```Not sure if it is possible```.\n",
      "\n",
      "In general, at 2023-10-08 23:37:00 a user named twezoalgo said ```Is it possible to loop this for every assistant response?```.\n",
      "\n",
      "In general, at 2023-10-08 23:12:16 a user named rais_47039 said ```I was overwhelmed with so much Gen-AI information and boared with programming same RAG based ChatBots. AutoGen sounds interesting, planning to develop something. Good Job Team AutoGen.```.\n",
      "\n",
      "In general, at 2023-10-08 22:54:07 a user named aditya0145 said ```Thanks @au8 thst worked for me too!```.\n",
      "\n",
      "In general, at 2023-10-08 22:32:46 a user named sonichi said ```did you follow https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints to set it up?```.\n",
      "\n",
      "In general, at 2023-10-08 22:27:33 a user named tc said ```bit confused, even if in my OAI config list i setup: \"model\": \"gpt-3.5-turbo-16k\"\n",
      "for few calls it used gpt-4 üëÄ```.\n",
      "\n",
      "In general, at 2023-10-08 22:25:40 a user named async00 said ```I think he meant more unlimited context; this recent paper uses some techniques to maintain low perplexity even into literally millions of tokens (https://browse.arxiv.org/pdf/2309.17453.pdf)```.\n",
      "\n",
      "In general, at 2023-10-08 22:25:24 a user named tc said ```cheers! that worked, i have also setup a custom signal handler for Ctrl+C, and i can save the chat even i force the exit!```.\n",
      "\n",
      "In general, at 2023-10-08 22:13:41 a user named c_bonadio said ```HI @tc , you can call autogen.ChatCompletion.start_logging() before you start and then print(autogen.ChatCompletion.logged_history) after the conversation, you can write the value of autogen.ChatCompletion.logged_history to a file if needed```.\n",
      "\n",
      "In general, at 2023-10-08 22:04:57 a user named tc said ```how can i dump the entire conversation into a text file? sorry quite new here```.\n",
      "\n",
      "In general, at 2023-10-08 22:04:16 a user named jew84930585 said ```i love the way you can pass it docs too```.\n",
      "\n",
      "In general, at 2023-10-08 22:01:29 a user named jew84930585 said ```nice! yes that would be cool```.\n",
      "\n",
      "In general, at 2023-10-08 22:00:54 a user named tonic_1 said ```there is  unlimited token limit, you just have to pay for it üòâ```.\n",
      "\n",
      "In general, at 2023-10-08 21:58:04 a user named frank.martinez said ```Cursor is my primary editor now; weird to go back to others; wish they had a cloud hosted version```.\n",
      "\n",
      "In general, at 2023-10-08 21:19:42 a user named tc said ```solved it myself, i had to install pyautogen instead of autogen```.\n",
      "\n",
      "In general, at 2023-10-08 21:10:32 a user named tc said ```how did you solved it?```.\n",
      "\n",
      "In general, at 2023-10-08 20:30:51 a user named aaronward_ said ```*Side note*: I'm still using either jupyter notebooks or streamlit apps for all my development. What are some cool tools you guys are using that you think i should use for LLM Application development?```.\n",
      "\n",
      "In general, at 2023-10-08 20:28:51 a user named aaronward_ said ```No local models yet, just used huggingface models - been busy the past few days. The [PR](https://github.com/microsoft/autogen/pull/95) is still open so it will be a little while yet until it's rolled out in a release.```.\n",
      "\n",
      "In general, at 2023-10-08 19:34:11 a user named pbeheca said ```Thank you, I got it running now üôÇ```.\n",
      "\n",
      "In general, at 2023-10-08 19:33:58 a user named jew84930585 said ```thats gonna be pretty hard but not impossible, you would need a beast of a machine too```.\n",
      "\n",
      "In general, at 2023-10-08 19:32:55 a user named quackduck. said ```question, im just downloading LM studio, its cool if it auto loads. but what if i want agents to be on seperate models is that still possible i would presume so```.\n",
      "\n",
      "In general, at 2023-10-08 19:31:38 a user named jew84930585 said ```you dont need to hard code the model in, you can just have it dynamically use whatever is loaded in LM studio```.\n",
      "\n",
      "In general, at 2023-10-08 19:31:24 a user named au8 said ```I don't actually think its that important due to the way the model is served. I've found you can type anything in there and the LM Studio will just serve the model you're hosting regardless```.\n",
      "\n",
      "In general, at 2023-10-08 19:30:07 a user named pbeheca said ```Ah so the full absolute path is the 'model' value?```.\n",
      "\n",
      "In general, at 2023-10-08 19:29:26 a user named au8 said ```right click your model at the top-center and click \"show in explorer\". You can then get the model name from the folder structure```.\n",
      "\n",
      "In general, at 2023-10-08 19:27:38 a user named au8 said ```no, you just need v1 for it```.\n",
      "\n",
      "In general, at 2023-10-08 19:27:28 a user named jew84930585 said ```yea maybe even `http://localhost:8000/v1/chat/completions` to be exact```.\n",
      "\n",
      "In general, at 2023-10-08 19:27:21 a user named pbeheca said ```do you leave the 'model' parameter empty? (dont use it?```.\n",
      "\n",
      "In general, at 2023-10-08 19:25:29 a user named au8 said ```you want the api_base to be `'api_base': \"http://localhost:8000/v1\",````.\n",
      "\n",
      "In general, at 2023-10-08 19:24:06 a user named au8 said ```I've had some issues with some models but that could be down to me not doing some things correctly but vicuna 16k for example works great```.\n",
      "\n",
      "In general, at 2023-10-08 19:24:04 a user named fxtoofaan said ```Anyone else use vllm server and littlellm ?```.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "Based on the context, Langchain appears to be an interoperability framework consisting of various agents that interact with other software solutions. One such agent it harbors is the CAMEL architecture, which can be compared to AutoGen. The user's intent seems to be to enable tools from Langchain to work with Autogen agents, fusing the unique advantages of both. If you have further questions about Langchain or related topics, feel free to ask!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# From a txt document \n",
    "user_question = \"Langchain\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=user_question, clear_history=True) \n",
    "# ragproxyagent.send(recipient=assistant, message=user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the context, Langchain appears to be an interoperability framework consisting of various agents that interact with other software solutions. One such agent it harbors is the CAMEL architecture, which can be compared to AutoGen. The user's intent seems to be to enable tools from Langchain to work with Autogen agents, fusing the unique advantages of both. If you have further questions about Langchain or related topics, feel free to ask!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print documents retrieved from Query\n",
    "ragproxyagent.retrieve_docs(\"Chainlit\")\n",
    "ragproxyagent._results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print documents retrieved from Query\n",
    "ragproxyagent.retrieve_docs(\"Langchain\")\n",
    "ragproxyagent._results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
