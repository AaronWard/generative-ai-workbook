{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Discord JSON Data\n",
    "\n",
    "This notebook is for preprocessing the extracted messages from the Autogen Discord. The purpose is to format and filter the data before putting it into a format that can be stored within a vector store for RAG operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils import api_utils\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Discord message JSON files\n",
    "path = '../data/chat_logs/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for \n",
    "def process_file(file_path):\n",
    "    file_name = os.path.basename(file_path).split('.')[0]\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            messages = json.load(file)\n",
    "            return pd.DataFrame([{\n",
    "                'channel': file_name,\n",
    "                'author_username': item['author']['username'],\n",
    "                'timestamp': item['timestamp'],\n",
    "                'content': item['content'],\n",
    "                'embeds': item['embeds']\n",
    "            } for item in messages])\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Get number of tokens per string\n",
    "def get_token_len(text):\n",
    "    return len([word for word in text.split(' ')])\n",
    "\n",
    "try:\n",
    "    df = pd.concat((process_file(fp) for fp in glob.glob(path) if process_file(fp) is not None), ignore_index=True)\n",
    "    df['timestamp'] =  pd.to_datetime(df['timestamp'],  errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['num_tokens'] = df.content.apply(get_token_len)\n",
    "    df['has_embedding'] = df.embeds.apply(lambda x: False if x == [] else True)\n",
    "    # Remove redundant short messages by token lengths \n",
    "    df = df[(df['has_embedding']) | (~df['has_embedding'] & (df['num_tokens'] >= 5))]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel\n",
       "general                 5106\n",
       "ideas-and-feedback      1077\n",
       "created-with-autogen     443\n",
       "forum-discussion         324\n",
       "dev-contributors         295\n",
       "issues-and-help          255\n",
       "announcements             38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.channel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>author_username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>content</th>\n",
       "      <th>embeds</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>has_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>announcements</td>\n",
       "      <td>sonichi</td>\n",
       "      <td>2023-09-21 02:57:45</td>\n",
       "      <td>*v0.1.1* is released to pypi. Make RetrieveAss...</td>\n",
       "      <td>[]</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6668</th>\n",
       "      <td>announcements</td>\n",
       "      <td>ToYari</td>\n",
       "      <td>2023-09-23 19:29:51</td>\n",
       "      <td>Hello everyone very interesting paper</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>announcements</td>\n",
       "      <td>tonykipkemboi.</td>\n",
       "      <td>2023-09-26 11:50:39</td>\n",
       "      <td>Hi y'all! Excited to try this!</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6661</th>\n",
       "      <td>announcements</td>\n",
       "      <td>jharleydev</td>\n",
       "      <td>2023-09-27 12:02:13</td>\n",
       "      <td>Hi, very cool paper can't wait to try this out !</td>\n",
       "      <td>[]</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6660</th>\n",
       "      <td>announcements</td>\n",
       "      <td>.mcalpha</td>\n",
       "      <td>2023-09-27 13:37:23</td>\n",
       "      <td>Weird that this paper hasn't seen more attenti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issues-and-help</td>\n",
       "      <td>aaronward_</td>\n",
       "      <td>2023-11-14 15:50:34</td>\n",
       "      <td>It was my fault, i didn't format the tool conf...</td>\n",
       "      <td>[]</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issues-and-help</td>\n",
       "      <td>ariel.andres</td>\n",
       "      <td>2023-11-14 18:11:25</td>\n",
       "      <td>Hi, I am trying to run the following example c...</td>\n",
       "      <td>[{'type': 'article', 'url': 'https://github.co...</td>\n",
       "      <td>148</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issues-and-help</td>\n",
       "      <td>sonichi</td>\n",
       "      <td>2023-11-14 19:01:34</td>\n",
       "      <td>https://microsoft.github.io/autogen/docs/Insta...</td>\n",
       "      <td>[{'type': 'article', 'url': 'https://microsoft...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>issues-and-help</td>\n",
       "      <td>razahin</td>\n",
       "      <td>2023-11-14 19:49:12</td>\n",
       "      <td>Hi @.beibinli, thank you very much for your of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issues-and-help</td>\n",
       "      <td>Lega</td>\n",
       "      <td>2023-11-15 10:41:54</td>\n",
       "      <td>im novice w programming so i may not have expl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              channel author_username            timestamp  \\\n",
       "6669    announcements         sonichi  2023-09-21 02:57:45   \n",
       "6668    announcements          ToYari  2023-09-23 19:29:51   \n",
       "6666    announcements  tonykipkemboi.  2023-09-26 11:50:39   \n",
       "6661    announcements      jharleydev  2023-09-27 12:02:13   \n",
       "6660    announcements        .mcalpha  2023-09-27 13:37:23   \n",
       "...               ...             ...                  ...   \n",
       "4     issues-and-help      aaronward_  2023-11-14 15:50:34   \n",
       "3     issues-and-help    ariel.andres  2023-11-14 18:11:25   \n",
       "2     issues-and-help         sonichi  2023-11-14 19:01:34   \n",
       "1     issues-and-help         razahin  2023-11-14 19:49:12   \n",
       "0     issues-and-help            Lega  2023-11-15 10:41:54   \n",
       "\n",
       "                                                content  \\\n",
       "6669  *v0.1.1* is released to pypi. Make RetrieveAss...   \n",
       "6668              Hello everyone very interesting paper   \n",
       "6666                     Hi y'all! Excited to try this!   \n",
       "6661   Hi, very cool paper can't wait to try this out !   \n",
       "6660  Weird that this paper hasn't seen more attenti...   \n",
       "...                                                 ...   \n",
       "4     It was my fault, i didn't format the tool conf...   \n",
       "3     Hi, I am trying to run the following example c...   \n",
       "2     https://microsoft.github.io/autogen/docs/Insta...   \n",
       "1     Hi @.beibinli, thank you very much for your of...   \n",
       "0     im novice w programming so i may not have expl...   \n",
       "\n",
       "                                                 embeds  num_tokens  \\\n",
       "6669                                                 []           8   \n",
       "6668                                                 []           5   \n",
       "6666                                                 []           6   \n",
       "6661                                                 []          11   \n",
       "6660                                                 []           9   \n",
       "...                                                 ...         ...   \n",
       "4                                                    []          18   \n",
       "3     [{'type': 'article', 'url': 'https://github.co...         148   \n",
       "2     [{'type': 'article', 'url': 'https://microsoft...           1   \n",
       "1                                                    []          75   \n",
       "0                                                    []          33   \n",
       "\n",
       "      has_embedding  \n",
       "6669          False  \n",
       "6668          False  \n",
       "6666          False  \n",
       "6661          False  \n",
       "6660          False  \n",
       "...             ...  \n",
       "4             False  \n",
       "3              True  \n",
       "2              True  \n",
       "1             False  \n",
       "0             False  \n",
       "\n",
       "[7538 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['channel', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_cols = ['channel', 'author_username', 'timestamp', 'content', 'embeds', has_embedding]\n",
    "output_file = \"../data/docs/22112023_chat_history.txt\"\n",
    "\n",
    "with open(output_file, 'w') as file:\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        additional_context = \"\"\n",
    "        try:\n",
    "            if row.has_embedding:\n",
    "                additional_context (f\"\"\"Additional information about the content linked by this user: \n",
    "                - Link title: {row.embeds[0].title}\n",
    "                - Link description: {row.embeds[0].description}\n",
    "                \"\"\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        formatted_text = (f\"\"\"In {row.channel}, at {row.timestamp} a user named {row.author_username} said ```{row.content}```.\\n {additional_context}\"\"\").strip()\n",
    "        file.write(formatted_text.strip().rstrip() + '\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_file = \"../data/docs/22112023_chat_history.txt\"\n",
    "with open(chat_history_file, 'r') as file:\n",
    "    chat_history = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"../data/docs/22112023_qa.txt\"\n",
    "CHUNK_SIZE = 3000  \n",
    "RATE_LIMIT_DELAY = 20 \n",
    "import time\n",
    "\n",
    "def get_chunks(text, chunk_size):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        yield ' '.join(words[i:i+chunk_size])\n",
    "\n",
    "# Process the context in chunks\n",
    "with open(output_file, 'w') as file:\n",
    "    for chunk in get_chunks(chat_history, CHUNK_SIZE):\n",
    "        try:\n",
    "            # Send chunk to API and get response\n",
    "            prompt_response = api_utils.prompt(context=chunk)\n",
    "            print(prompt_response)\n",
    "\n",
    "            # Write the response to the file\n",
    "            file.write(prompt_response.strip().rstrip() + '\\n')\n",
    "\n",
    "            # Wait before sending the next request\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing chunk: {e}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
