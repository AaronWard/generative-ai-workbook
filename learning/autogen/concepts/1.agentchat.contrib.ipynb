{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentchat Module\n",
    "\n",
    "AutoGen offers several classes allowing developers to work with LLMs and solve tasks, particularly in the domain of mathematics and retrieval-based tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-4', 'gpt-3.5-turbo']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import autogen\n",
    "import tempfile\n",
    "import chromadb\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "from utils.api_utils import config_list_from_dotenv\n",
    "\n",
    "config_list = config_list_from_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrieve_assistant_agent\n",
    "The RetrieveAssistantAgent belongs to the agentchat.contrib.retrieve_assistant_agent module and is designed to solve tasks with LLMs, including suggesting Python code blocks and debugging. This agent does not execute code by default and expects the user to execute the code. This class is a subclass of AssistantAgent, configured with a default system message to solve tasks with LLMs.\n",
    "\n",
    "Purpose: The RetrieveAssistantAgent is a specialized agent designed to solve tasks with Language Learning Models (LLMs) like GPT. It is configured with a default system message and is specialized in suggesting Python code blocks and assisting with debugging. By default, human_input_mode is set to \"NEVER\", and code_execution_config is set to False, meaning this agent does not execute code by default and expects the user to execute the code. It is particularly useful when the user needs suggestions or guidance in writing or debugging Python code, but the execution of the code is left to the user.\n",
    "\n",
    "retrieve_user_proxy_agent\n",
    "The RetrieveUserProxyAgent class is part of the agentchat.contrib.retrieve_user_proxy_agent module and seems to be designed to interact with users, asking for human inputs every time a message is received based on its configuration. It also allows the generation of initial messages with given problems and prompts and can be configured with various parameters like the task type, client, docs_path, collection_name, and model to use for the retrieve chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve_assistant_agent\n",
    "\n",
    "The `RetrieveAssistantAgent` belongs to the `agentchat.contrib.retrieve_assistant_agent` module and is designed to solve tasks with LLMs, including suggesting Python code blocks and debugging. This agent does not execute code by default and expects the user to execute the code. This class is a subclass of AssistantAgent, configured with a default system message to solve tasks with LLMs.\n",
    "\n",
    "**Purpose:**\n",
    "The RetrieveAssistantAgent is a specialized agent designed to solve tasks with Language Learning Models (LLMs) like GPT. It is configured with a default system message and is specialized in suggesting Python code blocks and assisting with debugging. By default, human_input_mode is set to \"NEVER\", and `code_execution_config` is set to False, meaning this agent does not execute code by default and expects the user to execute the code. It is particularly useful when the user needs suggestions or guidance in writing or debugging Python code, but the execution of the code is left to the user.\n",
    "\n",
    "\n",
    "#### retrieve_user_proxy_agent\n",
    "The `RetrieveUserProxyAgent` class is part of the `agentchat.contrib.retrieve_user_proxy_agent` module and seems to be designed to interact with users, asking for human inputs every time a message is received based on its configuration. It also allows the generation of initial messages with given problems and prompts and can be configured with various parameters like the task type, client, docs_path, collection_name, and model to use for the retrieve chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "\n",
    "# Start logging\n",
    "autogen.ChatCompletion.start_logging()\n",
    "\n",
    "# Create an instance of RetrieveAssistantAgent\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "path = Path(os.getcwd(), 'docs')\n",
    "str(path)\n",
    "\n",
    "client = chromadb.PersistentClient(path=f\"{os.getcwd()}/chromadb\")\n",
    "\n",
    "# Create an instance of RetrieveUserProxyAgent\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"task\": \"default\",\n",
    "        \"docs_path\": str(path), \n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": client, \n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Delete dir each instantiation\n",
    "#  client.delete_collection('autogen-docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_tokens is too small to fit a single line of text. Breaking this line:\n",
      "\tBLUE is the enterprise’s integrated, flexible and interoperable platform that will anchor the scale- ...\n",
      "Failed to split docs with must_break_at_empty_line being True, set to False.\n",
      "Number of requested results 20 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_0', 'doc_1', 'doc_2']]\n"
     ]
    }
   ],
   "source": [
    "ragproxyagent.retrieve_docs(\"some query string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_ids:  [['doc_2', 'doc_0', 'doc_1']]\n",
      "\u001b[32mAdding doc_id doc_2 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_0 to context.\u001b[0m\n",
      "\u001b[32mAdding doc_id doc_1 to context.\u001b[0m\n",
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the\n",
      "context provided by the user. You should follow the following steps to answer a question:\n",
      "Step 1, you estimate the user's intent based on the question and context. The intent can be a code generation task or\n",
      "a question answering task.\n",
      "Step 2, you reply based on the intent.\n",
      "If you can't answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.\n",
      "If user's intent is code generation, you must obey the following rules:\n",
      "Rule 1. You MUST NOT install any packages because all the packages needed are already installed.\n",
      "Rule 2. You must follow the formats below to write your code:\n",
      "```language\n",
      "# your code\n",
      "```\n",
      "\n",
      "If user's intent is question answering, you must give as short an answer as possible.\n",
      "\n",
      "User's question is: Who was the blacksmith?\n",
      "\n",
      "Context is: Cú Chulainn was a legendary hero of Irish myth and folklore. He was known for his incredible strength, bravery, and skill in battle. According to legend, Cú Chulainn was the son of the god Lug and the mortal woman Deichtine. When he was a young boy, he was given the name Sétanta, but he later earned the name Cú Chulainn, which means \"Culann's Hound,\" after he killed a fierce guard dog that belonged to a blacksmith named Culann.\n",
      "Cú Chulainn was known for his many feats of strength and bravery. He was said to be able to lift enormous weights and hurl them great distances, and he was a formidable warrior in battle. He was also renowned for his loyalty and honor, and he was willing to make great sacrifices for the people he loved.\n",
      "Despite his many accomplishments, Cú Chulainn's life was eventually cut short in a tragic manner. According to legend, he was killed in a battle against the armies of Connacht, after being betrayed by one of his own comrades. Despite his untimely death, Cú Chulainn's legacy lived on in Irish folklore and mythology, and he continues to be remembered as one of Ireland's greatest heroes.\n",
      "In Irish mythology, Culann was a blacksmith who lived in the kingdom of Ulster. He was known for having a fierce guard dog that protected his property. One day, a young boy named Sétanta (who later became known as Cú Chulainn) came to visit Culann, but when he arrived at the blacksmith's home, he was confronted by the guard dog. Sétanta was able to kill the dog in self-defense, but in doing so, he caused Culann great grief. In order to make amends, Sétanta offered to take the place of the guard dog and protect Culann's property himself until a new dog could be trained. From then on, Sétanta was known as Cú Chulainn, which means \"Culann's Hound.\"\n",
      "There are several versions of the story of Cú Chulainn and Culann, and the reason for Sétanta's visit to the blacksmith's home varies depending on the version of the story. In some accounts, Sétanta was simply passing through the area and stopped to visit Culann out of curiosity. In other versions of the story, Sétanta was visiting Culann in order to learn the art of blacksmithing, or to ask the blacksmith to make a weapon for him.\n",
      "Regardless of the reason for his visit, Sétanta's encounter with Culann's guard dog is a key event in the story of Cú Chulainn. The incident serves as a turning point in Sétanta's life, as it marks the beginning of his transformation into the legendary hero Cú Chulainn.\n",
      "BLUE is the enterprise’s integrated, flexible and interoperable platform that will anchor the scale-up our data science and technology-enabled clinical, pharma and provider businesses, and will be the launch-pad for rapid incubation and growth of new capabilities.  BLUE emphasizes the integration of our proprietary payer, provider and clinical data linked with high-value, third party data assets and promotes the reuse of assets for efficiency and quality. 1.  What is BLUE?2. What are the differentiating factors of BLUE?Enables new products and capabilities•Empowers UHG to rapidly experiment, prototype, deploy and scale internal and market facing opportunities: BLUE is the platform incubator for emerging businesses and for incremental growth•Links best-in-class UHG data science capabilities with third-party assets, such a weather, environment and vulnerability indices, considered key for growth in new Pharma Services, ESG services and bio-surveillance.•Enables a “Marketplace” to access de-identified healthcare and environmental data & insights, to access UHG apps, analytics and APIs or to create custom models, products and services leveraging the power of UHG’s data and technology assets.•Enhances customer data sets. BLUE’s Enterprise Logical Data Model (ELDM) empowers customers to adapt their data to the BLUE format. This facilitates integration and association of customer data with analogous data in BLUE’s thereby producing richer, more comprehensive insights while offering more balanced training data for artificial intelligence.Modern Technology Foundation•Large Language Models (LLMs). A BLUE-LLM could be trained on UHG’s Enterprise Logical Data Model (ELDM) to understand the structure, relationships and nuances of our complex data domains. One of the strengths of LLMs is processing natural language thus allowing users to create prompts that represent complex data inquiries. The LLM, familiar with the entirety of the ELDM can fetch, analyze and return the insights.  For example, “BLUE: identify trends in emergency department utilization in rural Tennessee”•Healthcare Data Security and Privacy. Dynamic de-identification, data protection and aggregation in compliance with privacy and policy will be applied to BLUE data prior to consumption by the user.  (Low-latency, safe-harbor de-identification approaches are in use today at UHG). Furthermore, BLUE will layer security and data access rules with customer roles applied at the lowest atomic level - row and column. This provides parity with the security implementations in use across UHG.  Synthetic Populations and Imputed Data •Synthetic data is information that has been artificially manufactured based on real-world data. Imputed data are estimates of unknown characteristics based on other, known predictors in real-world data.  Both approaches use AI to create the outcome. •Synthetic data retains the same attributes, correlations and results as its source, regulated data and is useful when business, privacy and deidentification policies prohibit real-world data use – For example: useful for Medicaid and other highly controlled real-world data sets. Improvements in synthetic population generation, particularly micro-population generation, signify a lead toward more precise and representative data sets. By integrating these synthetic datasets, the 100M+ lives represented in UHG’s data assets can be enriched: emphasizing segments that traditionally have been underserved or faced inequities. •Imputed data are predictions of missing characteristics of of a real-world data set, such as race, ethnicity or social determinants –For example: useful for estimating these values when they are not self-reported.15. Why is BLUE needed? What makes it differentiated and how can we think about growth enablement and ROI?\n",
      "23. Why is BLUE different from our current approach to enterprise data and product development?BLUE’s primary purpose is to drive and expedite growth through data science and technology enablement. Although BLUE supports additional enterprise platform goals such as efficiencies through reuse, consistency and standardization of assets. To our knowledge, no current or previous initiatives were designed with this primary purpose in mind. BLUE’s will not force overhaul or reconfiguration of existing capabilities that are already delivering value. Furthermore, unlike current initiatives that are separated by line of business objectives, governance and investments,  BLUE introduces an EMT-governed framework to prioritize business opportunities valued at $1B or more.  Focused governance ensures strategies are properly aligned, provides prioritization clarity while facilitating fast- track decision making. \n",
      "Several factors have contributed to UHG’s growth to the one of the largest and most successful healthcare companies in the world:   our unique acquisition strategy, diversification across the healthcare ecosystem, revenue growth from both Optum and UHC, increased earnings and higher market share. Today, economic uncertainty brought on by regulatory changes in Medicare and Medicaid reimbursement rates, increased legislative oversight for PBM, climate-change influencing investors and the ever-increasing healthcare cost require updates to UHG’s growth strategies. A better alignment of long-range plans (LRP) to enable business growth through leveraging existing assets is required.  BLUE’s governance framework provide cohesion across executive leadership and better transparency across LRPs. Growth enablement is about creating the optimal conditions, systems and tools to increase revenue, customers and brand value. It requires platform infrastructure for innovations, asset reuse, resource optimization and agile delivery.Internal research (performed by other teams) indicate that our primary data and analytics infrastructure is over $660M annually - divided by business service lines. We think this is underestimated. By emphasis on reuse of assets and leveraging best-in class solutions accounted for in our existing infrastructure, BLUE will minimize the need for large infrastructure investments to achieve ROI.   In the short-term, we believe that BLUE will be the launch pad for new businesses in OLS/Pharma Services, be the platform for strategic partnerships with CMS and be Optum’s commercial marketplace for patient and population risk assessment tools.We recognize previous visions and strategies toward creating enterprise platforms have had mixed results both at Optum and UHC. These efforts fell short of enterprise-wide success for a myriad of reasons:  •Inadequate senior G-level executive commitment•Challenges in securing funding or demonstrating a clear ROI•Underestimating technical and political complexities •Simply waning after rollout of the first use cases or MVPsGiven the short and mid-term financial goals of UHG businesses, they cannot risk primary business outcomes on building an enterprise platform asset that may not meet time and ROI requirements. This leads to our current set of bespoke products and solutions tailored to specific business needs: our current technical debt, data sprawl and duplication, rebuilding versus reusing philosophy is a consequence. 4. Why did these previous approaches not yield an enterprise capability?Opportunity: Become the market leader in health- related surveillance and the factors impacting health outcomes and equity\n",
      "36. What are examples of new services and businesses based on BLUE?The size of the UHG dataset(100M + lives) for the US market, low-latency of data elements, and uniqueness of interconnected dimensions enables a range of business services that can be designed as software with license fees or full-service monitor and actioning capabilities with the competitive advantage of UHGs proprietary data. • BLUE enables introduction of new revenue streams, for example, by shifting business models from ownership to access whereby customers could create their own AI and ML models and build products using BLUE’s deidentified data. •BLUE facilitates a health system marketplace where UHG apps, analytics and APIs can be accessed by consumers. For example, integrate UHG models of chronic disease prediction into care provider touchpoints.Biological and Ecological SurveillancePopulation Risk-Intervention MatchingEpidemiology and Clinical ImpactEnvironmental Impact Consulting and Solutions$5B TAMOpportunity: Go beyond monitoring to truly action and mitigate emerging risks with proactive intervention... based both on traditional medical risk but combined with external influences to drive priority $25B TAMOpportunity: Significantly expand offerings in the pharmaceutical services revenue pool with relevant insights and targeting capabilities $25B TAMOpportunity: Become the industry leader in mitigating the environmental impact of healthcare – turned internally and sold externally as a service $5-10B TAM7. Can BLUE reuse existing assets? Multiple existing efforts and capabilities will provide the foundational building blocks for BLUE, emphasizing of not starting from scratch but leveraging and reusing best-in-class internal / external solutions.BLUE will connect multiple activities currently underway across UHG.  Development and operationalization of BLUE and associated commercial products / services will be in Ireland to leverage the incentives there.BLUE will integrate our best thinking and assets including (not exhaustive):•Data and product assets from Optum Insight/Change Health and Optum Life Sciences that will facilitate growth in pharma services and create new revenue opportunities in biosurveillance and health equity. •Substantial insight and progress within Optum Health in platform scale-up, via OCM (Optum Care Manager) and core data services via Enterprise Clinical Data Hub, which provides consumption and persistence of standard clinical, patient and provider data. •The Enterprise Logical Data Model (ELDM), a single representation of UHG data concept and the Healthcare Platform Catalog, the only Preferred solution for an Enterprise Data Catalog.•The strategies and architectural considerations of the Optum Chief Data Office which has made significant progress in claims/payer data standardization, driven by UHC Claims and Benefit Operations. (We recommended actively engaging with Vasant’s group (Chief Data Office) to effectively harness the value of enterprise data, centrally govern it (with decentralized provisioning), and democratize its use to accelerate business insights and capabilities.)Technical partnerships with Google and Microsoft are pivotal as they supply the essential cloud and data services needed for BLUE. Additional partnerships with technology leaders in synthetic population generation would accelerate these capabilities.48. What's a high-level plan and what is needed to get started?End state: By 2028, Blue will provide data-on-demand to power experiences, journeys, insights, actionable outcomes, new businesses enabled by AI/ML and data. Blue will take in new data and derivations for immediate consumption – delivered by any skilled talent in our enterprise We propose the following to get started (after validating support with Executive Management Team):Phase 1: Analysis (2 months)Partnerships with ‘Big3’ strategy consulting firm highly recommended to drive the first phase. Two work streams in Phase 1:1.Market Offering Working Team. GOAL: Formulate market offering and prioritize use cases.This team will prioritize enterprise opportunities, services and use cases. Goals are to use market intelligence to prioritize use cases, construct the narrative to enable business cases for the BLUE platform. (In-person workshops recommended to create deliverables)2. Platform Team. GOAL: Platform architecture and technology enablement planAssemble platform leadership team from lead architects representing primary tech/data components, include data science capabilities enablement leader.. Goals are to create BLUE requirements document, conceptual architecture, create an estimated cost for feasibility phase and a high-level technical plan.  (In- person workshops recommended to create deliverables.Led by: Consulting FirmOLS/Pharma Services Leader (Millar)Strategy/Growth Leader (Schumacher)Optum Insight Strategy Leader (Emerson)Optum Health/Optum Serve Leader (Horoho) Optum Health VBC Innovation Leader (King)UHC Strategy Leader (Thompson)Sustainability Office Leader (Lewis)\n",
      "Led by: Consulting FirmChief Data Officer Architect (Manohar)Optum Health CTO Architect (Mosher)Healthcare Platform CTO Architect (Shiltz)Optum Insight Data Solutions Architect (Joshi)Technology Enablement Architect (Bridges)Phase 2: Feasibility and POC (3-4 months)Partnerships with “Big3” consulting firm to drive plan and technology implementation firms for POC (Microsoft/Google).  1.Business planning. Create business strategy and plan.Assemble team of internal subject matter experts (product and business) lead by consulting organization. Goals are to describe products/services, go-to-market strategy, create financial estimates include time to value, create funding request. 2. Platform POC build. Assemble subject matter experts from component teams (Data, infrastructure and applications/services) assigned to implementation teams to build proof of concept for priority capabilities.  Teams built of internal and partner resources. Goals are to create proof-of-concept and validate estimates.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "The blacksmith in the context provided is Culann from Irish mythology. He lived in the kingdom of Ulster and was known for his fierce guard dog. His guard dog was slain by a young boy named Sétanta, who then took on the name Cú Chulainn, meaning \"Culann's Hound\", offering to protect Culann's property until a new dog could be trained in recompense for the slain guard dog.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# From a txt document \n",
    "user_question = \"Who was the blacksmith?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=user_question) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### math_user_proxy_agent\n",
    "\n",
    "The `MathUserProxyAgent` is a part of the `agentchat.contrib.math_user_proxy_agent` module, and it is designed to handle math problems. It seems to be experimental at this stage. This class can generate initial messages, execute Python code, and run queries through Wolfram Alpha to solve mathematical problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
