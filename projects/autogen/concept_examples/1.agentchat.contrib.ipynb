{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentchat Module\n",
    "\n",
    "AutoGen offers several classes allowing developers to work with LLMs and solve tasks, particularly in the domain of mathematics and retrieval-based tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import autogen\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from .utils.api_utils import load_config_list_from_dotenv\n",
    "\n",
    "config_list = load_config_list_from_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve_assistant_agent\n",
    "\n",
    "The `RetrieveAssistantAgent` belongs to the `agentchat.contrib.retrieve_assistant_agent` module and is designed to solve tasks with LLMs, including suggesting Python code blocks and debugging. This agent does not execute code by default and expects the user to execute the code. This class is a subclass of AssistantAgent, configured with a default system message to solve tasks with LLMs.\n",
    "\n",
    "**Purpose:**\n",
    "The RetrieveAssistantAgent is a specialized agent designed to solve tasks with Language Learning Models (LLMs) like GPT. It is configured with a default system message and is specialized in suggesting Python code blocks and assisting with debugging. By default, human_input_mode is set to \"NEVER\", and `code_execution_config` is set to False, meaning this agent does not execute code by default and expects the user to execute the code. It is particularly useful when the user needs suggestions or guidance in writing or debugging Python code, but the execution of the code is left to the user.\n",
    "\n",
    "\n",
    "#### retrieve_user_proxy_agent\n",
    "The `RetrieveUserProxyAgent` class is part of the `agentchat.contrib.retrieve_user_proxy_agent` module and seems to be designed to interact with users, asking for human inputs every time a message is received based on its configuration. It also allows the generation of initial messages with given problems and prompts and can be configured with various parameters like the task type, client, docs_path, collection_name, and model to use for the retrieve chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import autogen\n",
    "import chromadb\n",
    "\n",
    "# Start logging\n",
    "autogen.ChatCompletion.start_logging()\n",
    "\n",
    "# Create an instance of RetrieveAssistantAgent\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "path = Path(os.getcwd(), 'docs')\n",
    "str(path)\n",
    "\n",
    "# Create an instance of RetrieveUserProxyAgent\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"task\": \"default\",\n",
    "        \"docs_path\": str(path), \n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=f\"{os.getcwd()}/chromadb\"), # NOTE: Delete after each instantiation\n",
    "        \"embedding_model\": \"all-mpnet-base-v2\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Simulate a user asking a question and initiate chat\n",
    "user_question = \"What is BLUE?\"\n",
    "ragproxyagent.initiate_chat(assistant, problem=user_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math_user_proxy_agent\n",
    "# retrieve_assistant_agent\n",
    "# retrieve_user_proxy_agent\n",
    "# agent\n",
    "# assistant_agent\n",
    "# conversable_agent\n",
    "# groupchat\n",
    "# user_proxy_agent\n",
    "# oai\n",
    "# completion\n",
    "# openai_utils\n",
    "# code_utils\n",
    "# math_utils\n",
    "# retrieve_utils\n",
    "\n",
    "\n",
    "\n",
    "# With all that you know about the following modules in AutoGen agentchat.contrib module, I want you to provide a comprehensive walk through of how autogen can be used,\n",
    "# the examples should follow some logical workflow to achieve a specific problem. Provide full commented code where appropriate. \n",
    "# Be detailed in your response. Show how the module can be used with other modules in your example, if it requires it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### math_user_proxy_agent\n",
    "\n",
    "The `MathUserProxyAgent` is a part of the `agentchat.contrib.math_user_proxy_agent` module, and it is designed to handle math problems. It seems to be experimental at this stage. This class can generate initial messages, execute Python code, and run queries through Wolfram Alpha to solve mathematical problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
