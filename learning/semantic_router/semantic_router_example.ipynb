{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Router\n",
    "\n",
    "Semantic router is a clever way to direct the flow of conversation using natural language. <br>\n",
    "Sometimes you may want to direct a query or user input like how you would using `if` or `elif` in python. <br>\n",
    "Adding this logic into your prompt can introduce complexity to your system messages that can reduce performance.\n",
    "\n",
    "You can also use semantic router to act as a guardrail against certain topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from semantic_router import Route\n",
    "from semantic_router.layer import RouteLayer\n",
    "from semantic_router.encoders import CohereEncoder, OpenAIEncoder\n",
    "from semantic_router.utils.function_call import get_schema\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "encoder = OpenAIEncoder()\n",
    "# encoder = CohereEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use this as a guide for our chatbot to avoid political conversations\n",
    "politics = Route(\n",
    "    name=\"religion\",\n",
    "    utterances=[\n",
    "        \"Do you believe in god?\"\n",
    "        \"Is god real?\"\n",
    "        \"Which religion are you?\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "# this could be used as an indicator to our chatbot to switch to a more\n",
    "# conversational prompt\n",
    "chitchat = Route(\n",
    "    name=\"animals\",\n",
    "    utterances=[\n",
    "        \"What is the fastest animal in the world?\"\n",
    "        \"How many breeds of dogs are there?\"\n",
    "        \"Do you have a pet at home?\"\n",
    "        \"What the difference between a Bonobo and a Chimpanzee?\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "# we place both of our decisions together into single list\n",
    "routes = [politics, chitchat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a router layer\n",
    "rl = RouteLayer(encoder=encoder, routes=routes)\n",
    "\n",
    "# Classify the text - `None` if no match\n",
    "rl(\"What religion are you?\").name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading routers\n",
    "\n",
    "You can save a load route configurations in a `.json` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save router\n",
    "rl.to_json(\"layer.json\")\n",
    "\n",
    "# load router\n",
    "loaded_rl = RouteLayer.from_json(\"layer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling\n",
    "You can also use semantic router for function calling. Which can be beneficial when you don't want to use an LLM for to deciding to ue a function, which can have longer processing times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function \n",
    "def get_company_info(query: str) -> str:\n",
    "    return \"ABCXYZ Company is a tech company established in 2001 in San Diego.\"\n",
    "    \n",
    "schema = get_schema(get_company_info)\n",
    "\n",
    "# dynamic route - Dynamic routes use an LLM\n",
    "route_with_function = Route(\n",
    "    name=\"get_domain_info\",\n",
    "    utterances=[\n",
    "        \"What is ABCXYZ?\",\n",
    "        \"When was ABCXYZ created?\",\n",
    "        \"Where was ABCXYZ made?\",\n",
    "    ],\n",
    "    function_schema=schema,\n",
    ")\n",
    "\n",
    "# Add the route to the route layer and query\n",
    "rl.add(route_with_function)\n",
    "rl(\"which city did ABCXYZ start up in?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling flow\n",
    "\n",
    "You can control the flow of how the system reacts to a certain semantic input based on the routes you define. For example, this can achieved by either checking the type of query that is being asked and starting up a different process OR it can be used to update system messages for an LLM further downstream in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different processes\n",
    "route = rl(\"Did she believe in god?\")\n",
    "if route.name == \"religion\":\n",
    "    # DO SOMETHING \n",
    "    pass\n",
    "elif route.name == \"animals\":\n",
    "    # DO SOMETHING ELSE\n",
    "    pass\n",
    "elif route.name == \"get_domain_info\":\n",
    "    # DO SOMETHING ELSE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic system messages\n",
    "def semantic_layer(query: str):\n",
    "    route = rl(query)\n",
    "    if route.name == \"religion\":\n",
    "        query += f\"<ADDITIONAL_CONTEXT>\"\n",
    "    elif route.name == \"animals\":\n",
    "        query += f\"<ADDITIONAL_CONTEXT>\"\n",
    "    elif route.name == \"get_domain_info\":\n",
    "        query += f\"<ADDITIONAL_CONTEXT>\"\n",
    "    return query\n",
    "\n",
    "query = \"<some_query>\"\n",
    "query = semantic_layer(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some things are not clearly defined as the project is new\n",
    "# TODO:\n",
    "# HybridRouteLayer\n",
    "# RouteConfig"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
