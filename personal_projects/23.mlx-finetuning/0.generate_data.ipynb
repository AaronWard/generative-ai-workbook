{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "\n",
    "Need to create a dataset in format it within a `jsjonl` representation to fine tune Mistral 7B\n",
    "\n",
    "`{\"text\":\"<s>[INST] Instruction[/INST] Model answer</s>[INST] Follow-up instruction[/INST]\"}`\n",
    "\n",
    "I've going to reuse the QA dataset i made for the autogen discord RAG from a previous project, \n",
    "\n",
    "**Useful Links:**\n",
    "- [Building your training data for fine-tuning](https://apeatling.com/articles/part-2-building-your-training-data-for-fine-tuning/)\n",
    "- [Documentation for the JSON Lines text file format](https://jsonlines.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in QA pairs to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I handle an invalid URL error when usi...</td>\n",
       "      <td>To fix an invalid URL error, ensure you're usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How should I approach feeding a local image in...</td>\n",
       "      <td>When you want to feed a local image into the M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I use the `--pre` flag in pip?</td>\n",
       "      <td>Use the `--pre` flag in pip to include pre-rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What do you do if you're charged for input tok...</td>\n",
       "      <td>You could modify the logic to terminate the op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I install a package from a pre-release...</td>\n",
       "      <td>To install pre-release versions of a package t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>What is the current state of support for integ...</td>\n",
       "      <td>According to a user's statement, Llama2 and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>How does one decide between using Autogen and ...</td>\n",
       "      <td>The provided text does not give a specific ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Are the developers of Autogen and Semantic Ker...</td>\n",
       "      <td>The text implies that there was some awareness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Can I use any AI model, like Llama2, or am I l...</td>\n",
       "      <td>There is no clear answer provided in the text;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>What should I do if I have ideas for the setup...</td>\n",
       "      <td>Though there is no direct answer in the text, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    How can I handle an invalid URL error when usi...   \n",
       "1    How should I approach feeding a local image in...   \n",
       "2                How do I use the `--pre` flag in pip?   \n",
       "3    What do you do if you're charged for input tok...   \n",
       "4    How can I install a package from a pre-release...   \n",
       "..                                                 ...   \n",
       "882  What is the current state of support for integ...   \n",
       "883  How does one decide between using Autogen and ...   \n",
       "884  Are the developers of Autogen and Semantic Ker...   \n",
       "885  Can I use any AI model, like Llama2, or am I l...   \n",
       "886  What should I do if I have ideas for the setup...   \n",
       "\n",
       "                                                Answer  \n",
       "0    To fix an invalid URL error, ensure you're usi...  \n",
       "1    When you want to feed a local image into the M...  \n",
       "2    Use the `--pre` flag in pip to include pre-rel...  \n",
       "3    You could modify the logic to terminate the op...  \n",
       "4    To install pre-release versions of a package t...  \n",
       "..                                                 ...  \n",
       "882  According to a user's statement, Llama2 and mo...  \n",
       "883  The provided text does not give a specific ans...  \n",
       "884  The text implies that there was some awareness...  \n",
       "885  There is no clear answer provided in the text;...  \n",
       "886  Though there is no direct answer in the text, ...  \n",
       "\n",
       "[887 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_qa(text):\n",
    "    \"\"\"Parse the text to extract questions and answers.\"\"\"\n",
    "    qa_pairs = re.findall(r'Question: (.*?)\\nAnswer: (.*?)\\n', text, re.DOTALL)\n",
    "    return qa_pairs\n",
    "\n",
    "def create_dataframe(filepath):\n",
    "    \"\"\"Read the text file and create a pandas DataFrame.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    qa_pairs = parse_qa(content)\n",
    "    df = pd.DataFrame(qa_pairs, columns=['Question', 'Answer'])\n",
    "    return df\n",
    "\n",
    "\n",
    "data_path = \"./data/22112023_qa.txt\"\n",
    "qa_df = create_dataframe(data_path)\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      <s>[INST] How can I handle an invalid URL erro...\n",
       "1      <s>[INST] How should I approach feeding a loca...\n",
       "2      <s>[INST] How do I use the `--pre` flag in pip...\n",
       "3      <s>[INST] What do you do if you're charged for...\n",
       "4      <s>[INST] How can I install a package from a p...\n",
       "                             ...                        \n",
       "882    <s>[INST] What is the current state of support...\n",
       "883    <s>[INST] How does one decide between using Au...\n",
       "884    <s>[INST] Are the developers of Autogen and Se...\n",
       "885    <s>[INST] Can I use any AI model, like Llama2,...\n",
       "886    <s>[INST] What should I do if I have ideas for...\n",
       "Length: 887, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_for_mistral(row):\n",
    "    # Formatting the question-answer pair with the required Mistral format\n",
    "    return f\"<s>[INST] {row['Question']} [/INST] {row['Answer']}</s>\"\n",
    "\n",
    "# Apply the formatting function to each row of the DataFrame\n",
    "formatted_data = qa_df.apply(format_for_mistral, axis=1)\n",
    "formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the formatted data to a JSONL file\n",
    "with open('./data/instructions.json', 'w') as file:\n",
    "    for entry in formatted_data:\n",
    "        json.dump({\"text\": entry}, file)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data in to train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_valid_file(formatted_data):\n",
    "    # Calculate 20% of the total lines for validation\n",
    "    twenty_percent = int(len(formatted_data) * 0.2)\n",
    "    validation_lines = formatted_data[:twenty_percent]\n",
    "    training_lines = formatted_data[twenty_percent:]\n",
    "\n",
    "    with open('./data/train.jsonl', 'w') as file:\n",
    "        for entry in training_lines:\n",
    "            json.dump({\"text\": entry}, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "    with open('./data/valid.jsonl', 'w') as file:\n",
    "        for entry in validation_lines:\n",
    "            json.dump({\"text\": entry}, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "create_valid_file(formatted_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning with MLX\n",
    "\n",
    "- Install mlx: `pip install mlx`\n",
    "- [LORA - MLX Documentation](https://github.com/ml-explore/mlx-examples/tree/main/lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[1;32m     15\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(command, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT, universal_newlines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(process\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mreadline, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line:  \u001b[38;5;66;03m# Check for a progress line\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(line, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Overwrite the previous line\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command and its arguments\n",
    "command = [\n",
    "    \"python\", \"lora.py\",\n",
    "    \"--train\",\n",
    "    \"--model\", \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"--data\", \"./data\",\n",
    "    \"--batch-size\", \"2\",\n",
    "    \"--lora-layers\", \"8\",\n",
    "    \"--iters\", \"1000\"\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    if \"Downloading\" in line or \"Fetching\" in line:  # Check for a progress line\n",
    "        print(line, end='\\r', flush=True)  # Overwrite the previous line\n",
    "    else:\n",
    "        print(line, end='')  # Print normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
