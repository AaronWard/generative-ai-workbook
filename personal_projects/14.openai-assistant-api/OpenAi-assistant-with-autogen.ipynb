{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Assistant with Autogen and Postgres\n",
    "\n",
    "This example hows how you can use the OpenAI Assistant agents with autogen, to solve database related tasks (Postgres DB).<br>\n",
    "This code takes a lot of inspiration from IndyDevDan's videos.\n",
    "\n",
    "\n",
    "One thing i noticed so far: its fast! it doesn't waste time talking back and foward with the `UserProxyAgent` before writing the query - potentially saving money on token costs, i'll need to look into this further. It also seems counter intuitive because usually the `UserProxyAgent` is the one who is executing the code. it's a great addition to autogen from what i can tell so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "from modules import llm\n",
    "from modules import rand\n",
    "from turbo4 import Turbo4\n",
    "from modules import embeddings\n",
    "from modules.instruments import PostgresAgentInstruments\n",
    "\n",
    "import autogen\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "\n",
    "\n",
    "DB_URL = os.environ.get(\"POSTGRES_CONNECTION_URL\")\n",
    "POSTGRES_TABLE_DEFINITIONS_CAP_REF = \"TABLE_DEFINITIONS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pyautogen\n",
    "# https://github.com/microsoft/autogen/releases/tag/0.2.0b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is formatted differently for autogen than if \n",
    "# you were to use the Assistants API directly.\n",
    "run_sql_tool_config = {\n",
    "    \"name\": \"run_sql\",\n",
    "    \"description\": \"This is a function that allows you to run SQL queries on a Postgres DB by passing the SQL as a string.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"sql\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"This is a string containing SQL for querying a postgres database.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\" : [\n",
    "            \"sql\"\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "# Configuration for GPTAssistantAgent\n",
    "config_list = autogen.config_list_from_dotenv(\n",
    "    dotenv_file_path='../../.env',\n",
    "    model_api_key_map={\n",
    "        \"gpt-4-1106-preview\": \"OPENAI_API_KEY\",\n",
    "    },\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4-1106-preview\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize User Proxy Agent\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"./autogen_results\",\n",
    "        \"use_docker\": False\n",
    "    },\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_ASSISTANT_SYSTEM_MESSAGE = \"\"\"\n",
    "You're an elite SQL developer. You generate the most concise and performant SQL queries. Use the  provided tool `run_sql` to run the SQL you've just generated.\"\n",
    "Say TERMINATE when everything is done and the overall task is complete.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_or_create_assistant(test, gpt-4-1106-preview)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.contrib.gpt_assistant_agent:assistant_id was None, creating a new assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to SQL_Assistant):\n",
      "\n",
      "Fulfill this database query: Get the mean age of those who have had covid..  Use these TABLE_DEFINITIONS to satisfy the database query.\n",
      "\n",
      "TABLE_DEFINITIONS\n",
      "\n",
      "CREATE TABLE patients (\n",
      "id integer,\n",
      "patient_id character varying(255),\n",
      "state character varying(2),\n",
      "fips integer,\n",
      "diagnosed_covid boolean,\n",
      "diagnoses_date date,\n",
      "current_age integer,\n",
      "age_at_diagnosis double precision\n",
      ");\n",
      "\n",
      "CREATE TABLE patient_medical_history (\n",
      "id integer,\n",
      "patient_id character varying(255),\n",
      "has_diabetes boolean,\n",
      "has_heart_disease boolean,\n",
      "has_lung_disease boolean,\n",
      "smoker_status character varying(10),\n",
      "bmi double precision,\n",
      "last_checkup_date date\n",
      ");\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION run_sql...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:autogen.agentchat.contrib.gpt_assistant_agent:Intermediate executing(run_sql, Sucess: True) : [\n",
      "    {\n",
      "        \"avg\": \"47.9756097560975610\"\n",
      "    }\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mSQL_Assistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The mean age of patients who have had COVID is approximately 47.98 years. \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "raw_prompt = \"Get the mean age of those who have had covid.\"\n",
    "prompt = f\"Fulfill this database query: {raw_prompt}. \"\n",
    "\n",
    "assistant_name = \"test\"\n",
    "session_id = rand.generate_session_id(assistant_name + raw_prompt)\n",
    "\n",
    "with PostgresAgentInstruments(DB_URL, session_id) as (agent_instruments, db):\n",
    "    \n",
    "    llm_config = {\n",
    "        \"config_list\": config_list,\n",
    "        \"assistant_id\": None,\n",
    "        \"tools\": [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": run_sql_tool_config,\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"gpt-4-1106-preview\"\n",
    "    }\n",
    "\n",
    "    # Initialize the assistant\n",
    "    sql_assistant = GPTAssistantAgent(\n",
    "        name=\"SQL_Assistant\",\n",
    "        instructions=SQL_ASSISTANT_SYSTEM_MESSAGE,\n",
    "        llm_config=llm_config\n",
    "    )\n",
    "\n",
    "    # Register the run_sql function\n",
    "    sql_assistant.register_function(\n",
    "        function_map={\n",
    "            \"run_sql\": db.run_sql\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Get table definitions from Postgres\n",
    "    database_embedder = embeddings.DatabaseEmbedder(db)\n",
    "    table_definitions = database_embedder.get_similar_table_defs_for_prompt(\n",
    "        raw_prompt\n",
    "    )\n",
    "\n",
    "    # Forumalte prompt\n",
    "    prompt = llm.add_cap_ref(\n",
    "        prompt,\n",
    "        f\"Use these {POSTGRES_TABLE_DEFINITIONS_CAP_REF} to satisfy the database query.\",\n",
    "        POSTGRES_TABLE_DEFINITIONS_CAP_REF,\n",
    "        table_definitions,\n",
    "    )\n",
    "\n",
    "    # Initiate autogen chat\n",
    "    user_proxy.initiate_chat(sql_assistant, message=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
