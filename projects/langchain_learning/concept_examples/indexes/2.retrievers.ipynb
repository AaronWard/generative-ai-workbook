{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrievers\n",
    "\n",
    "A Retriever is a component in Langchain that is responsible for finding and returning relevant documents in response to a user's query. Retrievers are typically backed by an index, which is a data structure that stores information about the documents in a corpus. When a user queries a Retriever, the Retriever will use the index to find the documents that are most likely to be relevant to the query, and then return those documents to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Large Language Models (LLMs) are a class of deep learning models designed to process and understand vast amounts of natural language data. \n",
    "They are built on neural network architectures, particularly the transformer architecture, which allows them to capture complex language \n",
    "patterns and relationships between words or phrases in large-scale text datasets. \n",
    "\n",
    "As a matter of fact, LLM can also be understood as variants of transformer.  The transformer architecture relies on a mechanism called self-attention,\n",
    "which allows the model to weigh the importance of different words or phrases in a given context. This has proven to be particularly effective in capturing \n",
    "long-range dependencies and understanding the nuances of natural language. \n",
    "\n",
    "Recall that the transformer architecture represents the neural network model for natural language processing tasks based on encoder-decoder architecture, \n",
    "which was introduced in the paper “Attention Is All You Need” by Vaswani et al. in 2017. The key component of the transformer architecture is \n",
    "the self-attention mechanism, which enables the model to attend to different parts of the input sequence to compute a representation for each position. \n",
    "The transformer consists of two main components: the encoder network and the decoder network. \n",
    "The encoder network takes an input sequence and produces a sequence of hidden states, while the decoder network takes a target sequence and uses the encoder’s \n",
    "output to generate a sequence of predictions. Both the encoder and decoder are composed of multiple layers of self-attention and feedforward neural networks. \n",
    "The picture given below represents the original transformer architecture.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/award40/Desktop/personal/github/ar-assistant/notebooks/research/langchain/3-indexes/2.retrievers.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/ar-assistant/notebooks/research/langchain/3-indexes/2.retrievers.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m CharacterTextSplitter(chunk_size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, chunk_overlap\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/ar-assistant/notebooks/research/langchain/3-indexes/2.retrievers.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39msplit_text(text)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/ar-assistant/notebooks/research/langchain/3-indexes/2.retrievers.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m embeddings \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/ar-assistant/notebooks/research/langchain/3-indexes/2.retrievers.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m db \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39mfrom_documents(texts, embeddings)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/ar-assistant/notebooks/research/langchain/3-indexes/2.retrievers.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m retriever \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mas_retriever()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dev/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(text)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "docs = retriever.get_relevant_documents(\"What does self attention do?\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
