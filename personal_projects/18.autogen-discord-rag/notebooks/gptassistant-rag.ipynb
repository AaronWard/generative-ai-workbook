{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "import autogen\n",
    "import chromadb\n",
    "from pathlib import Path\n",
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "from autogen.retrieve_utils  import query_vector_db, create_vector_db_from_dir\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING VECTOR STORE\n",
    "class ChromaDBManager:\n",
    "    def __init__(self, docs_path, db_path, collection_name):\n",
    "        self.docs_path = Path(docs_path)\n",
    "        self.db_path = Path(db_path)\n",
    "        self.collection_name = collection_name\n",
    "\n",
    "    def setup(self, clear_history=False):\n",
    "        if not self.docs_path.exists():\n",
    "            raise ValueError(f\"The docs directory at {self.docs_path} does not exist.\")\n",
    "        if self.db_path.exists():\n",
    "            if clear_history:\n",
    "                shutil.rmtree(self.db_path)\n",
    "                print(f\"Removed existing directory: {self.db_path}\")\n",
    "                self.client = chromadb.PersistentClient(path=str(self.db_path))\n",
    "                return\n",
    "            # else load in from str(self.db_path)\n",
    "\n",
    "       \n",
    "\n",
    "    def create_vector_db(self, max_tokens=3000, chunk_mode=\"multi_lines\"):\n",
    "        create_vector_db_from_dir(\n",
    "            dir_path=str(self.docs_path),\n",
    "            client=self.client,\n",
    "            collection_name=self.collection_name,\n",
    "            max_tokens=max_tokens,\n",
    "            chunk_mode=chunk_mode\n",
    "        )\n",
    "        print(\"Chroma DB created successfully.\")\n",
    "\n",
    "    def query_db(self, query_texts, n_results=10):\n",
    "        return query_vector_db(\n",
    "            query_texts=query_texts,\n",
    "            n_results=n_results,\n",
    "            client=self.client,\n",
    "            collection_name=self.collection_name\n",
    "        )\n",
    "    \n",
    "    def get_context(self, results):\n",
    "        doc_contents = \"\"\n",
    "        current_tokens = 0\n",
    "        _doc_idx = self._doc_idx\n",
    "        _tmp_retrieve_count = 0\n",
    "        for idx, doc in enumerate(results[\"documents\"][0]):\n",
    "            if idx <= _doc_idx:\n",
    "                continue\n",
    "            if results[\"ids\"][0][idx] in self._doc_ids:\n",
    "                continue\n",
    "            _doc_tokens = self.custom_token_count_function(doc, self._model)\n",
    "            if _doc_tokens > self._context_max_tokens:\n",
    "                func_print = f\"Skip doc_id {results['ids'][0][idx]} as it is too long to fit in the context.\"\n",
    "                print(func_print)\n",
    "                self._doc_idx = idx\n",
    "                continue\n",
    "            if current_tokens + _doc_tokens > self._context_max_tokens:\n",
    "                break\n",
    "            func_print = f\"Adding doc_id {results['ids'][0][idx]} to context.\"\n",
    "            print(func_print)\n",
    "            # print(func_print, \"green\"), flush=True)\n",
    "            current_tokens += _doc_tokens\n",
    "            doc_contents += doc + \"\\n\"\n",
    "            self._doc_idx = idx\n",
    "            self._doc_ids.append(results[\"ids\"][0][idx])\n",
    "            self._doc_contents.append(doc)\n",
    "            _tmp_retrieve_count += 1\n",
    "            if _tmp_retrieve_count >= self.n_results:\n",
    "                break\n",
    "        return doc_contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The docs directory at docs does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chroma_db_manager \u001b[39m=\u001b[39m ChromaDBManager(\u001b[39m'\u001b[39m\u001b[39m./docs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m./chromadb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautogen-discord\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m chroma_db_manager\u001b[39m.\u001b[39;49msetup()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m chroma_db_manager\u001b[39m.\u001b[39mcreate_vector_db()\n",
      "\u001b[1;32m/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocs_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe docs directory at \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocs_path\u001b[39m}\u001b[39;00m\u001b[39m does not exist.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdb_path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/award40/Desktop/personal/github/generative-ai-workbook/personal_projects/18.autogen-discord-rag/notebooks/gptassistant-rag.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         shutil\u001b[39m.\u001b[39mrmtree(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdb_path)\n",
      "\u001b[0;31mValueError\u001b[0m: The docs directory at docs does not exist."
     ]
    }
   ],
   "source": [
    "chroma_db_manager = ChromaDBManager('../data/docs', '../data/chromadb', 'autogen-discord')\n",
    "chroma_db_manager.setup()\n",
    "chroma_db_manager.create_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATIONS\n",
    "config_list = autogen.config_list_from_dotenv(\n",
    "    dotenv_file_path='../../.env',\n",
    "    model_api_key_map={\n",
    "        \"gpt-4-1106-preview\": \"OPENAI_API_KEY\",\n",
    "    },\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4-1106-preview\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "query_vector_db_tool_config = {\n",
    "    \"name\": \"query_vector_db\",\n",
    "    \"description\": \"Function to query the Chroma vector database.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query_texts\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        },\n",
    "        \"required\": [\"query_texts\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "get_context_tool_config = {\n",
    "    \"name\": \"get_context\",\n",
    "    \"description\": \"Function to get the context from query results of the Chroma vector database.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"results\": {\"type\": \"object\"}\n",
    "        },\n",
    "        \"required\": [\"results\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"assistant_id\": None,\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": query_vector_db_tool_config\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": get_context_tool_config\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"gpt-4-1106-preview\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_ASSISTANT_SYSTEM_MESSAGE = \"\"\"As a Retrieve-Augmented Chatbot, your role involves analyzing message history and using that to inform your responses. \n",
    "When a question is presented, you should:\n",
    "Step 1: Determine the user's intent by considering the question and its context. The intent might involve generating code or answering a question, or both.\n",
    "Step 2: Formulate a response based on the identified intent.\n",
    "\n",
    "If the task involves code generation, adhere to the specified coding format. \n",
    "For question-answering tasks, aim for concise and precise responses.\n",
    "\n",
    "\n",
    "For contextual understanding, use the `query_vector_db` tool to access information from the Chroma vector database. \n",
    "Enhance your replies by integrating context extracted from the Chroma DB using the `get_context` function. \n",
    "This approach will provide a well-informed basis for your responses.\n",
    "Say TERMINATE when everything is done and the overall task is complete.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE AGENTS\n",
    "\n",
    "sql_assistant = GPTAssistantAgent(\n",
    "    name=\"Chroma_RAG_Assistant\",\n",
    "    instructions=RAG_ASSISTANT_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "sql_assistant.register_function(\n",
    "    function_map={\n",
    "        \"query_vector_db\": chroma_db_manager.query_db,\n",
    "        \"get_context\": chroma_db_manager.get_context   \n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    is_termination_msg=lambda msg: \"TERMINATE\" in msg[\"content\"],\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3\n",
    ")\n",
    "\n",
    "initial_message = \"What is Autogen?\"\n",
    "user_proxy.initiate_chat(sql_assistant, message=initial_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.send(recipient=sql_assistant, message=\"Explain what the config_list is?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.send(recipient=sql_assistant, message=\"How can you use Chainlit with Autogen\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
