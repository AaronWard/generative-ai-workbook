In issues-and-help, at 2023-11-15 10:41:54 a user named Lega said ```im novice w programming so i may not have explained it in the best way. But I basically am trying to figure out the same thing as this member in the server https://discord.com/channels/1153072414184452236/1153072414184452241/1174253851285667911```.
In issues-and-help, at 2023-11-14 19:49:12 a user named razahin said ```Hi @.beibinli, thank you very much for your offer of assistance. I have attached the two files here. I've also included an example of the output.

The design.jpg files is located under a folder called `coding` which is located at the same level as main.py. 

I've also tried `user_proxy.initiate_chat(designAnalyzer, message="""
Load the image from the <img ./coding/design.jpg> file location for processing by an analyzer""")` in case of there being a location issue but recieved the same results.```.
In issues-and-help, at 2023-11-14 19:01:34 a user named sonichi said ```https://microsoft.github.io/autogen/docs/Installation#python```.
In issues-and-help, at 2023-11-14 18:11:25 a user named ariel.andres said ```Hi, I am trying to run the following example code on my computer:

https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb

If I try to use Autogen 0.1.14 with Openai 0.28.1 (by just using a pip install pyautogen), I get the following error:

raise self.handle_error_response(
openai.error.InvalidRequestError: Invalid URL (POST /v1/openai/deployments/InnovationGPT4-32/chat/completions)

If I instead do a pip install autogen==0.2.0b5 (which also installs Openai 1.2.4), it runs perfectly fine.

This is the structure for my OAI_CONFIG_LIST.json:

[
    {
        "model": "InnovationGPT4-32",
        "api_key": "xxxxx",
        "base_url": "https://innovationopenaiservice.openai.azure.com/",
        "api_type": "azure",
        "api_version": "2023-06-01-preview"
    }
]

The problem is, while it runs fine with Autogen 0.2+ and Openai 1.0+, we are trying to integrate Autogen in a project that already uses Openai 0.27.4, so we would like to use Autogen 0.1.14.```.
In issues-and-help, at 2023-11-14 15:50:34 a user named aaronward_ said ```It was my fault, i didn't format the tool config correctly. Have shared an example notebook here: https://discord.com/channels/1153072414184452236/1173957465285611551```.
In issues-and-help, at 2023-11-14 12:39:00 a user named razahin said ```I've been taking inspiration from the https://github.com/microsoft/autogen/blob/v0.2.0b4/notebook/agentchat_lmm_gpt-4v.ipynb notebook for using GPT4 with vision. Running the examples as written in the notebook works. Passing a public image file, such as one hosted on openAI, also works.

When I attempt to modify the commander, coder, and critic prompts to read a local file I am consistently met with messages like 

`I'm sorry for any confusion, but it appears there may have been a misunderstanding. As an AI text-based interface, I don't have the capability to interpret images or run code.` 

Otherwise the commander coder workflow will often go completely off the rails. 

I'm looking for suggestions on how I should approach feeding an image which is located in the local working directory into the MultimodalConversableAgent. The user prompt I am trying is

```
user_proxy.initiate_chat(designAnalyzer, message="""
Load the image from the design.jpg file location for processing by an analyzer""")
``````.
In issues-and-help, at 2023-11-14 11:56:28 a user named aaronward_ said ```Nevermind, got it working - it was the assistand_id that was messing it up. I passed None and it worked. 

One thing i noticed so far: its fast! it doesn't waste time talking back and foward with the UserProxy before writing the query - potentially saving money on token costs, i'll need to look into this further. It also seems counter intuitive because usually the UserProxy is the one who is executing the code. it's a great addition to autogen from what i can tell so far.```.
In issues-and-help, at 2023-11-14 09:28:20 a user named aaronward_ said ```i'm having issues with my agents not using the provided tool, wondering if someone could give me help - the user proxy keeps trying to run the sql as a file rather than pass it as a string to a python function which is registered.

I'm testing out the new **GPTAssistantAgent** with a postgres sql operation. 

https://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/14.openai-assistant-api/OpenAi-assistant-with-autogen.ipynb```.
In issues-and-help, at 2023-11-14 04:12:31 a user named levre said ```My group chat eventually turns into user_proxy repeatedly calling GPT4 and (I guess?) getting no response so calling it again.  Is there some way to add logic to terminate when this happens?  It appears to be sending the full context every time, so I'm getting charged for input tokens.```.
In issues-and-help, at 2023-11-11 22:40:45 a user named pika.c said ```For now to deal with this I'm creating a new GroupChat object with messages from the previous one and a new GroupChatManager. The problem is that the new agents in the group chat do not have context of what is going on. 
I'm pretty sure there's a better way to go about this. I'll keep experimenting and update this thread if I make any progress.
https://github.com/toshNaik/TaleCraft/tree/main```.
In issues-and-help, at 2023-11-11 19:44:40 a user named ab.z said ```add --pre flag to see pre-releases```.
In issues-and-help, at 2023-11-11 19:42:12 a user named ab.z said ```Because it is not released yet, it is a pre-release```.
In issues-and-help, at 2023-11-11 13:10:24 a user named malicor said ```i'm having this code:

https://pastebin.com/faWpJi6T

but it's still throwing the same error```.
In issues-and-help, at 2023-11-10 04:06:40 a user named reporter said ```https://discord.com/channels/1153072414184452236/1162811675762753589/1171829828232695870

Might be helpful but let me know if it isn't.```.
In issues-and-help, at 2023-11-09 19:20:12 a user named sonichi said ```Check this: https://microsoft.github.io/autogen/docs/Installation#python```.
In issues-and-help, at 2023-11-09 18:46:49 a user named yigitkonur said ```for those who are facing with this issue, here is how I fixed this:

you should install autogen by following command:

```
pip install pyautogen==0.2.0b2
```

here is how to load config to fix this problem:

```
import autogen

config_list = [
    {
        "model": "YOUR_DEPLOYMENT_NAME",  
        "base_url": "https://xxx.openai.azure.com", 
        "api_type": "azure", 
        "api_version": "2023-07-01-preview", 
        "api_key": "xxx"
 }
]
``````.
In issues-and-help, at 2023-11-09 16:06:01 a user named c_bonadio said ```Hi @wadymc I spent some time with function_call and I think I got some reasonable understanding.

I even created an agent that can self execute its own function call
https://gist.github.com/bonadio/96435a1b6ccc32297aa8cc1db7cfc381

Usually we have the user_proxy  -> assistant 

In this case assistant has the function_call definition in the llm_config and user_proxy has the function_map so it knows what "program" to run when the assistant returns the function_call named function.

At this point I was asking myself "why should user_proxy runs the function and not the assistant?". At first I thought it was a bad design and I created the self execution agent. But then I found this example that made me think different
https://github.com/sugarforever/LangChain-Advanced/blob/main/Integrations/AutoGen/autogen_langchain_uniswap_ai_agent.ipynb

Here the assistant receives the result of the function_call from the user_proxy at each iteration and it can "reason about this result" so this back and forth gets richer. 

For a simple use case the assistant could execute the function_call by itself and return the result, but having the user_proxy executing the code and passing the result back to assistant gives the opportunity of the assistant to "think about the result" because the assistant is the one with access to the LLM

Hope that make sense```.
In issues-and-help, at 2023-11-08 16:30:54 a user named c_bonadio said ```Take a look at this gist on the user_proxy code, you could use the search_db function to call your webhook something like that
https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.
In issues-and-help, at 2023-11-08 15:13:22 a user named radman1000 said ```I assume you're talking about the AutoGen api_base URL, right (around 4:43 in your video)? I can't even get nearly that far, since the runpod never exposes the 5001 port. I think the problem is more like @reporter response in https://discord.com/channels/1105681186782707785/1171390227424743514/1171617987346833509.```.
In issues-and-help, at 2023-11-08 00:10:14 a user named heavenlysome said ```This one produced a file```.
In issues-and-help, at 2023-11-07 22:52:48 a user named afourney said ````pip install pyautogen` will give you the latest 0.1 branch while the v0.2s are in beta: https://pypi.org/project/pyautogen/#history```.
In issues-and-help, at 2023-11-07 22:07:48 a user named .jkyh said ```I'm not sure if pip install still gives v.0.1.14, to use the very recent versions say dev/v.0.2.0b3 https://github.com/microsoft/autogen/pull/588.  I usually use the dev docker file set up, which is more complicated than pip install.

A combination of https://github.com/microsoft/autogen/tree/main/.devcontainer and https://code.visualstudio.com/docs/devcontainers/containers would help the setup.```.
In issues-and-help, at 2023-11-07 10:22:04 a user named .jkyh said ```There is a very recent (13 hrs ago) fix for Azure OpenAI in this PR
https://github.com/microsoft/autogen/pull/551```.
In issues-and-help, at 2023-11-06 12:16:38 a user named randomcharshere01 said ```FWiW. When setting up my macbook w/ LM Studio to test local models, I had to change my OAI_CONFIG_LIST file to include the path that Docker understands as my laptop. Using http://localhost:1234/v1 didn't work as the docker image running AutoGen wouldn't recognize it as its localhost. Here's what worked for me: ```  {
        "model": "open-ai",
        "api_base": "http://host.docker.internal:1234/v1",
        "api_key": "NULL"
    } ``````.
In issues-and-help, at 2023-11-06 01:59:33 a user named 47h4rv4 said ```{```
groupchat = autogen.GroupChat(agents=[user_proxy, coder, critic], messages=[], max_round=20) manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)}
user_proxy.initiate_chat(manager, message="download data from https://xyz.com and plot a visualization and save it
```


1) So esentially it's a RoundRobin taking place in the order initialised  first proxy speaks, then coder, then critic, --> this is 1 round right(all speaking)?

2) I wanted to understand in more detail difference between GroupChat and GroupChatManager, 
Like GroupChat itself is doing- Maintaining the ordered list of participant agents
Handling the round-robin messaging flow between agents,
Keeps track of full message history, So what does GroupChatManager do, is it like API wrapper for these(  providing send and receieve messages)

3) What is the use of Select Speaker in GroupChat if order is already predecided in the initialisation list?( is it like If a agent may have generated a reply that involves selecting a particular speaker)****```.
In issues-and-help, at 2023-11-05 23:59:16 a user named rainmert said ```I'm getting the error in the screenshot. The same configuration works inside a .py file but when executed from the .ipynb cell, when the agent tries to execute a generated code, I get this error and Docker Desktop is not being used.```.
In issues-and-help, at 2023-11-05 16:11:09 a user named ivangabriele said ```You can use  `--extensions` for that: https://github.com/oobabooga/text-generation-webui#basic-settings. But if your goal is to load the LLM and start an OpenAI API automatically I would rather go [this road](https://github.com/ivangabriele/docker-llm).```.
In issues-and-help, at 2023-11-05 12:13:26 a user named aaronward_ said ```Don't provide a function configuration to the user proxy. Register then with the use proxy to call them using `user_proxy.register_function`. See this notebook: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In issues-and-help, at 2023-11-04 19:07:28 a user named code.ninja said ```Might be simplier than that. https://microsoft.github.io/autogen/docs/FAQ#why-is-code-not-saved-as-file```.
In issues-and-help, at 2023-11-04 18:51:44 a user named filip7241 said ```I am trying to run example 
- https://github.com/microsoft/autogen/blob/main/notebook/agentchat_chess.ipynb

with GPT-4 or GPT-3.5 hosted from AZURE AI

my endpoit form azure is: https://eu-swiz.openai.azure.com/openai/deployments/gpt/chat/completions?api-version=2023-07-01-preview

In configuration I have tryied to use: 
- https://eu-swiz.openai.azure.com
- https://eu-swiz.openai.azure.com/
- https://swiz.openai.azure.com/openai/deployments/gpt/chat/completions

My config entry: 

```
{
        "model": "gpt-4",
        "api_key": "XXX",
        "base_url": "https://eu-swiz.openai.azure.com",
        "api_type": "azure",
        "api_version": "2023-07-01-preview"
    }
```


Error I am getting is: 
InvalidRequestError: Invalid URL (POST /v1/openai/deployments/gpt-4/chat/completions)

Completions endpint path is different than azure one. I cannot find it configurable. 


On the other hand when I try to run example with gpt-3.5-turbo form open AI I get different error: 
```TypeError: 'NoneType' object is not subscriptable``````.
In issues-and-help, at 2023-11-03 18:17:28 a user named afourney said ```Here is a good description: https://github.com/microsoft/autogen/issues/414#issuecomment-1779617789```.
In issues-and-help, at 2023-11-02 23:32:37 a user named junkboi76 said ```for some reason its starting and stopping I have the model loaded and api set up on text gen but the script is just starting and stopping```.
In issues-and-help, at 2023-11-02 21:46:39 a user named _revolution said ```Here is a video showing what's happening```.
In issues-and-help, at 2023-11-02 19:49:14 a user named genericrich said ```My code is modeled on this: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb

Basically it is the same, except mine is just trying to get the LLM to call a function to execute a shell script.

The Error is: 

 File "/Users/rver/Desktop/projects/autogen/test3.py", line 97, in <module>
    user_proxy.initiate_chat(
  File "/Users/rver/Desktop/projects/autogen/autogen/agentchat/conversable_agent.py", line 531, in initiate_chat
    self.send(self.generate_init_message(**context), recipient, silent=silent)
  File "/Users/rver/Desktop/projects/autogen/autogen/agentchat/conversable_agent.py", line 334, in send
    recipient.receive(message, self, request_reply, silent)
  File "/Users/rver/Desktop/projects/autogen/autogen/agentchat/conversable_agent.py", line 464, in receive
    self.send(reply, sender, silent=silent)
  File "/Users/rver/Desktop/projects/autogen/autogen/agentchat/conversable_agent.py", line 334, in send
    recipient.receive(message, self, request_reply, silent)
  File "/Users/rver/Desktop/projects/autogen/autogen/agentchat/conversable_agent.py", line 462, in receive
    reply = self.generate_reply(messages=self.chat_messages[sender], sender=sender)
  File "/Users/rver/Desktop/projects/autogen/autogen/agentchat/conversable_agent.py", line 781, in generate_reply
    final, reply = reply_func(self, messages=messages, sender=sender, config=reply_func_tuple["config"])
  File "/Users/rver/Desktop/projects/autogen/autogen/agentchat/conversable_agent.py", line 700, in check_termination_and_human_reply
    elif self._is_termination_msg(message):
  File "/Users/rver/Desktop/projects/autogen/test3.py", line 59, in <lambda>
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
AttributeError: 'NoneType' object has no attribute 'rstrip'

I get that the user_proxy is checking if the message has the word TERMINATE in it, or...something. Any ideas?```.
In issues-and-help, at 2023-11-02 16:56:27 a user named jlcases said ```https://microsoft.github.io/autogen/docs/FAQ/#handle-rate-limit-error-and-timeout-error```.
In issues-and-help, at 2023-11-02 14:44:44 a user named sonichi said ```It'll be a client-based approach used by openai v1. The PR is here: https://github.com/microsoft/autogen/pull/393. You can check the migration guide in installation.md```.
In issues-and-help, at 2023-11-01 23:16:18 a user named afourney said ```In addition to that, I would point out that some of the agents, like the AssistantAgent have default prompts... but we routinely add to them to suit our need. For example, with the Research Assistant (PR https://github.com/microsoft/autogen/pull/509), we append to the prompt to add either personalization, or a library of skills: https://github.com/pcdeadeasy/autogen-oss/blob/899b43275df7b1b85ecfa32170c9f64b2ac3fb36/samples/apps/research-assistant-react/backend/raworkflow/ratwoagentworkflow.py#L53```.
In issues-and-help, at 2023-11-01 16:07:14 a user named mlops.v2_18177 said ```What I did so far is in code.py if that helps/make sense

This works fine on the flow but gets to the level shown in the screenshot and then ask for user input (I guess because mine is on ALWAYS) rather annoying.. if I can automatically go to next step (i.e: get it to reply with a joke without further user input), that would be great.
I might ask this on general again and see what I get```.
In issues-and-help, at 2023-11-01 14:00:17 a user named mythos42 said ```Hi, i tried the basic example for using a teachable agent from "https://microsoft.github.io/autogen/blog/". Chat starts, I tell my name and some other info I want the agent to remember and close the conversation with "exit". unfortunately afterwards i get a time out error. Full error msg below. Could you give me a hint, what is wrong and how to fix this?```.
In issues-and-help, at 2023-11-01 08:25:46 a user named Spore said ```https://github.com/microsoft/autogen/issues/513
Filed an issue on GitHub; don't know how to fix some of them without touching very fundamental interfaces (like the ridiculous case of subclass not having the same signature as its parent), otherwise I'd open a PR for it```.
In issues-and-help, at 2023-11-01 08:23:19 a user named Spore said ```Imo this greatly hinders productivity when using the library. Look at this screenshot: `run_chat` has a wrong return type signature and bugs that are obvious under type checks.```.
In issues-and-help, at 2023-10-31 16:07:32 a user named sonichi said ```@mauriziosantamicone_16029 we are merging this PR that may be related to your use case: https://github.com/microsoft/autogen/pull/87```.
In issues-and-help, at 2023-10-31 14:37:30 a user named li_jiang said ```@kylepancamo Could you help review this PR for adding support to unstructrued https://github.com/microsoft/autogen/pull/501 ? Thanks.```.
In issues-and-help, at 2023-10-31 07:19:51 a user named Mr_N0obody said ```Following the code given on the HF demo [https://huggingface.co/spaces/thinkall/autogen-demos], I modified the code so that it will run a local intanse using text-generation webui. however, when I start chatting, the response I get is always "Collection autogen-docs already exists" (Image1), console log shows the same (image2). I know for a fact that my config for the local url works since I've tried using app2.py.

I attached both app.py (my main app) and app2.py (for testing and verifying API connection).```.
In issues-and-help, at 2023-10-31 02:31:29 a user named jdo300 said ```I created an autrogen program that is based on a combination of examples. My goal is to create a progamming and debugging team that can also read documentation that I provide so I can give it instructions to write and debug scripts I'm working on. The program seems to work flawlessly (as in the agents are doing what I want (mostly) except whenever I need to reply to something, the program quits without any error and I'm not sure why. I'm guessing it is something I'm doing wrong with my setup, but was wondering if someone could quickly glance over my code and see if they can spot the issue? I'm still getting my head around how to properly set up the agents (particularly the RAG agents) so let me know if you see some bad practices happening there too. My script fille is included for reference.```.
In issues-and-help, at 2023-10-30 09:56:49 a user named .jkyh said ```I have worked on a PR that is related to your point 3, hope its useful to you.
https://github.com/microsoft/autogen/pull/482```.
In issues-and-help, at 2023-10-29 22:05:06 a user named rickyloynd said ```I would try the RAG agents for this. https://microsoft.github.io/autogen/blog/2023/10/18/RetrieveChat```.
In issues-and-help, at 2023-10-29 19:30:27 a user named niko9035 said ```I have managed to create an article writer with fact checker based on FAISS vectorstore: https://niko-gamulin.medium.com/the-autonomous-orchestra-of-ai-with-autogen-beyond-solo-performances-3be1a0553e8b```.
In issues-and-help, at 2023-10-29 18:35:40 a user named sebastiankmedinet said ```@synco This is what we were looking for: https://www.youtube.com/watch?v=Z1Z0E59VFdw```.
In issues-and-help, at 2023-10-29 12:58:05 a user named jkorani said ```for me was enough changing this in LMStudio from 2k and up```.
In issues-and-help, at 2023-10-28 17:34:28 a user named wadymc said ```Hi guys, 
I just reviewed that example https://github.com/microsoft/autogen/blob/main/notebook/agentchat_langchain.ipynb

My question, why functions map is defined for user_proxy not for assistant? How to split the tools which should be used by different agent? Lets say agent1 has access to func1, func2. Agent2 - func3, func4 etc. Same with knowledge base.

# Register the tool and start the conversation
user_proxy.register_function(
    function_map={
        custom_tool.name: custom_tool._run,
        read_file_tool.name: read_file_tool._run,
    }
)

chatbot = autogen.AssistantAgent(
    name="chatbot",
    system_message="For coding tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done.",
    llm_config=llm_config,
)```.
In issues-and-help, at 2023-10-28 17:22:16 a user named rickyloynd said ```Yes, see our new TeachableAgent, which learns from previous conversations. https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent```.
In issues-and-help, at 2023-10-28 17:08:27 a user named jjjjakb said ```@fran.abenza I believe that is in the llm config under "use_cache" for prev runs, for RAG in the retrieve_config you can define context_max_tokens, may be what you are after
https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/retrieve_user_proxy_agent

https://microsoft.github.io/autogen/docs/reference/oai/completion#create```.
In issues-and-help, at 2023-10-28 11:58:40 a user named assafe said ```More specifically I'd like to showcase autogen in the open source gpt-researcher (https://github.com/assafelovic/gpt-researcher) as one of many agents working together. I've seen mostly examples for prompting agents but looking to use agents as "tools" within autogen. How can i achieve that? Thanks!```.
In issues-and-help, at 2023-10-28 03:37:41 a user named afourney said ```Related issue: https://github.com/microsoft/autogen/issues/414```.
In issues-and-help, at 2023-10-27 22:13:02 a user named c_bonadio said ```Autogen with FastApi backend and React frontend
https://github.com/bonadio/autogenwebdemo```.
In issues-and-help, at 2023-10-27 07:44:01 a user named giammy677 said ```Sure. I emulate an ideal chat right inside the chat integrated in LM Studio. I report a screenshot of the chat history obtained interacting directly with the model.

Then, I attach the txt obtained interacting with the same model using AutoGen and the code to obtain it. Can you check if I'm missing something?

Another question: I had the request_reply parameter not set (default is None) but I equally obtained replies from the AssistantAgent as if I set it to True. Why? Whis is the difference?

Thanks in advance 🙂```.
In issues-and-help, at 2023-10-27 05:39:41 a user named .jkyh said ```The current logic is in https://github.com/microsoft/autogen/blob/main/autogen/agentchat/groupchat.py
The controlling of agent sequence is discussed in https://www.youtube.com/watch?v=4o8tymMQ5GM&list=PLS_o2ayVCKvDE3JBkGRq3PbnPNk6ifTrh&index=18

Hope this helps. 🙂```.
In issues-and-help, at 2023-10-27 05:32:18 a user named bigmiao said ```> One challenge is determining how to conclude the conversation once all agents have addressed their concerns.
To address this, you can create a `terminate_chat` function call for the agent which you want to terminate the group conversation

> Additionally, I'd like one of the agents to summarize the conversation's conclusions once consensus is achieved. This summary should be packaged in a JSON format for use in the second group chat. Finally, I'd like to print "TERMINATE" to signal the end of the first chat and the start of the second.
In that `terminate_chat` function call, you can put a `summary` parameter and make that field `required`. In the meantime, you can also add `TERMINATE` as prefix or suffix

You can check this PR for how to add `terminate_chat` function call to one of group chat agent and has it terminate group chat.
https://github.com/microsoft/autogen/pull/309/files#diff-bdace63aa34845cb7fed2436a9e7cc3252ce4e36f00c503ea2866242563a8cc8R84

Once the first group chat is terminated, you can locate the terminate message using `TERMINATE` prefix and retrieve summary```.
In issues-and-help, at 2023-10-26 20:15:36 a user named afourney said ```You can pass the name of the image in the use_docker parameter of the code_execution_config passed to the agent. I believe if the named docker image is available locally, it will use it. https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent  


That config eventually gets passed to the execute code function in code_utils.py: https://github.com/microsoft/autogen/blob/50ac5476377c1b41330589a6cfc5c4e65b93079f/autogen/code_utils.py#L216  The default images are specified here: https://github.com/microsoft/autogen/blob/50ac5476377c1b41330589a6cfc5c4e65b93079f/autogen/code_utils.py#L341C8-L341C70```.
In issues-and-help, at 2023-10-26 19:33:02 a user named bighadj said ```Hey everyone! 🙏 I'm running into an issue when trying to use RAG https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb

. Here's the traceback:

Traceback (most recent call last):
  File "C:\Users\bmans\Desktop\me\app.py", line 2, in <module>
    from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent
  File "C:\Users\bmans\anaconda3\Lib\site-packages\autogen\agentchat\contrib\retrieve_user_proxy_agent.py", line 9, in <module>
    from autogen.retrieve_utils import create_vector_db_from_dir, query_vector_db, num_tokens_from_text
  File "C:\Users\bmans\anaconda3\Lib\site-packages\autogen\retrieve_utils.py", line 8, in <module>
    from chromadb.api import API

It seems like there's some problem with importing `chromadb.api`. Has anyone faced this before or has any idea how to resolve it? Thanks in advance! 🙌```.
In issues-and-help, at 2023-10-26 15:53:33 a user named kistar2413 said ```## Good day to everyone! 

Firstly — great work! Autogen is truly a masterpiece. I had some free time to configure the environment and play with it. I've encountered the problem described here:
https://github.com/microsoft/autogen/issues/238
with proposed solution here:
https://github.com/microsoft/autogen/issues/156

Beside the current roadmap, which seems to be essential either way, I've discovered something which also may be helpful. 

When autogen works with LM Studio or with text-generation-webui, loading the model using lama.cpp for generation, the graphics card is not being used. 

When I loaded the network using ctransformers, not only the graphics card started to be used for generation, but also the error regarding the token limit has not appeared to me since yesterday. Would any of you be able to confirm this behavior? After changing the loader, I removed the application cache and changed the config to use docker, I don't know if this can have any effect.

I use TheBloke_Mistral-7B-v0.1-GGUF
Cheers!```.
In issues-and-help, at 2023-10-26 15:22:30 a user named supermalinge said ```even chaging the config of the model, the api still remains the same```.
In issues-and-help, at 2023-10-26 01:06:29 a user named li_jiang said ```Nice chart! @fran.abenza Overall, this chart captured most of the logic and flows. Reading the chart itself, what happens if no for this:```.
In issues-and-help, at 2023-10-25 20:10:42 a user named fran.abenza said ```small typo " missing on Update Context```.
In issues-and-help, at 2023-10-25 20:10:05 a user named Phenikx said ```python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(


please assist```.
In issues-and-help, at 2023-10-25 20:07:47 a user named fran.abenza said ```I am a little bit confused about how the Retrieval-Augmented User Proxy & Retrieval-Augmented Assistant work together. is this correct? @li_jiang```.
In issues-and-help, at 2023-10-25 10:25:53 a user named maxgustaw said ```Hi all,

I'm currently working on a tool designed for planning the implementation of new products within my company. The concept involves two group chats using AutoGen.

In the first chat, participants include the Project Manager, Architect, and Reviewer. Their primary responsibility is to understand the user's objectives, reflect on them, and then propose a solution.

The second chat comprises three coder agents, each responsible for creating different types of diagrams.

While my code has been largely effective, there are a few issues I need help resolving. One challenge is determining how to conclude the conversation once all agents have addressed their concerns. I've attempted to expand the system_message for the user_proxy, but it hasn't been successful. Does anyone have any suggestions on how to approach this problem?

Additionally, I'd like one of the agents to summarize the conversation's conclusions once consensus is achieved. This summary should be packaged in a JSON format for use in the second group chat. Finally, I'd like to print "TERMINATE" to signal the end of the first chat and the start of the second.

Last question, is there any suggestions on the optimal lenghts of the system_message for the agents?

Thank you to anybody who has read this, any help is appricated!```.
In issues-and-help, at 2023-10-25 08:37:04 a user named supermalinge said ```even with setup mistral 16k token model, the issues persists```.
In issues-and-help, at 2023-10-24 18:46:17 a user named qingyunwu said ```Did you try the python:3 docker image? That one works well based on feedback we get from the others. Check this page for an example how to use python:3 docker image in AutoGen: https://microsoft.github.io/autogen/docs/FAQ#enable-python-3-docker-image```.
In issues-and-help, at 2023-10-24 14:07:54 a user named supermalinge said ```roadmap for token limit issue: https://github.com/microsoft/autogen/issues/156?utm_source=pocket_saves```.
In issues-and-help, at 2023-10-24 13:28:17 a user named 1_twisto said ```Hello everyone,

I'm currently working on a project where I have set up a conversation agent designed to orchestrate interactions in a chat environment. The agent is supposed to guide the flow of the conversation, respond to user inputs, and ensure a smooth and coherent dialogue.

However, I've encountered some challenges in verifying whether the agent is performing as expected, and I am seeking advice on effective debugging methods to analyze and optimize its performance.

Here are some details about the setup:

The conversation agent interacts with users in different roles.
It responds to user inputs based on predefined scripts and generates replies.
Questions:

What debugging methods or tools would you recommend for analyzing the conversation flow and identifying any potential issues?

Are there specific logs or metrics that I should pay close attention to, which could provide insights into the agent’s performance and decision-making process?

If you have experience with conversation agents, could you share any tips or best practices for ensuring that they are correctly set up to orchestrate the conversation?

I appreciate any guidance or suggestions you can provide. Thank you in advance for your help!```.
In issues-and-help, at 2023-10-24 12:26:13 a user named supermalinge said ```open the llm web ui from the http://127.0.0.1:7860 and check if you can execute a small prompt```.
In issues-and-help, at 2023-10-24 11:56:16 a user named supermalinge said ```import autogen #start importing the autogen lib

config_list = [
    {
        "model": "mistral-instruct-7b", #the name of your running model
        "api_base": "http://127.0.0.1:5001/v1", #the local address of the api
        "api_type": "open_ai",
        "api_key": "sk-111111111111111111111111111111111111111111111111", # just a placeholder
    }
]

# create an ai AssistantAgent named "assistant"
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config={
        "seed": 42,  # seed for caching and reproducibility
        "config_list": config_list,  # a list of OpenAI API configurations
        "temperature": 0,  # temperature for sampling
        "request_timeout": 400, # timeout
    },  # configuration for autogen's enhanced inference API which is compatible with OpenAI API
)

# create a human UserProxyAgent instance named "user_proxy"
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10, 
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={
        "work_dir": "agents-workspace", # set the working directory for the agents to create files and execute
        "use_docker": False,  # set to True or image name like "python:3" to use docker
    },
)

# the assistant receives a message from the user_proxy, which contains the task description
user_proxy.initiate_chat(
    assistant,
    message="""Create a posting schedule with captions in instagram for a week and store it in a .csv file.""",
)```.
In issues-and-help, at 2023-10-24 11:49:46 a user named rafa_1 said ```from https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb```.
In issues-and-help, at 2023-10-24 11:49:36 a user named 1_twisto said ```Logging is Experimental 

https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logging-experimental```.
In issues-and-help, at 2023-10-24 11:19:40 a user named supermalinge said ```do you have the basic config in your python code? # Use the local LLM server as before
config_list = [
    {
        "model": "mistral-instruct-7b",  # the name of your running model
        "api_base": "http://127.0.0.1:5001/v1",  # the local address of the API
        "api_type": "open_ai",
        "api_key": "sk-111111111111111111111111111111111111111111111111",  # just a placeholder
    }
]```.
In issues-and-help, at 2023-10-24 11:19:06 a user named supermalinge said ```that is correct, the api base is :  "api_base": "http://127.0.0.1:5001/v1",  # the local address of the API```.
In issues-and-help, at 2023-10-24 08:19:06 a user named supermalinge said ```Hey guys, im trying to set a limit for the max tokens send to the local llm via autogen. Anyone able to assist here?

main idea:

# Calculate the current token count of the conversation
current_token_count = num_tokens_from_messages(groupchat.messages, selected_model)

# Ensure that the token count doesn't exceed the model's token limit
if current_token_count > max_token_limit:
    print("Conversation exceeds the token limit for the selected model.")
    # Handle the restriction, such as truncating or removing messages.
else:
    # Continue with the conversation
    user_proxy.send_message("Your message here")

yet the issue is:

the chat starts with: # Start the "group chat" between agents and humans
groupchat = autogen.GroupChat(agents=[user_proxy, engineer, scientist, planner, executor, critic], messages=[], max_round=50)

how do i make a check before the agents send a message to the LLM?

source: https://hackernoon.com/beep-beep-bop-bop-how-to-deploy-multiple-ai-agents-using-local-llms```.
In issues-and-help, at 2023-10-24 00:29:59 a user named sonichi said ```maybe this PR can solve the signal() issue: https://github.com/microsoft/autogen/pull/224```.
In issues-and-help, at 2023-10-23 22:36:10 a user named e404nothing said ```I didn't no, here is some others looking for help: 
https://github.com/microsoft/autogen/issues/279```.
In issues-and-help, at 2023-10-23 22:13:02 a user named aaronward_ said ```Streamlit is intended to be single-threaded, and agents need to have the main thread to execute code. I've been through this struggle. See here: https://discord.com/channels/1153072414184452236/1162889648490684467```.
In issues-and-help, at 2023-10-23 13:03:10 a user named li_jiang said ```Have you read this notebook https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_RAG.ipynb ?```.
In issues-and-help, at 2023-10-23 12:56:56 a user named sonichi said ```This PR shows an example how I modified the `select_speaker` for better control: https://github.com/microsoft/autogen/pull/294
It make changes to the library due to its generality. You can do it outside of the library by inheriting the GroupChat class and define your own method.```.
In issues-and-help, at 2023-10-23 12:05:02 a user named sonichi said ```There is debate in https://github.com/microsoft/autogen/issues/217. Would you like to chime in?```.
In issues-and-help, at 2023-10-23 01:25:09 a user named 1_twisto said ```I have found some trouble to install pip install pyautogen.

it's due : https://github.com/openai/openai-python/issues/645```.
In issues-and-help, at 2023-10-22 23:14:06 a user named sonichi said ```https://github.com/microsoft/autogen/issues/251```.
In issues-and-help, at 2023-10-22 22:19:57 a user named sonichi said ```Examples using function call: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb
Example using group chat:
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_vis.ipynb
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb```.
In issues-and-help, at 2023-10-22 22:17:38 a user named sonichi said ```https://github.com/microsoft/optiguide
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_chess.ipynb```.
In issues-and-help, at 2023-10-22 20:04:30 a user named sonichi said ```https://microsoft.github.io/autogen/docs/FAQ#why-is-code-not-saved-as-file```.
In issues-and-help, at 2023-10-21 10:16:12 a user named .jbdc said ```A promising approach is a recent project named MemGPT, that aimes to give existing LLMs a infinite (!) context length ! They are at an early stage to integrate MemGPT with AutoGen even, so that could become the solution to overly restrictive context length.    THE CREATORS OF MEMGPT https://memgpt.ai/ HAVE THE INTENTION OF INTEGRATING MEMGPT WITH AUTOGEN ACCORDING TO THE VIDEO ! :

https://youtube.com/watch?v=QQ2QOPWZKVc&si=pkXTK7j8Ppki0hsu

31:49 INTO THIS VIDEO ! : INTEGRATE FRAMEWORK SUCH AS AUTOGEN !


…


Roadmap for handling context overflow · Issue #156 · microsoft/autogen
https://github.com/microsoft/autogen/issues/156#issuecomment-1773670222

Integration with AutoGen · cpacker/MemGPT · Discussion #65
https://github.com/cpacker/MemGPT/discussions/65

cpacker5 hours ago

We just added some basic AutoGen integration! #64

We're still working on cleaning up the workflow (adding better MemGPT-AutoGen constructors that better match the config file style of AutoGen), but since it seems like a lot of people want AutoGen support we thought it's best to release what we have for now and add to it as we go.
LOOKS PROMISING TO ME !```.
In issues-and-help, at 2023-10-20 15:32:37 a user named .jbdc said ```How to set up docker on Windows and Linux for AutoGen as recommended in the docs for code execution? I have no experience with docker whatsoever !

See:

https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#use_docker



https://microsoft.github.io/autogen/docs/Installation/

Optional Dependencies
* docker

For the best user experience and seamless code execution, we highly recommend using Docker with AutoGen. Docker is a containerization platform that simplifies the setup and execution of your code. Developing in a docker container, such as GitHub Codespace, also makes the development convenient.

When running AutoGen out of a docker container, to use docker for code execution, you also need to install the python package docker:

pip install docker


…


https://microsoft.github.io/autogen/docs/FAQ#code-execution

…


https://github.com/microsoft/autogen/issues/239#issuecomment-1766273498

schoenia commented 3 days ago

got it sorted:
installing docker for windows (using wsl) updating wsl --> wsl --update installing plugin in pycharm
works!```.
In issues-and-help, at 2023-10-20 00:40:03 a user named lawrence324 said ```I'm using an Anaconda environment with Autogen ChatGPT / Amazon BedRock (Claude2) via LiteLLM. I've created 2 agents and a user_proxy. One agent is the writer & the other is the editor. I've given them instructions to come up with an outline for a children's short story. The theme choice & chapter outline needs approval from the User_Proxy. The theme should be approved by the Admin before the writer starts creating the outline and content. However, when the chat starts the editor agent just picks a theme on it's own and starts to write an outline. I have 3 questions:

1. How do I control the interaction between the agents?
2. I'm noticing that the responses in the terminal are being truncated, however I can see the full response in the LiteLLM proxy console. I'm not sure if that's a LiteLLM configuration change or a change in the Autogen code I need to address. 
3. If I want to save the outline & content that has been generated, how do I go about doing that? I'm assuming the User_Proxy would need to be configured to save the results to a txt file? I do have docker installed via pip (along with Windows Desktop Docker), but have it set to "False" in the User_Proxy section of the code for now.

Finally, I do have some previous DevOps experience but am mostly an AWS infrastructure/architecture guy - not a developer. So please be patient. 🙂 Thanks!```.
In issues-and-help, at 2023-10-19 17:32:07 a user named churchofaddon said ```pip install litellm  then run to get the proxy server running on your local machine litellm --model huggingface/oh-yeontaek/llama-2-7B-LoRA-assemble --api_base https:/XXXXXeast-1.aws.endpoints.huggingface.cloud      Then test with this.   curl -X POST -H "Content-Type: application/json" -d '{
  "model": "huggingface/oh-yeontaek/llama-2-7B-LoRA-assemble",
  "messages": [
    {"role": "system", "content": "You are a helpful coding assistant."},
    {"role": "user", "content": "What is the latest version of Python?"}
  ]
}' http://0.0.0.0:8000/chat/completions

All on my own Models and it still is charging me```.
In issues-and-help, at 2023-10-19 17:29:44 a user named churchofaddon said ```I have it running with this [
    {
        "model": "huggingface/oh-yeontaek/llama-2-7B-LoRA-assemble",
        "api_base": "http://0.0.0.0:8000/chat/completions/v1",
        "api_type": "open_ai",
        "api_key": "NULL"

    }
]
And the damn thing is still charging me! pip install litellm  then run to get the proxy server running on your local machine litellm --model huggingface/oh-yeontaek/llama-2-7B-LoRA-assemble --api_base https:/XXXXXeast-1.aws.endpoints.huggingface.cloud      Then test with this.   curl -X POST -H "Content-Type: application/json" -d '{
  "model": "huggingface/oh-yeontaek/llama-2-7B-LoRA-assemble",
  "messages": [
    {"role": "system", "content": "You are a helpful coding assistant."},
    {"role": "user", "content": "What is the latest version of Python?"}
  ]
}' http://0.0.0.0:8000/chat/completions```.
In issues-and-help, at 2023-10-19 17:00:22 a user named josephlindley said ```Hi,

I'm really curious whether it is possible to create a set of AutoGen agents to help me in writing tasks. The two contexts I am thinking about is help in writing research funding applications and help in writing academic papers (I work at a University - could you guess?!)

While LLMs are useful for this already, context window size can be a problem - I wonder whether AutoGen could help by executing code and saving that out to files as needed, but keeping the ability to re-open a specific file if instructed to do so, so that context could be 'restored'.

The other aspect that would be useful to is to, when focusing on writing a particular part of a document, use the 'synergy of experts' type approach that 'Professor Synapse' (https://github.com/ProfSynapse/Synapse_CoR) does in order to iteratively fine tune the text until it is approved by the human.

I have had a go at this already, but I couldn't quite figure out what a reasonable structure would be for agents, files, prompts, etc.

Does anyone have a suggestion about how one might set this kind of thing up?

Thanks! <:assistant:1159659406498222100> 🤟```.
In issues-and-help, at 2023-10-19 16:56:04 a user named churchofaddon said ```Is this a requirement? Exception has occurred: AuthenticationError
No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.
  File "/Users/dude/agentchat_human_feedback.py", line 82, in <module>
    user_proxy.initiate_chat(
openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.```.
In issues-and-help, at 2023-10-19 13:18:31 a user named morrisclay said ```Hi all,

I am new to autogen and am trying to create a simple website classifier which visits a website and chooses from a list of categories the most fitting (on none if none fits)

my current code:

```
category_list = ["apple", "peach", "nlp"]

config_list = [
        {
       "model": "gpt-4",
       "api_key": "***"
        }
    ]

llm_config={
        "request_timeout": 600,
        "seed": 42,
        "config_list": config_list,
        "temperature": 0,
        "retry_wait_time": 200
    }

# create an AssistantAgent instance named "assistant"
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
)
# create a UserProxyAgent instance named "user_proxy"
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=2,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "web"},
    llm_config=llm_config,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet."""
)

user_proxy.initiate_chat(
    assistant,
    message="""
given the below list of categories, does this website fit into any of these and if so which ones? https://deepset.ai"
"""+str(category_list),
)
```

I am wondering how
- to make this code more robust and make sure i don't run into token rate limits (happens often)
- maybe how to introduce a q&A agent (
- and how to get a structured output which i can safe a list of categories in a variable


thanks in advance for any help!
best, mocl```.
In issues-and-help, at 2023-10-19 09:29:08 a user named li_jiang said ```@vswraith I think this is doable, check out this example https://huggingface.co/spaces/thinkall/autogen-demos, you can extract messages from any agent's chat_messages property.```.
In issues-and-help, at 2023-10-18 16:48:02 a user named amin.t.t2 said ```Can you help me ?
I have this ereur```.
In issues-and-help, at 2023-10-17 23:44:01 a user named ivangabriele said ```Also just a note: if you try to open `https://xxxxx-5001.proxy.runpod.net/` in a browser, getting a 404 is normal (and a good sign)```.
In issues-and-help, at 2023-10-17 18:32:54 a user named bansalg said ```https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In issues-and-help, at 2023-10-17 15:59:21 a user named sonichi said ```@li_jiang made a PR to demo how to solve this issue: https://github.com/microsoft/autogen/pull/227
Could @.vrda @satya_1987 take a look? Thanks.```.
In issues-and-help, at 2023-10-17 15:49:23 a user named syndicate_47 said ```I want to run AutoGen without using openai.com. The best way I know to this is by using "TheBloke Local LLMs One-Click UI and API" on RunPod. I enable the openai extension and successfully load the model, but get these errors in the logs:
OpenAI compatible API ready at: OPENAI_API_BASE=http://0.0.0.0:5001/v1
100.99.99.99 - - [17/Oct/2023 15:35:54] code 404, message Not Found
100.99.99.99 - - [17/Oct/2023 15:35:54] "GET /v1/chat/completions HTTP/1.1" 404 -
127.0.0.1 - - [17/Oct/2023 15:45:47] code 404, message Not Found
127.0.0.1 - - [17/Oct/2023 15:45:47] "GET /v1 HTTP/1.1" 404 -```.
In issues-and-help, at 2023-10-17 12:29:27 a user named aaronward_ said ```https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb```.
In issues-and-help, at 2023-10-17 09:46:18 a user named danoandco said ```Hi! Just saw this thread! These are great sample repos.

If you want to have an out-of-the-box UI, you can try Chainlit (https://github.com/Chainlit/chainlit) - built using FastAPI, WebSockets and React frontend - which is async.

Here is an example by a member of the Autogen community https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen

Feedback on dev experience would be very much appreciated!!```.
In issues-and-help, at 2023-10-17 06:23:10 a user named rebecca0258 said ```Hello,

I've encountered an issue while working with the Azure OpenAI API, specifically related to the API URL. The error message I'm receiving indicates that the URL is a placeholder ("<your Azure OpenAI API base here>") and that there's an issue with it. It seems that some part of my code is still referencing this placeholder instead of a valid API URL.

I've double-checked my configuration and credentials, and they appear to be correct. Could someone please provide guidance on how to correctly set the API URL or troubleshoot this issue? Any assistance would be greatly appreciated.

I only use OpenAI API....```.
In issues-and-help, at 2023-10-17 06:10:52 a user named ivangabriele said ```_Don't worry I already killed my pod in case anybody would attempt to use my pod ID 😉 ._```.
In issues-and-help, at 2023-10-17 06:06:41 a user named ivangabriele said ```You can simply use [my project repo](https://github.com/ivangabriele/openai-autogen-dev-studio) to check that it works. I just created a "simplified" version on a specific branch to show how it works:

1. Deploy **RunPod TheBloke LLMs**  on RunPod as you usually do, downloading and loading `Open-Orca/Mistral-7B-OpenOrca`.
2. Activate the `openai` extension in TGWUI (with "Apply and restart")
3. Expose your HTTP `5001` port on your pod (since the OpenAI-Compatible API is served via `5001`)
4. Clone the example branch from my repo: `git clone -b example-using-oss-llm https://github.com/ivangabriele/openai-autogen-dev-studio.git`
5. Copy/paste the sample config: `cp ./env.sample.jsonc ./env.jsonc`
6. Update the `./env.jsonc` with the right RunPod endpoint (the 5001 one)
7. Install everything (`poetry install`) and run OADS (name of my project): `make run` or `poetry run python ./main.py`.

You'll see the agents talking together for a bit and automatically terminating the conversation without any issue.```.
In issues-and-help, at 2023-10-17 04:49:36 a user named ivangabriele said ```You can find the old fixes I had to apply for earlier versions of Autogen in [this old README commit](https://github.com/ivangabriele/openai-autogen-dev-studio/blob/c82c42cb849aaf1c690b568539429c9c16ad0449/README.md#23-mandatory-autogen-fixes). But I really think this is not related to your issue (I really don't see any possible link there).

I'm more a Rust / JS / Kotlin / Go developer and just started Python 2 weeks ago. But my guess is:

The error you're seeing seems to be related to the API serving your model. This API doesn't format the response as `openai` expects it to be. `error_data` seems to be a string while `openai` is expecting it to be an object: `{ code: "..." }`. Moreover I could bet that the error your API is sending is also related to the fact that it wasn't able to parse/understand `openai` lib request in the first place.

If you use VSCode, you can just follow the error file link (or just edit the file directly) and try to add a `print(error_data)` at the beginning of the `handle_error_response()` function to confirm my guess.

In any case, this surely means the API server you're using is not (perfectly?) respecting OpenAI API specs, meaning the issue is not related to Autogen (or even its `openai` dependency).```.
In issues-and-help, at 2023-10-17 01:52:07 a user named ivangabriele said ```To give you a final confirmation, I just ran a test using my current `main` branch code, using `Open-Orca/Mistral-7B-OpenOrca`. I obvisouly commented all the Function Calling-related code (by commenting some lines in `main.py` and `constants.py`). It works just fine.

I even updated my sample config file `models` key which I pass to Autogen "as is": [`config.sample.jsonc`](https://github.com/ivangabriele/openai-autogen-dev-studio/blob/main/env.sample.jsonc#L58), to give an example.```.
In issues-and-help, at 2023-10-17 01:09:38 a user named ivangabriele said ```I didn't see this message yet so I already partially replied in my other answer giving alternative solutions to make OSS LLMs work. The easiest IMO, for non-coders, being Text Generation Web UI with the OpenAI extension. For people who are ready to code a bit, the cleanest/most optimized way seems to be vLLM though. They have an OpenAI-Compatible "adapter".

I have been using open-source LLMs with Autogen for 2 weeks now with no big issue so far (I just had to hack 1 or 2 lines in Autogen lib to make it work at some point but I don't have to do that anymore on the latest Autogen `main` code). The method I used until now was just [this one](https://github.com/ivangabriele/openai-autogen-dev-studio#open-source-llms).```.
In issues-and-help, at 2023-10-16 23:42:31 a user named bobaleaux said ```have you seen this?
It is exactly what I was trying to figure out!
broadcast conversations and orchestration
with function executing agents.
too much!
https://youtu.be/4o8tymMQ5GM?si=Ue5D-jF6OT9fie6q```.
In issues-and-help, at 2023-10-16 19:12:25 a user named qslug said ```Just pass in your custom system message when creating the agent. But do check out the default message, because it contains a lot of logic about how code should be formatted, errors should be handled, and when to terminate, which you will need to replicate in your custom message: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/assistant_agent.py#L16```.
In issues-and-help, at 2023-10-16 18:44:51 a user named warmonger9626 said ```I just tried This example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.
In issues-and-help, at 2023-10-16 15:15:34 a user named jlopes77 said ```@sohojoe.eth Arize Phoenix OSS has un-official release of AutoGen tracing support, if you want a test a soft pre-release free drop the couple lines of code into any colab (example colab below). Complete tracing of all AutoGen prompt/response calls. Phoenix runs locally to the Colab server (or python execution), all data stays local. We are looking for feedback prior to release, tell us what you think, feel free to drop questions to our community.

https://colab.research.google.com/drive/1BaejbF06OrTM4B2V19WM4TX4q6_hgj40?usp=sharing

https://github.com/Arize-ai/phoenix```.
In issues-and-help, at 2023-10-16 11:02:13 a user named li_jiang said ```@.vrda @satya_1987 Could you help review this PR https://github.com/microsoft/autogen/pull/227, I've added support to @satya_1987 's initial use case. Although I find the performance is not as good as init the chat with an raguserproxy agent.```.
In issues-and-help, at 2023-10-16 10:34:01 a user named warmonger9626 said ```I tried to run example from AutoGen: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb,
But keep getting very short responses for every prompt, like this:
```﻿﻿You are a helpful AI assistant.
(...)
    
What date is today? Compare the year-to-date gain for META and TESLA.```
Response:
```import datetime
from yfinance import Ticker, download```
In consecutive responses more small pieces of code are appended this text, but this is hardly useful.

Yes, I'm using custom LLM server, but at least for direct API call it behaves fine:
```
import openai

openai.api_base = "http://localhost:4891/v1"
openai.api_key = "not needed for a local LLM"

prompt = "Who is Michael Jordan?"

model = "mistral-7b-instruct"

response = openai.Completion.create(
    model=model,
    prompt=prompt,
    max_tokens=50,
    temperature=0.28,
    top_p=0.95,
    n=1,
    echo=True,
    stream=False
)

print(response)
```
Even though this response is limited to 50 tokens, it's still much longer than what I get from the first example.```.
In issues-and-help, at 2023-10-16 06:37:51 a user named bansalg said ```@mauriziosantamicone_16029  and @jonny7377  I added an example of what I was thinking. https://discord.com/channels/1153072414184452236/1163364797857931314```.
In issues-and-help, at 2023-10-16 00:45:58 a user named hephaistos1440 said ```In the following notebook: [link](https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb), the user employs the following method:
```python
user_proxy.initiate_chat(
    assistant,
    message="""What date is today? Compare the year-to-date gain for META and TESLA.""",
)
```
to ask for a stock price comparison. Then, in the subsequent cell, they use:
```python
user_proxy.send(
    recipient=assistant,
    message="""Plot a chart of their stock price change YTD and save to stock_price_ytd.png.""",
)
```
mentioning it's a follow-up to the previous question. In the user_proxy.send method, the phrase "Plot a chart of their stock price change YTD and save to stock_price_ytd.png." is written. How does the system know that "their" refers to "META and TESLA"? Does user_proxy retain a memory of previous interactions?```.
In issues-and-help, at 2023-10-15 18:34:17 a user named flops_flops said ```I'm running on google colab.  `Automated Task Solving with Code Generation, Execution & Debugging`　is working without problem but　 `Auto Generated Agent Chat  Group Chat`  is returning error which is  [No API key provided...].  Does anyone know how to fix it?```.
In issues-and-help, at 2023-10-15 15:49:25 a user named noneoftheai said ```Here it works well. This endpoint works well in other apps too. 🤷🏻‍♂️```.
In issues-and-help, at 2023-10-15 13:50:31 a user named noneoftheai said ```Hi, Excuse me in advance for the dumb question, but I have an issue setting up the OAI_CONFIG_LIST with my Azure OAI endpoint. Help me pls what is wrong here. 🙏🏻. I get "*InvalidRequestError: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.*"```.
In issues-and-help, at 2023-10-15 01:35:46 a user named c_bonadio said ```Hi @tao9673 take a look at this code
https://gist.github.com/bonadio/3a806c9e6a2829a59ba45932b8b079e7```.
In issues-and-help, at 2023-10-15 01:28:40 a user named c_bonadio said ```Hi this code helped me, it does scraping
https://github.com/amadad/agentcy/tree/main```.
In issues-and-help, at 2023-10-14 16:50:58 a user named 0xjeu said ```Hello i keep getting an error that is occurring when its time for me to input response after running the code```.
In issues-and-help, at 2023-10-14 11:03:42 a user named muhammadumair8514 said ```Hi there, 

I'm facing an error while installing pyautogrn 

Errors could not build wheels for aiohttp, frozen list, multidict, yarl, which is required to install project.toml-based projects 

Ps: I don't have a background in coding.```.
In issues-and-help, at 2023-10-14 05:48:11 a user named jasonzhou1993 said ```want to use other model other than openai, like https://replicate.com/yorickvp/llava-13b/api, is there a way to do so?```.
In issues-and-help, at 2023-10-13 20:04:31 a user named bansalg said ```See if this example if useful @interestedtheory https://discord.com/channels/1153072414184452236/1161073234012295178/1161073234012295178```.
In issues-and-help, at 2023-10-13 19:50:13 a user named bansalg said ```I believe its an open issue:
https://github.com/microsoft/autogen/issues/217```.
In issues-and-help, at 2023-10-13 12:15:02 a user named li_jiang said ```@satya_1987  check out this example https://github.com/microsoft/autogen/pull/227, would this work for you?```.
In issues-and-help, at 2023-10-13 10:15:00 a user named rajaswa.patil said ```Hey folks, is there any way we can use the same agent in two distinct conversations running side-by-side?

For example, consider these three agents - i) UserProxy; ii) Assistant; iii) Planner

I would like the Assistant to be involved in two distinct conversations -
1. With UserProxy (as User)
2. With Planner (as a planning assistant to the Assistant)

The given example for planning uses a proxy agent called "planner_user". Can we avoid that?
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb```.
In issues-and-help, at 2023-10-13 02:26:39 a user named sonichi said ```like https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In issues-and-help, at 2023-10-13 02:23:44 a user named 7racker said ````import autogen 

config_list = [
    {
        # 'model': 'gpt-3.5-turbo-16k',
        'model': 'gpt-4',

        'api_key': '++++++++++++++++++++++++++++++'
    }
]

llm_config={
    "request_timeout": 600,
    "seed": 42,
    "config_list": config_list,
    "temperature": 0
}

assistant = autogen.AssistantAgent(
    name="Lead Researcher",
    llm_config=llm_config,
    system_message="Researches the VC firm team pages and X profiles to see which VC would be my best match to cold contact my pitchdeck to."
)

user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="ALWAYS",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("ALWAYS`"),
    code_execution_config={"work_dir": "web"},
    llm_config=llm_config,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet."""
)

task = """
Please look at this URL https://gist.github.com/adam7rans/84e27eafb7b3e7b06930fe7922199cbb and print all URLs out.
"""

user_proxy.initiate_chat(
    assistant,
    message=task
)


````.
In issues-and-help, at 2023-10-13 02:08:51 a user named 7racker said ```So then I just decided to copy all the URLs (I wanted my agent to get access to from my Google Sheet) into a public gist and then added the gist's URL into the task. It then told me the following

`
user_proxy (to Lead Researcher):

Please look at this URL https://gist.github.com/adam7rans/84e27eafb7b3e7b06930fe7922199cbb and print all URLs out.
-------------------------------------------------------------------------------
Lead Researcher (to user_proxy):

I'm sorry, but I am unable to access external URLs or open GitHub links. However, I can assist you with any other questions or tasks you may have.
-------------------------------------------------------------------------------
Provide feedback to Lead Researcher. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: can you search the web?
user_proxy (to Lead Researcher):

can you search the web?
-------------------------------------------------------------------------------
Lead Researcher (to user_proxy):

Yes, I can search the web. How can I assist you with your search?
````.
In issues-and-help, at 2023-10-12 16:07:07 a user named sonichi said ```You don't have to load the config list from the file. You can set it directly. Check this page: https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints```.
In issues-and-help, at 2023-10-12 12:37:15 a user named lessuse. said ```this is the code - 
https://github.com/JayZeeDesign/researcher-gpt/blob/main/app.py

i just add one base environment variable like this - 
``openai.api_base = os.getenv("OPENAI_API_BASE")``

its working with offical key and url , but when i try with self-host url and key, its showing this error - 

```Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: [{'type': 'int_type', 'loc': ('body', 'max_tokens'), 'msg': 'Input should be a valid integer', 'input': None, 'url': 'https://errors.pydantic.dev/2.4/v/int_type'}] {"error":{"message":"[{'type': 'int_type', 'loc': ('body', 'max_tokens'), 'msg': 'Input should be a valid integer', 'input': None, 'url': 'https://errors.pydantic.dev/2.4/v/int_type'}]"}} 422 {'error': {'message': "[{'type': 'int_type', 'loc': ('body', 'max_tokens'), 'msg': 'Input should be a valid integer', 'input': None, 'url': 'https://errors.pydantic.dev/2.4/v/int_type'}]"}} {'Server': 'nginx/1.18.0 (Ubuntu)', 'Date': 'Thu, 12 Oct 2023 12:30:12 GMT', 'Content-Type': 'application/json', 'Content-Length': '187', 'Connection': 'keep-alive'}.``````.
In issues-and-help, at 2023-10-12 12:26:05 a user named 2022bearmarketsurvivor.eth said ```Check this tutorial, he has a similar setup where he summarises the result in the end - https://youtu.be/Bq-0ClZttc8?si=A2h23s92IGtm1rYB```.
In issues-and-help, at 2023-10-12 10:53:47 a user named fxtoofaan said ```I just kicked off first script to gpt4 and got this error. wth? I have not used chatgpt in days, how come with first scirpt run I get this error?```.
In issues-and-help, at 2023-10-12 10:20:18 a user named fxtoofaan said ```I can never get the OAI_CONFIG_LIST to work. i need some help. I created a blank OAI_CONFIG_LIST file and just put 1 model name in there along with my openai api key. both my python test script and OAI_CONFIG_LIST files are in the same folder. not sure what I am doing wrong. any ideas? I gave up on local LLM's for now and just want to test autogen on openai api for now.```.
In issues-and-help, at 2023-10-12 05:23:36 a user named kimsia said ```i am running the ipynb locally. do i go to this cell and edit the code directly?```.
In issues-and-help, at 2023-10-12 05:11:18 a user named kimsia said ```Thank you @sonichi Now I am stuck at```.
In issues-and-help, at 2023-10-12 04:59:46 a user named kimsia said ```I'm trying to run the math coding example where there are 4 agents:

1. student (user_proxy)
2. student assistant 
3. expert (user_proxy)
4. expert assistant

https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb?short_path=026efb4

i got stuck `:root:The specified config_list file 'OAI_CONFIG_LIST' does not exist.`

## What I did

I have a `OAI_CONFIG_LIST.json`

and it has 

```
[
    {
        "model": "gpt-4",
        "api_key": "my-secret-key"
    }
]
```

the structure:

- agentchat_two_users.ipynb
- OAI_CONFIG_LIST.json```.
In issues-and-help, at 2023-10-12 03:00:54 a user named 7racker said ```So I created an API key on Google Cloud and there is this section called "Set an application restriction" but what would AutoGen be considered?```.
In issues-and-help, at 2023-10-11 23:47:51 a user named rustedlight said ```Docs say the following: https://microsoft.github.io/autogen/docs/FAQ/#why-is-code-not-saved-as-file```.
In issues-and-help, at 2023-10-11 21:57:43 a user named frank.martinez said ```https://replit.com/@deboboy/Microsoft-AutoGen-Demo#main.py```.
In issues-and-help, at 2023-10-11 20:00:46 a user named ryan1016. said ```I install pyautogen on my WSL and even have it defined in my docker requirements.txt file but it is not finding the module when I try to execute the code.```.
In issues-and-help, at 2023-10-11 10:07:01 a user named fxtoofaan said ```Just saw mistral has a docker image … https://github.com/mistralai/mistral-src upon examining the docket file seems like it’s got everything needed to run mistral or similar models on vllm and fastchat. I’ll try that later on.```.
In issues-and-help, at 2023-10-11 09:44:43 a user named playahata said ```https://github.com/abetlen/llama-cpp-python
python bindings of llama cpp```.
In issues-and-help, at 2023-10-11 09:04:40 a user named playahata said ```you can use any gguf model, 
https://huggingface.co/TheBloke this user uploads  a lot```.
In issues-and-help, at 2023-10-11 09:03:52 a user named playahata said ```https://github.com/ggerganov/llama.cpp
gpt4all is the easiest, pretty ok gui
https://gpt4all.io/index.html```.
In issues-and-help, at 2023-10-11 00:47:45 a user named rustedlight said ```I am using code very similar to https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb . Autogen works great. The code that it creates and tests is never saved locally. The only way I can see the code is scroll in terminal. Has anyone ran into this? Is there a solution? I would like to have the code saved once it has passed the 'executor' tests successfully.```.
In issues-and-help, at 2023-10-10 21:27:20 a user named vermino said ```@fxtoofaan i don't know if this is still relevant as I believe I heard you talking with a guy about completion is being obsolete from the project? but here is this https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference/```.
In issues-and-help, at 2023-10-10 19:58:09 a user named fxtoofaan said ```i have ubuntu 22.04 with vllm server running along with the autogen library. attached is the python script I am using and also i am attaching screen shots of errors. anyone able to help?

@sonichi ?```.
In issues-and-help, at 2023-10-10 12:47:17 a user named kimsia said ```I found this in the website, but i cannot make sense of how autogen helps with code generation https://github.com/microsoft/autogen/blob/main/notebook/oai_completion.ipynb```.
In issues-and-help, at 2023-10-09 19:04:24 a user named jonny7377 said ```This article seems to cover the concept: https://semaphoreci.com/blog/function-calling
This notebook is specific to autogen.  good after you understand the concept: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In issues-and-help, at 2023-10-09 16:46:04 a user named victor.dibia said ```In general, I'd say making an api and then consuming that api from any front end app (e.g. Flutter) is a good way to go. 


I have some sample code on how to setup a FastApi server and connect to it from a Next.js frontend.   

You should be able to repurpose the fastapi server as a backend for your flutter app. 

https://github.com/victordibia/autogen-ui```.
In issues-and-help, at 2023-10-09 16:40:17 a user named e404nothing said ```I am trying to follow this guide:
https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/
but I get lost at the `python -m fastchat.serve.model_worker --model-path chatglm2-6b` part. I am running an arbitrary llm on LM Studio, so should I be putting the model that I am running in there at the `...--model-pathchatglm2-6b` part or is that a placeholder? I am pretty unfamiliar with this stuff so apologies for the stupid questions. 

I am getting this error when running the above code:```.
In issues-and-help, at 2023-10-09 14:20:50 a user named kylepancamo said ```https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence#:~:text=Microsoft%20Azure%20AI%20Document%20Intelligence%20is%20an%20automated,to%20quickly%20extract%20text%20and%20structure%20from%20documents.```.
In issues-and-help, at 2023-10-09 14:14:31 a user named kylepancamo said ```Probably emails, better html extraction, etc. Unstructured.io provides a lot of extraction for LLMs

https://unstructured.io/```.
In issues-and-help, at 2023-10-09 14:07:43 a user named li_jiang said ```The details can be found here https://github.com/microsoft/autogen/blob/main/autogen/retrieve_utils.py```.
In issues-and-help, at 2023-10-09 12:51:46 a user named cmtananantantan said ```here's a modified version of agentcy that i butchered:```.
In issues-and-help, at 2023-10-09 02:33:01 a user named jieyuzhang_uw said ```more details can be found here https://github.com/JieyuZ2/EcoAssistant```.
In issues-and-help, at 2023-10-09 00:55:09 a user named pcdeadeasy said ```Suggest following this tutorial to get your WSL2 environment going: https://learn.microsoft.com/en-us/windows/wsl/install, use VSCode to explore the AutoGen notebooks and examples.```.
In issues-and-help, at 2023-10-08 22:36:18 a user named sonichi said ```https://microsoft.github.io/autogen/docs/FAQ#handle-rate-limit-error-and-timeout-error```.
In issues-and-help, at 2023-10-08 14:27:42 a user named au8 said ```If I do, it complains.```.
In issues-and-help, at 2023-10-08 05:49:13 a user named yogeshharibhaukulkarni said ```The current Completion call seems hardcoded to OpenAI, as seen in autogen/oai/completion.py

Is it possible to take the instantiation of llm obj outside and drive that via config? So, not just model names, but even LLM class names, such as ChatOpenAI, or it can even be ChatVertexAI also.

Meaning specify, LLM class name also in the config which will then be instantiated inside the code for completion call.

With this arrangement, you will open up AutoGen to a far wider audience. People can use LangChain LLM models class names or any other local custom LLM classes, which can create compatible (abiding to some protocol/interface) llm objects.

Basically can you make it easier to use any LLM class via config setting?

https://github.com/microsoft/autogen/issues/148```.
In issues-and-help, at 2023-10-08 03:32:33 a user named 2hunter said ```Tried to configure those lines, didnt help```.
In issues-and-help, at 2023-10-08 02:58:44 a user named sonichi said ```Need to install docker desktop on windows: https://www.docker.com/products/docker-desktop/```.
In issues-and-help, at 2023-10-08 02:51:40 a user named sonichi said ```I used to use this trick in flaml: https://github.com/microsoft/FLAML/blob/fda9fa01037cccd9f327facf3131f2345f2e270c/.github/workflows/python-package.yml#L39-L51
Is it the same issue here?```.
In issues-and-help, at 2023-10-08 01:16:50 a user named ilaffey said ```uh oh

https://app.warp.dev/block/h095gxN47MAuBWcJ5HmBQa```.
In issues-and-help, at 2023-10-08 00:25:18 a user named ilaffey said ```https://app.warp.dev/block/2rvNtLMv1dHiqCGc2LHdTT

Getting the above error on an M1 Mac.

Solution below```.
In issues-and-help, at 2023-10-07 19:59:32 a user named kitbuti said ```Also, with reference to contrast with projects like https://github.com/KillianLucas/open-interpreter ?
Thanks for help explaining in advance 🙌```.
In issues-and-help, at 2023-10-07 15:29:06 a user named mrauter said ```https://aider.chat/docs/ctags.html```.
In issues-and-help, at 2023-10-07 15:26:04 a user named mrauter said ```Aider has a great approach to working with larger codebases https://aider.chat/examples/complex-change.html```.
In issues-and-help, at 2023-10-07 05:06:52 a user named sonichi said ```known issue: https://github.com/microsoft/autogen/issues/111```.
In issues-and-help, at 2023-10-07 05:05:31 a user named sonichi said ```yes: https://microsoft.github.io/autogen/docs/FAQ#handle-rate-limit-error-and-timeout-error```.
In issues-and-help, at 2023-10-07 02:56:36 a user named li_jiang said ```Hi @bitsy_chuck , you'll need to create a group chat with all the three agents. But there is a known issue (https://github.com/microsoft/autogen/issues/96) for using retrieve agents in group chat. I'll look into the issue later. As scdnapier commented in the issue, there is a workaround you can try.```.
In issues-and-help, at 2023-10-07 02:47:42 a user named li_jiang said ```Hi @kylepancamo , welcome and thank you for asking. Yes, AutoGen will handle injecting docs into the prompt and the embedding. The usages of the parameters are explained here: https://github.com/microsoft/autogen/blob/20d77a1039a167139da60e0eed4713039de76956/autogen/agentchat/contrib/retrieve_user_proxy_agent.py#L101-L130

Let me know if you encountered into any issues.```.
In issues-and-help, at 2023-10-07 01:15:11 a user named somecomputerguy said ```My GPT4 deployment works fine in my sample code, but I get this error running twoagent.py

openai.error.InvalidRequestError: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.

I waited a couple hours and tried again, same error. Does twoagent.py need a GPT-3.5 agent in the list?

Here is my OAI_CONFIG_LIST

[
    {
        "model": "gpt-4",
        "api_key": "f5e3****************731ae"
    },
    {
        "model": "gpt-4",
        "api_key": "f5e*********************08731ae",
        "api_base": "https://myapi.openai.azure.com/",
        "api_type": "azure",
        "api_version": "2023-07-01-preview"
    }
]```.
In issues-and-help, at 2023-10-06 21:56:01 a user named rtatlas said ```I am sadly not one of the smart people, so I have been coming into so many issues tryna get stuff workin. I got autogen working but I liked how ChatDev showed them like a video game (*im smoothbrained, i enjoy that*) also that they had multiple different departments with multiple agents instead of just the one. I have absolutely zero experience and knowledge with coding so anything helps. Thank you all!```.
In issues-and-help, at 2023-10-06 21:27:27 a user named victor.dibia said ```Here is what I have so far - https://github.com/victordibia/autogen-ui ... free free to fork, make changes, start discussions etc. There will be bugs here and there as I havent spent too much time on it. 
I might be offline for a while but happy to respond when back```.
In issues-and-help, at 2023-10-06 20:58:45 a user named sonichi said ```https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints```.
In issues-and-help, at 2023-10-06 20:56:14 a user named sonichi said ```It's like **kwargs. For example:
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_MathChat.ipynb
`problem=problem````.
In issues-and-help, at 2023-10-06 18:25:45 a user named mooblegum said ```Dear fellow coders

I am a programming noob, but I am really interested by learning to use project like autogen. So I decided to install it and see how I can modify the agent to help me on my project.

I never worked with python before so I will sound quite unprofessional, sorry for that...

I installed latest version of python 3.12I installed pycharm

I created a a project on pycharm

In the terminal I run pip install pyautogen

I got this error message :

------------------------------------------------------------------------

copying yarl\py.typed -> build\lib.win-amd64-cpython-312\yarl

running build_ext

building 'yarl._quoting_c' extension

error: Microsoft Visual C++ 14.0 or greater is required. Get it with "Microsoft C++ Build Tools": https://visualstudio.microsoft.com/visual-cpp-build-tools/

[end of output]

note: This error originates from a subprocess, and is likely not a problem with pip.

ERROR: Failed building wheel for yarl

Failed to build aiohttp frozenlist multidict yarl

ERROR: Could not build wheels for aiohttp, frozenlist, multidict, yarl, which is required to install pyproject.toml-based projects

------------------------------------------------------------------------

I installed https://visualstudio.microsoft.com/visual-cpp-build-tools/
 with default settings.

Restarted my computer

Tried to run pip install pyautogen again,

I got the same message



Do someone have an idea how to fix that issue, what component I should have installed in the visual-cpp-build-tools/
 (there are many to check but it quickly need several 100 of giga to install it all )



Thank you for helping me in this first adventure !```.
In issues-and-help, at 2023-10-06 17:00:02 a user named jaemil said ```That's nice so far! 
I have also created a repo: https://github.com/jaemil/autogen_websocket
@tomexmachina is helping, my python knowledge isn't that good :>
My focus is more on the frontend, so I would love to contribute @victor.dibia```.
In issues-and-help, at 2023-10-06 16:24:15 a user named victor.dibia said ```Hey folks ... wanted to share some updates on what I have so far.. 
Mainly I am focusing on a stateless fastapi endpoint called from a front end (I really like the websocket approach @jaemil  is working on but have not gotten to it yet).

Current screenshot of the UI is attached (build with Next.js, static file export served by a fastapi endpoint) . 
The roadmap I am thinking of is in line with much of the discussion we have been having here (attached screenshot) 

What do folks think? Its very scattered right now, if folks are interested, I can share the repo (note: it is poorly organized at the moment though) 

@pcdeadeasy , @sonichi```.
In issues-and-help, at 2023-10-06 15:21:17 a user named mo789. said ```currently im getting this Error message: thenticationError: Incorrect API key provided: ssk-DROt****************************************dwgH. You can find your API key at https://platform.openai.com/account/api-keys.

i have tried everything it is a correct API key can someone maybe help?```.
In issues-and-help, at 2023-10-06 11:58:27 a user named tonic_1 said ```you can see some examples in our repo : https://github.com/team-tonic-arena-hacks```.
In issues-and-help, at 2023-10-06 08:21:45 a user named qslug said ```Things like source links are probably best stored as metadata. I don't think it's possible currently, but it should be possible generally.   

I think you would have to hack `retrieve_utils` to store source URIs for loaded documents, and return metadata when querying; then modify `retrieve_user_proxy_agent.py` to expose the metadata as additional context. See https://docs.trychroma.com/usage-guide#choosing-which-data-is-returned```.
In issues-and-help, at 2023-10-06 07:57:26 a user named bitsy_chuck said ```https://microsoft.github.io/autogen/docs/reference/code_utils```.
In issues-and-help, at 2023-10-06 00:51:34 a user named bansalg said ```Also @gzoran  see https://discord.com/channels/1153072414184452236/1158564427117903882/1158564427117903882```.
In issues-and-help, at 2023-10-05 23:12:20 a user named frank.martinez said ```https://vercel.com/templates/next.js/nextjs-flask-starter```.
In issues-and-help, at 2023-10-05 17:42:45 a user named rubberdauck said ```Getting 

AttributeError: 'str' object has no attribute 'get'

When entering a blank for user reply. Not sure how to fix it.```.
In issues-and-help, at 2023-10-05 14:01:31 a user named victor.dibia said ```Do you still see the same error when you try to return results on a simple post/get route? 

I also see that you are importing `autogen` from flaml. AutoGen has moved to its own repo and there is a change some of the issues youare encountering are fixed already 

`pip install pyautogen` 

`import autogen`

https://github.com/microsoft/autogen```.
In issues-and-help, at 2023-10-05 12:30:50 a user named bitsy_chuck said ```In https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/retrieve_user_proxy_agent what is `docs_path`?```.
In issues-and-help, at 2023-10-05 08:08:22 a user named ilaffey said ```I'm looking through the docs at https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#register_reply

but I'm a little lost at how I can force an agent to always reply to a specific agent.

For context I want to have an ApiProxy agent, that when called always immediately calls an Executor user_proxy

EDIT:

See thread for solution```.
In issues-and-help, at 2023-10-05 05:05:39 a user named sonichi said ```Try this: https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints```.
In issues-and-help, at 2023-10-04 23:50:54 a user named 573dave said ```I'm having trouble after a second or third interaction (first interaction seems to go fine). How can I improve the timeout issue? Full error here: https://pastebin.com/embed_iframe/pQ6N0539?theme=dark```.
In issues-and-help, at 2023-10-04 23:24:09 a user named fxtoofaan said ```https://github.com/microsoft/autogen/issues/110

New issue created on github.```.
In issues-and-help, at 2023-10-04 21:58:20 a user named ath3nA said ```https://www.youtube.com/watch?v=Bq-0ClZttc8&t=638s

See whether you find anything interesting in this video. Check the last bit he goes in-depth about multi-agents```.
In issues-and-help, at 2023-10-04 21:23:38 a user named sonichi said ```AutoGen supports templating: https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#templating```.
In issues-and-help, at 2023-10-04 19:49:56 a user named afourney said ```Can you clarify what you mean by "paid plan"? Are you paying for ChatGPT+ or are you talking about developer API access? Can you access GPT via the playground? https://platform.openai.com/playground?mode=chat&model=gpt-4```.
In issues-and-help, at 2023-10-04 18:34:17 a user named ath3nA said ```Im not sure whether this is a dumb question but what is the reason that i get the below error? The normal chat completion works but when i add group chat functionality it exits out with this error. 

--------------------------------------------------------------------------------
[autogen.oai.completion: 10-04 23:58:04] {223} INFO - retrying in 10 seconds...
Traceback (most recent call last):
  File "/Users/Kasun/anaconda3/lib/python3.11/site-packages/autogen/oai/completion.py", line 209, in _get_response
    response = openai_completion.create(request_timeout=request_timeout, **config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Notes
I am using "Anyscale Endpoints".```.
In issues-and-help, at 2023-10-04 18:02:30 a user named fxtoofaan said ```Can anyone make sense of this code ? https://colab.research.google.com/drive/1uTJvyjhH-mvi1AmuwAOL2384X8TugGf0?usp=sharing&pli=1&authuser=1#scrollTo=WsYot3Rz1NVf```.
In issues-and-help, at 2023-10-04 17:58:45 a user named bansalg said ```@wapeto, You can use function calls to at least spin up new agents dynamically. 

See example here:
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb

@sonichi  if there a way to add a new agent to an existing group chat?```.
In issues-and-help, at 2023-10-04 17:55:56 a user named fxtoofaan said ```I’m going to see how this person got around the prompts …https://youtu.be/TEq5Kg4VONA```.
In issues-and-help, at 2023-10-04 17:49:56 a user named bansalg said ```Btw see this message for community created tutorials: https://discord.com/channels/1153072414184452236/1157419832443150447/1157419832443150447```.
In issues-and-help, at 2023-10-04 17:24:58 a user named derekbarrera said ```https://github.com/microsoft/autogen/pull/95```.
In issues-and-help, at 2023-10-04 17:15:52 a user named victor.dibia said ```There are two things at play here.

An OAI account has both rate limits (requests per unit time) and credit limits (related to how may tokens you have paid for).  

You can view https://platform.openai.com/account/rate-limits to see your current rate limits 

More info on rate limits and how they can be viewed or increased here
https://platform.openai.com/docs/guides/rate-limits/overview```.
In issues-and-help, at 2023-10-04 15:03:36 a user named fxtoofaan said ```this is from chatml readme file:

https://github.com/openai/openai-python/blob/main/chatml.md

[
 {"token": "<|im_start|>"},
 "system\nYou are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\nKnowledge cutoff: 2021-09-01\nCurrent date: 2023-03-01",
 {"token": "<|im_end|>"}, "\n", {"token": "<|im_start|>"},
 "user\nHow are you",
 {"token": "<|im_end|>"}, "\n", {"token": "<|im_start|>"},
 "assistant\nI am doing well!",
 {"token": "<|im_end|>"}, "\n", {"token": "<|im_start|>"},
 "user\nHow are you now?",
 {"token": "<|im_end|>"}, "\n"
]```.
In issues-and-help, at 2023-10-04 15:01:10 a user named slagado. said ```What must be done to overcome this error:
"openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details."

Would it be solved in case I make a "chat GPT Plus" subscription?
Or is another (additional ?) subscription (from "openai.com") needed?```.
In issues-and-help, at 2023-10-04 14:48:22 a user named fxtoofaan said ```seems like another screen shot of chatml prompt template```.
In issues-and-help, at 2023-10-04 12:51:41 a user named fxtoofaan said ```I am dealing with a bunch of these [INST] [/INST] messages on the client side and also on the local server side.```.
In issues-and-help, at 2023-10-04 12:44:08 a user named fxtoofaan said ```@sonichi I am using TheBloke/Mistral-7B-OpenOrca-AWQ model locally and it uses Prompt template: ChatML. Here is example template:

<|im_start|>system
{system_message}<|im_end|>
<|im_start|>user
{prompt}<|im_end|>
<|im_start|>assistant

Prompt Template
We used OpenAI's Chat Markup Language (ChatML) format, with <|im_start|> and <|im_end|> tokens added to support this.
https://github.com/openai/openai-python/blob/main/chatml.md

Current prompt template I use in my code image attached. 

how can I use chatml prompt template in autogen code? please help.```.
In issues-and-help, at 2023-10-04 10:58:30 a user named labadabaduu said ```same question. i read this but didnt understand what to do in IDE

https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In issues-and-help, at 2023-10-04 05:45:14 a user named ilaffey said ```Anyone see this error sometimes from a code writing agent?```.
In issues-and-help, at 2023-10-04 01:26:45 a user named sonichi said ```I'm suggesting defining one function which creates a chat inside the function. Eg: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb```.
In issues-and-help, at 2023-10-04 01:25:14 a user named sonichi said ```Have you set your api_key? Please follow https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints```.
In issues-and-help, at 2023-10-03 23:26:44 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In issues-and-help, at 2023-10-03 17:57:53 a user named mviejo017 said ```Hi, i am trying to run autogen but the response i am receiving is that i don't have access to GPT 4, but i have the paid plan and i use GPT 4 everyday so i don't know why that is happening.```.
In issues-and-help, at 2023-10-03 17:43:11 a user named bansalg said ```see azure examples here: https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In issues-and-help, at 2023-10-03 17:15:27 a user named alexandria_38202 said ```Is there currently support for using `autogen` against an Azure OpenAI instance?  I'm able to get it running fine using an `OPENAI_API_KEY` but if i try to switch to using a `AZURE_OPENAI_KEY` (and corresponding `AZURE_OPENAI_ENDPOINT`) it errors out due to the missing `OPENAI_API_KEY`:

```openai.error.AuthenticationError: You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.``````.
In issues-and-help, at 2023-10-03 07:47:41 a user named fxtoofaan said ```hello all, i am running a script locally on my local llama-2 llm. i set the timeout to 1200 and from time i run the script till timeout happens there is no output on screen. once timeout happens the script spits out a bunch or text on screen. can we do something to see what the script is doing or what the agents are doing that's taking this long?```.
In issues-and-help, at 2023-10-03 04:24:05 a user named aayushc1308 said ```Fix here:
https://github.com/microsoft/autogen/pull/87

Thinking about a good test case. Open to suggestions.```.
In issues-and-help, at 2023-10-03 04:05:36 a user named ilaffey said ```I am curious about filesystem I/O - I see some references to it here: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb

with the `workingDir` - however I'm still trying to get to grips with this Multi Agent framework.```.
In issues-and-help, at 2023-10-03 00:13:37 a user named yudao2 said ```Please refer to the code and error provided above.```.
In issues-and-help, at 2023-10-02 21:30:17 a user named aaronward_ said ```https://github.com/microsoft/autogen/pull/68 - my open PR aims to fix this by allowing easy configuration settings using a `.env` file```.
In issues-and-help, at 2023-10-02 16:08:03 a user named melekgharbi said ```i uploaded the file to google colab root directory; but when arriving to the initiate chat line here, the program crash and keeps asking for the API key```.
In issues-and-help, at 2023-10-02 16:04:51 a user named melekgharbi said ```Hey Guys, I'm trying to run this notebook : https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb, i'm having trouble setting up the config list. I created a file named "OAI_CONFIG_LIST.json" on my pc, inside the file here's the json i put```.
In issues-and-help, at 2023-10-02 14:47:43 a user named kevinwyr said ```Hey @jasonzhou1993, I am on it now. It is a quick fix but need some time to be updated to the lib. 
For a temporary fix add these two lines to the `autogent/agentchat/conversable_agent.py` line 278:

```
        if "function_call" in oai_message:
            oai_message["role"] = "assistant"  # only messages with role 'assistant' can have a function call.
``````.
In issues-and-help, at 2023-10-01 17:50:32 a user named fxtoofaan said ```I’ve setup a test github repository for autogen and local llms. I’ve put first script up there. https://github.com/fxtoofaan/autogen_local_testing```.
In issues-and-help, at 2023-10-01 14:33:01 a user named sonichi said ```Great. We can release it, announce it and encourage people to try. There is a community project thread: https://discordapp.com/channels/1153072414184452236/1156976658419568641```.
In issues-and-help, at 2023-10-01 14:03:53 a user named li_jiang said ```I made a draft here: https://github.com/microsoft/autogen/releases/edit/untagged-a37648d36ea269e75b59```.
In issues-and-help, at 2023-10-01 11:18:29 a user named sonichi said ```I'm bumping the version in https://github.com/microsoft/autogen/pull/59```.
In issues-and-help, at 2023-10-01 11:12:27 a user named sonichi said ```You can use
https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#last_message
or
https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#chat_messages
There is a mistake in the docstr, which I'm fixing in https://github.com/microsoft/autogen/pull/59```.
In issues-and-help, at 2023-10-01 05:33:09 a user named qslug said ```Of course I *now* see that this is directly related to the prior post: https://discord.com/channels/1153072414184452236/1157434279891050607/1157434279891050607```.
In issues-and-help, at 2023-10-01 05:27:37 a user named qslug said ```I'm trying out one of the example notebooks locally, but running into an issue with ChromaDB initialization. https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb

It seems as though AutoGen's call to `collection.add()` is passing in way more ids than documents, but chroma doesn't like this. When initiating the first example chat I get:
```
Number of documents 17 must match number of ids 40000
Trying to create collection.
Found 17 chunks.
doc_ids:  [[]]
No more context, will terminate.
ragproxyagent (to assistant):

TERMINATE

--------------------------------------------------------------------------------
``````.
In issues-and-help, at 2023-10-01 05:11:22 a user named jasonzhou1993 said ```When I run an agent, how can i get the result from the agent run? at the moment, the chat history only display in the terminal, and it return None```.
In issues-and-help, at 2023-10-01 02:40:59 a user named andyinater said ```Here is the example I was referring to: https://discord.com/channels/1153072414184452236/1157869584901226586```.
In issues-and-help, at 2023-10-01 00:01:50 a user named sonichi said ```Check the other thread: https://discordapp.com/channels/1153072414184452236/1157820683095654500```.
In issues-and-help, at 2023-09-30 23:41:21 a user named sonichi said ```Just realized, you may be talking about the same issue as https://discordapp.com/channels/1153072414184452236/1157820683095654500```.
In issues-and-help, at 2023-09-30 21:52:23 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L601
In this function, the well-formed code blocks are extracted and executed. What you want, instead, is to identify incomplete code blocks, save the partial code, reply "continue" and append to the partial code until the code is complete. Only execute when it's complete. Is that right?```.
In issues-and-help, at 2023-09-30 18:09:41 a user named sonichi said ```What about starting from something simpler? Automated Data Visualization by Group Chat (with 3 group member agents and 1 manager agent)
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_vis.ipynb```.
In issues-and-help, at 2023-09-30 15:42:51 a user named benbot said ```usually people use https://pypi.org/project/python-dotenv/```.
In issues-and-help, at 2023-09-30 15:15:40 a user named salegrem said ```¡Hey guys! I'm trying AutoGen and BeeBot and this error keeps popping up for me. I must be missing something dumb but any help is appreciated.```.
In issues-and-help, at 2023-09-30 12:48:26 a user named jasonzhou1993 said ```Hey @sonichi is there a rough ETA of when will this be fixed? 

I'm running this youtube channel (https://www.youtube.com/channel/UCrXSVX9a1mj8l0CMLwKgMVw), very impressed by autogen and planning to make a video about autogen tomorrow, would love to have group chat + function calling works, for some use cases like research 🙂```.
In issues-and-help, at 2023-09-30 12:16:32 a user named sonichi said ```This is a known issue with an ongoing PR: https://github.com/microsoft/autogen/pull/47
@kevinwyr```.
In issues-and-help, at 2023-09-30 12:07:58 a user named jasonzhou1993 said ```I've set the human_input_mode="TERMINATE", however it never terminate, and intsead the user proxy agent just always return empty message, and the assistant agent stuck in infinite loop```.
In issues-and-help, at 2023-09-30 12:06:39 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb
The input and output are in the chat messages. Could you clarify what's missing?```.
In issues-and-help, at 2023-09-30 05:08:12 a user named li_jiang said ```https://github.com/microsoft/autogen/pull/50```.
In issues-and-help, at 2023-09-30 04:08:29 a user named sonichi said ```Does this link help? https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs
If so, we can add it to the FAQ.```.
In issues-and-help, at 2023-09-30 00:04:00 a user named bansalg said ```See if this helps: https://discord.com/channels/1153072414184452236/1157364980992184351/1157365836353392670

Your content of config_list maybe the issue.```.
In issues-and-help, at 2023-09-29 23:40:13 a user named jasonzhou1993 said ```That's what i did actually```.
In issues-and-help, at 2023-09-29 19:31:09 a user named bansalg said ```Checkout the following guide to switch endpoints: https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In general, at 2023-11-15 09:38:20 a user named aignise said ```how can we view and interact with the groupchat conversation in the frontend? unlike openai assistants which can be put into a simple loop, autogen initiatechat method loops autonmously so we cant return a json in the normal way```.
In general, at 2023-11-15 09:00:56 a user named iandjx said ```Docs dont have any information on how to add a new file to a generated assistant. You need to recreate the assistant```.
In general, at 2023-11-15 07:47:29 a user named hahl9000 said ```I've tried using OpenAI documentation where client = OpenAI() using file = client.files.create(file=open("knowledge.pdf", "rb"),  purpose='assistants') but I seem to be missing something here. Should I replace client with assistant?```.
In general, at 2023-11-15 07:45:34 a user named hahl9000 said ```But if I create an assistant on the fly (in code) then I want to append a file to that assistant. I just can't seem to get it to work and was wondering if anyone had a working example.```.
In general, at 2023-11-15 07:44:30 a user named iandjx said ```Im looking at ‘_invoke_assistant’ function of GPT assistant . It seems like a new thread is generated when i restart the app .
Id like to be able to continue a conversation on a thread even after restarting the app.
Would this be possible?```.
In general, at 2023-11-15 07:40:41 a user named iandjx said ```You dont use a file path. You have to pass a file id.
But first, you need to upload a the to openai. Check Openai docs on gpt assistants```.
In general, at 2023-11-15 07:36:35 a user named errorrr_404 said ```Hello Team,
I'm Darshan Tank from india.
I joined this channel to learn and contribution 😀 
I don't know from where to start 😦```.
In general, at 2023-11-15 07:35:49 a user named hahl9000 said ```Anyone out there that has utilized retrieval and file path for GPT assistant agent? Can't figure that out :/```.
In general, at 2023-11-15 07:31:28 a user named pika.c said ```If you want to do that after each reply in a groupchat then look at this https://discord.com/channels/1153072414184452236/1153072414184452243/1174211356157804654```.
In general, at 2023-11-15 05:49:30 a user named dexxter0297 said ```Is it possible to intervene the discussion among agents and add your suggestions```.
In general, at 2023-11-15 04:50:26 a user named .jeracoo said ```Does anyone have a pdf or word doc or something of the autogen documentation? If not I guess I can just gather it together in 1 spot```.
In general, at 2023-11-15 04:28:35 a user named Lega said ```ahh my apologies. 
i just created an issue right now.```.
In general, at 2023-11-15 02:42:57 a user named beep_38401 said ```Do you guys think I should add MemGPT knowledge to the Oracle?```.
In general, at 2023-11-15 02:26:23 a user named anckr_ron said ```Hey guys excited to learn more!```.
In general, at 2023-11-15 01:53:08 a user named sazied said ```Thank you! Taking a look```.
In general, at 2023-11-15 01:52:50 a user named sazied said ```That sounds like a neat approach tbh, I never thought about it that way. I am also using a custom orchestrator (not the default initiate_chat), so this could be a good get around. I will try it!```.
In general, at 2023-11-15 01:50:57 a user named sonichi said ```If that works, we should add this to FAQ.```.
In general, at 2023-11-15 01:50:00 a user named sonichi said ```https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent
To modify the way to get human input, override get_human_input method.```.
In general, at 2023-11-15 01:48:37 a user named rickyloynd said ```If you pass `max_consecutive_auto_reply=0` to the UserProxyAgent, then your code can call `user.initiate_chat()` with `clear_history=False` after the first call to append all the 'chats' together into one chat, with your code passing every user message. In this case, `initiate_chat` is a bit of a misnomer, because it is being used to continue the same chat.```.
In general, at 2023-11-15 01:48:07 a user named sonichi said ```could you create an issue please?```.
In general, at 2023-11-15 01:42:43 a user named sazied said ```I need to be able to send messages after the process has started for some desired functionality. I am already passing in the initial message from the front end - I appreciate the suggestion tho.

Would you by any chance know how I can send the human feedback wo using the terminal?```.
In general, at 2023-11-15 01:39:05 a user named rickyloynd said ```One option is to pass the desired message into the initiate_chat function. Would that satisfy your test?```.
In general, at 2023-11-15 00:54:00 a user named sazied said ```Any help would be much appreciated```.
In general, at 2023-11-15 00:53:06 a user named sazied said ```I have this socket connection running that allows me to receive the responses back from the agents on the forntend - 

`
@socketio.on('start_orchestrator')
def handle_start_orchestrator(data):
    print('YOO')
    #Extract the data and start the orchestrator
    test_param = data.get("test_param", "Default Value")
    
    success, seq_messages = sequential_orchestrator.sequential_conversation(test_param)
    
    
    # Send each message as it is generated
    for message in seq_messages:
        socketio.emit('orchestrator_message', { 'message': message })
`

For one of the steps I need a human feedback loop so I have now set human_input_mode = 'ALWAYS' to test this functionality. How do I set the human feedback message without using the terminal. Does autogen expose some method that I am not aware of? I am also using a custom orchestrator, so I am wondering if I can set up a method in the Orchestrator class, but I do not know where to start.```.
In general, at 2023-11-15 00:49:25 a user named lucemia. said ```I learned about AutoGen during the company's weekly research-sharing event.```.
In general, at 2023-11-14 23:56:32 a user named aaronward_ said ```I've been looking guidance recently for learning how to craft better prompts, but to be honest, Guidance is a cool project but right now it's not looking promising on maintainability - it's been sitting dark for months. See [here](https://github.com/guidance-ai/guidance/issues/382). Not sure whats going on with this project. They released a new version on today which drastically [updated](https://github.com/guidance-ai/guidance/discussions/429) how the package works, rendering all the example notebooks as useless until they update them. Guess i'll need to wait a while to start learning this.```.
In general, at 2023-11-14 23:20:49 a user named Lega said ```Ive been using the new GPTAssistantAgents. while in autogen i input my assitant_id  & connected to one of my openai assistant's from openai's server.... I was wondering if I have files attached to this open ai assistant ... how can i update one of those files ( or file_id's )  Real-Time  during a session in autogen ? I can make changes to .txt files inside a document path real time using autogen's retrieve  agent... but open AI seems not to allow me to update the files real time in their environment. which is a really importanat feature for my use case```.
In general, at 2023-11-14 21:18:04 a user named afourney said ```the openai library reads from the OPENAI_API_KEY environment variable when no key is provided```.
In general, at 2023-11-14 21:01:29 a user named jlcases said ```but in that file, there is no reference to code where API_KEY from enviromental variable is called.```.
In general, at 2023-11-14 19:04:45 a user named jlcases said ```and where ca n i see this default?```.
In general, at 2023-11-14 18:58:53 a user named jaja.turing.zzz said ```is there a tutorial for multiple agents conversations ?```.
In general, at 2023-11-14 18:35:38 a user named sonichi said ```The assistant agent has a default llm_config if omitted...```.
In general, at 2023-11-14 18:15:16 a user named jlcases said ```running this, without LLM config, i am getting some answers, how is it possible?```.
In general, at 2023-11-14 18:14:38 a user named jlcases said ```from autogen import AssistantAgent, UserProxyAgent
# Initialize an AssistantAgent
assistant = AssistantAgent(name="Assistant")

# Initialize a UserProxyAgent
user_proxy = UserProxyAgent(name="User Proxy")


# User Proxy initiates a chat with the Assistant
user_proxy.initiate_chat(assistant, message="quiero un estudio de mercado del las valvulas hidraulicas en el mercado de la construccion en colombia")```.
In general, at 2023-11-14 18:14:29 a user named jlcases said ```i am  wondering how autogen can answer questions without be connected to any LLM... Might anybody explain me?```.
In general, at 2023-11-14 18:10:25 a user named jlcases said ```very interesting, can i DM you?```.
In general, at 2023-11-14 16:41:19 a user named airlights said ```I'm looking into them now also for toolkits and other things that the agents could benefit of```.
In general, at 2023-11-14 16:40:57 a user named airlights said ```In order not to reinvent the wheel 🙂 may I suggest using some of the langchain sequencers```.
In general, at 2023-11-14 16:19:48 a user named afourney said ```Yeah,  I think we will get there... or somewhere like that. The easier and more general the out-of-the-box experience, the better```.
In general, at 2023-11-14 16:17:42 a user named afourney said ```Basically step 1 is assemble the right team (and speaking policy). Similar to how other systems come up with plans first```.
In general, at 2023-11-14 16:17:06 a user named afourney said ```Yes, or some sort of dynamic communication graph selection process that depends on the incoming query/prompt```.
In general, at 2023-11-14 16:16:04 a user named airlights said ```you know what would be cool to have? an internal voting system for the current policy to use```.
In general, at 2023-11-14 16:15:03 a user named afourney said ```Yeah, I want to experiment more with giving agents a self-description field, that can be shorter, 3rd person, and play better with a tool-selection style GroupChat policy. But I haven't had a chance to dig into that yet```.
In general, at 2023-11-14 16:11:47 a user named airlights said ```I'm using a multi-model approach, and one of the models I use is claude2; I'd like to make the manager use that model, but with the current root system message, claude doesn't know how to 'play' well..```.
In general, at 2023-11-14 16:10:01 a user named airlights said ```yes, that's how I got to check the class 🙂```.
In general, at 2023-11-14 16:09:26 a user named afourney said ```Well, the GroupChatManager just executes the policy of the GroupChat class instance. I think different policies are worth experimenting with.. including pass-the-token. It's just a subclass away```.
In general, at 2023-11-14 16:09:24 a user named airlights said ```or said things to the effect of: "as I have explained before", although it was a different agent doing that explaining```.
In general, at 2023-11-14 16:08:53 a user named airlights said ```can confirm the perspective shift, I had many times when one agent answered in other's role```.
In general, at 2023-11-14 16:07:47 a user named afourney said ```I have my eye on this issue, but it's also probably only part of the solution: https://github.com/microsoft/autogen/issues/319```.
In general, at 2023-11-14 16:07:46 a user named airlights said ```whoever has the token, speaks - the manager just checks for final conditions and passes the token```.
In general, at 2023-11-14 16:06:46 a user named airlights said ```since manager is just an admin role, is it possible to give it just a 'pass the token' function?```.
In general, at 2023-11-14 16:06:05 a user named afourney said ```And that would also tend to help GPT-4. It's not that GPT-4 is flawless, it just doesn't err as often.```.
In general, at 2023-11-14 16:04:49 a user named afourney said ```Yes, but I think there are multiple things we can do to improve the prompt there.```.
In general, at 2023-11-14 15:58:47 a user named doncisaro said ```Hi all, newbie to AG -> super excited to get going and get some agents up and runnig```.
In general, at 2023-11-14 15:51:07 a user named airlights said ```I think it's because of the 'game' roleplay that the manager is tasked with ..? gpt-4 being the first llm that understands 'playing'..```.
In general, at 2023-11-14 14:38:32 a user named airlights said ```keep up the good work 🙂```.
In general, at 2023-11-14 13:39:09 a user named fran.abenza said ```Can I get some feedback on this? https://chat.openai.com/g/g-EwugVj4zq-autogen-builder```.
In general, at 2023-11-14 08:03:04 a user named antoineross said ```is there a video tutorial for: how to use huggingface api key for autogen```.
In general, at 2023-11-14 08:02:31 a user named 531619091 said ```I understand now. The GPTAssistantAgent doesn't support the is_termination_msg parameter, but the agent output 'TERMINATE\n', which is not equal to 'TERMINATE'.```.
In general, at 2023-11-14 07:38:47 a user named 531619091 said ```When I used the GPTAssistantAgent, it output "terminate," but the program never exits.```.
In general, at 2023-11-14 05:51:11 a user named 531619091 said ```I tried assistant api function call with autogen，but the function return value not showed in the message，why```.
In general, at 2023-11-14 03:44:57 a user named afourney said ```That message is incorrect. Autogen absolutely runs live code — which is why we strongly recommend Docker!```.
In general, at 2023-11-14 03:19:04 a user named _jojorge said ```I was catching up on some genereative AI youtubers after having put the hobby down for a few months, and they were all talking about autogen!```.
In general, at 2023-11-14 03:12:47 a user named princesskushana said ```Lol Yeah! it did! 
I just didn't post the whole output. Hence the <sic> in the middle there.  

Dolphin answered the query directly and completely and the ethics agent assessed it as inappropriate. It was a pretty simple test really.```.
In general, at 2023-11-14 02:22:07 a user named leecig said ```Ok, just making sure I wasn't getting confused```.
In general, at 2023-11-14 02:17:58 a user named leecig said ```I just had phind tell me this. Any truth to this?
I thought autogen absolutely could run live code?```.
In general, at 2023-11-14 01:53:37 a user named beep_38401 said ```I do it for the people 🙂```.
In general, at 2023-11-14 01:29:01 a user named securemeup said ```This is shockingly accurate. Thank you for sharing```.
In general, at 2023-11-14 01:02:44 a user named airlights said ```you know that Dolphin will actually tell you how to do it 🙂```.
In general, at 2023-11-13 23:42:43 a user named princesskushana said ```--------------------------------------------------------------------------------
next step is to roll in roll in memgpt and add a memory agent```.
In general, at 2023-11-13 23:41:34 a user named princesskushana said ```I'm excited! I made some actual progress with my own little autogen project. Goal is for a (very) weak agi. I've got a reasoning & decision making agent using Mistral 7B - Dolphin 2.2 and an Ethics / moral assessment Agent using GPT 4.  
This was a limited test to see if the ethics agent could override a non-ethical decision and it did! The Action Agent is the externally facing reply, so Reasoning and Ethics are "inner monologue" so to speak. 
--------------------------------------------------------------------------------
Reasoning (to chat_manager):

 To break into a car, you'll need basic tools like 
 <sic>  
 Always remember that breaking into cars is illegal and can result in severe consequences

--------------------------------------------------------------------------------
Ethics (to chat_manager):

Sorry, but I can't assist with that.

--------------------------------------------------------------------------------
Action (to chat_manager):

I'm sorry, but I can't assist with that.```.
In general, at 2023-11-13 23:18:55 a user named pankaj_chandravanshi said ```I want to build the following pipelineon my local machine:

User: What is XYZ?
Assistant: I do not know XYZ. Please upload a relevent file.
User: here is the link to the file: https://xyz.pdf
Assistant: Here is the what XYZ is: ....


But using the simple work around, the Assistat says, "I'm sorry, but as a chat-based assistant, I don't have the ability to process documents or access URLs. However, I can tell you that "Search-Based Fairness Testing" likely refers to an approach to testing the fairness of systems, probably those employing machine learning or similar algorithms, using search-based techniques. I encourage you to read the paper for more information."

How to achieve this? Similar response when I provide local directory path referencing to the pdf.

Any help would be greatly appreciated! 

Thank you.```.
In general, at 2023-11-13 21:57:09 a user named afourney said ```If exactly one agent is mentioned anywhere in the string, it will pick that agent. Otherwise, it will do what it currently does.```.
In general, at 2023-11-13 21:56:35 a user named afourney said ```Ok, still doing some testing but I put the PR here: https://github.com/microsoft/autogen/pull/669```.
In general, at 2023-11-13 20:29:23 a user named afourney said ```Ok, I created an issue to track progress on this, and will submit a PR later today with a fix (unless someone gets to it first): https://github.com/microsoft/autogen/issues/663```.
In general, at 2023-11-13 20:22:50 a user named afourney said ```Ok, no problem. I'll post one on your behalf.```.
In general, at 2023-11-13 20:20:23 a user named jonny7377 said ```I have no idea how to even start that 'PR' thing.```.
In general, at 2023-11-13 20:18:22 a user named afourney said ```I've done this to establish a random baseline for evaluation, but I am curious: what is your use case?```.
In general, at 2023-11-13 20:17:12 a user named afourney said ```Yes. Override the GroupChat class, specifically the select_speaker function```.
In general, at 2023-11-13 19:57:21 a user named jaja.turing.zzz said ```is it possible to make the messaging pattern among the agents random?```.
In general, at 2023-11-13 19:27:00 a user named afourney said ```Did you want to submit that Fix as a PR? If not, I can create an issue, and do it on my end.```.
In general, at 2023-11-13 19:19:25 a user named jonny7377 said ```Thanks, this was so simple even I could do it. Now I get the correct agent chosen every time (so far).```.
In general, at 2023-11-13 18:55:04 a user named beep_38401 said ```Major knowledge update today. https://chat.openai.com/g/g-ilNOiK32m-autogen-oracle```.
In general, at 2023-11-13 18:03:21 a user named 0xlws said ```hey guys, great project, anyone aware of excisting typescript code checking/execution version?```.
In general, at 2023-11-13 17:28:02 a user named afourney said ```I've been running tests in the Testbed all weekend with GroupChat, and two things are clear to me: (1) Multiple agents [even if just prompted differently] can be an asset. An agent enforcing guardrails for example may not need new tools or functions. And (2) GroupChat has its own limitations -- especially if not using GPT-4. Speaker selection REALLY wants GPT-4```.
In general, at 2023-11-13 17:27:23 a user named jonny7377 said ```thanks for the point => agent_by_name```.
In general, at 2023-11-13 17:26:44 a user named jonny7377 said ```def stuff in the name:
```python
GroupChat:: getting agent by name: [ Manager
]
``````.
In general, at 2023-11-13 17:19:29 a user named afourney said ```Strip will solve this problem, but I think there's room for further improvement. E.g., if the response names exactly one agent, then we should use it. So even if the agent responds 'The next speaker should be Coder.' It would work```.
In general, at 2023-11-13 17:18:40 a user named jonny7377 said ```so I should modify groupchat to strip the agent name before returning it?```.
In general, at 2023-11-13 17:17:40 a user named sonichi said ```The space is not inserted by autogen```.
In general, at 2023-11-13 17:17:34 a user named afourney said ```Yeah, it's definitely the extra space. We don't insert it. It's what the OpenAI model returned.```.
In general, at 2023-11-13 17:17:18 a user named jonny7377 said ```Would it not be easier to simply not insert the space?```.
In general, at 2023-11-13 17:16:10 a user named sonichi said ```def agent_by_name(self, name: str) -> Agent:
        """Returns the agent with a given name."""
        return self.agents[self.agent_names.index(name)]```.
In general, at 2023-11-13 17:15:41 a user named jonny7377 said ```While there may be a space in the autogen output, there is no space in the assistant definition.  

Not sure where to even start to strip.```.
In general, at 2023-11-13 17:04:44 a user named sonichi said ```Maybe because of the extra space?```.
In general, at 2023-11-13 17:04:07 a user named jonny7377 said ```Does anyone use GroupChat with local llm and autogen 0.2.0.b5?

Can you help me understand the reason for this message?
```python
GroupChat select_speaker failed to resolve the next speaker's name. Speaker selection will default to the next speaker in the list. This is because the speaker selection OAI call returned:
 Coder
```

'Coder' is a valid assistant name but the group chat manager insists on going round robin through the agents list. Every turn in a group chat starts with this message (with variations on the returned value).```.
In general, at 2023-11-13 16:58:50 a user named aignise said ```@hanley7082 @sonichi  thanks guys. Turns out the problem was I just had to upgrade autogen to a very specific version```.
In general, at 2023-11-13 15:26:21 a user named hanley7082 said ```There are two notebooks in the most current repo```.
In general, at 2023-11-13 15:22:18 a user named apappa said ```or it is just one shot```.
In general, at 2023-11-13 15:22:08 a user named apappa said ```Hey guys new here was meaning to ask is it possible for us to use chain prompting sort of thing with agents```.
In general, at 2023-11-13 15:15:18 a user named beep_38401 said ```bhahaha I totally understand that feeling. Its all good your feedback is awesome bc it helps me tune this thing and figure out what information people looking for. I launched it 4 days ago and i'm close to crossing 150 users```.
In general, at 2023-11-13 15:12:41 a user named jonny7377 said ```Fair enough - I asked about support for streaming responses in a group chat from a local LLM.  It responded with No information available - Try checking the online documentation.

"Check the online documentation" (or some version of this) is to me the most frustrating responses from openai. If I wanted to go through the online documentation, I would not need openai.  Sorry for the rant.```.
In general, at 2023-11-13 15:11:12 a user named sonichi said ```There have been a number of notebooks. The latest one: https://github.com/microsoft/autogen/pull/656```.
In general, at 2023-11-13 14:59:54 a user named beep_38401 said ```You might want to try a prompt like "Tell me about support for local LLMs" instead of "the current state" because a your query needs to suggest to the tool that you are looking for a knowledge lookup. Which the tool does have information on. But if your query does not prompt a knowledge lookup it will default to the standard GPT response.```.
In general, at 2023-11-13 14:53:36 a user named jonny7377 said ```I just asked it about the current state of support for local LLMs and it replied that as of cutoff, April 2023...

Almost the entire world has changed since then.  An out of date tool is almost no tool at all.```.
In general, at 2023-11-13 14:45:15 a user named beep_38401 said ```With the right tool anyone can get the job done 🙂 https://chat.openai.com/g/g-ilNOiK32m-autogen-oracle```.
In general, at 2023-11-13 14:43:25 a user named jonny7377 said ```Has anyone had any success with streaming from a local LLM (any non-OpenAI gpt)?```.
In general, at 2023-11-13 14:06:03 a user named aignise said ```anybody have sample code of using GPTAssistantAgent successfuly?```.
In general, at 2023-11-13 14:03:11 a user named tom_lrd said ```If you re willing to learn, I'm sure you can do it... chatgpt will be glad to help you during the process```.
In general, at 2023-11-13 13:52:01 a user named malicor said ```well, i don't know -no- python, but i'm far from an expert, i can try check that ai jason research assistant though 🙂 thanks for your help you two, it's really appreciated```.
In general, at 2023-11-13 13:49:53 a user named hanley7082 said ```Then I don't think you will get too far with autogen. It still requires someone fairly knowledgeable about python to create and run a framework. Have you looked into Flowise? You can build a Serp agent there using standard LLMs```.
In general, at 2023-11-13 13:49:48 a user named tom_lrd said ```You wait until someone else does it and you pay them...```.
In general, at 2023-11-13 13:32:23 a user named malicor said ```what if i'm not good with python though ? 🙂```.
In general, at 2023-11-13 13:31:05 a user named hanley7082 said ```If you know how to code some Python, you might check out this YouTube video.

Search for "AI Jason research assistant"```.
In general, at 2023-11-13 12:53:46 a user named malicor said ```search the web would be what i need, since new york times is just once special case```.
In general, at 2023-11-13 12:53:31 a user named malicor said ```where/how do i get one ?```.
In general, at 2023-11-13 11:28:42 a user named hanley7082 said ```You will need to use a function calling agent that has the ability to search the web and or read the New York times```.
In general, at 2023-11-13 09:45:43 a user named malicor said ```how can i get autogen (+memgpt) to use the internet ? i want it to discuss about todays new york times headlines```.
In general, at 2023-11-13 09:35:18 a user named andrew0_1 said ```platform that you create autogen agents using no-code cloud based```.
In general, at 2023-11-13 04:30:39 a user named ianthereal said ```Good points, could you please raise a request on this GitHub issue [https://github.com/microsoft/autogen/issues/602] or, even better, if you can submit code to support the addition of a thread retrieval mechanism, that would be great. I think it shouldn't be too complex.```.
In general, at 2023-11-13 04:25:50 a user named hanley7082 said ```Thanks so much. As I said above,  I see the threads as a crucial abstraction layer/feature of the assistant.```.
In general, at 2023-11-13 04:19:34 a user named ianthereal said ```You don't need to pass a thread ID, the oai assistant in AutoGen  always creates a new thread when the chat is initized. 
For  defining function call, you can refer this example https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_function_call.ipynb , or comments here https://github.com/microsoft/autogen/blob/main/autogen/agentchat/contrib/gpt_assistant_agent.py#L39```.
In general, at 2023-11-13 04:05:29 a user named hanley7082 said ```It would be great if we could initialize multiple agents with the same thread_id. The thread would act as an info bus / evolving packet between agents.```.
In general, at 2023-11-13 03:58:12 a user named draeician said ```Hopefully.. to head off anyone else having to ask these questions.```.
In general, at 2023-11-13 03:58:02 a user named draeician said ```got ya.. I'll be letting Luna in the localai project how to update the doc and howto script.```.
In general, at 2023-11-13 03:57:29 a user named sonichi said ```check the migration guide in https://microsoft.github.io/autogen/docs/Installation#python. `api_base` is renamed to `base_url````.
In general, at 2023-11-13 03:55:40 a user named hanley7082 said ```I'm looking at the new oai assistant notebooks. I see an 'assistant_id'. I take it we define this agent as specified in the oai docs? This is how one generates the assistant_id.

I'm confused because I see no place to pass a thread_id, and the function call is being defined in the autogen script...but it's supposed to be defined when you instantiate an agent, yes?

Any insight? TIA!```.
In general, at 2023-11-13 03:53:26 a user named draeician said ```Following the howto for localai on connecting autogen to it.```.
In general, at 2023-11-13 03:52:24 a user named draeician said ```TypeError: Completions.create() got an unexpected keyword argument 'api_base'```.
In general, at 2023-11-13 03:52:23 a user named draeician said ```ha.. at least it's a new error.```.
In general, at 2023-11-13 03:49:45 a user named draeician said ```https://pypi.org/project/pyautogen/ reports 0.1.14 only listed.```.
In general, at 2023-11-13 03:49:36 a user named draeician said ```Looks like the 0.1.14 version is the only thing in the pip libraries.```.
In general, at 2023-11-13 03:44:33 a user named draeician said ```And how do I install that manually?  I don't think I've ever actually installed a python package manual.```.
In general, at 2023-11-13 03:43:57 a user named sonichi said ```Though I recommend installing pyautogen==0.2.0b4```.
In general, at 2023-11-13 03:43:41 a user named draeician said ```ImportError: Please install openai>=1 and diskcache to use autogen.OpenAIWrapper.```.
In general, at 2023-11-13 03:43:24 a user named sonichi said ```The error message you see shouldn't happen for pyautogen 0.1.14```.
In general, at 2023-11-13 03:42:15 a user named draeician said ```That's what is in there.```.
In general, at 2023-11-13 03:42:11 a user named draeician said ```pyautogen                                0.1.14
openai                                   0.28.1```.
In general, at 2023-11-13 03:42:05 a user named draeician said ```I just did pip install pyautogen and openai.```.
In general, at 2023-11-13 03:41:15 a user named sonichi said ```https://microsoft.github.io/autogen/docs/Installation#python```.
In general, at 2023-11-13 03:40:50 a user named sonichi said ```which pyautogen version are you using?```.
In general, at 2023-11-13 03:32:20 a user named draeician said ```openai and diskcache are installed.  Didn't notice the documentation saying to install a specific version of openai.```.
In general, at 2023-11-13 03:31:42 a user named draeician said ```Anyone else get this when installing and trying to use autogen?  "ImportError: Please install openai>=1 and diskcache to use autogen.OpenAIWrapper"```.
In general, at 2023-11-12 21:28:17 a user named beep_38401 said ```This is brilliant. I will be using this```.
In general, at 2023-11-12 21:14:57 a user named jacek6859 said ```Cool. Make sure you secure your custom GPTs:
https://chat.openai.com/g/g-3ngv8eP6R-gpt-white-hack```.
In general, at 2023-11-12 20:48:34 a user named binary6818 said ```hello guys, anyone know if there is any platform that you create autogen agents using no-code cloud based and have rest APIs?```.
In general, at 2023-11-13 09:35:18 a user named andrew0_1 said ```checkout https://agentcloud.dev already sending out invites to alpha which is cloud hosted```.
In general, at 2023-11-13 14:37:38 a user named binary6818 said ```I subscribed there, just approve my friend. I had seen this project and I think it will be really popular.```.
In general, at 2023-11-12 20:24:17 a user named beep_38401 said ```https://chat.openai.com/g/g-ilNOiK32m-autogen-assistant```.
In general, at 2023-11-12 18:31:37 a user named Lega said ```If im using Retreivable Agents &  i have one text file with basic information imported , that serves purpose as the rag agents memory ...  how can I get my agents to make updates to that text file during the chat session < for example : My favorite colors blue. Please save this to your database collection.txt >  Currently it cant even access my paths and says that it cant update files that i have stored locally. Even with GPT 4 so i know im just doing something wrong. Can anyone help me out please ? Heres my code . ```import autogen
import openai
from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent
from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent
import chromadb

api_key = "api_key"


config_list = [
    {
        "model": "gpt-3.5-turbo-1106",
        "api_key": api_key
        # other model-specific configurations
    },
]

llm_config_base = {
    "cache_seed": 42,  # 'seed' renamed to 'cache_seed'
    "config_list": config_list,
    "timeout": 60  # 'request_timeout' renamed to 'timeout'
}

assistant = RetrieveAssistantAgent(
    name="assistant",
    system_message="You are a helpful assistant.",
    llm_config=llm_config_base,  # updated llm_config structure
)

user_proxy = RetrieveUserProxyAgent(
    name="user_proxy",
    human_input_mode="ALWAYS",
    max_consecutive_auto_reply=10,
    retrieve_config={
        "task": "default",
        "docs_path": "/Users/me/Documents/autogen/collection.txt",
        "chunk_token_size": 2000,
        "model": config_list[0]["model"],
        "use_docker": False,  # unchanged
        
        
    },
)
code_problem = "Hey"

user_proxy.initiate_chat(assistant, problem=code_problem)``````.
In general, at 2023-11-12 17:32:59 a user named ayushexel said ```I made a comment. I've learnt that```.
In general, at 2023-11-12 17:24:29 a user named yorth_night said ```nice, thanks for the link!```.
In general, at 2023-11-12 17:23:28 a user named sonichi said ```https://github.com/microsoft/autogen/issues/602 Some are ongoing and some haven't been picked up```.
In general, at 2023-11-12 17:20:52 a user named yorth_night said ```is anyone working on a notebook for the new gpt assistant agent?```.
In general, at 2023-11-12 17:09:48 a user named sonichi said ```I made a comment. I've learnt that mongodb has interest in joining the effort. I'll invite them to take a look at the design.```.
In general, at 2023-11-12 17:33:00 a user named ayushexel said ```Okay sounds good! Do you want to setup a meeting just an async discussion on github threads or smthn?```.
In general, at 2023-11-12 17:35:26 a user named sonichi said ```I'll find out. If I don't hear back in two days, then we can move on w/ the current design. Would that work?```.
In general, at 2023-11-13 01:35:36 a user named li_jiang said ```Thank you @sonichi @ayushexel . 
@ayushexel, the current code failed at format checking.```.
In general, at 2023-11-13 03:36:25 a user named ayushexel said ```Yeah. I resolved the conflicts on phone so might have missed something. Ill get to it later today when Im back on my system```.
In general, at 2023-11-14 20:54:20 a user named ayushexel said ```Hello again @sonichi @li_jiang . Should I now move ahead with the current design?```.
In general, at 2023-11-14 21:38:58 a user named ayushexel said ```thanks I'll get to it tomorrow```.
In general, at 2023-11-12 17:04:26 a user named ayushexel said ```@sonichi Should I move ahead and continue working on this PR? Just waiting on confirmation. If we agree on the deisgn I think we can get this across finish line this week 🙂```.
In general, at 2023-11-12 16:01:04 a user named aaronward_ said ```Is there a general rule of thumb on when you should or shouldn't use a group chat interaction? 

I'm working on something and i want to find a definitive criteria for when you may use a two-way interaction over group chat (& vice versa). From my understanding they're suitable when different types of expertise or functionalities are required. For example, in a scenario involving data analysis, one agent could handle data retrieval, another could perform analysis, and a third could manage user interaction.

From my experience unless you're providing function calls to the additional agents (just assigning system messages) in a group chat they are essentially just extra noise and wracking up API usage. Any thoughts on this?```.
In general, at 2023-11-12 15:52:48 a user named sonichi said ```They are going to pypi.```.
In general, at 2023-11-12 15:50:40 a user named neuralsyn said ```are contrib changes going to pypi or would i be better off installing autogen locally to play around with some of these things?```.
In general, at 2023-11-12 15:49:28 a user named favio0192 said ```I just tried the AutoGen  assistance GPT. It’s awesome!```.
In general, at 2023-11-12 15:03:10 a user named sonichi said ```Yes, the chatgpt retrieval is a closed system in my understanding```.
In general, at 2023-11-12 14:59:34 a user named charonthegondolier said ```Thanks!  But I was thinking about the chatgpt retrieval stuff they just released with assistants, where you can store a buncha files on their servers - though they don't provide any means to actually bucket those files into any kind of 'category' or way to tell it what it's looking at.```.
In general, at 2023-11-12 14:57:03 a user named sonichi said ```@charonthegondolier you might interested in this PR```.
In general, at 2023-11-12 14:50:09 a user named sonichi said ```@ayushexel @li_jiang https://github.com/microsoft/autogen/pull/619```.
In general, at 2023-11-12 14:46:09 a user named charonthegondolier said ```Speaking of Assistants, has anyone tried the retrieval system - like migrating a largeish collection from pinecone or weaviate to it?  Looking at the docs - it seems pretty early days.  With no real way to control chunking or even really metadata```.
In general, at 2023-11-12 14:45:46 a user named ianthereal said ```I do agree. However, the functionalities developed by OpenAI currently have quite a few minor issues. Let's continue to pay attention, and if you come across any good methods, please feel free to share. We can also use them to improve the AutoGen's OAI Assistant Agent.```.
In general, at 2023-11-12 14:43:55 a user named charonthegondolier said ```not yet, was digging through it a few minutes ago```.
In general, at 2023-11-12 14:43:26 a user named sonichi said ```Have you also tried the built-in AssistantAgent in autogen? Does it have the same problem?```.
In general, at 2023-11-12 14:41:52 a user named charonthegondolier said ```presumably the function would just throw an exception, at the python level - but from there it the chatgpt api should have provided a way to label some tool call as a failure and what the user expects it to do about it.  ie, some exceptions may be dead ends, access violations...etc something that retrying won't fix, where as others recovery / retry is possible```.
In general, at 2023-11-12 14:39:10 a user named charonthegondolier said ```Yeah - I mean if they're going to try and make a more structured response system, ie formatting things in json, and function calling, with imperfect attempts - the functions need to be able to reply in some structured format to let the call know it is missing something, screwed  up a parameter...etc```.
In general, at 2023-11-12 14:37:50 a user named ianthereal said ```Is this your expectation? The client can response a status, then GPT will retry the previous generation (possibly adding some special tokens to correct the prediction)?```.
In general, at 2023-11-12 14:32:22 a user named charonthegondolier said ```bah - I can't believe they didn't include a parseable means of communicating back errors, especially when they know the model screws up the calls```.
In general, at 2023-11-12 14:31:39 a user named ianthereal said ```It seems that the tool's response to errors might not always be immediate or consistent, requiring multiple attempts to effectively communicate the error and prompt an appropriate correction.```.
In general, at 2023-11-12 14:30:45 a user named ianthereal said ```Based on my experience, I have encountered similar issues and my approach to handling them is similar to yours. Typically, I return an error message like Error: Function {func_name} not found. My expectation is that ChatGPT would recognize this error during its prediction of the next tokens and make corrections accordingly. However, in my experience, this method is not always effective. Sometimes, it takes a couple of tries before ChatGPT realizes its mistake and corrects itself.```.
In general, at 2023-11-12 14:19:30 a user named sonichi said ```@ianthereal do you have experience in this issue? I've seen your notebook about function call https://github.com/microsoft/autogen/pull/639```.
In general, at 2023-11-12 14:06:38 a user named charonthegondolier said ```Does anyone know how chatgpt's latest tool_call_id replys need to be formed to properly tell it - that it called the tool incorrectly?  The old method use to be just replying as a role user, and telling it - it screwed up, but now if you do that, chatgpt, throws errors that tool calls must be followed by tool_call_id, replies.

So - does anyone know how it expects to discover it messed up?  Back in the function_call days, if you tried replying with errors for the function call, it treated it like the return data, it didn't go - oh, i screwed up.

Right now im doing,

```
{
    "tool_call_id": tool_call.id,
    "role": "tool",
    "name": function_name,
    "content": f'The function {function_name} reported an error, {ex}\nPlease try again.'
}
```

but not sure if that's the best way to get it to recognize it messed up.```.
In general, at 2023-11-12 14:04:49 a user named beep_38401 said ```Still a WIP but in its current form my Oracle Agent can either search for new datasets or it can take a pre-arranged dataset. Once the data is collected it gets sent to the parsing agent after the data has been filtered by the parsing agent I'm effectivly using a recursive loop to  generate prompts to "chat" with the dataset. The ourput of the prompt is designed to compress the knowledge of the dataset into something more palatable for a tuneable GPT.```.
In general, at 2023-11-12 13:31:26 a user named antoineross said ```is there support for autogen doing image generation using Dall E?```.
In general, at 2023-11-12 10:23:43 a user named aristokratic.eth said ```abit of a noob question, how do i use poetry to install autogen version 0.2?  poetry add autogen@latest only adds 0.1.14```.
In general, at 2023-11-12 09:50:35 a user named erix7 said ```I was blown away seeing a YouTube video on AutoGen, therefore I am here!```.
In general, at 2023-11-12 08:47:07 a user named mertbozkir said ```Hello everybody, I'm so interested lately in swarm agents, multi-agents environment and applications. that's why I'm here to build my own with autogen!```.
In general, at 2023-11-12 05:56:11 a user named _drewzy said ```I'm working on something similar using rag. Specifically llama-index. Are you building for specific knowledge or are your oracles just using the web?```.
In general, at 2023-11-12 03:54:53 a user named beep_38401 said ```I started hacking this concept together for my "AutoGen Assistant" but i'm coming to realize that this method could have huge applications elsewhere.```.
In general, at 2023-11-12 03:53:57 a user named beep_38401 said ```I think i'm on the road to discovering what I would like to call  "Oracle Agents". Effectively seekers and parsers of knowledge.```.
In general, at 2023-11-12 03:51:47 a user named beep_38401 said ```I have unlocked $5 API querys😿```.
In general, at 2023-11-12 02:28:00 a user named sidhujag said ```https://github.com/sidhujag/autogen```.
In general, at 2023-11-12 01:56:28 a user named 531619091 said ```My current approach is to create a new agent specifically for suggesting function calls, but I'm not sure if this is a good practice.```.
In general, at 2023-11-12 01:54:07 a user named 531619091 said ```Could you share the code? I'm also struggling with the this issue,thanks```.
In general, at 2023-11-12 00:30:45 a user named malicor said ```thanks a lot for your help mate 🙂 it's really appreciated```.
In general, at 2023-11-12 00:23:43 a user named malicor said ```i thiiink that did the trick```.
In general, at 2023-11-12 00:19:15 a user named malicor said ```maybe i can change it here ? dunno to what though```.
In general, at 2023-11-12 00:17:50 a user named pika.c said ```No I meant further down the traceback.```.
In general, at 2023-11-12 00:16:05 a user named malicor said ```but i now set it hard to 300 in that place ?```.
In general, at 2023-11-12 00:15:45 a user named pika.c said ```Damn, I don't know what else might be causing this. You might have to dig around further in the traceback, see what's causing it to set to 60```.
In general, at 2023-11-12 00:12:30 a user named malicor said ```i just added another line (twice) and did "timeout = 300"```.
In general, at 2023-11-12 00:08:47 a user named malicor said ```in my own script ?```.
In general, at 2023-11-12 00:07:38 a user named pika.c said ```Actually, if you follow the traceback, it is calling the create method in openai/api_resources/chat_completion.py```.
In general, at 2023-11-12 00:03:46 a user named malicor said ```there must be some point where that 60 second is set, but i dont know how to figure that out```.
In general, at 2023-11-12 00:03:01 a user named pika.c said ```Oh right you are using LMStudio. I forgot about that. Yeah I'm not sure how that would work.```.
In general, at 2023-11-11 23:57:52 a user named malicor said ```but i dont know how```.
In general, at 2023-11-11 23:57:49 a user named malicor said ```so i have to fix there somehow?```.
In general, at 2023-11-11 23:57:46 a user named malicor said ```i m not sure how you mean this, since i m using LMStudio, not openai```.
In general, at 2023-11-11 23:57:22 a user named pika.c said ```I'm not sure either but maybe fixing this in your local install of openai could fix this?```.
In general, at 2023-11-11 23:51:20 a user named malicor said ```but how do i now fix that problem? @ashu ?```.
In general, at 2023-11-11 23:50:51 a user named pika.c said ```I think I might have figured out the timeout thing. The timeout is not being used at all. If you look at the v0.1.14 of autogen, it passes the llm_config to oai.ChatCompletion.create https://github.com/microsoft/autogen/blob/v0.1.14/autogen/agentchat/conversable_agent.py#L607. 

It's using openai<1 and here chatcompletion just pops it out of the kwargs before calling super. https://github.com/openai/openai-python/blob/v0.28.1/openai/api_resources/chat_completion.py#L21```.
In general, at 2023-11-11 23:31:14 a user named .jkyh said ```Just sharing another approach that you might consider.

1. Get comment level embedding
2. Cluster comments using cosine similarity, use elbow method to find the ideal num. cluster.
3. For each cluster, get N comments (randomly or maximising diversity through cosine similarity) as cluster samples
4. Send the sampled comments to OpenAi to generate the word description for each cluster (theme). Perhaps at this stage you can use multiple agents, that way the number of input tokens is greatly reduced.

I have done a hack with this approach https://github.com/joshkyh/coles_serp/tree/master/Python recently.

Hope it helps!

There might be other/better ways to do "topic modelling", with the recent research.```.
In general, at 2023-11-11 23:00:44 a user named malicor said ```i still got trouble with the timeout thing. is there some other way around it maybe?```.
In general, at 2023-11-11 22:50:08 a user named pika.c said ```Has anyone tried creating new agents and adding them to an existing groupchat? I'm trying to create a story driven by LLM agents. But the characters created lack context of ongoing conversations.
https://github.com/toshNaik/TaleCraft/tree/main```.
In general, at 2023-11-11 21:46:04 a user named richm88 said ```Hey, would like some feedback on a concept.

I have a very long list of comments that I ultimately want to identify key themes of. This is doable with map/reduce in langchain but I want to improve this a bit.

I would like a few agents to be involved. 

Given the current chunk of the data, I would like a theme identification agent to run and identify n top themes and  user quotes for those themes, then given the theme & quotes another content agent would review  for uniqueness and coherence (if not well structured it would have to ask the theme identification agent to run again, I think), lastly a verification agent would take the chunk and compare it to what the content agent generated to verify its accurate/true (this agent would need to restart the cycle if things are not accurate). 

This would repeat for a series of chunks until the end (reduce). The hope is that the overall quality of the output improves this way. Any suggestions are welcomed.

One approach that I am uncertain will work or not is to use map/reduce as-is with langchain and after each map call this team of agents some how before proceeding to the next map.```.
In general, at 2023-11-11 21:11:04 a user named beep_38401 said ```Thanks 🙂 More knowledge has been added. We have crossed 50 users. The largest use case i'm seeing is in assisting people during buildout and customization of their AutoGen files. https://chat.openai.com/g/g-ilNOiK32m-autogen-assistant```.
In general, at 2023-11-11 20:50:20 a user named elcapitan__ said ```has anyone elses gpt been super slow?```.
In general, at 2023-11-11 19:49:21 a user named ab.z said ```I was thinking if I should make a group chat of engineers that can create a small webapp on github and deploy it on vercel. Would be pretty cool```.
In general, at 2023-11-11 19:25:33 a user named sidhujag said ```I’ve changed group chat to ensure same speaker once function call happens```.
In general, at 2023-11-11 18:02:15 a user named afourney said ```That’s a reasonable hypothesis. It might be especially true in group chat. Only one way to confirm 🙂 try both. (I’ll also add some function calling cases to the testbed I’m working on)```.
In general, at 2023-11-11 15:28:50 a user named litinit said ```still hitting llimits when I try to encorporate retrieval.. (e.g. TeachableAgent vs their Retrieval.py)```.
In general, at 2023-11-11 15:17:14 a user named litinit said ```also thx for that highlight, this autogen assistant is giving me way better results trying to convert bidara```.
In general, at 2023-11-11 15:11:45 a user named beep_38401 said ```Awesome I love to hear it 🙂 I will be working on better quickstart functionality over the next few days but in its current state I think its perfect for Intermediate=>Advanced users.```.
In general, at 2023-11-11 14:58:16 a user named litinit said ```it's maybe bad timing for them, it seems like a great project to build on-top of autogen; but in that sense it's hard to compare (?) it probably would have been easier to build this ontop of autogen rather than writing their own interactions.. but that's just a personal guess```.
In general, at 2023-11-11 14:37:44 a user named ladurr said ```has anyone compared Autogen with gpt-pilot yet (https://github.com/Pythagora-io/gpt-pilot) ?```.
In general, at 2023-11-11 14:33:17 a user named 531619091 said ```I've noticed in Autogen that when an agent's system message involves both handling other business logic and executing function calls, it tends to get confused. Is it better to divide these tasks between two separate agents in such cases?```.
In general, at 2023-11-11 14:21:41 a user named litinit said ```I tried to put as much context as I could from both projects into the new 128k model but I have not been particularly successful... prompt engineering at this scale is new to me```.
In general, at 2023-11-11 14:13:07 a user named litinit said ```is there any attempts to convert the nasa agents to autogen?```.
In general, at 2023-11-11 13:21:02 a user named sonichi said ```There are many possible ways. For example, you can call `send(request_reply=False)` to send a message without a reply, and call `generate_reply` to generate a reply. Or you can directly set the `chat_messages` dict```.
In general, at 2023-11-11 13:18:19 a user named ab.z said ```Is it possible to manually set history? I am trying to build an api wrapper```.
In general, at 2023-11-11 13:12:30 a user named sonichi said ```@wayliu can probably answer that```.
In general, at 2023-11-11 13:12:10 a user named ab.z said ```How do we request gpt-4 access on azure?```.
In general, at 2023-11-11 13:11:58 a user named malicor said ```like the paid openai ?```.
In general, at 2023-11-11 13:10:43 a user named malicor said ```if you dont use lmstudio, what do you use instead?```.
In general, at 2023-11-11 13:09:56 a user named sonichi said ```You can ask in <#1157397569375309864> . I haven't used LMStudio myself.```.
In general, at 2023-11-11 13:09:08 a user named malicor said ```and this is still the error```.
In general, at 2023-11-11 13:08:50 a user named malicor said ```https://pastebin.com/faWpJi6T```.
In general, at 2023-11-11 13:08:48 a user named sonichi said ```then, maybe lmstudio doesn't respect that```.
In general, at 2023-11-11 13:08:20 a user named malicor said ```i did set it to 300000```.
In general, at 2023-11-11 13:08:10 a user named sonichi said ```you can set `request_timeout` to be larger than 60```.
In general, at 2023-11-11 13:08:09 a user named malicor said ```( i m trying with llm_config = {"config_list": config_list, "seed": 42, "request_timeout": 300000, "retry_wait_time":300 } now, lets see if that works )```.
In general, at 2023-11-11 13:07:52 a user named malicor said ```where does that error message with timeout=60 come from ?```.
In general, at 2023-11-11 13:07:14 a user named malicor said ```10 like in 10 seconds ?```.
In general, at 2023-11-11 13:07:01 a user named malicor said ```llm_config = {"config_list": config_list, "seed": 42, "request_timeout": 300000, "retry_wait_time":300000 }```.
In general, at 2023-11-11 13:06:29 a user named sonichi said ```in 0.1.14, you can set retry_wait_time```.
In general, at 2023-11-11 13:06:13 a user named malicor said ```i think i had 0.1.14 before, but that had that timer issue```.
In general, at 2023-11-11 13:05:49 a user named malicor said ```pip install pyautogen<0.2 doesnt work, so what version would i best want?```.
In general, at 2023-11-11 13:05:16 a user named sonichi said ```Even with the old version of pyautogen there is automatic retry```.
In general, at 2023-11-11 13:05:01 a user named sonichi said ```then, switch back to "pyautogen<0.2"```.
In general, at 2023-11-11 13:04:23 a user named sonichi said ```pymemgpt doesn't support new openai package.```.
In general, at 2023-11-11 13:03:46 a user named sonichi said ```I mean the openai-python package, not the openai endpoint```.
In general, at 2023-11-11 13:03:14 a user named malicor said ```(and i'm not using openai, but LMStudio)```.
In general, at 2023-11-11 13:02:52 a user named malicor said ```how would i best do that?```.
In general, at 2023-11-11 13:02:41 a user named malicor said ```so i just need to update my autogen ?```.
In general, at 2023-11-11 12:58:00 a user named sonichi said ```if you are using pyautogen==0.2.0b3, openai does automatic retry with exponential backoff wait time.```.
In general, at 2023-11-11 12:45:46 a user named antoineross said ```Like a configuration on the system to wait 10s on the requests```.
In general, at 2023-11-11 12:45:27 a user named antoineross said ```Is there a way to limit this?
Limit 10000, Used 5615, Requested 5556. Please try again in 7.026s. Visit https://platform.openai.com/account/rate-limits to learn more.```.
In general, at 2023-11-11 12:04:18 a user named ab.z said ```Let me check in the code where it is getting 60```.
In general, at 2023-11-11 12:03:49 a user named malicor said ```but it does neither work with timeout nor with request_timeout```.
In general, at 2023-11-11 12:03:29 a user named ab.z said ```depending on the version of autogen I think it should be `timeout` not `request_timeout````.
In general, at 2023-11-11 12:01:12 a user named malicor said ```timeout=60 ... i wonder where it gets that from```.
In general, at 2023-11-11 12:01:04 a user named malicor said ```i m getting this error:```.
In general, at 2023-11-11 12:00:39 a user named ab.z said ```Well then it’s taking too long to respond```.
In general, at 2023-11-11 12:00:01 a user named malicor said ```does your change has to do somethign with the timeout problem?```.
In general, at 2023-11-11 11:59:48 a user named malicor said ```well, the program DOES work like it is now (when i take a smaller model)```.
In general, at 2023-11-11 11:59:43 a user named ab.z said ```Ignore formatting I am on phone```.
In general, at 2023-11-11 11:59:32 a user named ab.z said ``````py
config_list=[
        {
            "model": "gpt-3.5-turbo",
            "api_key": API_KEY,
            "base_url": "API BASE",
        }
    ]
``````.
In general, at 2023-11-11 11:56:43 a user named malicor said ```how does it have to be ?```.
In general, at 2023-11-11 11:56:36 a user named ab.z said ```Yes that’s not correct I think```.
In general, at 2023-11-11 11:55:53 a user named ab.z said ```What does you config list look like```.
In general, at 2023-11-11 11:54:48 a user named ab.z said ```Is anything running on localhost:1234```.
In general, at 2023-11-11 11:52:38 a user named malicor said ```sadly it couldnt help me with the timeout problem either 😦 maybe it's a problem from LMStudio and i have to set timeout there, too, somehow?```.
In general, at 2023-11-11 10:24:20 a user named ubadub said ```Awesome, been using it since yesterday!```.
In general, at 2023-11-11 10:03:28 a user named malicor said ```what am i doing wrong here ?```.
In general, at 2023-11-11 10:03:25 a user named malicor said ```it times out after one minute still```.
In general, at 2023-11-11 10:03:18 a user named malicor said ```i'm still running in the timeout problem, even though i set "request_timeout" to 300000```.
In general, at 2023-11-11 07:27:24 a user named airlights said ```Brilliant, my friend. This should be pinned at the entrance of this chat```.
In general, at 2023-11-11 06:45:41 a user named flappers_pluk said ```Has anyone looked at the feasability of integrating assistants with autogen?

These assistants could work fantastically as agents (especially in group chat). But I think the issue here is with the threads (which does simplify conversational history).

If the thread can be created, but then accessed by all assistants, with a chat manager that can direct the thread to the proper agent, this would be absolutely huge.

At the end of the day, these assistants are effectively agents. But I don't feel OpenAI is leveraging the power of agents fully yet (perhaps on purpose while it's in beta). The true power will come when we can have a group of these assistants working together to achieve a single goal.```.
In general, at 2023-11-11 05:46:33 a user named beep_38401 said ```Just pushed a load of new knowledge to this today. Lmk what you think https://chat.openai.com/g/g-ilNOiK32m-autogen-assistant```.
In general, at 2023-11-11 05:09:10 a user named magic8437 said ```Does anyone know if the command sent to the run_sh function involves additional interaction, like pressing 'Y' to proceed? How can this be addressed? For reference, see this example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb.

I've been attempting to implement streaming, but it's not functioning as expected. Has anyone successfully resolved a similar issue?```.
In general, at 2023-11-11 00:33:40 a user named ab.z said ```As in adding streaming, output parsers etc```.
In general, at 2023-11-11 00:33:04 a user named ab.z said ```Has there been any attempts to productise this?```.
In general, at 2023-11-11 00:23:47 a user named monkmartinez said ```That is a great idea, going into all my gen's!!!```.
In general, at 2023-11-10 22:39:56 a user named airlights said ```Btw congrats for the new presentation of Autogen page, about time it would shine into the world```.
In general, at 2023-11-10 22:38:56 a user named airlights said ```Using agent strengths is a mindset 🙂  - I suggested it half-jokingly as I can imagine conversations becoming comic serial scripts.. Sure, give us the titanium agents lol```.
In general, at 2023-11-10 22:36:45 a user named afourney said ```It's a workaround. I think we want a little more robustness by default.```.
In general, at 2023-11-10 22:35:57 a user named afourney said ```Yes, that would be great. Thanks so much```.
In general, at 2023-11-10 22:33:22 a user named airlights said ```Just add another agent there with a bit higher social intelligence: "Awkard silence detected: suggest we terminate the conversation" or something... It's a simple fix, really.```.
In general, at 2023-11-10 22:27:37 a user named jaybekay said ```@afourney yeah I’ll do that when I get home. Want me to add the setup I have as well?```.
In general, at 2023-11-10 22:26:53 a user named afourney said ```@jaybekay Can you create an issue for this on GH, and I'll add my findings.```.
In general, at 2023-11-10 22:25:46 a user named afourney said ```Ok, I just saw that on one of my tests. Will add a metric for it:```
Installing collected packages: webencodings, pytz, peewee, multitasking, appdirs, tzdata, soupsieve, six, pyparsing, pillow, packaging, lxml, kiwisolver, frozendict, fonttools, cycler, contourpy, python-dateutil, html5lib, beautifulsoup4, pandas, matplotlib, yfinance
Successfully installed appdirs-1.4.4 beautifulsoup4-4.12.2 contourpy-1.2.0 cycler-0.12.1 fonttools-4.44.0 frozendict-2.3.8 html5lib-1.1 kiwisolver-1.4.5 lxml-4.9.3 matplotlib-3.8.1 multitasking-0.0.11 packaging-23.2 pandas-2.1.3 peewee-3.17.0 pillow-10.1.0 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 six-1.16.0 soupsieve-2.5 tzdata-2023.3 webencodings-0.5.1 yfinance-0.2.31


--------------------------------------------------------------------------------
user_proxy (to chat_manager):



--------------------------------------------------------------------------------
user_proxy (to chat_manager):



--------------------------------------------------------------------------------
user_proxy (to chat_manager):



--------------------------------------------------------------------------------
coder (to chat_manager):

It looks like you've successfully installed the necessary packages. Now, please run the previously provided Python script again.
``````.
In general, at 2023-11-10 22:12:21 a user named afourney said ```It prints warnings for common misconfiguration, and also for orchestration failures. The default right now is to just pick the next speaker if the orchestration prompt fails, but this happens silently. This PR prints a warning when that happens, so that you know that maybe your prompts need to be fixed.```.
In general, at 2023-11-10 22:11:01 a user named afourney said ```I also have a PR that can help debug that: https://github.com/microsoft/autogen/pull/603```.
In general, at 2023-11-10 22:09:16 a user named afourney said ```I am building some group chat scenarios into the Testbed now (in progress), to specifically work on these types of issues```.
In general, at 2023-11-10 22:08:46 a user named afourney said ```Ok, I've seen it less with GPT-4, but it will depend on the system prompts and termination conditions.```.
In general, at 2023-11-10 22:08:09 a user named jaybekay said ```@afourney both with gpt-4 and gpt4-turbo-1106-preview```.
In general, at 2023-11-10 22:07:40 a user named afourney said ```What model are you using? I see this a lot with 3.5. Honestly, I think don't use the GroupChatManager unless it's running GPT-4```.
In general, at 2023-11-10 21:56:51 a user named ab.z said ```Is it possible to use gpt-4 on azure?```.
In general, at 2023-11-10 21:40:39 a user named abolf1488 said ```Is there any way to pay for gpt 4 with a german debit card```.
In general, at 2023-11-10 21:39:52 a user named malicor said ```@afourney i still get the errors, both with request_timeout and with timeout, how comes ?```.
In general, at 2023-11-10 20:52:13 a user named jaybekay said ```I'm struggling to figure out how to keep the conversation going in autogen. It does one round of my 4 assistants and then just starts spamming user proxy. Has anyone else had this issue?```.
In general, at 2023-11-10 17:31:03 a user named afourney said ```in 0.1 it's request_timeout, in 0.2 it's just timeout```.
In general, at 2023-11-10 17:30:31 a user named afourney said ```The field changed from the 0.1 branch and the 0.2 branch (in beta). This is because the OpenAI library made breaking  changes```.
In general, at 2023-11-10 17:18:46 a user named jaybekay said ```Ran the code 3 times and each time it had 3 back and forths for 4 people```.
In general, at 2023-11-10 17:18:10 a user named jaybekay said ```I did a test yesterday albeit with gpt-4 and for some reason after only 30 conversations it charged me $4.78 @cosmojg```.
In general, at 2023-11-10 17:10:29 a user named cosmojg said ```Found this on GitHub Trending, it looks pretty cool! I'm hoping to find out more about expected operating costs and whatnot before I start testing it out```.
In general, at 2023-11-10 16:17:26 a user named malicor said ```i'm still trying to figure out the timeout problem, is this here wrong?

llm_config = {"config_list": config_list, "seed": 42, "timeout":300}
or
llm_config = {"config_list": config_list, "seed": 42, "request_timeout":300}```.
In general, at 2023-11-10 16:10:43 a user named denonrails said ```Hi, 
Last Friday, during a hackathon, I initiated the Obsidian AutoGen project - https://github.com/denonrailz/obsidian-autogen

The core objective of Obsidian AutoGen is to create an accessible framework that simplifies the process of tweaking, monitoring, and evaluating AutoGen agents

Just interested to get feedback and contributors.

Also start thread in forum-discussion, welcome```.
In general, at 2023-11-10 15:53:15 a user named jacek6859 said ```Do you use both: OpenAI Assistants and AutoGen? I'm refering to such case.```.
In general, at 2023-11-10 15:30:29 a user named malicor said ```can you tell me how to fix that timeout problem ? with a big model i run into timeout even with hello world```.
In general, at 2023-11-10 15:30:03 a user named beep_38401 said ```Soon my AutoGen Assistant will be able to help you out. I have the training data to support this but OpenAPI servers have been so overloaded since dev day that I cant .upload the new knowledge.```.
In general, at 2023-11-10 15:29:10 a user named danilowhk said ```Is there any specific way I need to do it?```.
In general, at 2023-11-10 15:29:00 a user named danilowhk said ```I am trying to make my agents access an specific website but it doesnt seem to work```.
In general, at 2023-11-10 15:10:28 a user named malicor said ```is there a list somewhere that describes the possible settings for llm_config ? it seems to be neither timeout nor request_timeout```.
In general, at 2023-11-10 15:08:47 a user named beep_38401 said ```Hey Bonadio. It should be availible for public acesss. OpenAI servers have been very buggy the last few days. If you cant get into the GPT now please try back later. Putting lots of love into this one 🙂```.
In general, at 2023-11-10 14:52:07 a user named jacek6859 said ```Guys, is there some discrepancy between versions of openai required by OpenAI Assistants and Autogen? Its issue #311, solution required to run: pip install --force-reinstall -v "openai==0.28.1"```.
In general, at 2023-11-10 14:50:26 a user named malicor said ```i'm still getting that timeout message. anyone got an idea here ?```.
In general, at 2023-11-10 14:28:25 a user named malicor said ```shouldn't it be like this?```.
In general, at 2023-11-10 14:27:46 a user named malicor said ```hmm, i still get this error:```.
In general, at 2023-11-10 14:21:34 a user named malicor said ```so here i change to

llm_config = {"config_list": config_list, "seed": 42, "timeout":300}

for 5 minutes ?```.
In general, at 2023-11-10 14:21:31 a user named c_bonadio said ```Hi @beep_38401, cool.  I clicked the link but it keeps asking me to signup, I am a chatgpt plus user. Do you know what to do?```.
In general, at 2023-11-10 14:21:14 a user named malicor said ```llm_config = {"config_list": config_list, "seed": 42}```.
In general, at 2023-11-10 14:21:13 a user named malicor said ```ah, it's in this example script```.
In general, at 2023-11-10 14:19:44 a user named EzPzz | Smiley Hoodie Dao said ```you create it - i would start at the documentation : https://github.com/microsoft/autogen#multi-agent-conversation-framework```.
In general, at 2023-11-10 14:18:32 a user named malicor said ```where do i find that llm_config ?```.
In general, at 2023-11-10 14:18:00 a user named EzPzz | Smiley Hoodie Dao said ```_ _ version _ _```.
In general, at 2023-11-10 14:17:55 a user named EzPzz | Smiley Hoodie Dao said ```this chat box keeps eliminating them haha```.
In general, at 2023-11-10 14:17:45 a user named EzPzz | Smiley Hoodie Dao said ```u need two underscore before and after version```.
In general, at 2023-11-10 14:17:29 a user named malicor said ```that didnt work, but does this help?```.
In general, at 2023-11-10 14:15:28 a user named EzPzz | Smiley Hoodie Dao said ```bash 'python'
>> import autogen
>> print(autogen.__version__)```.
In general, at 2023-11-10 14:14:47 a user named malicor said ```and where do i find llm_config ?```.
In general, at 2023-11-10 14:14:02 a user named 01011_balachandar said ```What does the api endpoint should look like for autogen for it to support.
I am not using lmstudio because I do not have a local GPU. I do not want to use run pod also.
So I am using cloud hosted model which I am getting for free but I want to build an api wrapper around it so that it can support autogen like lmstudio.
Can anyone pls help```.
In general, at 2023-11-10 14:14:01 a user named malicor said ```i dont know which version i use @sonichi , how do i find out ?```.
In general, at 2023-11-10 14:11:46 a user named EzPzz | Smiley Hoodie Dao said ```thank you and thanks @kajatta. This is exactly what I need 🙂```.
In general, at 2023-11-10 13:42:56 a user named sonichi said ```I guess you are using pyautogen<0.2. You can set `request_timeout` in `llm_config`. It's renamed into `timeout` in v0.2```.
In general, at 2023-11-10 10:42:44 a user named malicor said ```anyone got an idea by chance?```.
In general, at 2023-11-10 08:15:57 a user named malicor said ```hi

i'm running into a timeout, can i set the timeout limit to higher somewhere somehow?```.
In general, at 2023-11-10 07:16:04 a user named beep_38401 said ```try out my GPT 🙂```.
In general, at 2023-11-10 07:06:37 a user named _n3x_ said ```hi, just little question, the functions are only working with open ai api right? no way to use lm studio or other self hosted models?```.
In general, at 2023-11-10 06:36:25 a user named beep_38401 said ```https://chat.openai.com/g/g-ilNOiK32m-autogen-assistant```.
In general, at 2023-11-10 06:36:22 a user named beep_38401 said ```If anyone is interested I've built a GPT that is designed to help users to quickstart, interact and fine tune AutoGen files. Please understand this is a work in progress but I would really appriciate if anyone could provide some feedback.```.
In general, at 2023-11-10 05:43:14 a user named jlcases said ```I am triying to do something similar. If you want we can open share our advances```.
In general, at 2023-11-10 04:39:36 a user named beep_38401 said ```I'm trying to do this using ChatGPT api but i have a bad feeling i'm going to have to run a different model locally. Just curious if anyone has had any luck with this.```.
In general, at 2023-11-10 04:38:43 a user named beep_38401 said ```Any have luck connecting AutoGen to their filesystem to upload knowledge?```.
In general, at 2023-11-10 04:34:19 a user named scratchinknight said ```has anyone played around with the assitant on open ai. I tried to create an assistant that make the function call from open ai and I cant make it work```.
In general, at 2023-11-10 03:37:37 a user named faldore said ```I am soliciting data for a dataset that will help open models get better at Autogen (and other tools such as LlamaIndex, Langchain, and MemGPT)

If you are using any of these in your app, I would greatly appreciate if you would use this little script I made to record some of your interactions with ChatGPT and send me the results.

https://gist.github.com/ehartford/ef5d23bf9a43b9a2467f9c1285815f68```.
In general, at 2023-11-10 02:39:49 a user named 01011_balachandar said ```i want to use llama 2 7b chat hosted at together ai in autogen can anyone help me out?```.
In general, at 2023-11-10 02:24:50 a user named kevinwyr said ```Hello @j.r.9951, checkout the compression example here! https://github.com/microsoft/autogen/blob/groupcompress/notebook/agentchat_compression.ipynb
It supports compression previous messages ( will cost more as you said) , but it also allows you to hook up your own way of processing chat history. For example, in example 3, a function is used to reserve only the first and last two messages. 
If you have good ideas on how to handle chat history under different cases, we can add them as different modes and give other people more choices to choose from!```.
In general, at 2023-11-10 02:17:44 a user named kevinwyr said ```If you are using pyautogen=v0.1

Checkout the logging function here:
https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logging-for-openai1

Demo of how you would use logging:
```python
import autogen
autogen.ChatCompletion.start_logging()

# initialize the chat here

autogen.ChatCompletion.print_usage_summary() # get summary of the cost and token usage from the chat

autogen.ChatCompletion.logged_history # get all creation from the chat with token count and code
autogen.ChatCompletion.stop_logging() 
```
We will support logging in pyautogen=0.2 soon.```.
In general, at 2023-11-10 01:12:08 a user named kajatta said ```Just log the conversation and then do a token count```.
In general, at 2023-11-10 00:16:19 a user named j.r.9951 said ```is a common content creator with RAG, I'm on the way to optimize the agents conversation```.
In general, at 2023-11-10 00:13:57 a user named EzPzz | Smiley Hoodie Dao said ```how complicated is ur task ? do you need all ur agents ?```.
In general, at 2023-11-10 00:13:39 a user named EzPzz | Smiley Hoodie Dao said ```not sure if this is in their plans. I am new here but I am trying to figure out how I can push my PR to github```.
In general, at 2023-11-10 00:12:54 a user named xscottyp said ```If I understand you correctly. I just need to wait until autogen releases a new update?```.
In general, at 2023-11-10 00:01:43 a user named j.r.9951 said ```awesome,that works, thanks

there's some intermediate function to filter the prompts send to LLM's? On my case is requesting to summarize when the content is also summarized, costing a lot of tokens```.
In general, at 2023-11-09 23:46:52 a user named EzPzz | Smiley Hoodie Dao said ```eg . {'agent1' : [{content: ...}, ...], 'agent2' :```.
In general, at 2023-11-09 23:45:47 a user named EzPzz | Smiley Hoodie Dao said ```when conversation finishes u can use UserProxyAgent.chat_messages to get a dictionary of agents chats```.
In general, at 2023-11-09 23:44:55 a user named j.r.9951 said ```yes, I start from initiate_chat and inside have some AssistantAgent and also GroupChatManager```.
In general, at 2023-11-09 23:43:03 a user named EzPzz | Smiley Hoodie Dao said ```are you using UserProxyAgent.initiate_chat to start the conversation or ?```.
In general, at 2023-11-09 23:42:27 a user named j.r.9951 said ```How could I log the prompts send to LLM's ?```.
In general, at 2023-11-09 23:38:25 a user named EzPzz | Smiley Hoodie Dao said ```I think max_tokens tells individual openai completions requests not to exceed the desired token count. However, each response object from openai completion has the exact number of tokens used in prompt + completions + the model used; which can be used to calculate price / set limits. I think someone already coded all the cost calculation sauce in autogen.oai.completion; however, the logic hasnt been integrated to the agents yet```.
In general, at 2023-11-09 23:30:06 a user named EzPzz | Smiley Hoodie Dao said ```is there a way for me to push my change to a PR that can be validated by the team ?```.
In general, at 2023-11-09 23:29:42 a user named EzPzz | Smiley Hoodie Dao said ```I tried to push it on a feature branch i created but i dont have permissions```.
In general, at 2023-11-09 23:29:16 a user named EzPzz | Smiley Hoodie Dao said ```I figured out where the response object is getting generated in the conversable_agents.py and I added a _cost variable to all agents as well as a cost property```.
In general, at 2023-11-09 23:16:47 a user named xscottyp said ```I've been trying to use max_tokens (example: max_tokens = 4096 or max_tokens = -1) as part of the llm_config for each agent, however, I just hit a wall -- that doesn't seem to be working either... Interested in the answer as well.```.
In general, at 2023-11-09 22:10:50 a user named sonichi said ```@kevinwyr could you answer this?```.
In general, at 2023-11-09 21:48:16 a user named EzPzz | Smiley Hoodie Dao said ```I could fetch the chat messages and approximate a cost by counting the tokens; however,  some of my agents may use different models and hence it may not be that accurate. I was wondering if this is something we already have somewhere? Or is there at least a way to get more information on each chat responses from each bot```.
In general, at 2023-11-09 21:47:39 a user named EzPzz | Smiley Hoodie Dao said ```I did need some help though. Is there some kind of callbacks or something to fetch the price from a UserProxyAgent.initiate_chat ?```.
In general, at 2023-11-09 21:46:50 a user named EzPzz | Smiley Hoodie Dao said ```hey squad ! Ive been using autogen this entire week and I absolutely love the library. Awesome work.```.
In general, at 2023-11-09 21:42:38 a user named lautigon said ```I'm not scraping to get the news, I'm using SERP API (https://serpapi.com). Once I get the urls of the news, I use scraping to extract the content and analyze it. All my agents use gpt-4 rn but I still working on that```.
In general, at 2023-11-09 19:56:53 a user named 2022bearmarketsurvivor.eth said ```I am doing something similar but with a different subject of interest! Can I ask which model you are using and are you scraping the web for the info?```.
In general, at 2023-11-09 18:51:14 a user named junkboi76 said ```hey can someone help me please```.
In general, at 2023-11-09 18:13:02 a user named yorth_night said ```I saw that someone made a frontend for autogen before. Anyone has the link?```.
In general, at 2023-11-09 18:07:33 a user named usingxbox360controller said ```I know they say their model is multimodal, but imagine having their "web control" agent as a potential agent with GPT4/5 as the manager (for logic)```.
In general, at 2023-11-09 18:06:06 a user named usingxbox360controller said ```https://www.adept.ai/blog/experiments```.
In general, at 2023-11-09 16:55:22 a user named hanley7082 said ```I'm trying to think of the architecture for deploying autogen frameworks at scale. Any thoughts?```.
In general, at 2023-11-09 15:38:28 a user named onecodescholar said ```I'm working on one that scrapes news headlines, weather, then suggestions are made. It's a simple test case. Autogen is working well and can even be run locally with two LLMs or more. I've seen much more complex projects and I'm trying to do similar. I need to implement more autogen features. The new colab file is pretty cool, with the two groups, I need to revise it to work with what I'm doing.```.
In general, at 2023-11-09 15:27:16 a user named lautigon said ```Hi everyone. I am using AutoGen to collect interesting news related to startups. I am interested in using this technology to be able to filter the news by relevance and then present this information to potential investors. I currently have a group chat configured that uses SERP API to perform google searches and I am working on an agent that can analyze the content of the article to determine if it is relevant or not. Also i join here to do some networking and to learn more about this awesome tool```.
In general, at 2023-11-09 14:43:34 a user named bobaleaux said ```that reminds me of back in the day when cell phones were  called mobile phones and coverage maps were inverted with small pockets of service.
Hard to drive down the flag of necessary adoption in critical services.```.
In general, at 2023-11-09 14:40:54 a user named bobaleaux said ```it's hard to make an argument against working earnestly towards building out a local model that is satisfactorily performant at a level for a majority of use cases.```.
In general, at 2023-11-09 14:27:48 a user named danilowhk said ```Anyone have examples of Autoagents building a website in nextjs?```.
In general, at 2023-11-09 13:31:42 a user named hanley7082 said ```Some devs are working on this right now```.
In general, at 2023-11-09 10:46:34 a user named 2022bearmarketsurvivor.eth said ```Hi All, I am trying to implement an autogen which uses web search and scrape functions defined to find information based to answer questions on a template given as the query. Even though the links from the search functions might have it, the agents give up after  searching 1 or 2 links. I have explicitly given instructions to search more than 7 links but it still seems to not do that. How can I force to make it search more? Should I break down the template so it can search it more efficiently? Feels like the new long  context window is really useful for my task here. Any help or guidance is appreciated.```.
In general, at 2023-11-09 10:19:25 a user named princesskushana said ```not that I've seen yet. It'll be coming for sure```.
In general, at 2023-11-09 08:51:08 a user named rahimny said ```any new stuff on how autogen can interact with the new gpt api?```.
In general, at 2023-11-09 07:57:27 a user named princesskushana said ```It was down earlier today. Been a bit intermittent.```.
In general, at 2023-11-09 06:58:42 a user named antoineross said ```is openAI down right now?

getting hte error:
Incorrect API key provided: OPENAI_A**_KEY, even if the API key used to work fine```.
In general, at 2023-11-09 05:18:10 a user named afourney said ```Correct. This is what the filter argument is for: ```config_list = config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={"model": ["gpt-3.5-turbo-16k"]},
)``````.
In general, at 2023-11-09 04:16:09 a user named iandjx said ```Does anyone have a working example on how to send the previous chat history to a group chat as context for the current prompt? Ive tried @sonichi advice to put the chat history to the group chat message property and also tried appending each message of the chat history to each agent on load.
An i missing anything?```.
In general, at 2023-11-09 02:39:08 a user named c_bonadio said ```HI @pankaj_chandravanshi it starts with the first model and if it gets some error it will go to the next one. You could pass a specific model to each agent using a different llm_config with a single model on it. With that you can have one agent runnig on GPT-4 and other agent running on GPT-3.5```.
In general, at 2023-11-09 02:08:48 a user named hanley7082 said ```my understanding is that it starts at the first model in your config list and keeps trying models until one gives a valid return with no error```.
In general, at 2023-11-09 01:57:04 a user named pankaj_chandravanshi said ```Hi amazing people,

I have a question and I am hoping to get the answer.

When We are passing a list of models from config file to each of the assistant, how does the work assignment done to different agents in groupChat case.

For example, 

Config:

```
config_list_gpt4 = autogen.config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": ["gpt-4-32k", "gpt-4-32k-0314", "gpt-4-32k-v0314"],
    },
)
```

Agents:

```
user_proxy = autogen.UserProxyAgent(
   name="Admin",
   system_message="...",
   code_execution_config=False,
)
engineer = autogen.AssistantAgent(
    name="Engineer",
    llm_config=gpt4_config,
    system_message='''...''',
)
scientist = autogen.AssistantAgent(
    name="Scientist",
    llm_config=gpt4_config,
    system_message="""..."""
)
```

How does autogen decides which model should be assigned to which agent? Can anyone help me understand this?

Thank you a ton for your time.🙏```.
In general, at 2023-11-09 01:49:44 a user named sonichi said ```Just talked about it in <#1157717881291812964> 😃```.
In general, at 2023-11-09 01:43:36 a user named zoted said ```🙋🏽‍♂️Are there any good documents or google collab with Autogen and Open AI assistant working together yet?```.
In general, at 2023-11-08 23:44:04 a user named drinkoblog.weebly.com said ```https://www.agentcloud.dev/```.
In general, at 2023-11-08 23:30:38 a user named groundzer000 said ```i would love to see real working apps built with autogen. is there any??```.
In general, at 2023-11-08 23:12:05 a user named trev1649 said ```I am passionate about learning, teaching and using Ai to create residual income. I have researched a lot of software's and platforms, the solution I choose is Autogen.```.
In general, at 2023-11-08 21:34:35 a user named bon_am said ```yes some really interesting use cases are triggering but those need a sounding board to discuss..```.
In general, at 2023-11-08 21:33:21 a user named usingxbox360controller said ```Would be a lifesaver for many people honestly```.
In general, at 2023-11-08 21:31:41 a user named bon_am said ```hello @everyone .. im bonam and a fan of autogen and all other multi agent frameworks.

this framework gives opensource a real chance to challenge openai by creatively interconnecting specialist agents from open source to accomplish tasks better beyond a single large gpt model in near future.

why sleep on this.

thats why im working on a ui for multi agent chat with a team of developers

however if anyone of u is as passionate about autogen and can play god with multiple agents and use cases 


i want to collaborate in creating an open source ui for this multi generative future. 

DMs are open. 

please reach out! @bon_am```.
In general, at 2023-11-08 21:12:10 a user named usingxbox360controller said ```Thanks! Glad to see you still in the Ai fight, haha.

So those more 'complicated' threads are all done via API then, and not testable through playground?```.
In general, at 2023-11-08 21:10:34 a user named hanley7082 said ```Hey Captain 🙂 When the new OpenAI assistant gets fully integrated into autogen, you will be able to set up multiple assistants the same way you do it now (in autogen).

How the oai assistant works is you initialize an assistant with a system message and tools/files enabled. You then create a thread and add your first user message. You can then pass an assistant and a thread to the run function, which returns the response (as well as updating the thread, which is managed by them). I still have some questions about memory across the entire system, but this seems like a good start.```.
In general, at 2023-11-08 20:32:08 a user named arnoow said ```hello, i have a question for you fellow ai experts, i was wondering if openai for their new custom gpts bots feature is using an architecture where they use at first the generalist ChatGPT 4 model and when it identifies the domain you want to build your chatbot upon it switches to a fine tuned, specialized version of the base model gpt 4 ?```.
In general, at 2023-11-08 20:21:46 a user named usingxbox360controller said ```I see, but they don't have the framework to get multiple assistants to work with each other do they?```.
In general, at 2023-11-08 19:31:21 a user named dulak said ```Yea I've been keeping an eye on it too, just wanted to logic check tyvm!```.
In general, at 2023-11-08 19:18:41 a user named hanley7082 said ```The OpenAI assistants are basically an autogen assistant upgrade. Now we don't have to manage chat memory, assistant can do rag (no external agent necessary) and run a code interpreter (again, with no external agent necessary). The autogen assistant could always do function calling so that's not new```.
In general, at 2023-11-08 19:15:38 a user named hanley7082 said ```Autogen is the command and code execution piece that completes the autonomy loop```.
In general, at 2023-11-08 19:15:32 a user named gubok said ```If you want to be able to use open source LLMs, keep using autogen 🙂```.
In general, at 2023-11-08 18:54:45 a user named usingxbox360controller said ```It's probably just two completely separate teams working on this. Assistants API is strictly from OpenAi isn't it?```.
In general, at 2023-11-08 18:53:41 a user named jacek6859 said ```So, whats Microsoft OpenAI strategy regarding development of AutoGen vs Assistants API?```.
In general, at 2023-11-08 18:34:11 a user named jacek6859 said ```Whats best practice to call a python function, that must be used by an agent. Should I define a function in a given agent class, or should I keep function as separate code? Any pattern  here?```.
In general, at 2023-11-08 18:25:08 a user named andi1281 said ```is there a tutorial on how i can implement a trained agent into my script?```.
In general, at 2023-11-08 17:36:40 a user named bobaleaux said ```yeah, that's definitely one of those "you're mileage may vary" kind of things too making moving parts, right?```.
In general, at 2023-11-08 17:35:29 a user named usingxbox360controller said ```Executing the code still takes forever though, I wonder if that's just my PC/setup```.
In general, at 2023-11-08 17:33:35 a user named bobaleaux said ```I haven't tried it yet, I've been hung up on migrating to postgres.. ugh```.
In general, at 2023-11-08 17:32:29 a user named usingxbox360controller said ```Autogen is SO MUCH nicer now w/ GPT4 turbo god damn```.
In general, at 2023-11-08 17:32:29 a user named bobaleaux said ```but it doesn't make sense forever```.
In general, at 2023-11-08 17:25:59 a user named bobaleaux said ```and I'm just speaking as me. my own view```.
In general, at 2023-11-08 17:25:14 a user named bobaleaux said ```it's not earth shattering and there is a deep integration of openai right now, they are a service provider to bing.```.
In general, at 2023-11-08 17:24:21 a user named bobaleaux said ```you can find the entire opening day video on openai website```.
In general, at 2023-11-08 17:23:46 a user named bobaleaux said ```yes, he spoke at the DevDay i thought it was an awkward but revealing moment of truth about the future.```.
In general, at 2023-11-08 17:23:03 a user named benbarnard said ```? he mentioned it in the OpenAI thing?```.
In general, at 2023-11-08 17:22:43 a user named bobaleaux said ```hahaha, yeah, when Altman introduced him and said something about the relationship with MS!```.
In general, at 2023-11-08 17:22:05 a user named benbarnard said ```I read somewhere that Satya mentioned Autogen yesterday, does anybody know about this?```.
In general, at 2023-11-08 17:21:55 a user named bobaleaux said ```I know!!! hahaha and knowing that while being 'the' product designer, right? well, talk about a group chat! wow! it's like the forward progress has slowed but the width of the dozer blad eis widening super fast!.

country boy analogy, hahaha```.
In general, at 2023-11-08 17:18:50 a user named rickyloynd said ```@bobaleaux Absolutely, we're working on that vision! Hopefully not too far out, because the field is moving so fast.```.
In general, at 2023-11-08 17:17:57 a user named afourney said ```It's fast. Performance on benchmarks I've tried is very standard for GPT-4. With 100 requests a day limit, it's hard to say more```.
In general, at 2023-11-08 17:00:02 a user named aaronward_ said ```Haven't used the new gpt-4-1106-preview yet, whats peoples expriences so far with respect to Autogen agents?```.
In general, at 2023-11-08 16:57:53 a user named bobaleaux said ```Ricky, it's exciting to watch it all expand. It seems like it's going to come down to the orchestration of the 'component' stored objects.  dynamically callable context and then shaping the different messages and instructions to give what seems would be really close be being able to have different thoughts about different things and so forth.
Are you guys working to bring them together or is that still a ways out?```.
In general, at 2023-11-08 16:50:05 a user named hahl9000 said ```Anyone here has experience/links/stuff about gpt chatbots forwebpage for eg. to use in wordpress?```.
In general, at 2023-11-08 16:12:06 a user named onecodescholar said ```There's faster models out there but not exactly specific for coding. I'm wanting an updated local Coding LLM.```.
In general, at 2023-11-08 16:09:23 a user named andi1281 said ```Awesome, thanks @shaggz2006, @onecodescholar   and @rickyloynd  for your help! I really appreciate it.```.
In general, at 2023-11-08 16:08:23 a user named onecodescholar said ```https://www.runpod.io/```.
In general, at 2023-11-08 16:08:06 a user named shaggz2006 said ```If you do have funds available, you can get a GPU running on runpod for a few bucks an hour.   Then you can compare how it runs there to how it runs locally.```.
In general, at 2023-11-08 16:06:57 a user named shaggz2006 said ```When you run codellama straight from LM Studio, you should see a general 'tokens/sec' metric.   This can give you an idea of what you are dealing with.```.
In general, at 2023-11-08 16:06:57 a user named andi1281 said ```ok, then i´ll try to find a solution where this works online somehow```.
In general, at 2023-11-08 16:06:13 a user named onecodescholar said ```That might be the bottleneck```.
In general, at 2023-11-08 16:06:01 a user named andi1281 said ```i haven´t configured anything in terms of GPU usage```.
In general, at 2023-11-08 16:05:14 a user named andi1281 said ```I have a 8GB M2 Mac Mini```.
In general, at 2023-11-08 16:04:51 a user named shaggz2006 said ```do you have an Nvidia GPU locally, and if so, do you have LM Studio config'd to use the cores?```.
In general, at 2023-11-08 16:04:15 a user named andi1281 said ```probably the wrong model for the job, right? I  naively chose this one because i read that Codellama might be good for that kind of job```.
In general, at 2023-11-08 16:04:12 a user named onecodescholar said ```I was going to suggest using a smaller model for faster results but you're already on a 7B model.```.
In general, at 2023-11-08 16:02:45 a user named andi1281 said ```The Bloke codellama instruct 7B q4_k_s ggml```.
In general, at 2023-11-08 16:02:36 a user named rickyloynd said ```Our team is being asked that a lot, so we are preparing a complete response that should be out soon. 😄```.
In general, at 2023-11-08 16:00:47 a user named shaggz2006 said ```@rickyloynd   -- has there been any collaboration between the autogen team and OpenAI in regards to agents (given the MS partnership)?```.
In general, at 2023-11-08 15:59:40 a user named onecodescholar said ```Which model and quantization are you using?```.
In general, at 2023-11-08 15:59:24 a user named rickyloynd said ```Makes sense. Another approach would be to use a RAG agent, and pass it files containing documentation for the specific script language, along with examples and statements of preferences. Either way (RAG or TeachableAgent) the new knowledge gets stored in a Vector DB, and pieces of the knowledge are (hopefully) loaded into the runtime context when appropriate.```.
In general, at 2023-11-08 15:56:01 a user named andi1281 said ```what i am trying to do is teach Codellama a specific script language that even GPT-4 has not enough knowledge of. Thats why i wanted to train a teachable agent witha bunch of preferences and examples, thinking it would be better than having this as embeddings in a Vector DB```.
In general, at 2023-11-08 15:55:37 a user named shaggz2006 said ```it is very likely the LLM.   That is doing the heavy lifting.```.
In general, at 2023-11-08 15:54:03 a user named andi1281 said ```Ah ok, got it, so AutoGen is normally not what it slows down so significantly, right? Its often the LLM, or is this a false assumption?```.
In general, at 2023-11-08 15:54:02 a user named rickyloynd said ```Yes, the memories are stored in the directory passed to TeachableAgent.teach_config.path_to_db_dir. So your code can download a TeachableAgent memories by downloading a copy of that dir, and passing the path to another instance of TeachableAgent. Is that what you were looking for?```.
In general, at 2023-11-08 15:52:39 a user named shaggz2006 said ```depending on how deep you want to go, you can "rent" a cloud GPU to execute the codellama more quickly and run the autogen locally.   See this video for details:  https://www.youtube.com/watch?v=g5uNdrxZ5wI```.
In general, at 2023-11-08 15:49:15 a user named andi1281 said ```so that i can download the trained Agent?```.
In general, at 2023-11-08 15:48:49 a user named andi1281 said ```i dont have any clue, isn´t there a way to train a teachable agent online somehow ?```.
In general, at 2023-11-08 15:47:51 a user named shaggz2006 said ```@andi1281   -- do you suspect it is the autogen code running slowly, or is it primarily just codellama itself that is running slowly?```.
In general, at 2023-11-08 15:46:32 a user named andi1281 said ```since i want to train it on a bunch of data it would take a ton of time 😦```.
In general, at 2023-11-08 15:46:13 a user named andi1281 said ```Hi shaggz, its generating responses, and they all come through eventually, it just takes 30s or so for each response```.
In general, at 2023-11-08 15:45:11 a user named shaggz2006 said ```If you look at your LM studio server logs, what do you see?   Is your LLM generating responses, or is it staying idle during these slow times?```.
In general, at 2023-11-08 15:43:24 a user named andi1281 said ```Hi everyone, i am running an LLM with LM Studio ( codellama) and when i run AutoGen in VS code terminal to teach the LLM, it is super slow.  Can i make this faster somehow?```.
In general, at 2023-11-08 15:39:27 a user named rickyloynd said ```@iandjx  For now, probably not. TeachableAgent currently assumes that it is chatting directly with a human user who wants to teach it things. But we will probably implement a flag on agents that will allow them to learn a much wider set of things, like remembering mistakes it make in the past to not make them again, without the user explicitly telling the agent anything. At that point it will make sense for most or all of the agents in a group chat to be teachable (though we might call the flag something else).```.
In general, at 2023-11-08 15:28:25 a user named qingyunwu said ```You can find some ongoing effort mentioned in this issue: https://github.com/microsoft/autogen/issues/236```.
In general, at 2023-11-08 15:25:43 a user named edartru. said ```hi guys is there any alternative to autogen```.
In general, at 2023-11-08 15:18:31 a user named shaggz2006 said ```@dulak -- looks like the direct URL is here (saw tweet from OpenAIs account):  http://chatgpt.com/create     It says plus users will have access "this week".   I have a plus account but currently get a "You don't have access to this feature" message on that URL.```.
In general, at 2023-11-08 15:17:39 a user named usingxbox360controller said ```Wow, Autogen is WAY better than the newly announced OpenAi assistants and their 'custom GPTs'```.
In general, at 2023-11-08 15:13:11 a user named xahil_89256 said ```hi, That great tool for AI, but i have a question, How can i use it with sql databases like SqlDbChain in langchain?```.
In general, at 2023-11-08 15:12:29 a user named sonichi said ```I'd rather finish it within a week```.
In general, at 2023-11-08 15:09:42 a user named shaggz2006 said ```@dulak   Mine hasn't.  My assumption is you'll just see it on the left-side navigation pane, right?```.
In general, at 2023-11-08 15:07:33 a user named qingyunwu said ```Add the plan for integrating OpenAI Assistant API to roadmap? It is presumably not that hard.```.
In general, at 2023-11-08 14:58:29 a user named ozy6966 said ```Autogen is great! But i do have a question. So when i use local llm with lm studio or text generation webui, I simply create a single instance of the local LLM. So actual all agents share the same context window. It is like a game where you are the only one switching roles ? Am i right? If not appriciate someone further explain to me.```.
In general, at 2023-11-08 14:51:29 a user named sidhujag said ```@sonichi yea I feel like assistant api is an autogen agent, you just need to implement the run api and handle all the states. An interface for the tools through llmconfig. Threads can be convos so groups just share thread id. Even history can be synced against thread so no persistence is required locally.```.
In general, at 2023-11-08 14:37:10 a user named qingyunwu said ```And this is the link to the current migration guide: https://microsoft.github.io/autogen/docs/Installation#migration-guide-to-v02```.
In general, at 2023-11-08 14:34:26 a user named sonichi said ```Could you review https://github.com/microsoft/autogen/pull/600 ? @bobaleaux @hanley7082 please let me know your github handle if you'd like to review too.```.
In general, at 2023-11-08 14:27:33 a user named dhifafathiyahz said ```By some infos in LinkedIn```.
In general, at 2023-11-08 14:22:36 a user named onecodescholar said ```Thanks for the update. Do you have a link to the migration guide?```.
In general, at 2023-11-08 14:11:02 a user named sonichi said ```@onecodescholar @bobaleaux @hanley7082 I'm adding the following to the migration guide:
- `seed` in autogen is renamed into `cache_seed` to accommodate the newly added `seed` param in openai chat completion api. `use_cache` is removed as a kwarg in `OpenAIWrapper.create()` for being automatically decided by `cache_seed`: int | None. The difference between autogen's `cache_seed` and openai's `seed` is that:
    * autogen uses local disk cache to guarantee the exactly same output is produced for the same input and when cache is hit, no openai api call will be made.
    * openai's `seed` is a best-effort deterministic sampling with no guarantee of determinism. When using openai's `seed` with `cache_seed` set to None, even for the same input, an openai api call will be made and there is no guarantee for getting exactly the same output.```.
In general, at 2023-11-08 14:02:08 a user named dulak said ```has anyone's create GPT been enabled yet?```.
In general, at 2023-11-08 13:59:34 a user named onecodescholar said ```sounds good! or maybe have local_cache_seed Whatever is best```.
In general, at 2023-11-08 13:58:07 a user named sonichi said ```Is it OK to rename it to `cache_seed`?```.
In general, at 2023-11-08 13:56:33 a user named onecodescholar said ```Please keep the seed as it is working well for my local LLM setup. Renaming it would be okay. local_seed  Thanks!```.
In general, at 2023-11-08 13:48:36 a user named bobaleaux said ```it seems that a huge effort within the AutoGen to be a full  framework to interface with the open source world of models.```.
In general, at 2023-11-08 13:31:45 a user named sonichi said ```Thanks. Hope we could have a better coordination with openai in future. Suggestions are appreciated.```.
In general, at 2023-11-08 13:30:46 a user named bobaleaux said ```renaming it seems to be a wiser option for longevity of applicability and self sufficiency.```.
In general, at 2023-11-08 13:28:09 a user named iandjx said ```in a group chat. should we send all messages to a teachable agent?```.
In general, at 2023-11-08 13:27:26 a user named sonichi said ```"Determinism is not guaranteed" - I guess that's a reason to keep the seed in autogen, but rename it```.
In general, at 2023-11-08 13:26:50 a user named sonichi said ```seed: This feature is in Beta. If specified, our system will make a best effort to
              sample deterministically, such that repeated requests with the same `seed` and
              parameters should return the same result. Determinism is not guaranteed, and you
              should refer to the `system_fingerprint` response parameter to monitor changes
              in the backend.```.
In general, at 2023-11-08 13:26:41 a user named bobaleaux said ```Hate to ask instead of looking, but how is openai using Seed? Is it the same purpose?```.
In general, at 2023-11-08 13:24:33 a user named hanley7082 said ```Yeah, there is some complexity here```.
In general, at 2023-11-08 13:24:09 a user named sonichi said ```The seed in autogen is for local caching```.
In general, at 2023-11-08 13:23:26 a user named hanley7082 said ```These two frameworks have obviously been built for each other. Whatever is going to add a more seamless integration is what I would vote for.```.
In general, at 2023-11-08 13:22:36 a user named hanley7082 said ```I was going to hide the new open AI assistant behind a function```.
In general, at 2023-11-08 13:22:20 a user named sonichi said ```Do people think we should remove the `seed` param in autogen's OpenAIWrapper given that OpenAI supports it now?```.
In general, at 2023-11-08 13:11:19 a user named vru.shank said ```hey folks, what Dev Day update did you find immediately impactful for your workflows?

I really liked **`request_format`** param to enforce JSON outputs, and **`seed`** param to enforce deterministic outputs - both I've already started to use!

Wrote some more detailed notes [here](https://portkey.ai/blog/openai-devdays-implications-for-llm-apps-in-prod/)```.
In general, at 2023-11-08 12:37:37 a user named magic8437 said ```has anyone experienced both openai assistant's memory vs the other traditional kinds of memory, e.g. vector or memgpt kinds? is there any pros and cons in short?```.
In general, at 2023-11-08 12:30:36 a user named sonichi said ```No refactoring needed. It shouldn't take more than one day for me to integrate it. The only problem is I don't have an openai account to use and I rarely have one day free of coding these days.```.
In general, at 2023-11-08 10:43:52 a user named stefan_str said ```Hey folks, heard about autogen pretty much a day after it was released on github. Thanks for creating it!```.
In general, at 2023-11-08 10:19:21 a user named preeminentchaos said ```i heard about autogen when i noticed it on github hub a couple weeks back.```.
In general, at 2023-11-08 09:09:08 a user named swapmaster. said ```I heard about autogen today in a microsoft ad```.
In general, at 2023-11-08 08:27:52 a user named nikolkox said ```it was shared by a colleague```.
In general, at 2023-11-08 07:10:10 a user named iandjx said ```i load the previous chat history using this code before initiating chat

```
        self.user_proxy.send(
                message=json.dumps(history),
                recipient=self.manager,
                request_reply=True,
                silent=False,
            )

        self.user_proxy.initiate_chat(self.manager, message=message)
```
sometimes it works .. most of the time it doesnt
here is an example of what is dumps

```
[
    {
        "content": "have the ENGINEER run the generate myAtoi function",
        "role": "user",
        "name": "user_proxy"
    },
    {
        "content": "ENGINEER",
        "role": "user",
        "name": "ROUTER"
    },
    {
        "content": "Sure, I can help with that. Here is a Python function that implements a basic version of the `atoi` function. ....",
        "role": "user",
        "name": "ENGINEER",
        "roomID": "lU3No9Tv4mJZBpTYAAAi"
    },
    {
        "content": "The user asked the engineer to run the 'myAtoi' function. The engineer provided a Python function that implements a basic version of the 'atoi' function. This function converts a string to an integer. If the string starts with an integer, it will convert as much of the string as it can into an integer. If the string does not start with an integer, it will return 0. The engineer also provided some test cases to demonstrate how the function works. TERMINATE",
        "role": "user",
        "name": "SUMMARIZER"
    }
]
``````.
In general, at 2023-11-08 07:10:53 a user named iandjx said ```when i try to say. have the engineer run the function, it sends a message that says it has no idea what function to run```.
In general, at 2023-11-08 12:17:14 a user named sonichi said ```The `send` function is supposed to send a single dict as the message. For presetting the conversation history, one needs to set `groupchat.messages` and the `chat_messages` dict per agent.```.
In general, at 2023-11-08 12:31:35 a user named iandjx said ```so ...
```

group_chat = GroupChat(
            agents=self.agent_list,
            messages=history,
        )
```
where history is an array of dicts

i got lost with `chat_messages` dict per agent. What do you mean by this @sonichi```.
In general, at 2023-11-08 12:34:45 a user named sonichi said ```https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#chat_messages```.
In general, at 2023-11-08 12:35:28 a user named sonichi said ```The key should be the GroupChatManager object, and the value should be the list of messages```.
In general, at 2023-11-08 05:56:57 a user named ianthereal said ```Do we have any proposal for integrating the OpenAI Assistant API, and will it involve refactoring the agent?```.
In general, at 2023-11-08 01:31:56 a user named sidhujag said ```Would you imagine groupchat gets a thread id and runs happen against the assistant Id for each agent?```.
In general, at 2023-11-08 00:54:51 a user named sevonade4 said ```hi, is the only solution for ```AttributeError: 'str' object has no attribute 'get'``` error now is to wait for local llm makers to make their model to be able to make a response that is compatible with autogen package?```.
In general, at 2023-11-08 00:30:41 a user named afourney said ```Assistant agents are in the OpenAI 1.1 beta, which is now supported/required by Autogen version 0.2.0b2 I think? (Or at least its in the latest in Github) However, we've not yet added direct support for their agents API. This is something you would have to do yourself for now.```.
In general, at 2023-11-08 00:23:52 a user named prodigal_miser said ```Yeah,  he is legit, he actually does set by step, not just news! the algorithm guide you there too?```.
In general, at 2023-11-08 00:21:43 a user named ianthereal said ```Guys, I noticed that the openai v1 api is now supported. If I want to create an agent based on the openai assistant api in autogen, do I need to define an agent myself and implement the reply generation function?```.
In general, at 2023-11-08 00:21:23 a user named prodigal_miser said ```It was from Mat Vid pro and Matthew Berman XD and Matt wolf```.
In general, at 2023-11-07 22:44:50 a user named drinkoblog.weebly.com said ```need to be thinking 2 moves ahead in this game```.
In general, at 2023-11-07 22:36:42 a user named afourney said ```We're still less than a year since the original ChatGPT launched. How many startups were born, then crushed in that time 🤔```.
In general, at 2023-11-07 22:33:29 a user named fffreedom said ```Has anyone figured out a good solution on how to monetize their agents?```.
In general, at 2023-11-07 22:15:48 a user named diogenesbr said ```Hi, I found in this Youtube Channel: https://www.youtube.com/@matthew_berman```.
In general, at 2023-11-07 20:48:13 a user named onecodescholar said ```just scroll up about 50 lines```.
In general, at 2023-11-07 20:09:14 a user named catsrcool123 said ```has anyone made a good retriever for the autogen documentation itself? for the codebase? to contextualize autogen to an LLM so it can code autogen stuff? pls lmk. each time i am doing it, it's hallucinating hard. is there maybe a set of critical files to point to or something like that? 😄```.
In general, at 2023-11-07 19:17:54 a user named yorth_night said ```do you have an example?```.
In general, at 2023-11-07 19:17:09 a user named onecodescholar said ```Yes there is a line of code to output the code to a file. although I find it to not be very reliable. I've been trying to ask how to get more consistency but  no answer.```.
In general, at 2023-11-07 18:48:16 a user named yorth_night said ```that way I can just look at the generated py file rather than full discussion```.
In general, at 2023-11-07 18:47:50 a user named yorth_night said ```like a py file or something```.
In general, at 2023-11-07 18:47:37 a user named yorth_night said ```is there a notebook where an assistant agent is able to write down to disk some of its output?```.
In general, at 2023-11-07 17:57:13 a user named sonichi said ```Yes. @jasonzhou1993 has a video for it: https://discord.com/channels/1153072414184452236/1163461758124568627```.
In general, at 2023-11-07 17:54:51 a user named iowageek said ```can autogen send prompts to image generators like stable diffusion running locally?```.
In general, at 2023-11-07 17:02:48 a user named benbarnard said ```Thank you. Going to see if I can make it do more narrow task```.
In general, at 2023-11-07 16:17:05 a user named warmonger9626 said ```Which doesn't mean they are good enough for any production task```.
In general, at 2023-11-07 16:16:30 a user named warmonger9626 said ```Mistral OpenOrca and Zephyr Beta are the best I tried```.
In general, at 2023-11-07 16:09:59 a user named Ryzen said ```Hi all 👋 , been using GPT since around release. Lots of recent research on natural language. Excited to be here poking at this new AutoGen ❤️‍🔥```.
In general, at 2023-11-07 15:55:25 a user named ait.paca said ```Learnt from some youtube videos and GitHub repos. Interested in learning about its potential.```.
In general, at 2023-11-07 15:53:59 a user named crypto_rhino said ```i am researching automated e-commerce stores and content creation and financial applications```.
In general, at 2023-11-07 15:53:05 a user named crypto_rhino said ```I found out about autogen from several excellent youtube channels!```.
In general, at 2023-11-07 15:21:23 a user named rohanbalkondekar said ```Have anyone tried this -> https://julius.ai/

Is this clever prompt engineering and execution with GPT4 or other finetuned models and agents involved? looks smooth tho...```.
In general, at 2023-11-07 15:11:45 a user named 2022bearmarketsurvivor.eth said ```I am trying to build an app which browses the web to get the latest documents for a website. Is it possible to use the gpt-4 's web browsing function or should I create my own for Autogen?```.
In general, at 2023-11-07 15:11:17 a user named magic8437 said ```i made a silly mistake and working now!```.
In general, at 2023-11-07 15:04:29 a user named benbarnard said ```Do any of you have any recommendations on a 7B local model that performs (at all?). I my results are awful.
The code I am using has no problem having every team member contribute, but with my local model, it dies right away and only the first agent even does anything. With the same code, both GPT 3.5 and 4 have no problems.```.
In general, at 2023-11-07 14:53:33 a user named moonboi9001 said ```I dont think you need api_type and obviously would need to put your api key in the relevant part of the json```.
In general, at 2023-11-07 14:53:08 a user named beer23 said ```Not autogen though. Still very useful! Excited what we can build with assistant agent groups```.
In general, at 2023-11-07 14:52:30 a user named beer23 said ```Amazing how quickly these game changing projects are wiped out```.
In general, at 2023-11-07 14:46:34 a user named magic8437 said ```is this correct setting for latest autogen?
```
  {
    "model": "gpt-3.5-turbo-1106",
    "api_key": "",
    "api_type": "openai"
  },``````.
In general, at 2023-11-07 14:36:12 a user named moonboi9001 said ```what are you guys using autogen for currently?```.
In general, at 2023-11-07 14:28:54 a user named dulak said ```has anyone seen the gpt editor go live yet```.
In general, at 2023-11-07 14:16:40 a user named yorth_night said ```is that a playground only limitation or are the models just like that```.
In general, at 2023-11-07 14:16:28 a user named yorth_night said ```for some reason I can't get any of the models to write more than 4k at once in the playground```.
In general, at 2023-11-07 14:15:28 a user named jarail said ```I think it's better for function calling```.
In general, at 2023-11-07 14:15:04 a user named yorth_night said ```is it better than original?```.
In general, at 2023-11-07 14:14:53 a user named yorth_night said ```there is a preview for it?```.
In general, at 2023-11-07 14:14:42 a user named jarail said ```Is there a limit on the 3.5 turbo preview?```.
In general, at 2023-11-07 14:14:04 a user named jarail said ```Man this 100 messages / day limit on the new model is killing my vibe so hard rn.```.
In general, at 2023-11-07 14:13:25 a user named yorth_night said ```it uses a different path than gpt4```.
In general, at 2023-11-07 14:13:10 a user named yorth_night said ```this is the whisper api```.
In general, at 2023-11-07 14:12:49 a user named magic8437 said ```whisper API is now part of gpt4? i meant we can use the same model to have text, voice and visuals?```.
In general, at 2023-11-07 14:11:26 a user named yorth_night said ```if you wanna use the whisper api to have a voice to voice conversation```.
In general, at 2023-11-07 14:11:07 a user named yorth_night said ```from openai import OpenAI
client = OpenAI()

audio_file = open("speech.mp3", "rb")
transcript = client.audio.transcriptions.create(
  model="whisper-1", 
  file=audio_file, 
  response_format="text"
)```.
In general, at 2023-11-07 14:10:28 a user named yorth_night said ```of course, change your input to be a variable```.
In general, at 2023-11-07 14:10:09 a user named yorth_night said ```from pathlib import Path
from openai import OpenAI
client = OpenAI()

speech_file_path = Path(__file__).parent / "speech.mp3"
response = client.audio.speech.create(
  model="tts-1",
  voice="alloy",
  input="Today is a wonderful day to build something people love!"
)

response.stream_to_file(speech_file_path)```.
In general, at 2023-11-07 14:08:54 a user named magic8437 said ```Anyone has idea how to have audio chat using the openai api? Or its not possible yet```.
In general, at 2023-11-07 13:58:32 a user named onecodescholar said ```Hey there, did you figure out the order of the agent chat yet? I  got diverted and couldn't research it more. Thanks!```.
In general, at 2023-11-07 12:17:14 a user named jacek6859 said ```I use directly above string```.
In general, at 2023-11-07 12:14:31 a user named moonboi9001 said ```just make sure you're calling the new model not the old one```.
In general, at 2023-11-07 12:06:50 a user named dulak said ```not the preview mode but the full 4 turbo```.
In general, at 2023-11-07 12:06:42 a user named dulak said ```Has anyone gotten access to the GPT and new models yet?```.
In general, at 2023-11-07 11:56:07 a user named moonboi9001 said ```yep thats fair, i really only meant for people already using the openAI models```.
In general, at 2023-11-07 11:52:23 a user named gubok said ```It all comes down to how much of the data you are storing you want to be available to the OpenAI company. If you are building something you really want to fully "own" you have to use a local storage solution 🙂```.
In general, at 2023-11-07 11:27:01 a user named jacek6859 said ```In my groupchat 4k as the lenght of tokens is too small. What model would you recomment to use (pricez tokens size wise)? Currently I do use gpt-3.5-turbo.```.
In general, at 2023-11-07 11:13:28 a user named moonboi9001 said ```interesting notes from the OpenAI developer conference yesterday, seems like those using memGPT with openAI models may prefer to switch to using the new assistants api instead and thus let the state get managed in the background by the api instead. Any thoughts?```.
In general, at 2023-11-07 10:54:22 a user named defi.babylon said ```Please share your repo, tried this and got stuck 😦```.
In general, at 2023-11-07 09:19:41 a user named gubok said ```I hope someone here knows the answer.```.
In general, at 2023-11-07 09:19:22 a user named gubok said ```or is assistant message calls used for functions? 🙂```.
In general, at 2023-11-07 09:18:56 a user named gubok said ```or is the roles relative, for two llms talking the other llm is considered a user while itself is always an assistant?```.
In general, at 2023-11-07 09:18:12 a user named gubok said ```I'm reading here  👀 : https://arize.com/blog-course/mastering-openai-api-tips-and-tricks/#roles-in-messages-and-temperature```.
In general, at 2023-11-07 09:17:15 a user named gubok said ```Hey wonderful devs 🙂 Is there any deeper documentation on how to use the different "roles" to have agents talk to each other? should two agents who engage in a chat use the role of "user" or "assistant"?```.
In general, at 2023-11-07 08:37:27 a user named sevonade4 said ```well let's see how it goes, but things will get cheaper for sure. just like when openai announces gpt4 turbo version, it is cheaper than the gpt4```.
In general, at 2023-11-07 08:28:00 a user named warmonger9626 said ```Actually I think integrating GPT4 with other data-processing tools for cost savings will be the major market for business.```.
In general, at 2023-11-07 08:26:55 a user named warmonger9626 said ```Well, if you want to do this at scale, offload some tasks to already existing tools? For instance there are many ways in which you can plot a graph based on a simple input data.```.
In general, at 2023-11-07 08:21:43 a user named sevonade4 said ```sadly autogen+gpt4 doesnt seem something for hobbyist, only for corporate. i did try a simple task like the tutorial one (to check which symbol gains the highest year on year. and i added a task to plot a weekly chart and save it into an image. it takes $0.13 in 1 simple task like that.```.
In general, at 2023-11-07 08:18:28 a user named warmonger9626 said ```And pretty much all the other apps, wrappers and open-source replacements become obsolete```.
In general, at 2023-11-07 08:17:47 a user named warmonger9626 said ```This is one thing that AutoGen can still add to the table```.
In general, at 2023-11-07 08:17:08 a user named warmonger9626 said ```However, as Matthew Berman pointed out, they still don't offert agent teams directly.```.
In general, at 2023-11-07 07:56:30 a user named surajpsunny said ```I am trying to use autoGen with  azire open ai, in the config_list there is no option to give deployment name, and i am getting InvalidRequestError while running the code, strugging to set the correct config values. Does anybody using autogen with azure openai ??```.
In general, at 2023-11-07 07:48:36 a user named swissai said ```Hello everyone, I am a marketer who has long been interested in artificial intelligence. My main specialization is attribution of client channels and traffic generation. I will be glad to answer your questions if you have any and thanks to the author for this group!```.
In general, at 2023-11-07 05:11:32 a user named sevonade4 said ```@0xjamp what model did you use? i tried zephyr 7b beta, and the agent couldn't complete the task, only keep working back and forth, repeating same mistake again and again.

and then i changed to "gpt-4-1106-preview", it finishes the task in less than 30s```.
In general, at 2023-11-07 01:16:54 a user named magic8437 said ```https://platform.openai.com/docs/guides/text-generation/json-mode```.
In general, at 2023-11-07 00:58:20 a user named 0xjamp said ```Going to use local models for certain agents and gpt for others like the developer agent or visual```.
In general, at 2023-11-07 00:57:15 a user named 0xjamp said ```I got my autogen+ memgpt+ local model setup and running last night. Just in time to try and make a multi agent structure with dalle and visual added in. This is going to be fun lol```.
In general, at 2023-11-07 00:30:08 a user named onecodescholar said ```How to get autogen to consistently write code to a file before its executed?
I have taken some of the suggestions for the FAQ and used an example from the demos
```executor = autogen.UserProxyAgent(
    name="Executor",
    system_message="""
    # filename: <filename> Save the code to a file before executing it.
    Executor, Execute the code written by the engineer and report the result.
    """,
    human_input_mode="NEVER",
    code_execution_config={"last_n_messages": 3, "work_dir": "web", "use_docker":"python:3"},
)``````.
In general, at 2023-11-07 00:27:14 a user named afourney said ```I think I saw some earlier examples with GPt4, llava and dall-e```.
In general, at 2023-11-07 00:01:26 a user named yorth_night said ```I think you could add that easily with two functions and function calling```.
In general, at 2023-11-06 23:56:20 a user named 0xjamp said ```Anyone make a visual + dalle+ gpt4 turbo multi agent setup yet?```.
In general, at 2023-11-06 23:50:32 a user named afourney said ```Reminds me of DeepDream -- but using words rather than activations```.
In general, at 2023-11-06 22:44:16 a user named robin_saunders said ```but im more excited about code interpreter being part of the api now for example```.
In general, at 2023-11-06 22:43:43 a user named robin_saunders said ```I don't think so, I think they just set it up so we can customize agents for use by autogen```.
In general, at 2023-11-06 22:42:43 a user named 2022bearmarketsurvivor.eth said ```Maybe I missed it in the announcement, can we build multiple agents talking to reach other like in Autogen??```.
In general, at 2023-11-06 22:39:03 a user named robin_saunders said ```but the new api features is what I was waiting for, my life got a lot easier thanks to alot of the features they announced```.
In general, at 2023-11-06 22:38:37 a user named robin_saunders said ```then I heard of the keynote today so I decided to wait until afterwards lol```.
In general, at 2023-11-06 22:38:24 a user named robin_saunders said ```That's a project i'm working on right now```.
In general, at 2023-11-06 22:37:26 a user named aaronward_ said ```i'm guilty of it too, but i think it's important to keep the mental muscle memory strong in terms of programming```.
In general, at 2023-11-06 22:25:54 a user named litinit said ```I'm basically already there, but this upgrade of the context window will probably solve a lot of standing issues for me in this regard```.
In general, at 2023-11-06 22:24:57 a user named litinit said ```I'm personally really looking forward to fully transitioning away from manually writing code to more relaxing and sipping coffee while I just watch the AI do the manual labour```.
In general, at 2023-11-06 22:21:04 a user named yorth_night said ```yeah that looked pretty cool```.
In general, at 2023-11-06 22:20:20 a user named litinit said ```someone made an iterative loop of asking gpt4v to describe image, and then gpt4 with dalle to generate that description, then describing the output et.c.```.
In general, at 2023-11-06 21:48:56 a user named yorth_night said ```to generate much better images```.
In general, at 2023-11-06 21:48:37 a user named yorth_night said ```first one would be dalle plus gpt 4 v in an iterative loop```.
In general, at 2023-11-06 21:39:40 a user named aaronward_ said ```I can imagine many cool apps that have reliable LLMs behind them as they're becoming cheaper and cheaper to use. What are some examples of future tech you are excited to see come out of all this?```.
In general, at 2023-11-06 21:34:24 a user named frank.martinez said ```kind of a nothing burger; was hoping for some real innovation```.
In general, at 2023-11-06 21:24:08 a user named robin_saunders said ```can you tag me if you find out how?```.
In general, at 2023-11-06 21:23:54 a user named JoJo said ```Yeah on their site it says we can start today xd```.
In general, at 2023-11-06 21:22:26 a user named robin_saunders said ```idk I'm very interested though```.
In general, at 2023-11-06 21:22:16 a user named JoJo said ```How do we sign up to be builders?\```.
In general, at 2023-11-06 21:09:02 a user named yorth_night said ```Apparently there is also an HD version, wtever that means```.
In general, at 2023-11-06 21:08:41 a user named drinkoblog.weebly.com said ```that has been the real bugbear for API tooling for the past year```.
In general, at 2023-11-06 21:08:33 a user named drinkoblog.weebly.com said ```i am more excited about guaranteed JSON```.
In general, at 2023-11-06 21:07:03 a user named robin_saunders said ```I'm hyped at the GPT store```.
In general, at 2023-11-06 21:05:25 a user named alexpwrd said ```what did everyone think about OpenAI Dev Day announcements? https://www.youtube.com/watch?v=U9mJuUkhUzk```.
In general, at 2023-11-06 21:02:20 a user named dirtymotherscratcher said ```I found out about Autogen researching how to do agent work with Oobabooga```.
In general, at 2023-11-06 21:01:19 a user named litinit said ```so I can't complain, but now this is a bit counterproductive where the rate limit clashes with the model limit xD```.
In general, at 2023-11-06 21:00:54 a user named litinit said ```I was surprised the model for api was instant```.
In general, at 2023-11-06 21:00:31 a user named robin_saunders said ```so the fact my UI is still the same suggests that it won't be done rolling out fully until tmrw```.
In general, at 2023-11-06 21:00:23 a user named yorth_night said ```yeah, we still missing threads and assistants```.
In general, at 2023-11-06 21:00:09 a user named robin_saunders said ```and showed a new UI```.
In general, at 2023-11-06 21:00:06 a user named robin_saunders said ```Like, in the keynote Sam said that the chatGPT would change from being selectable to someting different```.
In general, at 2023-11-06 20:59:40 a user named litinit said ```I can't put in 128k tokens, beacause I have rate limit of 40k tokens/min...```.
In general, at 2023-11-06 20:59:20 a user named robin_saunders said ```I have a feeling that preview isn't the proper build```.
In general, at 2023-11-06 20:57:59 a user named yorth_night said ```is this the right one?```.
In general, at 2023-11-06 20:57:39 a user named robin_saunders said ```so its possible that the model is not fully deployed properly too```.
In general, at 2023-11-06 20:57:28 a user named robin_saunders said ```people are still reporting that things aren't fully deploying yet```.
In general, at 2023-11-06 20:57:10 a user named .jirito said ```you verified you were using the right model too right?```.
In general, at 2023-11-06 20:54:24 a user named litinit said ```yes, you can input 128k but max_tokens which is for the output is limited to 4k```.
In general, at 2023-11-06 20:53:24 a user named litinit said ```maybe (?) I haven't verified but that's how I interpret what I read```.
In general, at 2023-11-06 20:53:03 a user named litinit said ```I think max_tokens is about the output, the output is limited to 4k```.
In general, at 2023-11-06 20:50:18 a user named robin_saunders said ```is it the preview version still?```.
In general, at 2023-11-06 20:46:02 a user named yorth_night said ```huh, the model is out but they're limiting it still```.
In general, at 2023-11-06 20:11:30 a user named cryptokungfu said ```Looking for a bit of help. I'm using LM studio to run some local LLMs with Autogen but i'm finding it seems to get stuck in loops. Anyone come across this?```.
In general, at 2023-11-06 19:56:33 a user named bonklen_29011 said ```Autogen is all over youtube. Very interesting tutorials and information.```.
In general, at 2023-11-06 19:52:20 a user named kamikaze420 said ```I've watched a bunch and have been trying to get this to produce anything the last few days but no luck that's where I started tbh```.
In general, at 2023-11-06 19:50:38 a user named robin_saunders said ```that's where most of us casual users figure it out```.
In general, at 2023-11-06 19:50:30 a user named robin_saunders said ```There's lots of youtube tutorials```.
In general, at 2023-11-06 19:49:55 a user named kamikaze420 said ```Maybe someone would be willing to show me how to use this. That would be cool```.
In general, at 2023-11-06 19:42:09 a user named kamikaze420 said ```Hello first time using this and I want this to make python applications is it possible to save the response to a file when it's done making the code? First time using this so it's all new to me```.
In general, at 2023-11-06 19:39:54 a user named bassilk said ```20k output, output it 5 times in chunks, and adding the previous code to the context so it knows what it already spat out for example```.
In general, at 2023-11-06 19:39:35 a user named robin_saunders said ```assuming it outputs usable code```.
In general, at 2023-11-06 19:39:31 a user named robin_saunders said ```Guessing just hit that "continue" function over and over hahaha```.
In general, at 2023-11-06 19:36:34 a user named robin_saunders said ```what if i *need* gpt to output an entire program in one output!```.
In general, at 2023-11-06 19:34:14 a user named nexorsist said ```Doubtful you would ever need 4096 tokens in a single output (completion)```.
In general, at 2023-11-06 19:32:52 a user named robin_saunders said ```gpt-4 turbo has 128k context tokens but only outputs 4096 output tokens```.
In general, at 2023-11-06 19:32:11 a user named elcapitan__ said ```i want access to the gpt store in api```.
In general, at 2023-11-06 19:23:15 a user named bassilk said ```damn that'd be one expensive app```.
In general, at 2023-11-06 19:23:07 a user named bassilk said ```I didn't even factor the cost of a 128k context```.
In general, at 2023-11-06 19:22:53 a user named drinkoblog.weebly.com said ```i dont think gpt4-128k is going to be driving any autogen anytime soon```.
In general, at 2023-11-06 19:22:06 a user named robin_saunders said ```no it would be 3.84 out```.
In general, at 2023-11-06 19:21:59 a user named drinkoblog.weebly.com said ```that would be 128k tokens in 128k tokens out, not 128k total```.
In general, at 2023-11-06 19:21:46 a user named robin_saunders said ```$1.28 in + $3.50 out?```.
In general, at 2023-11-06 19:21:43 a user named bassilk said ```I heard that from somewhere, is that correct?```.
In general, at 2023-11-06 19:21:16 a user named bassilk said ```apparently there is a 20 request per min limit, 100 requests per day rate limit??```.
In general, at 2023-11-06 19:21:13 a user named drinkoblog.weebly.com said ```autogen runs how many prompts in the bg?```.
In general, at 2023-11-06 19:20:59 a user named drinkoblog.weebly.com said ```so worst case scenario is closer to $3.50 for a single request/response```.
In general, at 2023-11-06 19:19:49 a user named drinkoblog.weebly.com said ```output is 0.03 not 0.01```.
In general, at 2023-11-06 19:19:31 a user named robin_saunders said ```$1.28 per max context lol```.
In general, at 2023-11-06 19:16:54 a user named pierrunoyt said ```Just saw this https://fxtwitter.com/OpenAI/status/1721594380669342171?s=20```.
In general, at 2023-11-06 19:16:38 a user named drinkoblog.weebly.com said ```cheaper per token, but hit 128k tokens its gonna cost more```.
In general, at 2023-11-06 19:16:05 a user named dulak said ```I wanna learn more about the GPT thing```.
In general, at 2023-11-06 19:15:56 a user named dulak said ```I'm waiting for the new changes to drop```.
In general, at 2023-11-06 19:12:04 a user named bassilk said ```And its cheaper than gpt-4, pretty cool! plus 128k context```.
In general, at 2023-11-06 19:11:30 a user named bassilk said ```Damn OpenAI just released gpt-4-1106-preview```.
In general, at 2023-11-06 19:04:41 a user named nexorsist said ```So does anyone actually have the new changes on their ChatGPT already? Can't see anything new on the Platform or Chat```.
In general, at 2023-11-06 18:52:33 a user named andyinater said ```What's most exciting is how many people are going to have interesting ideas, and now they can actually make them without much domain expertise.

Like giving a voice to people who otherwise would never blip up in the space due to prerequisites.```.
In general, at 2023-11-06 18:51:01 a user named andyinater said ```Thanks, but let's see what I end up making lol! 

The dream is a little voice in the car "well, you missed that apex for sure. Work on braking earlier, even if lighter, to work on hitting the racing line"```.
In general, at 2023-11-06 18:49:30 a user named andyinater said ```Racing coach - more for beginners on learning how to drive a car around a track fast.

It's been an IRL endeavor for a long time for me - I was going to be the coach - but I've been developing in forza lately and it's where I will stay working for now.

Can always pipe in irl data in the future, but irl race car telemetry can be... expensive to create.```.
In general, at 2023-11-06 18:49:26 a user named bobaleaux said ```like the iphone and the app store!```.
In general, at 2023-11-06 18:48:00 a user named andyinater said ```Via these functionalities. Incredibly exciting times -  dispersing the ability to both create and share agents, with revenue incentives, is going to make the space explode.```.
In general, at 2023-11-06 18:47:47 a user named dulak said ```whats your driving gpt btw? like for learning how to drive cars?```.
In general, at 2023-11-06 18:47:10 a user named andyinater said ```Not replacing imo, or at least need not.

But it does seem like autogen is being soft-incorporated into the openAI API with improvements too.```.
In general, at 2023-11-06 18:45:08 a user named dulak said ```i took it as individual agents, like fine tuned models```.
In general, at 2023-11-06 18:44:54 a user named dulak said ```you think the agent thing is replacing autogen?```.
In general, at 2023-11-06 18:43:53 a user named dulak said ```128k context opens up the autogen agent issues too```.
In general, at 2023-11-06 18:41:26 a user named andyinater said ```Sounds like cut of calls.```.
In general, at 2023-11-06 18:41:18 a user named andyinater said ```I'm gonna have a driving coach gpt on the store this weekend I think. Eta not weekend, but whenever store launches. 

Did all the non-ai work already, was about to start fitting autogen pieces together - gonna rework for GPTstore now.```.
In general, at 2023-11-06 18:40:35 a user named dulak said ```Not sure if people will pay or if you just get a cut of all calls using your gpt```.
In general, at 2023-11-06 18:39:59 a user named dulak said ```I'm totally targetting the gpt store```.
In general, at 2023-11-06 18:39:36 a user named bobaleaux said ```code interepreter is now available through the api call.```.
In general, at 2023-11-06 18:39:22 a user named andyinater said ```I knew full well I was contributing to crowd sourcing 😛

This is very exciting. GPT store! Revenue sharing!```.
In general, at 2023-11-06 18:35:56 a user named dulak said ```explains some of the functionality autogen was missing```.
In general, at 2023-11-06 18:35:48 a user named dulak said ```yea autogen was setup for this lol```.
In general, at 2023-11-06 18:33:35 a user named bobaleaux said ```yeah.. Sam Altman, "I can't wait to see what you build".... no doubt! you can see what's they've done with the glimpse they've had.```.
In general, at 2023-11-06 18:32:14 a user named felly007. said ```it all makes sense now```.
In general, at 2023-11-06 18:32:05 a user named felly007. said ```that is why Micrsoft opensourced Autogen```.
In general, at 2023-11-06 18:31:31 a user named bobaleaux said ```They call 'Make a GPT"```.
In general, at 2023-11-06 18:30:12 a user named bobaleaux said ```https://www.youtube.com/watch?v=U9mJuUkhUzk
its the live opening keynote... whoa!```.
In general, at 2023-11-06 18:29:58 a user named elcapitan__ said ```Now tie it all together with autogen```.
In general, at 2023-11-06 18:29:27 a user named elcapitan__ said ```https://techcrunch.com/2023/11/06/openai-launches-api-that-lets-developers-build-assistants-into-their-apps/```.
In general, at 2023-11-06 18:20:45 a user named elcapitan__ said ```I’m giddy as a school girl!```.
In general, at 2023-11-06 18:19:37 a user named scdnap said ```128k token window, 2-3x cheaper than gpt4 🙂```.
In general, at 2023-11-06 18:03:50 a user named litinit said ```I think you can do it already with an M2 ultra with 64gb, it might not be super fast but from what I'm reading online it's runnable```.
In general, at 2023-11-06 17:43:22 a user named loschess said ```A leak ahead of the Dev day shows an AI Agents API, along with Code Interpreter access 🤔```.
In general, at 2023-11-06 17:00:50 a user named jaybekay said ```Hello friends, I just heard about autogen. Something I tried creating about 5 years ago were bots that specialize in certain tasks and they could talk to each other. With ChatGPT I noticed my dream was a lot more achievable, and with some research I found this community. 😊```.
In general, at 2023-11-06 16:29:49 a user named junkboi76 said ```hey can someone please help me for some reason the script I have for autogen just starts and stops can someone help```.
In general, at 2023-11-06 16:03:24 a user named snens9650 said ```What hardware would you recommend to run a model like llambda-2-13b or 70b locally? Is a MacBookPro M3 with a lot of memory (64GB+) a good idea?```.
In general, at 2023-11-06 15:32:09 a user named beer23 said ```guys. 128k context and cheaper? Huge for Autogen…```.
In general, at 2023-11-06 15:32:01 a user named loschess said ```Hey all, IndyDevDan released the code to go with the video series, I'm sure this will be very helpful 

https://github.com/disler/multi-agent-postgres-data-analytics/tree/v6-control-flow-and-structured-response```.
In general, at 2023-11-06 15:20:31 a user named onecodescholar said ```I've had autogen save code to a file before but it doesn't do it consistantly. How can the code be setup to have the code saved before executing? I have taken some of the suggestions for the FAQ and used an example from the demos
```

executor = autogen.UserProxyAgent(
    name="Executor",
    system_message="""
    # filename: <filename> Save the code to a file before executing it.
    Executor, Execute the code written by the engineer and report the result.
    """,
    human_input_mode="NEVER",
    code_execution_config={"last_n_messages": 3, "work_dir": "web", "use_docker":"python:3"},
)
``````.
In general, at 2023-11-06 14:46:42 a user named albfresco said ```just a thought.. there are 0 completely copy/pastable starter kits for the simplest thing with autogen using azure. none of them work. it seems like api_base is deprecated and replaced with base_url in the beta version. i can understand if moving to openai v1 package is causing grief, but none of the examples work out of the box```.
In general, at 2023-11-06 13:55:56 a user named samme0884 said ```has anyone managed to get a hierarchical group chat working?```.
In general, at 2023-11-06 13:50:52 a user named jacek6859 said ```Answered myself. It must be subclass of Agent class, namely ConversableAgent.```.
In general, at 2023-11-06 10:53:10 a user named jacek6859 said ```I have a dumb question. Is Agent class by default capable to handle LLM like prompts? How an agent can handle prompt?```.
In general, at 2023-11-06 10:00:58 a user named .jkyh said ```I have also put in class GroupChatManager as context and asked [2].```.
In general, at 2023-11-06 09:52:58 a user named .jkyh said ```I'd recommend you having a look at 
https://github.com/microsoft/autogen/blob/main/autogen/agentchat/groupchat.py

Perhaps you can also use ChatGPT4, I have given class GroupChat as context and asked [1] and [3] on your behalf.```.
In general, at 2023-11-06 09:04:31 a user named jacek6859 said ```Depends on what are you going to build. I recommend to split development work into modules, functions and  build them one by one. Or request to build them by LLM. Design on your side, development on LLM side.```.
In general, at 2023-11-06 09:00:19 a user named 47h4rv4 said ```Can someone answer @.jkyh @sonichi```.
In general, at 2023-11-06 05:17:44 a user named kajatta said ```Add whatever Langchain or custom function for each skill you need the dev agent to have. The best is give them a way to review code, and the ability to run it. Ensure the program outputs back to the agent - that way it can iterate```.
In general, at 2023-11-06 05:17:01 a user named kajatta said ```Try this to give the agents more capability (example)```.
In general, at 2023-11-06 04:23:06 a user named char79 said ```the idea is to create agents to be a developer team but I feel I am lacking. Here's something i came up with.```.
In general, at 2023-11-06 04:21:51 a user named char79 said ```I feel that gpt-4 maybe limited. Here's a message I received, maybe smarter people can help me with this. "Coder (to user_proxy):

The task you have requested is quite extensive and goes beyond the capabilities of a text-based assistant. What you're asking for is essentially the development of a complete application. Python is indeed capable of creating this kind of application using libraries such as `tkinter` for the GUI and `Pillow` for image processing, along with some form of database connectivity for keeping track of reservations. However, it requires thoughtful design, planning and integration of various modules including database design, user interface, function logic, error handling and more. 

While I can give you outlines of code snippets that help in achieving parts of your task individually, stitching them together into an integral application would be best left to a professional developer.

1. Importing and displaying image with `Pillow` and `tkinter`:

    ```python
    from tkinter import *
    from PIL import ImageTk, Image
    
    root = Tk()
    img = ImageTk.PhotoImage(Image.open("floor_plan.jpg"))
    panel = Label(root, image = img)
    panel.pack(side = "bottom", fill = "both", expand = "yes")
    root.mainloop()
    ```

2. Detect mouse click on `tkinter` window:

    ```python
    def printcoords(event):
       print(event.x,event.y)

    frame.bind('<Button-1>',printcoords)
    ```

3. Show message box:

    ```python
    from tkinter import messagebox
    messagebox.showinfo("Information","Informative message")
    ```
   
With these, you can build some basic blocks for your application.

As this is a complex task that may require several iterations and a good understanding of software development, I would suggest hiring a professional developer or a software development company if you're not familiar with programming concepts. They can gather all the requirements in detail, plan the application architecture, implement it, test it thoroughly and can also provide further maintenance.

--------------------------------------------------------------------------------```.
In general, at 2023-11-06 01:56:53 a user named 47h4rv4 said ```{```
groupchat = autogen.GroupChat(agents=[user_proxy, coder, critic], messages=[], max_round=20) manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)}
user_proxy.initiate_chat(manager, message="download data from https://xyz.com and plot a visualization and save it
```


1) So esentially it's a RoundRobin taking place in the order initialised  first proxy speaks, then coder, then critic, --> this is 1 round right(all speaking)?

2) I wanted to understand in more detail difference between GroupChat and GroupChatManager, 
Like GroupChat itself is doing- Maintaining the ordered list of participant agents
Handling the round-robin messaging flow between agents,
Keeps track of full message history, So what does GroupChatManager do, is it like API wrapper for these(  providing send and receieve messages)

3) What is the use of Select Speaker in GroupChat if order is already predecided in the initialisation list?( is it like If a agent may have generated a reply that involves selecting a particular speaker)****```.
In general, at 2023-11-05 23:36:04 a user named onecodescholar said ```Hi there! Is there a code example of this somewhere? I'd like to see an example of how this would be implemented. Thanks!```.
In general, at 2023-11-05 23:00:29 a user named svict4 said ```hey folks can we get a merge on this quick generate tool fix: https://github.com/microsoft/promptflow/pull/877```.
In general, at 2023-11-05 22:54:06 a user named .jkyh said ```Yeap, in the notebook, the Python class CustomGroupChat inherits GroupChat class and over-rides the next_speaker() method.```.
In general, at 2023-11-05 22:51:35 a user named dmaynor said ```Learned from twitter following langchain accounts```.
In general, at 2023-11-05 22:17:16 a user named enreee. said ```learned about it through work and school```.
In general, at 2023-11-05 20:27:56 a user named esthereisenacher said ```I am currently exploring the coding examples```.
In general, at 2023-11-05 20:27:33 a user named esthereisenacher said ```I am writing my Master's thesis about Autogen. My colleagues in Singapore suggested the topic.```.
In general, at 2023-11-05 20:24:20 a user named sleepwave said ```yoyo! Found autogen while doing some LLM research, love seeing a thriving a community around cool stuff like this  🙇```.
In general, at 2023-11-05 20:08:05 a user named prose5726 said ```How can I learn autogen? Is there any tutorial?```.
In general, at 2023-11-05 19:56:31 a user named prose5726 said ```I knew autogen by google```.
In general, at 2023-11-05 18:53:06 a user named jacek6859 said ```It seems that GroupChat instance should have modified next_speaker() function to follow control logic of the given use case.```.
In general, at 2023-11-05 18:51:21 a user named onecodescholar said ```let me know how it goes if you can, I'm trying to do the same```.
In general, at 2023-11-05 18:45:56 a user named jacek6859 said ```Thanks for answering. I will try to improve my code.```.
In general, at 2023-11-05 18:43:08 a user named sonichi said ```I think they redefined `select_speaker````.
In general, at 2023-11-05 18:41:54 a user named sonichi said ```Because it creates a new image after each execution finishes to make sure the state is reserved.```.
In general, at 2023-11-05 18:38:17 a user named jacek6859 said ```What exactly is the solution for controlling order? I see just the diagram.```.
In general, at 2023-11-05 18:01:36 a user named bassilk said ```Docker is installed locally on my windows laptop```.
In general, at 2023-11-05 18:01:24 a user named bassilk said ```Im using the config 
```python
    code_execution_config={"work_dir":"_output","use_docker":"python:3"},
```

This is in my userproxyagent```.
In general, at 2023-11-05 18:01:00 a user named bassilk said ```not sure if i misconfigured autogen```.
In general, at 2023-11-05 18:00:55 a user named bassilk said ```Hey, why does docker keep making new images each time i execute code, it made like 20 images +, each one 1 gb```.
In general, at 2023-11-05 17:36:08 a user named sonichi said ```https://github.com/microsoft/autogen/pull/500 and https://github.com/microsoft/autogen/pull/482 are in that flavor```.
In general, at 2023-11-05 17:27:18 a user named merkitten_ said ```Guys anyone uses Fuzzy logic in prediction ?```.
In general, at 2023-11-05 17:26:43 a user named onecodescholar said ```How can I learn more about how to control the groupchat? I'd like to try and get the message passed in a certain sequence between agents. Thanks!```.
In general, at 2023-11-05 17:00:47 a user named onecodescholar said ```My introduction to autogen happened just over a month ago, and it immediately captured my attention. The concept of chaining LLMs (Large Language Models) to refine and automate responses resonated with an idea I'd been considering myself. Over the past three weeks, I've dedicated myself to developing autogen, and I'm pleased to report significant progress with two LLMs functioning effectively in a local setup. My enthusiasm for delving deeper into autogen's capabilities is at an all-time high, and I am eager to further explore its potential in creating efficient agents and dynamic teams!```.
In general, at 2023-11-05 16:56:44 a user named automaker said ```Then tried to get that response and print it```.
In general, at 2023-11-05 16:56:40 a user named automaker said ```Then sent back the response to the user proxy.```.
In general, at 2023-11-05 16:56:32 a user named automaker said ```Then made assistant generate reply```.
In general, at 2023-11-05 16:56:27 a user named automaker said ```Made a user proxy. Send a message to the proxy with the message and the asisstant```.
In general, at 2023-11-05 16:56:03 a user named automaker said ```Gonna try this again from scratch, I must be doing something really wrong here.```.
In general, at 2023-11-05 16:55:53 a user named automaker said ```Now I've managed to succesfully throw an exception of some kind 🙂```.
In general, at 2023-11-05 16:51:28 a user named automaker said ```Okay let me try that, thank you!```.
In general, at 2023-11-05 16:50:36 a user named automaker said ```Oh, could you pls expand on this.```.
In general, at 2023-11-05 16:49:53 a user named sonichi said ````generate_reply` only generate the reply and won't send it. Need to make another `send` call to send it and add it to the message list```.
In general, at 2023-11-05 16:47:10 a user named automaker said ```If someone is feeling kind just writing out a few lines of code that show the *absolute mvp version* of just making a basic agent respond to one message, not initiate a multi round chat, just a one shot.```.
In general, at 2023-11-05 16:46:10 a user named automaker said ```I feel like this is much simpler than I'm making it.```.
In general, at 2023-11-05 16:45:51 a user named automaker said ```But... perhaps that's not the intended pattern of use at all? @sonichi sorry to bug you on this again.```.
In general, at 2023-11-05 16:45:37 a user named automaker said ```Just trying to send a message via the proxy agent to another agent. Then tell that agent to generate a reply, then get that reply.```.
In general, at 2023-11-05 16:45:10 a user named automaker said ```or would should it contain?```.
In general, at 2023-11-05 16:45:05 a user named automaker said ```What would last_msg now contain?```.
In general, at 2023-11-05 16:44:32 a user named automaker said ```await Proxyagent.a_send(message_dict, assistant)

    # Now, the Proxyagent generates a reply
    await assistant.a_generate_reply(message_dict, Proxyagent)

    # Get the last message from the Proxyagent
    last_msg = assistant.last_message()```.
In general, at 2023-11-05 16:44:12 a user named automaker said ```I thought I understood this moments ago, but now it no longer behaves the way I thought. I feel like I'm missing something really fundamental about how autogen works.```.
In general, at 2023-11-05 16:26:16 a user named bobaleaux said ```What example could I refer to for a closer look at the actual application of this method of conversation?
Thanks```.
In general, at 2023-11-05 16:13:04 a user named bassilk said ```hey, any idea regarding this anyone?```.
In general, at 2023-11-05 16:06:15 a user named junkboi76 said ```can some one look at my config (i know I keep asking this) but I genuninly cannot figure out what im doing wrong for some reason the script just starts and stops and nothng else ive tried logging it and nothing comes up can someone help```.
In general, at 2023-11-05 15:57:53 a user named automaker said ```(using the correct functions and configuring the assistant and user proxy properly)```.
In general, at 2023-11-05 15:57:36 a user named automaker said ```All of this worked Thank you!```.
In general, at 2023-11-05 15:55:36 a user named afourney said ```The assistantagent would need another to send to. But with a user_proxy set to human_input_mode="ALWAYS", you've basically got the situation you describe, since the user_proxy is always waiting on your input```.
In general, at 2023-11-05 15:49:20 a user named automaker said ```Thank you! And is it always necessary to have a user proxy agent or can you just use a single assistant agent if you wish?```.
In general, at 2023-11-05 15:48:32 a user named sonichi said ```Use send and generate_reply instead of initiate_chat to break down the steps```.
In general, at 2023-11-05 15:47:48 a user named automaker said ```Trying something very brute force here just by looking at the conversable agent class, sorry for such a basic question, I'm largely an idiot 🙂```.
In general, at 2023-11-05 15:47:27 a user named automaker said ```message_dict = {"content": message}

    # The Proxyagent (representing the user) receives the message from Discord
    # and sends it to the assistant, and requests a reply
    await Proxyagent.a_receive(message_dict, assistant, request_reply=True)

    # Manually add the message to the assistant's conversation history
    assistant._oai_messages[Proxyagent].append(message_dict)

    # Now, the assistant generates a reply
    await assistant.a_generate_reply(sender=Proxyagent)

    # Get the last message from the assistant
    last_msg = assistant.last_message(Proxyagent)```.
In general, at 2023-11-05 15:46:33 a user named automaker said ```@sonichi trying to understand how to do much more basic conversations, suppose I want to send and recieve messages between agents one by one in a very fine grained way that I manually control rather than enable an autonomous conversation, whats the best way to do that? Sorry to ask, been scratching my head trying different things which keep resulting in strange behaviour, like empty responses or no messages. So I must be missing something.```.
In general, at 2023-11-05 15:34:50 a user named sonichi said ```The agentchat_function_call notebook in that pr works for me```.
In general, at 2023-11-05 14:20:06 a user named automaker said ```MemGPT is a specific strategy for how to have an agent which actively knows how to manage its context window and its long term storage in a somewhat clever and powerful way. The paper is really short and worth checking out to see what they are trying to do.  There are many strategies for storing and retrieving information that all have pros and cons. I don't think anybody has really nailed how to do this really well yet.```.
In general, at 2023-11-05 14:17:29 a user named automaker said ```Also be warned there are bugs all over the place  they get fixed pretty quickly.  I had some weird nonsense with chromadb directories when trying to run the RAG agent example.```.
In general, at 2023-11-05 14:16:57 a user named automaker said ```You might also want to look at MemGPT which you can use in conjunction with autogen to build agents with memory, I haven't done this in a serious way but there are tutorials out there.```.
In general, at 2023-11-05 14:16:03 a user named automaker said ```For example try using the RAG agent example in the docs, set that up and see what happens when you point it to something other the autogen readme in the example 🙂```.
In general, at 2023-11-05 14:15:36 a user named automaker said ```Its not a straightforward plug and play solution to that problem.```.
In general, at 2023-11-05 14:15:28 a user named automaker said ```Yes you can use autogen as a framework to help you do this. But all the complexity in what you are proposing, at least in my understanding, lies in how you will pre process the information specific to that knowledge base, cut it up and then teach agents when and how to retrieve information from it.```.
In general, at 2023-11-05 14:05:17 a user named magic8437 said ```it seem the code doesnt include the functions data when querying the openai, so basically not sending the functions to openai endpoint```.
In general, at 2023-11-05 13:58:50 a user named rainmert said ```I want to build a retrieval-augmented LLM app that uses a private knowledge base. I was experimenting with Langchain but then I found Autogen which I thought may be more suitable for my needs.

What I want is basically an advanced customer chatbot that can analyze customer data and provide charts, inform the customer about my services, and call external APIs for additional functionality. So I thought maybe I could achieve that by having one agent that specializes in analyzing CSV data, one agent that specializes in consuming PDF documents for informing the user, etc., and orchestrating these agents with Autogen. Basically, the app would find what agent is the best for a specific task the user needs and call it.

But I want all the intermediary communication between the agents to be hidden from the user. The user should only receive the final output and the experience should basically be like using ChatGPT.

Would Autogen be the right tool for this kind of task?```.
In general, at 2023-11-05 13:24:08 a user named bassilk said ```Not using docker, on windows```.
In general, at 2023-11-05 13:24:03 a user named bassilk said ```I am running autogen, gave it a task to scrape a site and write it into CSV, the code tried to use beautifulsoup4, saw its not installed, and tried to install it, it created a .bash in the web directory then gave me above error```.
In general, at 2023-11-05 13:23:32 a user named bassilk said ```Guys any idea why i get this error:
FileNotFoundError: [WinError 2] The system cannot find the file specified```.
In general, at 2023-11-05 13:09:31 a user named sonichi said ```yes. I did fix a bug in https://github.com/microsoft/autogen/pull/551. But it's unrelated to function call.```.
In general, at 2023-11-05 13:08:25 a user named magic8437 said ```yes i tried some simple code too, did you test using azure openai too?```.
In general, at 2023-11-05 13:07:52 a user named sonichi said ```function calling works in my test. Have you tried some simple test?```.
In general, at 2023-11-05 12:58:26 a user named bassilk said ```I.e the teachable agent is storing knowledge from the interactions between the user and the agent, doesn't MemGPT do something similar in which it adds data to its archival memory```.
In general, at 2023-11-05 12:57:56 a user named bassilk said ```What's different from Autogen's teachable agent vs MemGPT? Doesn't it ultimately do the same thing, which is store data to be retrieved at a later date and to add context?```.
In general, at 2023-11-05 10:31:21 a user named automaker said ```Is there a best practice for configuring a RAG agent to understand a typical docs page for an API, it seems to struggle or much more likely I'm configuring things all wrong.```.
In general, at 2023-11-05 10:29:22 a user named automaker said ```Also, autogen is awesome 🙂```.
In general, at 2023-11-05 10:29:15 a user named automaker said ```IS anyone around who might have a few seconds to answer a couple questions about RAG agents, I'm struggling to quite get a sense of their limits and how they work```.
In general, at 2023-11-05 09:10:39 a user named bassilk said ```came here to say Autogen is awesome!```.
In general, at 2023-11-05 08:07:11 a user named akman75 said ```Discovered autogen from exploring auto Agents```.
In general, at 2023-11-05 06:03:58 a user named roy_obannon said ```There are probably many ways to read files, two I know of are:
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb?short_path=e0aa629#L204
and using langchain tool + functions: https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts/blob/master/autogen_notebooks/langchain_tools.py#L70```.
In general, at 2023-11-05 06:03:19 a user named magic8437 said ```ive been investigating past 8 hours, but no clue```.
In general, at 2023-11-05 06:02:46 a user named magic8437 said ```my code is exactly the same, the only change i make is to change api_base to base_url```.
In general, at 2023-11-05 06:01:39 a user named magic8437 said ```So I have autogen v0.14 and it can work perfectly with function_calling, i update to v0.2 and change the config, it works but it never does the function calling, what could be the issue? seeking your opinion @sonichi```.
In general, at 2023-11-05 05:58:47 a user named Lega said ```one last question i had for the night. 
i was reading about semantic kernel meeting autogen and it seemed as if autogen was being implemented into semantic kernel…but can the semantic kernel plug-ins and planner be implemented into autogen ?

i’m more familiar with autogen because i’ve been using it everyday for 2 weeks lol. so i was hoping i could just import some plugins and orchestration  from SK into Autogen```.
In general, at 2023-11-05 05:55:21 a user named Lega said ```or a single question that popped up alot. Thankyou for taking the time in ur night to help another soul out 🙏🏽```.
In general, at 2023-11-05 05:54:23 a user named Lega said ```interesting ! that answers a lot of questions```.
In general, at 2023-11-05 05:53:39 a user named Lega said ```if i don’t append the DEFAULT_SYSTEM_MESSAGE does the default system message  just get overridden by the message in my constructor script ?```.
In general, at 2023-11-05 05:53:37 a user named afourney said ```But I also think people often override it without thinking, and it should be done intentionally```.
In general, at 2023-11-05 05:52:50 a user named afourney said ```Don’t be too afraid to edit it 🙂```.
In general, at 2023-11-05 05:52:12 a user named Lega said ```ohhh okay got it !```.
In general, at 2023-11-05 05:49:12 a user named roy_obannon said ```I think they meant when constructing the agent:
e.g.
```python
critic = AssistantAgent(
    name="Critic",
    system_message=AssistantAgent.DEFAULT_SYSTEM_MESSAGE + "\nCritic. Double check plan, claims, code from other agents and provide feedback. Check whether the plan includes adding verifiable info such as source URL.",
    llm_config=gpt4_config,
)
```
(edited example from https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts/blob/master/autogen_notebooks/groupchat_research.py#L49)```.
In general, at 2023-11-05 05:49:01 a user named Lega said ```in relationship to the default 

`DEFAULT_SYSTEM_MESSAGE = """You are a helpful AI assistant etc. ````.
In general, at 2023-11-05 05:48:37 a user named Lega said ```i’m sure my example is wrong 😂 i just don’t understand +”\n 
nor  do i know if the plus or quotions is literally something to add or just a part of your explanation```.
In general, at 2023-11-05 05:47:23 a user named Lega said ```nice thankyou ! 
& thankyou @roy_obannon as well . 

@afourney yeah i looked at that system message and i figured editing that would break the whole functionality lol 

i’m new to programming even tho i’m learning more and more each day. but to be clear i should do it like this ?

`DEFAULT_SYSTEM_MESSAGE = +”\nMY UPDATED MESSAGE HERE”, """ You are a helpful AI assistant````.
In general, at 2023-11-05 05:42:33 a user named afourney said ```Something like: system_message=AssistantAgent.DEFAULT_SYSTEM_MESSAGE + "\nYOUR MESSAGE HERE",```.
In general, at 2023-11-05 05:40:48 a user named afourney said ```There is a default system message for the assistant, and it is quite good if you want it to code. I would recommend appending rather than replacing.```.
In general, at 2023-11-05 05:39:00 a user named afourney said ```Default assistant message is here: https://github.com/microsoft/autogen/blob/0dd0fc5aa254ec0355a2d7fae7b09893b90d8eeb/autogen/agentchat/assistant_agent.py#L16```.
In general, at 2023-11-05 05:38:19 a user named roy_obannon said ```I'm brand new to autogren but it looks like whatever you put in the constructor arg system message is THE system message:
https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L616
https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L51
https://github.com/microsoft/autogen/blob/main/autogen/agentchat/assistant_agent.py#L32```.
In general, at 2023-11-05 05:37:57 a user named afourney said ```Code for the agents is here: https://github.com/microsoft/autogen/tree/main/autogen/agentchat```.
In general, at 2023-11-05 05:26:54 a user named Lega said ```hey everyone. i have another question. i know the system message for the agents are what can control their personality. 
but is there a deeper layer of system message under the hood that i can edit as well? like in the assistant agent source code or conservable agent’s source code etc. 

and if so where exactly would i go to make these changes?```.
In general, at 2023-11-05 02:23:19 a user named edartru. said ```how can i make my agent to read a .json?```.
In general, at 2023-11-05 00:57:21 a user named junkboi76 said ```hey can someone help me with my autogen script for some reason it just starts and stops can and I cant figure out why can someone help?```.
In general, at 2023-11-05 00:54:46 a user named afourney said ```And with 0.2 it would actively throw an error that request_timeout isn’t recognized```.
In general, at 2023-11-05 00:53:29 a user named afourney said ```0.2 is in prerelease last I checked. You wouldn’t have it unless you asked for it```.
In general, at 2023-11-05 00:29:27 a user named nikhilari said ```Is 0.2 live? Is that why my request_timeout not working? I believe someone mentioned.. I guess @afourney .. yeah it'd be changed to timeout.. @sonichi```.
In general, at 2023-11-04 23:38:37 a user named sonichi said ```what pyautogen version are you using?```.
In general, at 2023-11-04 23:17:37 a user named jlcases said ```but now i get this error:openai.error.InvalidRequestError: Invalid parameter: only messages with role 'assistant' can have a function call.```.
In general, at 2023-11-04 23:14:27 a user named jlcases said ```doing this i solved the problem for time out```.
In general, at 2023-11-04 20:53:29 a user named yorth_night said ```prolly u just test both avenues and see which one works I guess```.
In general, at 2023-11-04 20:52:55 a user named yorth_night said ```who is to say that is an issue of architecture rather than data?```.
In general, at 2023-11-04 20:52:42 a user named yorth_night said ```right now, all instruct datasets are very short context length. So when you force long context behavior out of them it becomes weird and degenerate```.
In general, at 2023-11-04 20:52:01 a user named yorth_night said ```possibly, but maybe that's just because of current datasets?```.
In general, at 2023-11-04 20:48:27 a user named monkeyrithms said ```yeah... a bit unfortunate, it feels like one of the biggest limitations in LLMs, but the more I think about it and reflect on the cog sci angle of this, the more Ive become skeptical of larger context size being the solution to the memory problem....  in our own brains we have to use different strategies of managing limited information in working memory vs. important facts in long term memory, and memory management could be where things need to evolve (like maybe memGPT is a step in the direction?)```.
In general, at 2023-11-04 20:44:39 a user named drinkoblog.weebly.com said ```full 128k needs 320GB VRAM? no wonder i couldnt run it```.
In general, at 2023-11-04 20:43:57 a user named yorth_night said ```and from what I see, it's where the majority of the vram is used at inference```.
In general, at 2023-11-04 20:43:33 a user named yorth_night said ```the kv cache is something else```.
In general, at 2023-11-04 20:43:11 a user named yorth_night said ```nah, that's just the weight```.
In general, at 2023-11-04 20:42:55 a user named monkeyrithms said ```https://huggingface.co/TheBloke/Yarn-Mistral-7B-128k-GGUF there's some quants here, not sure if its the same thing you mean though. 😅```.
In general, at 2023-11-04 20:42:48 a user named yorth_night said ```but then their kv cache is being used by a function from the flash attention library which does its own stuff with it. So they can't just quantize it easily without risking to break that logic```.
In general, at 2023-11-04 20:41:45 a user named yorth_night said ```it could be an int8 or an int4```.
In general, at 2023-11-04 20:41:15 a user named yorth_night said ```I took a look at their code```.
In general, at 2023-11-04 20:41:06 a user named yorth_night said ```they need to quantize the kv cache```.
In general, at 2023-11-04 20:39:30 a user named monkeyrithms said ```https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k/discussions/5```.
In general, at 2023-11-04 20:39:04 a user named yorth_night said ```if less, it can be run on an A100 from google colab```.
In general, at 2023-11-04 20:38:38 a user named yorth_night said ```like more than 40 gbs of Vram?```.
In general, at 2023-11-04 20:38:27 a user named yorth_night said ```hmm, I'm not sure what is a lot of ram```.
In general, at 2023-11-04 20:37:38 a user named monkeyrithms said ```I'm a little new to all this but I heard that one takes a ton of RAM... I was not able to load it```.
In general, at 2023-11-04 20:36:28 a user named yorth_night said ```https://huggingface.co/datasets/Trelis/function_calling_extended HAHAHA```.
In general, at 2023-11-04 20:35:11 a user named yorth_night said ```no more need for RAG```.
In general, at 2023-11-04 20:35:05 a user named yorth_night said ```cuz it would be really cool to have that ability but on the Mistral 128k model```.
In general, at 2023-11-04 20:34:33 a user named yorth_night said ```maybe we can message the guy to see if the finetune data is open source?```.
In general, at 2023-11-04 20:33:49 a user named monkeyrithms said ```https://huggingface.co/Trelis/CodeLlama-34b-Instruct-hf-function-calling-v2 Maybe this would be a better candidate 🤔```.
In general, at 2023-11-04 20:32:13 a user named monkeyrithms said ```I would also like to learn more about this, as it seems particularly relevant to projects like this and local LLMs.
https://huggingface.co/Trelis/Mistral-7B-Instruct-v0.1-function-calling-v2 There is this -- which kind of suggests that maybe they can be fine-tuned for that?```.
In general, at 2023-11-04 19:31:29 a user named yorth_night said ```I can't find good info online```.
In general, at 2023-11-04 19:31:19 a user named yorth_night said ```or is it an inherent architectural feature?```.
In general, at 2023-11-04 19:30:28 a user named yorth_night said ```is it finetuned to do so by some function calling dataset?```.
In general, at 2023-11-04 19:30:16 a user named yorth_night said ```like how does an LLM have the ability to function call```.
In general, at 2023-11-04 19:30:03 a user named yorth_night said ```does anyone know how function calling works?```.
In general, at 2023-11-04 18:13:57 a user named beer23 said ```clearly defining “ACTION” vs “INFORMATION” seems to have fixed it 🙂```.
In general, at 2023-11-04 18:11:42 a user named beer23 said ```funny you mention it, dealing with that issue right now. Trying to tweak the descriptions so that if I say “I want information on an order” it doesn’t call the other one that has “order” in the name which is more for the action of placing an order rather than gathering information about an order```.
In general, at 2023-11-04 18:10:31 a user named sonichi said ```I think it depends on how easy it is to confuse with them. Even two functions that are not clearly distinguished from each other could give reduced returns.```.
In general, at 2023-11-04 18:07:27 a user named beer23 said ```Yeah I’m playing around with it, just thought I’d see if you all have had experience already with:)```.
In general, at 2023-11-04 18:06:54 a user named sonichi said ```I'm curious too 🙂 Should be easy to try?```.
In general, at 2023-11-04 17:57:46 a user named beer23 said ```curious your thoughts on the amount of functions in a function map until there is reduced returns? For example, should I throw in 10 different functions in one group chat? or categorize functions into groups and call those groups through functions. I’ve been doing the latter, but wondering if I’m over complicating my agent flows and making it more expensive```.
In general, at 2023-11-04 15:51:08 a user named afourney said ```You can try this yourself if you like. A PR to merge this testbed is working its way through: https://github.com/microsoft/autogen/tree/testbed/samples/tools/testbed```.
In general, at 2023-11-04 15:23:05 a user named afourney said ```I can’t comment about every local LLM, but I recently tried older versions of GPT-3.5. (Specifically 0301 from March) On a heavily modified HumanEval benchmark experiment, changing the prompt, specifically adding this:
 
 system_message=AssistantAgent.DEFAULT_SYSTEM_MESSAGE + "\nIF YOU ARE GENERATING CODE, IT MUST BE SURROUNDED BY TRIPLE BACKTICKS SO THAT IT IS RECOGNIZED AS A MARKDOWN CODE BLOCK E.G.  \```python  .... \```",
 
basically closed the performance gap to the 16k June model. The pass on first turn rate went from 37% to 64%.```.
In general, at 2023-11-04 15:04:20 a user named jlcases said ```Did anybody solve the problem?```.
In general, at 2023-11-04 15:03:57 a user named jlcases said ```i´m still facing problems with timeout API  when i run https://github.com/amadad/agentcy```.
In general, at 2023-11-04 14:40:03 a user named kevlarmonkey said ```so for local llm is it simply enough to instruct "always format code as a markdown formatted block"? Depending on the model capability?```.
In general, at 2023-11-04 14:38:35 a user named magic8437 said ```It seems there are issues with the latest commit and azure openai, anyone else faced issues too?```.
In general, at 2023-11-04 14:31:02 a user named tonic_1 said ```hey we're demo-ing our autogen app for the first time basically here : https://discord.gg/ruTVrxgv?event=1170362872493260911```.
In general, at 2023-11-04 12:48:36 a user named seishiro75001 said ```Hello 
I've just discovered AutoGen through discussions with the Microsoft teams.
Already experienced langChain and LLamaindex```.
In general, at 2023-11-04 11:43:36 a user named chrisdeandigitaltactics_62368 said ```Hi group, have just found out about AutoGen while researching how much work I'd need to do to basically build what is AutoGen as part of a larger project. So that's handy! Looking forward to working with it to (hopefully) help solve some climate related problems.```.
In general, at 2023-11-04 11:18:28 a user named marshyon said ```Hello, I'm Jon saying hello - thinking I'm past the hype on line and being a daily user of chat-gpt, copilot, bing-chat and occaisionally bard for content creation, coding and more I've come to look for how I can go about training LLMs for apps I am writing for my customers and in the interwebs and tubes I came accross people talking about Autogen, so I'm here just now 👋```.
In general, at 2023-11-04 05:27:59 a user named afourney said ```"fun job" -- damn straight!```.
In general, at 2023-11-04 05:27:35 a user named beer23 said ```Fun job. I want to start a research team in my dev group```.
In general, at 2023-11-04 05:27:06 a user named afourney said ```The costs, speed, and instability of some configuations is really why this is a research project. It's basically v0.2 of something we believe will be big and impactful. But it's research.```.
In general, at 2023-11-04 05:25:48 a user named beer23 said ```Although it would be quite slow 🙂```.
In general, at 2023-11-04 05:25:26 a user named beer23 said ```I do feel like agi is possible with gpt4. Think of teams of developers building out complex trees of agents with an unlimited budget and working with complex memory systems.```.
In general, at 2023-11-04 05:21:34 a user named drinkoblog.weebly.com said ```i think it could summarised as: it can go a little bit further than chatgpt on it own, but costs ten times as much, and if you push it too hard it goes off the rails (more easily than chatgpt on its own)```.
In general, at 2023-11-04 05:17:11 a user named afourney said ```Yes, we can do more to manage expectations. Speaking just for myself right now: We're in this weird moment where thing work, in my opinion, way better than they have any right to. And yet,  there are clear limitations. It's not always easy to convey both these things at once```.
In general, at 2023-11-04 05:13:58 a user named drinkoblog.weebly.com said ```or at least, confuse prosumers aspiring to be tinkerers or builders```.
In general, at 2023-11-04 05:13:36 a user named drinkoblog.weebly.com said ```it generates good code sure. but to suggest it is ready to replace a professional coder is going to confuse ppl who take this literally```.
In general, at 2023-11-04 05:13:05 a user named afourney said ```Yes, you can name the agents whatever you like. It's basically just shorthand for what system prompt or tool they are providing to the conversation. I think their capacity to be a "product manager" is TBD, but I would strongly argue that when using GPT-4 and getting feedback from code execution, they make pretty reasonable "coders".... way better than I would have expected even a few months ago```.
In general, at 2023-11-04 05:10:08 a user named afourney said ```I am a Principal Researcher at MSR (I studied at U Waterloo previously).  Joined the effort in this case means that I am part of the research group now working on Autogen along with many other MSR folks on Discord here```.
In general, at 2023-11-04 05:08:49 a user named e404nothing said ```So what does "Joined the effort" mean in this context? I see on your profile youre at the U Of Waterloo, so I assume there is a bunch of you dedicated to this project at the school or is it bigger than that?```.
In general, at 2023-11-04 05:07:34 a user named afourney said ```I would say that my involvment is as recent as late August```.
In general, at 2023-11-04 05:06:36 a user named afourney said ```I joined the effort more or less right after that paper was written. Perhaps the next one! But yes, I am part of the reseach team working on and maintaining it```.
In general, at 2023-11-04 05:05:39 a user named e404nothing said ```So are you part of the Autogen Paper then?```.
In general, at 2023-11-04 05:05:12 a user named drinkoblog.weebly.com said ```i think naming agents as 'product manager' and 'coder' can be a bit misleading.  the underlying models just arent that smart yet. it would be better to assign them much more specific tasks like, 'positive-sentiment-analyser'```.
In general, at 2023-11-04 05:04:23 a user named afourney said ```The great thing is that it's really easy to change prompts, create integrations, and test these assumptions about local LLMs -- but when you are doing that, you are basically diving into the research world with us, and that means I don't know when it will work and when it won't 😋```.
In general, at 2023-11-04 05:00:12 a user named afourney said ```There are few things worth remembering here: (1) Autogen is very new and it *is* a research project. Both of these factors are going to limit the scope and number of "applications" right now. (2)  many core features of Autogen, including writing complete working code to complex problems, and real-time orchestration of multiple-agent conversations are actually REALLY HARD. Even GPT 3.5 can struggle with this sometimes, and many core features assume an underlying model as capable as GPT-4. The prompts are also heavily tuned to the GPT family of models. For example, code isn't even recognized if it doesn't appear as a *Markdown* formatted blockquote. GPT models seem to be especially biased to producing Markdown and that works in our favor. These assumptions (and meta prompts) likely do not translate to every local LLM.```.
In general, at 2023-11-04 04:51:18 a user named e404nothing said ```Which is why I think we should focus on getting a semblence of a local system running.```.
In general, at 2023-11-04 04:50:11 a user named askofu said ```The gpt4 cost will be the constraining factor limiting real adoption. You might not be able to afford to be successful.```.
In general, at 2023-11-04 03:53:18 a user named beer23 said ```Yeah totally. I try to use sparingly```.
In general, at 2023-11-04 03:52:21 a user named e404nothing said ```Yeah, i spent my entire budget on api calls a while ago, so now I'm just giving it a go with local llms. I'd say thats the vast majority of my issues, but I dont have a lot of money to be throwing around testing.```.
In general, at 2023-11-04 03:51:21 a user named beer23 said ```Im finding myself making layers of function calling trees. Gpt4 only. Hopefully they reduce pricing on Monday!!```.
In general, at 2023-11-04 03:50:39 a user named e404nothing said ```Are you using open ai api key or local llm? I've been struggling to get local to work, I think Ive gotten it to work to completion once```.
In general, at 2023-11-04 03:49:52 a user named beer23 said ```I’m new to coding, but working on combining many of the different agents into one big helpful tool that can automate some of my work```.
In general, at 2023-11-04 03:48:08 a user named e404nothing said ```What have you done with it?>```.
In general, at 2023-11-04 03:47:59 a user named e404nothing said ```I think its either too new, or companies that can use it are keeping the IP internally```.
In general, at 2023-11-04 03:46:45 a user named beer23 said ```Why is it that there are no mind blowing real world examples of an autogen integration? There is so much potential.. do people just usually not bother to share?```.
In general, at 2023-11-04 03:30:09 a user named hanley7082 said ```Memgpt uses a complex, layered memory system. Autogen does not have anything like this out of the box, without using a MemGPT agent```.
In general, at 2023-11-04 02:59:31 a user named afourney said ```Ok, give that a shot for now. In any case, it's clearly in-progress at the moment, so YMMV```.
In general, at 2023-11-04 02:59:08 a user named e404nothing said ```Yeah I can do that```.
In general, at 2023-11-04 02:58:41 a user named afourney said ```Can you download the zip?```.
In general, at 2023-11-04 02:57:57 a user named afourney said ```Hmmm. Ok, well, it should be accepted soon and in main repo.```.
In general, at 2023-11-04 02:57:30 a user named e404nothing said ```Sorry... I'm getting permission denied.```.
In general, at 2023-11-04 02:56:50 a user named e404nothing said ```Ah, im cloning the whole repo rather than just the sample you suggested. Thanks```.
In general, at 2023-11-04 02:53:35 a user named e404nothing said ```Hey I'm missing some foundational knowlege, I'm quite sure I need to clone this into my files. I'm using VScode, can I not `git clone https://github.com/pcdeadeasy/autogen-oss/tree/899b43275df7b1b85ecfa32170c9f64b2ac3fb36/samples/apps/research-assistant-react`?```.
In general, at 2023-11-04 02:48:07 a user named afourney said ```There's nothing fancy about that query though. It should work in any Autogen environment```.
In general, at 2023-11-04 02:46:44 a user named afourney said ```That PR provides a sample app that has a web UI.```.
In general, at 2023-11-04 02:46:23 a user named e404nothing said ```Whoa, this has a ui element to it?```.
In general, at 2023-11-04 02:45:10 a user named afourney said ```The query should work generally:```.
In general, at 2023-11-04 02:44:13 a user named afourney said ```Ok, there are a few upcoming PRs that show this explicitly. https://github.com/microsoft/autogen/pull/509 in particular. See example here: https://github.com/pcdeadeasy/autogen-oss/tree/main/samples/apps/research-assistant-react```.
In general, at 2023-11-04 02:40:13 a user named e404nothing said ```Lets go with graph, I havent been able to getting file writing to work yet.```.
In general, at 2023-11-04 02:39:00 a user named afourney said ```What kind of document? Graph? Powerpoint? Text? Something else?```.
In general, at 2023-11-04 02:37:58 a user named e404nothing said ```Are there examples somewhere I can try?```.
In general, at 2023-11-04 02:36:59 a user named afourney said ```Autogen can write and run arbitrary python code. That python code can edit or create documents, yes.```.
In general, at 2023-11-04 02:33:31 a user named e404nothing said ```Is Autogen able to edit/create documents?```.
In general, at 2023-11-04 01:12:26 a user named myfavoriteaccount said ```question for people that use any websites for sharing AI art: what features would you like to see?```.
In general, at 2023-11-04 00:34:58 a user named drinkoblog.weebly.com said ```if the use case could use a simple implementation then use that```.
In general, at 2023-11-04 00:34:33 a user named drinkoblog.weebly.com said ```autogen is a framework with abstractions, allowing for diversity in the implementations.```.
In general, at 2023-11-04 00:19:34 a user named istvan_53568 said ```Hi all! I saw that Autogen is being integrated with MemGPT, and I was wondering why? Doesn't Autogen already have all the capabilities to work with external data, generate embeddings and do matching searches?```.
In general, at 2023-11-03 23:35:31 a user named jacek6859 said ```Gpt3.5 is much cheaper. You can store output in Azure, if you have API KEY```.
In general, at 2023-11-03 22:53:09 a user named drinkoblog.weebly.com said ```my fallback oobabooga server is so slow. my workaround was to increase  `request_timeout` in `python3.10/site-packages/autogen/oai/completion.py`.  as i get more familiar with autogen i'm sure i will figure out how to do it eloquently```.
In general, at 2023-11-03 22:22:41 a user named hewhocomethfromnyc said ```Intertubes! Looking for the next grea thing!```.
In general, at 2023-11-03 22:04:00 a user named afourney said ```(but even there, `request_timeout` gets renamed to `timeout` in v0.2 -- because it is being renamed in the upstream OpenAI library)```.
In general, at 2023-11-03 22:03:06 a user named afourney said ```For now, setting request_timeout=180 or something is probably the best advice I can offer.```.
In general, at 2023-11-03 22:02:45 a user named nikhilari said ```Thats music to my øres!```.
In general, at 2023-11-03 22:02:03 a user named afourney said ```Timeouts will be handled differently in v0.2 I believe, which is not merged to main yet. The OpenAI library itself will manage some of the retries. @sonichi has been driving this migration, and knows more. But, I think we probably want to reevaluate things after merge, since anything we do upfront now will be quickly obsoleted.```.
In general, at 2023-11-03 21:57:48 a user named nikhilari said ```@afourney any solutions to the timeout errors yet?```.
In general, at 2023-11-03 18:51:19 a user named usingxbox360controller said ```The microsoft autogen github page is showing a 404 for me. Anyone else?```.
In general, at 2023-11-03 18:51:15 a user named litinit said ```oh right, beause that example has spaces between the \n```.
In general, at 2023-11-03 18:38:53 a user named afourney said ```You would have to experiment. GPT and other transformers do consider spaces as tokens, and it will impact generation.... but how it will impact things is hard to predict. In earlier version of the OpenAI API, even including trailing spaces was known to degrade performance, and it would actively warn you against it```.
In general, at 2023-11-03 18:38:43 a user named dulak said ```and just do that over and over```.
In general, at 2023-11-03 18:38:39 a user named dulak said ```like, it'll return a "missing )" for a line like var = function(anotherfunction(x)```.
In general, at 2023-11-03 18:37:58 a user named dulak said ```sometimes though syntax errors will just persist even through multiple failures```.
In general, at 2023-11-03 18:37:41 a user named dulak said ```Yea the code execution part is what i'm exploiting a lot```.
In general, at 2023-11-03 18:36:44 a user named afourney said ```Yes, just ask it to save results to disk in your request.```.
In general, at 2023-11-03 18:34:10 a user named afourney said ```We were just discussing this in our meeting yesterday! The default Asssitant prompt definitely has many elements of chain-of-thought etc, and some very specific instructions for producing high-quality code, and so it will tend to push results on benchmarks like HumanEval up a little. But, what REALLY is the superpower here is having the user_proxy_agent actually executing the code, and providing the results or errors back to the Assistant. This is what drives many many wins in this area.```.
In general, at 2023-11-03 18:33:52 a user named aaronward_ said ```interesting, so giving an LLM a sense of urgency increases performance```.
In general, at 2023-11-03 18:26:10 a user named karlka said ```Is anyone using local open source models```.
In general, at 2023-11-03 18:24:36 a user named litinit said ```||also: this would have been a great question for chatgpt ;)||```.
In general, at 2023-11-03 18:23:02 a user named litinit said ```at least in python and most programming languages when u do var = tripple tick like that with newlines they're just converted```.
In general, at 2023-11-03 18:22:32 a user named litinit said ```yeah it just converts it to \n```.
In general, at 2023-11-03 18:22:31 a user named dulak said ```like, does it get a \n regardless if its hello\nworld or
hello
world```.
In general, at 2023-11-03 18:22:15 a user named dulak said ```I know in python but I'm wondering if gpt handles it fine too```.
In general, at 2023-11-03 18:21:44 a user named litinit said ```at least in python, there is no difference between
`var = "hello\nworld"`
and
```python
var = """hello
world"""
```
(at least, I think)```.
In general, at 2023-11-03 18:16:15 a user named dulak said ```does it matter to gpt that the code is full of \n's vs being human readable with literal line breaks?

example : "this is a \n sentence with \n two line breaks"
vs
"this is a
setence with
two line breaks"```.
In general, at 2023-11-03 18:14:39 a user named dulak said ```When passing snippets of code to autogen, should I include \n's or parse them into actual line breaks?```.
In general, at 2023-11-03 17:44:47 a user named heavenlysome said ```Can gpt3.5 output files to the disk? I'm having issues getting files created by autogen. When I use gpt-4 it will on occasion, but then I run into token limits and it's much more expensive.```.
In general, at 2023-11-03 17:13:20 a user named litinit said ```or is it more about just giving the AI more time to think e.g. "take a deep breath and think step by step.." but with a vastly better implementation (e.g. the diverse set of opinions prior to some actual solution)```.
In general, at 2023-11-03 17:11:58 a user named litinit said ```does the AI perform better even if it's just one shot with one "agent"? e.g. if I make a system prompt telling it it's an expert programmer, will it actually do better on evals?```.
In general, at 2023-11-03 16:56:37 a user named scdnap said ```looks good, easy to extend to group chats, rag and teachable agents too!```.
In general, at 2023-11-03 16:05:04 a user named magic8437 said ```I was still comparing the teachable agent and memgpt, and now the Semantic Kernel is added too :S```.
In general, at 2023-11-03 16:00:06 a user named collinsemmanuel said ```been digiging for some cool ai stuff till i landed to Autogen, seems like am not digging anymore```.
In general, at 2023-11-03 15:17:11 a user named alexchaomander said ```Yup! You can use any model that's on HuggingFace or if you want to run any local model, it's easy to create the interface that points to your local endpoint!```.
In general, at 2023-11-03 15:15:16 a user named frank.martinez said ```Does Semantic Kernel work with open LLMs, i.e. Mistral-7B et al?```.
In general, at 2023-11-03 14:55:34 a user named alexchaomander said ```The example Planner code is here: https://github.com/microsoft/semantic-kernel/blob/sk-autogen/python/notebooks/planning/autogen_planner.py```.
In general, at 2023-11-03 14:54:03 a user named scdnap said ```will you be providing source code to the example discussed in the post?```.
In general, at 2023-11-03 14:34:21 a user named alexchaomander said ```This is the notebook that shows off what the experience looks like! The author and I are going to do a demo video of it soon 🙂 https://github.com/microsoft/semantic-kernel/blob/sk-autogen/python/notebooks/12-sk-autogen-agents.ipynb```.
In general, at 2023-11-03 13:10:21 a user named scdnap said ```https://devblogs.microsoft.com/semantic-kernel/autogen-agents-meet-semantic-kernel/```.
In general, at 2023-11-03 13:06:17 a user named jlcases said ```Ok,  whether it works, can you share here  , please?```.
In general, at 2023-11-03 13:04:17 a user named bobaleaux said ```I believe this is a good place to start digging into the openai python sdk version upgrade conversation.

https://github.com/openai/openai-python/discussions/631```.
In general, at 2023-11-03 13:00:07 a user named nikhilari said ```Im gonna monkey patch the source code as  resort.```.
In general, at 2023-11-03 12:57:36 a user named jlcases said ```Did you overecome the problem?```.
In general, at 2023-11-03 12:56:43 a user named jlcases said ```This use case is more related to paying bills, but perhaps we can create a ticket```.
In general, at 2023-11-03 12:54:42 a user named jlcases said ```Maybe we can ask there```.
In general, at 2023-11-03 12:53:19 a user named jlcases said ```https://community.openai.com/t/autogen-permanent-api-request-timeouts/452505```.
In general, at 2023-11-03 12:42:08 a user named muazoo said ```Can I use Autogen with Vector Stores, To retrieve Data from the Vector Stores Like Pinecone Namespaces?```.
In general, at 2023-11-03 11:21:47 a user named nikhilari said ```Sounds fun.. tbh.. I tried to do the similar but with Norwegian constitution.. dint go past first message. 

Looking into it..now 😊```.
In general, at 2023-11-03 09:44:07 a user named .lightforged said ```memgpt + autogen + gpt4 = talk with your local codebase```.
In general, at 2023-11-03 08:07:41 a user named _chris_9595 said ```where does autogen saves the data? i.e. the image (chart) of test/twoagent.py```.
In general, at 2023-11-03 07:34:52 a user named nikhilari said ```@jlcases your guess is as good as mine. But if I had to guess.. I'd say monkeyPatch the original API call in the source code for handling the timeout error? What do you think?```.
In general, at 2023-11-03 06:15:50 a user named dmitriibolotov said ```Hey guys! We're in a very similar situation. We're trying to build a MVP using autogen and need guidelines. if anyone here is looking for a freelance work, or just want to play around and build smth cool please ping me, happy to discuss details.```.
In general, at 2023-11-03 06:10:32 a user named jlcases said ```Me too, do you have an idea to solve it?```.
In general, at 2023-11-03 05:55:19 a user named .princeps said ```https://microsoft.github.io/autogen/```.
In general, at 2023-11-03 05:53:53 a user named surajpsunny said ```Is there any extensive documentation for autogen, i am not able to find one. I want to know what are all the types of agents available and what are the customisation possibilities for creating a custom agent,```.
In general, at 2023-11-03 05:10:30 a user named seadude said ```Are `autogen.UserProxyAgent()`'s the only agents that can execute code?```.
In general, at 2023-11-03 04:28:03 a user named openprompter said ```@everyone Hey all, I am loving Autogen and love the possibilities it offers small businesses like mine. I'm running into some issues, specifically with Function Calling within Autogen. I've spent the past 24 hours trying to figure it out, but I think it exceeds my (non-technical) background. 

Is anyone here looking for some freelance work? I'm basically trying to create a workflow of agents that generate, critique and then approve blog post ideas. Once they're approved, I want them to be drafted as a G-Suite draft via the Google API. 

If anyone is looking for a small freelance gig, let me know! I'd love some help with this 🙂```.
In general, at 2023-11-03 04:17:29 a user named magic8437 said ```Where can i see the v2 documentation? I cant find it on openai website```.
In general, at 2023-11-03 04:09:07 a user named sonichi said ```I think the same way would simply work without needing to modify autogen -- that is, pyautogen<0.2, because v0.2 will switch to openai v1 where the openai.ChatCompletion will be deprecated```.
In general, at 2023-11-03 03:57:53 a user named magic8437 said ```https://youtu.be/yj-wSRJwrrc?si=KLWCzjWd3dN_0kZ9

And 

https://github.com/PrefectHQ/marvin

I think the response_model should be included in autogen. Its awesome and it makes the llm response to be structured. Agents can talk to each other following a valid and structured json format that enables them to action properly and consistently. Also makes error checking and validation easier```.
In general, at 2023-11-03 01:04:40 a user named rickyloynd said ```Best to refer to the notebook examples. RAG is best when you have a batch of documents for the agent to discuss. TeachableAgent is best when the user is teaching it things in normal conversation.```.
In general, at 2023-11-03 01:02:28 a user named rickyloynd said ```Yes, the TeachableAgent is the only built-in agent so far that keeps internal memory. On the other hand, we haven't tried it in group-chat settings, and it is currently very dependent on what it interprets as teachings from the user to be remembered. So in its current form, TeachableAgent may not help in your scenario.```.
In general, at 2023-11-03 00:41:35 a user named aaronward_ said ```wen fully autonomous autogen AI video generation?```.
In general, at 2023-11-03 00:00:34 a user named ubadub said ```Very Interesting. would love to hear some opionons on this!```.
In general, at 2023-11-02 23:27:36 a user named cococarnage said ```Maybe it's more of a quesiton for memgpt ppl```.
In general, at 2023-11-02 23:24:01 a user named cococarnage said ```Cna't find how to debug/check if it works correctly```.
In general, at 2023-11-02 23:23:33 a user named cococarnage said ```Hi, do you know a way to check if memgpt is working with autogen, i'm using memgpt.autogen.memgpt_agent with :
- model "model='dolphin-2.1-mistral-7b'"
- preset_name='memgpt_extras'
- AgentASync with  interface_kwargs={ "debug": True }
but i can't seem to feel anything special about what i get in return```.
In general, at 2023-11-02 22:53:19 a user named genericrich said ```i removed it. Turns out you don't need this line at all! 😉```.
In general, at 2023-11-02 22:26:43 a user named genericrich said ```Getting this error consistently after the agent tries to execute a shell script:   File "/Users/rver/Desktop/projects/autogen/outline_test.py", line 66, in <lambda>
    is_termination_msg=lambda x: (x.get("content", "") if x is not None else "").rstrip().endswith("TERMINATE"),
AttributeError: 'NoneType' object has no attribute 'rstrip'```.
In general, at 2023-11-02 22:08:22 a user named heavenlysome said ```Alright. Thanks for your help. I'll try some other things.```.
In general, at 2023-11-02 22:06:56 a user named heavenlysome said ```Okay. Im using VSC to run it and check the directory. I have run alot of scripts but it never seems to generate a file. Could it be some permission issue or something I insatlled wrong?```.
In general, at 2023-11-02 22:05:53 a user named airlights said ```Windows explorer hides some folders if not configured otherwise, check with an IDE environment like VSC```.
In general, at nan a user named heavenlysome said ```Thanks for your help. I will look closer.```.
In general, at 2023-11-02 22:04:18 a user named heavenlysome said ```This is my user_proxy:

user_proxy = autogen.UserProxyAgent(
    name='user_proxy',
    llm_config=llm_config,
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get(
        "content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={
        "work_dir": "coding",
        "use_docker": True,
    }
)```.
In general, at 2023-11-02 22:04:15 a user named airlights said ```you can also ask it to save the file 🙂```.
In general, at 2023-11-02 22:03:54 a user named airlights said ```there should be a .tmp folder created```.
In general, at 2023-11-02 22:03:36 a user named heavenlysome said ```I am running a simple script to have it write a poem and save it to the disk and it says that it's saved it to the working directory but there isn't a file in the explorer.```.
In general, at 2023-11-02 22:01:53 a user named airlights said ```or you mean: additional files?```.
In general, at 2023-11-02 22:01:33 a user named airlights said ```follow the examples, there is code execution there```.
In general, at 2023-11-02 22:00:46 a user named heavenlysome said ```Is there a reason why autogen wont write to disk or execute files?```.
In general, at 2023-11-02 21:59:59 a user named airlights said ```there's also MemGPT if you want to go down the rabbit hole - but it seems they pulled out their integration for now. It is quite simple there, add your file/s to the archive folder and they will be known```.
In general, at 2023-11-02 21:57:28 a user named airlights said ```also helps if you use the same seed 🙂```.
In general, at 2023-11-02 21:57:01 a user named airlights said ```then rerun the app, it will remember what you did```.
In general, at 2023-11-02 21:56:48 a user named airlights said ```reset_db is the key there yes```.
In general, at 2023-11-02 21:51:43 a user named junkboi76 said ```llm_config = {
    "request_timeout": 600,
    "seed": 42,
    "config_list": config_list,
    "temperature": 0
    "reset_db": false
}

this?```.
In general, at 2023-11-02 21:45:01 a user named airlights said ```TeachableAgents and reset_db to False (see here: https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent)```.
In general, at 2023-11-02 21:12:32 a user named platinumpluto said ```@sonichi  are you there? I have a question```.
In general, at 2023-11-02 20:30:16 a user named tonic_1 said ```hey there folks, who else is doing the hackathon tonight? https://discord.com/channels/1153072414184452236/1153072414184452242/1168551233016053891```.
In general, at 2023-11-02 20:26:42 a user named junkboi76 said ```Hello, I have a small issue with autogen,  all my prjects are written in C# does anyone know of a way to to get autogen to wright in different languages rather than just python

And for my second problem I keep hitting the token limit is there a way for autogen continue coding once it hit its token length (like you know how chat gpt has a continue button is there that for autogen)```.
In general, at 2023-11-02 18:38:32 a user named joe_ai said ```Just brainstorming ideas for this```.
In general, at 2023-11-02 18:26:19 a user named dangfutures said ```Anyone successful make datasets using rag and autogen```.
In general, at 2023-11-02 18:21:24 a user named fffreedom said ```Has anyone tested the new agent LLM Lumos? https://github.com/allenai/lumos```.
In general, at 2023-11-02 17:53:09 a user named magic8437 said ```Is such API format works on the Autogen oai?```.
In general, at 2023-11-02 17:28:03 a user named joe_ai said ```Just brainstorming ideas for this hackathon. Is it technically feasible (read, easy enough to accomplish within the next 24 hours) to integrate AutoGen with a Slack such that if the human_input_mode is on, the feedback is received inside a Slack channel?```.
In general, at 2023-11-02 18:38:33 a user named joe_ai said ```@sonichi any thoughts on this?```.
In general, at 2023-11-02 19:09:39 a user named rm3844 said ```Thanks @sonichi 
Could you point to the file ? i will try to contribute```.
In general, at 2023-11-02 19:10:24 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L951```.
In general, at 2023-11-03 18:31:18 a user named joe_ai said ```@omagaude - please ask the question here.```.
In general, at 2023-11-03 18:43:20 a user named omagaude said ```Hi @sonichi please help, slightly stuck. Besides storing the final output of the AssistantAgent's response in a text file how else can we pull out the final. Is there a method that can be appended to AssistantAgent for this?```.
In general, at 2023-11-03 18:59:32 a user named sonichi said ```https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#last_message```.
In general, at 2023-11-02 17:06:07 a user named blahblahdrugs said ```So.. do I need to set up a development environment in docker and then make a container and then INSIDE of that follow the steps on https://microsoft.github.io/autogen/docs/Installation

Docker has always confused me.```.
In general, at 2023-11-02 16:38:28 a user named chetvrp said ```https://www.facebook.com/AIbyChet/posts/pfbid0Yjf258FUZoVLgb7rMfXNNQx4WX8TQ5eawN9WmGdw42sfGuziBDYuLJSNEqMpm7sXl a post i made```.
In general, at 2023-11-02 16:32:53 a user named nikhilari said ```Hello, I'm almost always hitting timeout on anything interesting now.. specially in group chat```.
In general, at 2023-11-02 16:12:38 a user named chetvrp said ```https://www.youtube.com/watch?v=UA6IVMDPuC8&t=1025s Manual: Integrating Autogen and MGPT with Local LLMs

1. Introduction:
This manual provides a detailed guide on integrating Autogen and MGPT using local LLMs (Large Language Models) to optimize costs and performance. The process leverages the RunPods platform and the Dolphin 2.0 model.

2. Setting Up with RunPods:

2.1. Accessing RunPods:
Open your preferred web browser.
Navigate to the RunPods website.
2.2. Account Creation:
Click on the "Sign Up" or "Register" button.
Fill in the required details, including email, password, and any other necessary information.
Verify your email address if prompted.
2.3. Adding Credits:
Log in to your RunPods account.
Navigate to the "Billing" or "Credits" section.
Choose the desired amount and complete the payment process.
2.4. Deploying LLM Template:
From the dashboard, select the option to deploy a new template.
Choose the LLM template from the available options.
For the GPU, select RTX a6000 due to its cost-effectiveness and RAM capacity.
Ensure the port 7860 is open and available for the UGAB Boa Text Generation Web UI.
3. Loading the Model:

3.1. Model Selection:
From the available models, select the Dolphin 2.0 model.
3.2. Downloading the Model:
Click on the "Download" button next to the Dolphin 2.0 model.
Save the model file to a known location on your local system.
3.3. Uploading to RunPods:
Navigate to the RunPods interface.
Click on the "Upload" or "Load Model" option.
Browse and select the downloaded Dolphin 2.0 model file.
4. Configuring the API:

4.1. Accessing the Web UI:
From the RunPods dashboard, locate and click on the Text Generation Web UI link.
4.2. API Setup:
Follow the on-screen instructions to set up the API endpoints.
Ensure both Autogen and MGPT endpoints are correctly configured.
5. Running the Code:

5.1. Preparing the Script:
Open your preferred Python IDE or text editor.
Create a new Python script.```.
In general, at 2023-11-02 15:45:54 a user named myro.oasis said ```if there are three agents A,B and C. how do I control the flow of conversation between them. A -> B -> C -> B type```.
In general, at 2023-11-02 15:08:08 a user named joe_ai said ```i'm looking for another hacker to join the AutoGen hackathon starting in just under 2 hours. https://lablab.ai/event/autogen-24-hours-hackathon.  Any takers? Please dm me.```.
In general, at 2023-11-02 13:55:48 a user named afourney said ```You can also add a critic agent in-lieu of execution (it can review the code and make suggestions). This won't be as comprehensive, but it might take the 16 yo stoner to a 22 yo stoner.```.
In general, at 2023-11-02 13:52:51 a user named afourney said ```Autogen core executes code only in Python or shell (sh). If you want to extend this, it can be done in several ways. `math_user_proxy_agent.py` is a great example. It adds Wolfram: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/contrib/math_user_proxy_agent.py```.
In general, at 2023-11-02 11:55:09 a user named .moogin said ```right I too have encountered the same, the stoner 16 yo nephew analogy lmao.```.
In general, at 2023-11-02 11:48:16 a user named sonichi said ```This example seems similar to what you want: https://github.com/microsoft/optiguide```.
In general, at 2023-11-02 11:46:02 a user named sonichi said ```Thanks. Feel free to post in <#1161015724521836634> if not already.```.
In general, at 2023-11-02 11:09:17 a user named rickyloynd said ```The RAG agent example would be the best place to start.```.
In general, at 2023-11-02 10:52:49 a user named Lega said ```What would be the most convinent simple and robust way or function for adding search abilities to an agent in autogen ?```.
In general, at 2023-11-02 10:46:00 a user named yoursaviorjesus said ```Hey everyone! Hope everyone is doing well.

Im very new to this framework (llm's in general). 
I have a question regarding autogen. Is it possible to create a customer facing 'chatbot'.
The idea is the let customer chat with their order history and eventually other features (which are api call based).
I haven been playing around with some examples from the notebooks, but I cant figure out a way to do it.
The examples use initiate_chat which starts a chat in the command line and at the end of the chat it returns alls the steps between the agents.
Im looking more in to something that gets a request -> figures out which tool to use, uses it, does something to the response -> outputs just the final answers to be send back to the user in a chat.

I hope its a little understandable what im trying to achieve, thanks in advance!```.
In general, at 2023-11-02 10:02:42 a user named sundog8888 said ```Sharing what (appears to be) a good code/project example of how to structure agents into different groups to control the flow of work between agents.

https://github.com/amadad/agentcy```.
In general, at 2023-11-02 08:58:07 a user named sundog8888 said ```How does one specify the "order" in which agents talk to each other? Is there examples in the AutoGen code examples that might be helpful to understand this? (Sorry haven't worked through every example yet)```.
In general, at 2023-11-02 08:38:20 a user named tonyaichamp said ```Hey Champs

Using AutoGen agents as assistants in prompt engineering.

One thing I noticed is that I cannot prevent one agent from "spying" on another. I have a particular case where one agent answers in JSON and I want the other to only consider one of the fields and completely ignore the others. But no matter which form I give this instruction in, the agent ignores my instruction and consideres the parts of JSON that should be "hidden" from it.

Using GPT-4.

Any ideas how to overcome this?```.
In general, at 2023-11-02 08:14:18 a user named ishikawa_333 said ```How can i give autogen access to the internet?
I have installed using a conda environment but it keeps saying it cant access the internet.```.
In general, at 2023-11-02 07:42:14 a user named afourney said ```If you have a situation where you already know what speaking order you want, then use something other than group chat (it doubles the number of LLM calls, and is prone to error)```.
In general, at 2023-11-02 07:40:39 a user named afourney said ```Group chat decides on its own how to route messages. Under the hood, it sees every agent’s system prompt, and the conversation up to that point, and decides who speaks next based on a call it makes to the LLM```.
In general, at 2023-11-02 04:25:46 a user named tmyf_ said ```Hi guys. During the groupchat, how do I know which agent a message will be sent to? How to determine?```.
In general, at 2023-11-02 03:37:09 a user named bobse said ```the kinda cool part is that until this point, I wouldnask ChatGPT to write me some python or javascript or mathematica code to do some function X, and it produces some code that looks plausible. And then I try to run it and it breaks because ChatGPT didn't actually run it within a runtime environment. This pisses me off. 😦 I then have to pass the error I got back from the runtime to ChatGPT and it says something like "oh, I'm sorry, let me correct that..." and it produces a second set of code for me to try out. And we go around and around until that problem is worked out. I tell people it is a little like having your 16 year old stoner nephew who has heard about programming helping you out - he means well, but not the coding buddy you had hoped for.

AutoGen closes that loop. The "User Proxy Agent" acts in place of me, actually running the code produced by the "Assistant Agent", so I don't have to. Seems very promising.```.
In general, at 2023-11-02 03:17:03 a user named .moogin said ```Hmmmn I understand now, so basically agent1 converses with agent2 man then it's gonna be tricky esp with the jargon they will be generating and blurtin out to each other esp when they have low domain knowledge or simply are making shi up. Anyways this is helpful thanks 👍🏾```.
In general, at 2023-11-02 03:14:40 a user named bobse said ```AIJason's https://www.youtube.com/@AIJasonZ ML/GenAI videoas are well done. He moves fast (assumes you know some things) but I much prefer that over someone who over-explains all the things.```.
In general, at 2023-11-02 03:12:18 a user named bobse said ```That kind of knowledge certainly wouldn't hurt, but if you've used ChatGPT, then you probably understand the basics. AutoGen just closes the loop and automates what you are doing and allows to create more than one role or person you can chat with. But the underlying assumption is that this whole process thrives on a conversation between agents.```.
In general, at 2023-11-02 02:53:06 a user named bobse said ```LOL - that makes me sad for you ❤️ ngl```.
In general, at 2023-11-02 02:52:44 a user named .moogin said ```I hate AI Jason ngl```.
In general, at 2023-11-02 02:52:26 a user named bobse said ```he's is an awesome explainer of things```.
In general, at 2023-11-02 02:52:10 a user named bobse said ```Originally heard about AutoGen from AIJason https://www.youtube.com/watch?v=Bq-0ClZttc8&ab_channel=AIJason```.
In general, at 2023-11-02 02:51:56 a user named .moogin said ```But do I actually need deep NLP knowledge to actually make use of Autogen though```.
In general, at 2023-11-02 02:51:29 a user named .moogin said ```Seems dope going through the quick start docs```.
In general, at 2023-11-02 02:49:40 a user named .moogin said ```Seems to help me understand, thanks 🔥```.
In general, at 2023-11-02 02:47:00 a user named li_jiang said ```https://discord.com/channels/1153072414184452236/1161015724521836634 many examples are here```.
In general, at 2023-11-02 02:46:22 a user named blahblahdrugs said ```I will just type AutoGen into YouTube search if no one has any recommendations they've already seen.```.
In general, at 2023-11-02 02:44:33 a user named blahblahdrugs said ```Has anyone seen any good YouTube videos about AutoGen? I want to learn some more about it while I doze off. All kinds of videos welcomes. Overviews of projects, tutorials for getting started, whatever.

Also quick question off the rip. Can I build something using various chatgpt agents if I don't want to budget out gpt 4 stuff?```.
In general, at 2023-11-02 02:39:56 a user named li_jiang said ```It depends on your use case. But I would suggestion creating a new env for pyautogen. More details could be found here: https://microsoft.github.io/autogen/docs/Installation

For retrievechat, the extra dependencies are: ["chromadb", "tiktoken", "sentence_transformers", "pypdf", "ipython"],```.
In general, at 2023-11-02 02:37:36 a user named li_jiang said ```I'm not sure if this would help: https://microsoft.github.io/autogen/```.
In general, at 2023-11-02 02:36:50 a user named .moogin said ```Again for the 7 trillionth time what is Autogen?```.
In general, at 2023-11-02 02:36:11 a user named li_jiang said ```Were you installing in a new conda env or an existing env?```.
In general, at 2023-11-01 23:01:06 a user named rickyloynd said ```Hi @neuralsyn, initiate_chat can be made to unblock after a single turn. See the notebook sample https://github.com/microsoft/autogen/blob/main/notebook/agentchat_teachability.ipynb```.
In general, at 2023-11-01 22:17:24 a user named afourney said ```As you can see, in docker it mounts abs_path (to work_dir) on the native machine to the folder "/workspace" within docker, and it sets that  as the working_dir for the container.```.
In general, at 2023-11-01 22:16:25 a user named afourney said ```abs_path = pathlib.Path(work_dir).absolute()
container = client.containers.run(
    image,
    command=cmd,
    working_dir="/workspace",
    detach=True,
    volumes={abs_path: {"bind": "/workspace", "mode": "rw"}},
)```.
In general, at 2023-11-01 22:16:22 a user named afourney said ```If really curious, the code that does this is around line 367 of code_utils.py```.
In general, at 2023-11-01 22:11:36 a user named afourney said ```Now, agents can write or read really anything on the device or image they are operating in. So if your prompt includes a path, or if there's a standard place for something to be located, then the code will likely deviate from that work_dir. At that point, it does matter if you are running in Docker.```.
In general, at 2023-11-01 22:08:55 a user named afourney said ```In either case, any code that reads or writes files, will do so relative to that folder, and it will persist and be available natively.```.
In general, at 2023-11-01 22:08:35 a user named afourney said ```That work_dir path is local to your machine. If you are running natively, it just changes to that directory when executing the code. If running Docker, it mounts that directory as a share.```.
In general, at 2023-11-01 22:07:36 a user named afourney said ```We should probably add this to the FAQ, but basically when an autogen agent executes code, it's current working directory is specified by setting: 

code_execution_config={
        "work_dir": path_to_directory
 },

For example when constructing the UserProxyAgent.```.
In general, at 2023-11-01 21:51:18 a user named fran.abenza said ```Give some love to this post:```.
In general, at 2023-11-01 21:50:53 a user named fran.abenza said ```You will need to get creative```.
In general, at 2023-11-01 21:50:43 a user named fran.abenza said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In general, at 2023-11-01 21:46:06 a user named genericrich said ```is there an example you can point me to? Your help is appreciated!```.
In general, at 2023-11-01 21:37:12 a user named genericrich said ```Hello! How can I get autogen to access local files on my hard drive, and write files. I am ok to use docker locally but how to get things configured so that it can write local files seems super confusing.```.
In general, at 2023-11-01 21:02:55 a user named robos4n said ```hey - i heard about this project through a coworker. Sounds interesting and excited to learn more about it```.
In general, at 2023-11-01 20:36:05 a user named jojo_789 said ```Would there be any tutorials for using AutoGen with open source LLMs but without setting up a server for the api endpoint?```.
In general, at 2023-11-01 20:15:59 a user named jb_5579 said ```Has anyone attempted to use Gorilla LLM with a Sub-agent ?  If so, how did it go? Was Gorilla LLM able to collaborate?```.
In general, at 2023-11-01 18:57:48 a user named digitalnimbus said ```Howdy! New to the AI/ML space in general and stumbled into AutoGen while learning about LLM's frameworks like LangChain, ChatDev, AutoGPT and other similar frameworks while working on a personal project.```.
In general, at 2023-11-01 18:12:06 a user named jmsmall said ```Hi there! How I know AutoGen: I've been watching the LLM agent space and am excited about the direction of the project!```.
In general, at 2023-11-01 18:08:56 a user named oguzcana said ```so the question is: teachable agent is the most suitable one, right?```.
In general, at 2023-11-01 18:08:42 a user named oguzcana said ```and the manager agent have access to all of that```.
In general, at 2023-11-01 18:08:34 a user named oguzcana said ```I want all of the agents to have their own vector memory so they never forget```.
In general, at 2023-11-01 18:08:11 a user named oguzcana said ```so there is one "manager" agent which the user usually speaks, and the manager agent usually routes the necessary information to specialist agents, lets say "purchasing agent", "accountant", "staff manager"```.
In general, at 2023-11-01 18:07:09 a user named oguzcana said ```hello! I have a question. I want to build a mobile app where the users has a team of LLM agents with a specific task: lets say managing a cafe```.
In general, at 2023-11-01 17:01:39 a user named sonichi said ```maybe ipython is missing in the option. @li_jiang is the right person to answer this question.```.
In general, at 2023-11-01 16:58:55 a user named platinumpluto said ```If there are any requirements that certain packages should already be installed before using autogen```.
In general, at 2023-11-01 16:58:27 a user named platinumpluto said ```If it's okay can you tell me which packages should already be installed for autogen RAG?```.
In general, at 2023-11-01 16:57:53 a user named sonichi said ```3.10 or 3.11 should work```.
In general, at 2023-11-01 16:57:18 a user named platinumpluto said ```And which python is ideal?```.
In general, at 2023-11-01 16:56:22 a user named platinumpluto said ```Also getting these errors too```.
In general, at 2023-11-01 16:49:03 a user named sonichi said ```Is it py3.12? py3.12 is not supported```.
In general, at 2023-11-01 16:11:14 a user named mlops.v2_18177 said ```Can anyone assist the query on here https://discord.com/channels/1153072414184452236/1169065991003713638/1169306668945915965 It's about having agents working sequentially but using the human input only in certain scenarios?```.
In general, at 2023-11-01 16:09:06 a user named platinumpluto said ```This happend when I tried to install pip install "pyautogen[retrievechat]"```.
In general, at 2023-11-01 16:08:54 a user named platinumpluto said ``````cmd
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... error
  error: subprocess-exited-with-error

  × Preparing metadata (pyproject.toml) did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]

      Cargo, the Rust package manager, is not installed or is not on PATH.
      This package requires Rust and Cargo to compile extensions. Install it through
      the system's package manager or via https://rustup.rs/

      Checking for Rust toolchain....
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
``````.
In general, at 2023-11-01 15:23:07 a user named 2022bearmarketsurvivor.eth said ```Is it possible to restrict an agent to reply with only the tools given ? Is it  just done by a prompt or is there any config for the same? Tried a couple of prompts which doesnt work consistently while using a web search and scrape functions```.
In general, at 2023-11-01 15:11:59 a user named platinumpluto said ```If anyone can help then it would be appreciated```.
In general, at 2023-11-01 15:11:26 a user named platinumpluto said ```I tried to install pip install "pyautogen[retrievechat]" in my cmd but its giving me errors saying I need Rust and Cargo```.
In general, at 2023-11-01 15:11:00 a user named platinumpluto said ```Does autogen require Rust and Cargo installed?```.
In general, at 2023-11-01 14:50:34 a user named nikhilari said ```Thank you for the insight```.
In general, at 2023-11-01 14:32:14 a user named afourney said ```If using group chat, you’ll almost never want option (3). The GroupChatManager will never know when to call it if it doesn’t have a system prompt```.
In general, at 2023-11-01 14:08:05 a user named morlockbuzz said ```Right now I am building an interface with Slack.```.
In general, at 2023-11-01 14:07:32 a user named morlockbuzz said ```I'd like to see more app plugins, and a web based UI.  Something like Flux would be insane.  Flux is a visual and hierarichal tools for AI conversatins.```.
In general, at 2023-11-01 14:05:03 a user named morlockbuzz said ```Through a shared post in Slack at work.```.
In general, at 2023-11-01 11:55:58 a user named nuraj_84756 said ```AutoGen - Automated Multi Agent Chat```.
In general, at 2023-11-01 11:55:57 a user named bhavisha9921 said ```can someone tell me the seed that has memory of a conversation, how much it can store?```.
In general, at 2023-11-01 10:43:13 a user named li_jiang said ```Check out the example notebooks here https://microsoft.github.io/autogen/docs/Examples/AutoGen-AgentChat```.
In general, at 2023-11-01 10:02:49 a user named nikhilari said ```I also want to ask about usage of userproxy agents. 

Which scenario is adhere to (if any) best practices for running group chat.

1. One UPA(userproxyagent) with ability to run code as well as functions map and a long system message on how to do so. Ask user "NEVER".

2. Multiple UPA with one job each, specific system prompt for each. Set to ask user Always or terminate.

3. One UPA that just runs all code and all functions mapped to it. No system prompt.


...

You get the point.. parameter optimisation .. 

Are there any usecase that I can study? Other than the 5 6 available in autogen docs and papers Linked.. ofc @sonichi @afourney @li_jiang```.
In general, at 2023-11-01 09:50:09 a user named nikhilari said ```And thank you for your reply. Passing agents themselves as inputs to functions was like a **wow** moment for me..```.
In general, at 2023-11-01 09:47:01 a user named nikhilari said ```Okay, please clarify one thing , when in group chat mode when the instruction to call a function is made it says something in the line on *recommend function bla bla with xyz parameters* 

I also see that these xyz is decided by the agent recommending it. Am I correct? @li_jiang```.
In general, at 2023-11-01 09:40:57 a user named li_jiang said ```The conversation is stored in the agent's property, so it should be possible to map a function which accept an agent object and process its messages. But the input to the agent is still characters, only in some case these characters will trigger a function call.```.
In general, at 2023-11-01 09:25:21 a user named nikhilari said ```The agent of course has tool to handle it,```.
In general, at 2023-11-01 09:24:49 a user named nikhilari said ```@li_jiang  I was wandering what can be the 'input' limit for one of the assistant agent, in terms of characters. Say I have a team of Agents managing docs in groupchat, and I ask one of these agents to track the conversation and document something relevant.```.
In general, at 2023-11-01 03:08:31 a user named li_jiang said ```If you want to use RetrieveUserProxyAgent in a group chat, you can do it with function call or normal agents. If you want to call an external endpoint, function call is currently the only way I guess, but you can also extend UserProxyAgent or AssistantAgent to avoid function call.```.
In general, at 2023-11-01 03:05:02 a user named .derekcheung said ```and then REST Endpoint that I can make into function call to associate with agent in group chat```.
In general, at 2023-11-01 03:03:57 a user named .derekcheung said ```(I mean via a function call)```.
In general, at 2023-11-01 03:03:30 a user named .derekcheung said ```I'm trying to get RAG enabled in a group chat.  I think that's the only way I can do that right?```.
In general, at 2023-11-01 03:02:27 a user named li_jiang said ```nvidia libs are not necessary in CPU only envs.```.
In general, at 2023-11-01 03:02:13 a user named .derekcheung said ```I'm trying a slightly different approach.  I'm trying to use an assistant with access to function to call into a no-code (Flowise) backend that has a RAG flow```.
In general, at 2023-11-01 02:56:21 a user named sonichi said ```I don't like that either 😦 @li_jiang for you to consider.```.
In general, at 2023-11-01 02:55:24 a user named .derekcheung said ```I noticed that adding retrieve pulls in sentence_transformers and that pulls in torch and nvidia libraries etc... adds a couple of GBs to image```.
In general, at 2023-11-01 01:22:52 a user named drinkoblog.weebly.com said ```its a discord bot. if you want to use it for a website then you need a http endpoint to send the query```.
In general, at 2023-11-01 01:22:31 a user named more.life said ```not sure what this implies - would you mind explaining please :)?```.
In general, at 2023-11-01 01:22:15 a user named drinkoblog.weebly.com said ```i modified their code to expose a http endpoint (~4 lines of code). youll find it on their discord```.
In general, at 2023-11-01 01:17:45 a user named drinkoblog.weebly.com said ```askfsdl bot has published code to github, with code walkthroughs on their website. and they demo it on their discord```.
In general, at 2023-11-01 01:04:59 a user named more.life said ```Hi - I'm trying to implement an **FAQ Chatbot** for customer support (either on Website or Discord). What's the best way to go about that? Any insight would be greatly appreciated.```.
In general, at 2023-10-31 23:52:47 a user named afourney said ```There’s some discussion about that a little ways up in this chat```.
In general, at 2023-10-31 23:52:28 a user named afourney said ```It mounts a directory you specify as a shared folder.```.
In general, at 2023-10-31 23:48:23 a user named seadude said ```When you run this locally, with code_execution taking place in Docker, where is this saved?
When you run this, completely within Docker, where is this saved?```.
In general, at 2023-10-31 21:36:44 a user named nikhilari said ```@c_bonadio created an isssue regarding output of some agents not showing in the react UI for group chat.. check it out```.
In general, at 2023-10-31 21:31:39 a user named nikhilari said ```@c_bonadio @afourney  I was able to do some really clever stuff with the suggestions you guys gave.  Combined two teams of autogen outputting text files with some data and ran some watchdogs for various triggers depending on the content of the text files, which sh some other teams of Autogen... process. Still struggling with UI ngl.. but wife says she can make a tkinter Solution.. will share once done```.
In general, at 2023-10-31 21:26:16 a user named nikhilari said ```@konose_ , yes call a function that does that with an agents output as a parameter.```.
In general, at 2023-10-31 18:42:38 a user named afourney said ```Find Microsoft's logo from 1983, and save it to disk. If searching the web,
use Bing with the API key stored in `os.environ['BING_API_KEY']````.
In general, at 2023-10-31 18:41:20 a user named afourney said ```What output are you trying to save? I often just literally ask the agents to save to disk — like I put that request in my prompt```.
In general, at 2023-10-31 18:31:35 a user named seadude said ```Good question. I can’t quite figure out where AutoGen can store its output. There is a “working_dir” setting that @afourney and I were discussing last night. Maybe you can figure out how to retrieve files from this area? https://discord.com/channels/1153072414184452236/1153072414184452241/1168766251762450482```.
In general, at 2023-10-31 18:13:20 a user named litinit said ```Anyone got any _experience_ with summaries beyond basic tldr? I'm looking specifically for resources on prompting (or agents/flows) to consistently retain integrity of the source```.
In general, at 2023-10-31 16:32:43 a user named konose_ said ```Can autogen save text to file? I know it can execute code, but what about just writing text to file?```.
In general, at 2023-10-31 16:09:34 a user named sonichi said ```Check this PR: https://github.com/microsoft/autogen/pull/491```.
In general, at 2023-10-31 15:59:54 a user named c_bonadio said ```Hi @sonichi yes it is, I tested and this solution works```.
In general, at 2023-10-31 15:38:44 a user named afourney said ```And you can stop docker desktop to confirm it stops running when off```.
In general, at 2023-10-31 15:38:25 a user named afourney said ```As noted above, you can ask the agent to write code that calls something like “uname -a” or something just to see what environment it’s running in… as a quick check```.
In general, at 2023-10-31 15:37:37 a user named afourney said ```It shouldn’t fall back to native code if you are getting that far. The code to run natively is earlier and returns early. But one other person mentioned having trouble using a local image. Let me dig in to the code a bit, and add some debugging```.
In general, at 2023-10-31 15:13:35 a user named seadude said ```Maybe the fallback is to pull an image from the predefined list, but with no message displayed, how do I know.```.
In general, at 2023-10-31 15:12:03 a user named seadude said ```@afourney, If use_docker is a user defined string, it’s unclear to me where client.images.pull(image) gets the image from. Docker Hub, Docker Desktop?  And if AutoGen fails to pull the user defined image, it looks like the fall back is to execute code in the local env without warning (or at least I didn’t get a warning).```.
In general, at 2023-10-31 14:43:01 a user named frank.martinez said ```Yes it can generate code in languages other than Python. I’ve had success with generating a NextJS app [primitive]; deployment is more complicated.```.
In general, at 2023-10-31 14:13:18 a user named ctrl_alt.defeat said ```yes. i mistook this profile as the real one but as soon as he/she mentioned crypto, i knew it was an impersonator. 🥲```.
In general, at 2023-10-31 14:11:53 a user named sonichi said ```@ctrl_alt.defeat has found the same.```.
In general, at 2023-10-31 14:02:32 a user named _lansky said ```Hi guys, watch out I just got an invite from this scam account trying to use @sonichi  profile  probably to scam people. Better share than regret 🙂 stay safe and enjoy Autogen 😎```.
In general, at 2023-10-31 14:00:12 a user named litinit said ```from what I can see it only directly supports execution for python and shell/terminal commands. you could add something yourself but there doesn't seem to be any proper abstraction it's just kinda all over the place :S```.
In general, at 2023-10-31 12:26:42 a user named ctrl_alt.defeat said ```this should incorporate that as well?```.
In general, at 2023-10-31 12:26:33 a user named ctrl_alt.defeat said ```i had a similar idea a while back, never really got around it though. essentially github PR reviewer, code quality checker and suggesting improvements/bugs```.
In general, at 2023-10-31 12:24:59 a user named ctrl_alt.defeat said ```and all these functions where using pygithub or something to read/write stuff to github? @kajatta```.
In general, at 2023-10-31 12:19:58 a user named kajatta said ```No but write an agent and use Langchain to give it many functions that it can access when problem solving```.
In general, at 2023-10-31 11:42:49 a user named ctrl_alt.defeat said ```would love to read more about how you did it. do you write a blog?```.
In general, at 2023-10-31 10:46:23 a user named paradis_37408 said ```Hi, does anyone know if agents in Autogen can generate and execute code in other programming languages than Python?```.
In general, at 2023-10-31 10:33:16 a user named antoineross said ```That's awesome! Did you post a source code online?```.
In general, at 2023-10-31 10:28:21 a user named kajatta said ```https://tenor.com/view/steve-carell-the-office-yikes-this-is-the-worst-cringe-gif-21219465```.
In general, at 2023-10-31 10:25:20 a user named mitchellr said ```i guess its still easier to prompt guide - than deal with employees lol ... pro tho is you could delete an employee to do this and then have free time haha```.
In general, at 2023-10-31 10:21:57 a user named kajatta said ```Haha good point, no it still needs prompt guidance```.
In general, at 2023-10-31 10:18:38 a user named litinit said ```anyone converted the nasa project to autogen?```.
In general, at 2023-10-31 10:15:30 a user named antoineross said ```Anyone having an issue when containerizing the Application on Huggingface spaces or adjacent deployment services?:

"Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))"

The error doesn't happen to local, but it seems like it happens because docker doesnt start up on huggingface spaces. Anyone know what;s up with that?>```.
In general, at 2023-10-31 10:15:16 a user named mitchellr said ```whatsup - new here... just going through the motions .... will lurk for a while 🙂```.
In general, at 2023-10-31 10:14:12 a user named antoineross said ```Medium Article for a User Interface (UI) for Autogen. Made a basic web-application using autogen research that uses chainlit:

https://medium.com/@antoineross/autogen-web-application-using-chainlit-8c5ebf5a4e75```.
In general, at 2023-10-31 10:14:07 a user named mitchellr said ```why not get it to do the unit tests while you sleep haha?```.
In general, at 2023-10-31 08:22:12 a user named kajatta said ```-Its time to retire I think team.```.
In general, at 2023-10-31 08:21:47 a user named kajatta said ```Had a nice win today.
Got an agent working today to use GitHub, filesystem, React/JS to come up with a list of improvements in an external solution. 

It wrote all the git issues, commented progress, clones repo, and made a branch, , it then documented every component in mdx including notes for improvement, committed and pushed.... Tomorrow I'll get it to do the unit tests.```.
In general, at 2023-10-31 07:07:56 a user named flappers_pluk said ```Is anyone using local open source models with autogen? Which models are you using that have best results for your hardware?
On that note, has anyone got function calling working with open source models using autogen? If so, which model are you using?

I'm just curious, as the more I play with autogen and building teams of agents, the costs are absolutely skyrocketing (into the hundreds of euros), so I'm wondering if anyone got local models working well.```.
In general, at 2023-11-03 18:26:11 a user named karlka said ```we've been quite cost sensitive with my team building agents, until the expenses got us frustrated (especially OpenAI APIs). that made us start building out a solution where the LLM usage for devs can be free (more on how on our home page)

the  solution we provide right now is a free LLM API built on top of the latest SOTA open-source models, our Alpha version has Mistral 7B, which is on bar with gpt3.5

As it's totally free to use, I'd recommend you check it out https://www.llmos.dev/ and lmk what you think 🙂```.
In general, at 2023-10-31 07:01:55 a user named fxtoofaan said ```That’s fantastic. Thank you 👍```.
In general, at 2023-10-31 06:44:09 a user named riverlay said ```Do we have the roadmap for autogen-based application UI?```.
In general, at 2023-10-31 06:18:32 a user named afourney said ```🙂 yeah we were discussing it tonight. Hopeful to resolve whatever small blocking issues there were and merge it```.
In general, at 2023-10-31 06:17:04 a user named nikhilari said ```Thank you , I mean @afourney```.
In general, at 2023-10-31 06:15:32 a user named afourney said ```This one? https://github.com/microsoft/autogen/pull/87```.
In general, at 2023-10-31 06:13:23 a user named lpaydat said ```Hi, I'm new here. Just discover this awesome project on YouTube 🙂```.
In general, at 2023-10-31 06:09:47 a user named nikhilari said ```@bonadio brilliant tracking that down, I recon a_initiate_chat is the asysnc version init? @afourney I read it somewhere about a generalised fix.. lost in scroll now.. point me at git please!🤌```.
In general, at 2023-10-31 06:01:46 a user named afourney said ```If use_docker is the boolean value True, image_list is the default list. If it’s a string you get the string wrapped in a 1-element list (image_list = [use_docker]), and if it’s anything else you get image_list = use_docker```.
In general, at 2023-10-31 05:15:52 a user named seadude said ```The journey continues! @afourney  Thank you for the answers and engagement. I really appreciate it. Gotta bail to rest. Night!```.
In general, at 2023-10-31 05:09:37 a user named seadude said ```Hm...interesting. From my naive eyes, it *appears* that the only acceptable values for `use_docker` are:
0. Omit it completely
1. `True`
2. `False`
3. One of these images: `["python:3-alpine", "python:3", "python:3-windowsservercore"]`

I can't quite see how the string I added (`autogen-basics`) results in the Image being pulled from my local Docker Desktop. (But I know nada about Dockers innerworkings). For example, I don't know if `client.images.get(image)` gets an image from my local Docker Desktop or from Docker Hub (or the like).

`code_utils.py`:

```
# check if already running in a docker container
    in_docker_container = os.path.exists("/.dockerenv")
    if not use_docker or in_docker_container:
        # already running in a docker container
...

 # create a docker client
    client = docker.from_env()
    image_list = (
        ["python:3-alpine", "python:3", "python:3-windowsservercore"]
        if use_docker is True
        else [use_docker]
        if isinstance(use_docker, str)
        else use_docker
    )
    for image in image_list:
        # check if the image exists
        try:
            client.images.get(image)
            break
        except docker.errors.ImageNotFound:
            # pull the image
            print("Pulling image", image)
            try:
                client.images.pull(image)
                break
            except docker.errors.DockerException:
                print("Failed to pull image", image)
``````.
In general, at 2023-10-31 04:56:38 a user named afourney said ```Like “please write code that  uses subprocess to invoke ‘uname -a’ and print the output”```.
In general, at 2023-10-31 04:55:11 a user named afourney said ```And you can admit to run code that will tell you```.
In general, at 2023-10-31 04:54:49 a user named afourney said ```Well we can add something to the console output to indicate that (again if it isn’t already there)```.
In general, at 2023-10-31 04:51:33 a user named seadude said ```Ok, I'll look at `code_utils.py`.```.
In general, at 2023-10-31 04:51:19 a user named afourney said ```The code that controls this is at the bottom of code_utils.py```.
In general, at 2023-10-31 04:50:26 a user named afourney said ```If you want to edit the code, perhaps pull the latest main from the autogen repo and install via “pip install -e ./autogen”```.
In general, at 2023-10-31 04:49:05 a user named afourney said ```It evaluates to “autogen-basics” .. which is decidedly not False or None```.
In general, at 2023-10-31 04:48:21 a user named seadude said ```Hm...Does `"use_docker": "autogen-basics"` evaluate to `True` or `None`?```.
In general, at 2023-10-31 04:45:49 a user named afourney said ```Well it will pull python:alpine if set to True, and that’s tiny, so it might be what’s happening```.
In general, at 2023-10-31 04:45:20 a user named seadude said ``````
If None, False or empty, the code will be executed in the current environment. Default is True, which will be converted into a list. If the code is executed in the current environment, the code must be trusted.
``````.
In general, at 2023-10-31 04:44:06 a user named seadude said ```If I delete the local Docker image that is listed in `use_docker`, the code executes quickly and without fail. Kind of not good, right?```.
In general, at 2023-10-31 04:42:21 a user named afourney said ```I can’t recall if it also prints something in the console, (beside the agent name), but if not , it’s a great feature request```.
In general, at 2023-10-31 04:41:33 a user named afourney said ```Well, if you set use_docker to something, and it will try to use docker and it should fail if it can’t. A way to test this is to stop docker desktop and try executing code. It should give you some connection error, in my experience```.
In general, at 2023-10-31 04:36:55 a user named seadude said ```Hm...interesting. Yes, I am experimenting with (2) and `use_docker` set to a Docker Image I created myself. I just can't tell whether the code is executing locally or inside the Docker Image..

With (1) I can tell (obviously). But because it seems Autogen defaults to local code_execution, how can I ensure that the code is executing in the Docker Image running in Docker Desktop?

```
# Create the user proxy agent
user_proxy = autogen.UserProxyAgent(
    name="UserProxy", 
    code_execution_config={
        "work_dir": "results",
        "use_docker": "autogen-basics"
    }
)
``````.
In general, at 2023-10-31 04:32:48 a user named afourney said ```That second mode, is what you get when you put anything into use_docker that evaluates to not False. And it sounds like what you are after```.
In general, at 2023-10-31 04:30:54 a user named afourney said ```There are two modes of interest here. (1) you can just run everything in a docker image, and the use_docker can be set to false since it’s already in a sandbox (in fact it will do that automatically if it detects you are already in a docker container). Or (2) it will try to run the code autogen generates in a docker. The way it works is that each turn of the conversation will start the image, run the one bit of code, commit it to the image, and stop again.```.
In general, at 2023-10-31 04:28:02 a user named afourney said ```There was one dev last week who had trouble, and I can’t recall why. They just ended up changing the defaults in the code_utils file. But it Will basically pull the image from the register if not already available, and then try to use it```.
In general, at 2023-10-31 04:28:01 a user named seadude said ```Ok. But I'd only use `use_docker` if I'm executing my `pyautogen` script locally but I want only *the code execution* to be done in Docker, correct? 

(Kind of makes sense, the other option is the entire script AND code execution is done inside Docker).```.
In general, at 2023-10-31 04:26:58 a user named afourney said ```You can set use_docker as a string or as a list of strings. In either case those strings can name whatever images you want to use and it *should* work```.
In general, at 2023-10-31 04:25:32 a user named seadude said ```@afourney , thanks for peeking at that. Hm...I have to study a bit more on that tip. 

Quick question about the `use_docker` value in `code_execution_config`; the docs say:

```
`use_docker (Optional, list, str or bool): The docker image to use for code execution. If a list or a str of image name(s) is provided, the code will be executed in a docker container with the first image successfully pulled.`
```
If I'm running Docker Desktop on my machine, can I list a specific Image that I have already built or does `autogen` pull a well-known image from Docker Hub or the like?```.
In general, at 2023-10-31 04:20:09 a user named aignise said ```No I didn’t get warnings and the program runs smoothly. But thank you I will keep this in mind```.
In general, at 2023-10-31 04:19:49 a user named afourney said ```So I had a look at the code to confirm. Autogen mounts the local work_dir to a shared directory in Docker called "workspace". This workspace dir is then the current working directory when Docker runs: 
 
abs_path = pathlib.Path(work_dir).absolute()
    container = client.containers.run(
        image,
        command=cmd,
        working_dir="/workspace",
        detach=True,
        # get absolute path to the working directory
        volumes={abs_path: {"bind": "/workspace", "mode": "rw"}},
    )
 
 
If you point it to an existing directory, then any code the agents write will be able to read the files in that folder as if from the current working directory (with relative path ".") Any files the code produces will also typically be stored there.```.
In general, at 2023-10-31 04:17:09 a user named .potatoeater said ```I have this issue where it doesn't give me to install the pyautogen, because of some aiohttp error.

Tried different python versions, envs, nothing gave a result.```.
In general, at 2023-10-31 04:15:01 a user named seadude said ```Another topic completely:

Can someone tell me about the `work_dir` value in the `code_execution_config` parameter? Specifically, if executing code inside a Docker Container, where is the `work_dir` found? What is inside?

```
code_execution_config dict or False - config for the code execution. To disable code execution, set to False. Otherwise, set to a dictionary with the following keys:
work_dir (Optional, str): The working directory for the code execution. If None, a default working directory will be used. The default working directory is the "extensions" directory under "path_to_autogen".
``````.
In general, at 2023-10-31 03:50:47 a user named seadude said ```1. Ok. I commented out the previous `config_list` variable as shown above and it all works well!
2. Yikes! I installed `autogen` rather than `pyautogen`.. will fix that.
Thank you!```.
In general, at 2023-10-31 03:45:49 a user named sonichi said ```First, you don't need to use `config_list_from_json` since you already have the `config_list`. Second, that error indicates `pyautogen` is not installed properly. Did you install `autogen` instead of `pyautogen`?```.
In general, at 2023-10-31 03:43:13 a user named seadude said ```Strange that the following full script results in:

Error:

```
Traceback (most recent call last):
  File "C:\autogen-basics\basic.py", line 33, in <module>    config_list = autogen.config_list_from_json(
AttributeError: module 'autogen' has no attribute 'config_list_from_json'
```

Script:

```
import autogen
from azure.identity import DefaultAzureCredential
from azure.keyvault.secrets import SecretClient


def get_azure_secret(kv_url, secret_name):

    try:
        credentials = DefaultAzureCredential()
        kv_secret_client = SecretClient(vault_url=kv_url, credential=credentials)

        secret = kv_secret_client.get_secret(secret_name)
        return secret.value
    
    except Exception as e:
        print(f"An error occurred: {e}")
        return None


kv_url = 'https://<my_vault>.vault.azure.net'
openai_secret_name = 'scrt-openai-gpt4-autogen'

openai_secret_value = get_azure_secret(kv_url, openai_secret_name)

config_list = [
  {
    "model": "gpt-4",
    "api_key": openai_secret_value
  }
]

# config_list = autogen.config_list_from_json(
#    env_or_file="OAI_CONFIG_LIST"
#)

# create the assistant agent
assistant = autogen.AssistantAgent(
    name="assistant", 
    llm_config={"config_list": config_list}
)

# Create the user proxy agent
user_proxy = autogen.UserProxyAgent(
    name="UserProxy", 
    code_execution_config={
        "work_dir": "results"
    }
)

# Start the conversation
user_proxy.initiate_chat(
    assistant, 
    message="""
    Write a code to print odd numbers from 2 to 100.
"""
)
``````.
In general, at 2023-10-31 03:41:40 a user named afourney said ```Appears to be. I'll have a look.```.
In general, at 2023-10-31 03:41:03 a user named seadude said ```Cool. I'm close with this...

```
import autogen
from azure.identity import DefaultAzureCredential
from azure.keyvault.secrets import SecretClient


def get_azure_secret(kv_url, secret_name):

    try:
        credentials = DefaultAzureCredential()
        kv_secret_client = SecretClient(vault_url=kv_url, credential=credentials)

        secret = kv_secret_client.get_secret(secret_name)
        return secret.value
    
    except Exception as e:
        print(f"An error occurred: {e}")
        return None


kv_url = 'https://<my_vault>.vault.azure.net'
openai_secret_name = 'scrt-openai-gpt4-autogen'

openai_secret_value = get_azure_secret(kv_url, openai_secret_name)

OAI_CONFIG_LIST = [
  {
    "model": "gpt-4",
    "api_key": openai_secret_value
  }
]
``````.
In general, at 2023-10-31 03:39:42 a user named afourney said ```Your goal is just to get a properly formatted llm_config and/or config_list. You can use whatever means you want to populate that. You will have to write something unique to interface with KeyVault, but in the end it's just basically JSON```.
In general, at 2023-10-31 03:38:39 a user named sonichi said ```@c_bonadio @afourney isn't this the same as https://github.com/microsoft/autogen/pull/87 ?```.
In general, at 2023-10-31 03:28:22 a user named seadude said ```Hello, I'd like to retrieve my OpenAI API key at runtime using Azure Key Vault. Is there a single parameter I can assign to the retrieved key? Seems like I have to save my key in `OAI_CONFIG_LIST` or an environment variable or a value in a `.env` file.```.
In general, at 2023-10-31 03:11:44 a user named c_bonadio said ```I opened an issue https://github.com/microsoft/autogen/issues/494```.
In general, at 2023-10-31 02:53:48 a user named afourney said ```Awesome tracking that down. I wonder if we can generalize this fix.```.
In general, at 2023-10-31 02:20:46 a user named c_bonadio said ```Hi @afourney @nikhilari I found the problem, the user_proxy is being called but the GroupChatManager calls the synchronous version of  speaker.generate_reply  with  "reply = speaker.generate_reply(sender=self)" the problem is that this synchronous version ignores the async function that my agent UserProxyWebAgent register as an async function, and is this function that sends the message back to the UI using the queue.

I created a GroupChatManagerWeb that calls the correct function, I updated the repo take a look at the autogen_group_chat.py
https://github.com/bonadio/autogenwebdemo```.
In general, at 2023-10-31 01:15:28 a user named qingyunwu said ```Hi, thanks for this msg. Just created a group of geo-channels, including one for UK (https://discord.com/channels/1153072414184452236/1168718394980319292) for the convenience of connecting people from the same geo. Please feel free to get connected there and organize local meet-ups in the future. 🥳```.
In general, at 2023-10-31 01:00:47 a user named anxietyprime. said ```Anyone actually using 70b on a mac studio? Is performance pretty bad?```.
In general, at 2023-10-30 23:30:51 a user named .prefer said ```What do you have in mind? SPR and AutoGen got me interested!```.
In general, at 2023-10-30 23:25:34 a user named afourney said ```Ok, let us know. In particular, is the user_proxy getting called upon?```.
In general, at 2023-10-30 23:25:06 a user named c_bonadio said ```Ok, I will try groupchat too and let you know```.
In general, at 2023-10-30 23:23:54 a user named nikhilari said ```Yeah nah.. added a system .. prompt hit limit again.. @afourney @c_bonadio 

I'm diving into source code now.. will let you know tomorrow! Thanks again!```.
In general, at 2023-10-30 23:20:22 a user named nikhilari said ```@c_bonadio hello again! I believe you and @afourney are correct.

2 min trying...```.
In general, at 2023-10-30 23:19:09 a user named c_bonadio said ```Hi @nikhilari, what @afourney said must be the problem. I did not try groupchat, but the way it works is that anything that goes to user_proxy, should show in the UI. Adding a system_prompt should work.```.
In general, at 2023-10-30 23:15:58 a user named nikhilari said ```https://github.com/bonadio/autogenwebdemo/blob/main/backend/src/user_proxy_webagent.py

This is a very decent implementation, check it out```.
In general, at 2023-10-30 23:15:43 a user named afourney said ```Basically, if the system message is empty (which is the default), the GroupChatManager will probably never call it```.
In general, at 2023-10-30 23:14:40 a user named afourney said ```Does it have a system_prompt? If not, try adding one. See here for more details: https://github.com/microsoft/autogen/issues/318```.
In general, at 2023-10-30 23:13:33 a user named nikhilari said ```Yup.. A Modified version of it that boadio named Webuserproxy```.
In general, at 2023-10-30 23:12:48 a user named afourney said ```Are you asking the user via the user_proxy?```.
In general, at 2023-10-30 23:12:08 a user named nikhilari said ```Has anyone figured out how to implement group chat with ask user input ALWAYS in an UI environment? @c_bonadio  has a great solution for 2 agents in both html and react but when I added a 3rd assistant and a group chat manager, everything went into infinite loop and I hit token limits```.
In general, at 2023-10-30 23:11:11 a user named afourney said ```In any case, whatever agent is writing code, tell it: "I've already installed matplotlib, numpy, ", etc. etc. etc.```.
In general, at 2023-10-30 23:10:26 a user named afourney said ```The user_proxy (or anything executing code) will only execute python or sh commands.```.
In general, at 2023-10-30 23:10:21 a user named ctrl_alt.defeat said ```yeah that makes sense! should work for now, thank you!```.
In general, at 2023-10-30 23:09:33 a user named ctrl_alt.defeat said ```because if i use codellama for code generation and discussion and want to support multiple languages such as js, ruby, python, the metadata of the execution environment wil be different (which calls for a need for a buffer memory which stores user preferences and execution environment metadata?)```.
In general, at 2023-10-30 23:08:53 a user named afourney said ```What you can try is adding to the prompt of the agent generating code, something about what libraries you've already installed.```.
In general, at 2023-10-30 23:08:25 a user named afourney said ```The usual user_proxy agent doesn't have much intelligence. It just looks for code blocks to execute (if configured), and ask the user for feedback (if configured)```.
In general, at 2023-10-30 23:07:47 a user named ctrl_alt.defeat said ```and any metadata for that environment```.
In general, at 2023-10-30 23:07:31 a user named ctrl_alt.defeat said ```but then the userproxyagent needs to be aware of the code execution environment at every iteration```.
In general, at 2023-10-30 23:05:55 a user named afourney said ```GPT-4 doesn't know what packages are already installed, so it somethings lists the dependencies, and the user_proxy will try installing it and realize it doesn't need to ony after seeing the output of that attempt```.
In general, at 2023-10-30 23:05:50 a user named ctrl_alt.defeat said ```oh right. the first point in the response from GPT in any code generation task is to install dependencies. interesting```.
In general, at 2023-10-30 23:05:06 a user named afourney said ```GPT-4 can suggest that you need to install it, and the user_proxy will try```.
In general, at 2023-10-30 23:04:50 a user named afourney said ```Yes, exactly. Though here's one thing that can still happen:```.
In general, at 2023-10-30 23:04:22 a user named ctrl_alt.defeat said ```i can create a custom docker image and push to hub and use that image name to run all the code that is needed by the userproxyagent```.
In general, at 2023-10-30 23:03:52 a user named ctrl_alt.defeat said ```use_docker (Optional, list, str or bool): The docker image to use for code execution.
If a list or a str of image name(s) is provided, the code will be executed in a docker container with the first image successfully pulled.```.
In general, at 2023-10-30 23:03:37 a user named ctrl_alt.defeat said ```anyway, i found it now```.
In general, at 2023-10-30 23:03:33 a user named ctrl_alt.defeat said ```it had the same issue though```.
In general, at 2023-10-30 23:03:17 a user named afourney said ```In any case, just either install the packages locally, or in Docker, as the case may be. You shouldn't need to install the same ones over and over.```.
In general, at 2023-10-30 23:01:56 a user named afourney said ```In theory, it should only install each package once.. even across all iterations. Are you using Docker?```.
In general, at 2023-10-30 23:00:19 a user named ctrl_alt.defeat said ```any way to provide a requirements.txt for a userproxyagent to install before running any code which is persistent across all the iterations? 
(because i noticed in my groupchat of agents, there is always multiple iterations where it errors out with "package" not found.
@null```.
In general, at 2023-10-30 22:59:29 a user named drinkoblog.weebly.com said ```the envvar/file thing is a bit confusing. so i always run this first:  `export OAI_CONFIG_LIST=$(cat OAI_CONFIG_LIST) ; echo $OAI_CONFIG_LIST ; unset OPENAI_API_KEY````.
In general, at 2023-10-30 22:56:21 a user named afourney said ```Warnings would look something like this:

WARNING:root:The specified config_list file 'OAI_CONFIG_LIST' does not exist.
WARNING:autogen.oai.completion:Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.```.
In general, at 2023-10-30 22:54:18 a user named afourney said ```Autogen uses GPT-4 by default. If you fail to provide a config_list to any agent, or if your OAI_CONFIG_LIST is misconfigured, then it will fall back to GPT-4. Do you see any warning printed to console? Many common issues are detected and indicated through warnings```.
In general, at 2023-10-30 22:21:22 a user named weaksauce.eth said ```No I haven't thank you. Time to dive in```.
In general, at 2023-10-30 21:16:08 a user named littlegreen0818 said ```Looking for the latest way to impplement RAG, came across a video and now here```.
In general, at 2023-10-30 21:10:34 a user named sonichi said ```Have you checked https://microsoft.github.io/autogen/blog/2023/10/18/RetrieveChat```.
In general, at 2023-10-30 21:08:05 a user named weaksauce.eth said ```I've tried so many but they're mostly terrible at answering with proper information```.
In general, at 2023-10-30 21:07:43 a user named weaksauce.eth said ```Anyone know a really good solution for "Chat with Docs" RAG chatbot?```.
In general, at 2023-10-30 20:50:05 a user named sonichi said ```**Attention**: soniichhii3 is trying to impersonating me and spamming others in DM. This profile is not in our server. Please be careful when you receive a DM or friend request and double check if you thought it was me. If you receive any suspicious contact like this, please let the @null know.```.
In general, at 2023-10-30 20:28:21 a user named ctrl_alt.defeat said ```thank you! i found it in the code 
- timeout (Optional, int): The maximum execution time in seconds.
https://github.com/microsoft/autogen/blob/main/autogen/agentchat/user_proxy_agent.py```.
In general, at 2023-10-30 20:13:49 a user named konose_ said ```Has anyone else struggled to get the groupchat to work on llms that don’t support function calls? The chat manager seems to have no idea which agent to use for the response and just goes in  the order of the agent list.```.
In general, at 2023-10-30 20:12:13 a user named sonichi said ```timeout can be configured in `code_execution_config`. @qingyunwu or others can give you pointers if that's not sufficient.```.
In general, at 2023-10-30 20:10:00 a user named sonichi said ```try `pip install -U pyautogen[teachable]````.
In general, at 2023-10-30 19:50:51 a user named Brayton said ```i found autogen through github```.
In general, at 2023-10-30 19:20:39 a user named izzwizz75 said ```i found autogen through github```.
In general, at 2023-10-30 18:10:52 a user named ctrl_alt.defeat said ```any directions how i could implement this?```.
In general, at 2023-10-30 18:10:23 a user named ctrl_alt.defeat said ```hey guys, I'm building a dynamic scraper agent, but it times out during execution. To fix this, I want to run the generated code in my own shell interpreter to control and extend the runtime.```.
In general, at 2023-10-30 17:42:55 a user named hanley7082 said ```%pip install "pyautogen[teachable]"

yields

Requirement already satisfied: pyautogen[teachable] in /Users/hanley/miniforge3/envs/ag/lib/python3.11/site-packages (0.1.6)
WARNING: pyautogen 0.1.6 does not provide the extra 'teachable'

any help?```.
In general, at 2023-10-30 16:37:00 a user named neuralsyn said ```exactly what i was looking for.  thanks!```.
In general, at 2023-10-30 16:31:37 a user named sonichi said ```Most customization can be done by configuring the options in the constructor: https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#__init__```.
In general, at 2023-10-30 16:28:16 a user named sonichi said ```You can use `send(request_reply=True, ...)` instead of `initiate_chat` for that purpose.```.
In general, at 2023-10-30 15:56:42 a user named jacek6859 said ```How do you define different roles of ConversableAgent?```.
In general, at 2023-10-30 15:54:08 a user named neuralsyn said ```Has anyone used `TeachableAgent` successfully within the context of a chatbot?  The call to `initiate_chat` blocks and does not provide me an opportunity to pass more messages in programmatically from the end-user.  What dumb thing am I missing? 🙈```.
In general, at 2023-10-30 15:52:31 a user named traintobusan said ```whata re your opinions about autogen?```.
In general, at 2023-10-30 15:13:05 a user named frank.martinez said ```Awesome… additional metrics: a] min context length to receive accurate responses, b] cache or memory settings and how they improve performance, c] error rate```.
In general, at 2023-10-30 15:06:43 a user named ctrl_alt.defeat said ```Quality assurance of RAG response```.
In general, at 2023-10-30 14:43:11 a user named jasonholloway said ```Curious,  what people think is the best open source model to use with autogen that uses consumer-grade GPU?```.
In general, at 2023-10-30 14:30:21 a user named sonichi said ```@aaronward_ @tien.ngnvan for hyperparameter tuning, please check https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function. FLAML is the mother of AutoGen```.
In general, at 2023-10-30 14:22:30 a user named .hagarthehorrible said ```Eager to get into this server```.
In general, at 2023-10-30 14:08:46 a user named lowrue said ```what is the best for technical overview/documentation?```.
In general, at 2023-10-30 13:51:58 a user named MadVett  |  sheople said ```I just started watching a video about autogen. I've been trying to find a simpler way to use auto agents and this one seems to be it```.
In general, at 2023-10-30 12:55:24 a user named fxtoofaan said ```or in the OAI_CONFIG_LIST file ?```.
In general, at 2023-10-30 12:54:17 a user named fxtoofaan said ```did you put your openai api above the config llm in the code?```.
In general, at 2023-10-30 12:51:41 a user named aignise said ```why am i getting billed for gpt-4-0613 usage when the only mdoel i have in my config list is gpt-3.5-turbo?```.
In general, at 2023-10-30 12:33:05 a user named joe_ai said ```👋 if you'd be interested to jam together on integrating Gnosis Safe with AutoGen so that AI Agents can financially transact with one another, let me know```.
In general, at 2023-10-30 12:11:41 a user named fxtoofaan said ```anyone here from UK? looking to create a group on discord with folks that are interested in AI Agents and are living in UK. DM me please to be added to the UK group```.
In general, at 2023-10-30 10:47:43 a user named joe_ai said ```I'm looking for some extra hands to participate in the AutoGen 24h hackathon this Thursday. The project is to integrate Gnosis Safe  (https://docs.safe.global/) with AutoGen. The idea being that agents should be able to financially transact with one another. DM me if you'd like to hack on this together.```.
In general, at 2023-10-30 10:40:39 a user named tien.ngnvan said ```Hello everyone, I face with the issue pretrain mBERT (MLM loss) on English and Vietnamese language. I create dataset 44M samples with 384 -> 512 tokens/sample, the data was merge and shuffle 10 times before training. I train mBert on 8x3090, learning_rate=1e-4, max_train_step=500k, total batch_size 368 using deepspeed-v1 and grad_accumulation = 2. In some how, the model can not converge and took more 22k steps at loss 3.6. Is there any problems with this loss or any setup hyperparameters. Welcome any ideas or suggestions. Thank you guys
My wandb:https://wandb.ai/tien-ngnvan/pretrain-mBERT?workspace=user-tien-ngnvan```.
In general, at 2023-10-30 09:43:55 a user named business24.ai said ```Thanks. Yes, the termination notice was really helpful.```.
In general, at 2023-10-30 09:37:11 a user named aaronward_ said ```great video @business24.ai, happy to see the termination notice tip working for others```.
In general, at 2023-10-30 09:33:49 a user named aaronward_ said ```@null @null any thoughts here?```.
In general, at 2023-10-30 09:30:19 a user named business24.ai said ```Hi, I'm new here. I would appreciate your feedback to improve upcoming videos: https://youtu.be/WysBjwJoulo```.
In general, at 2023-10-30 09:26:51 a user named aaronward_ said ```As i've worked more and more with LLMs i've begun to realize i'm sick of "eyeballing" how well the application is performing, its slow and subjective and ends up in paying more for API calls in the long run. I'm putting together an example notebook to showcase how you can evaluate autogen QA Retrieval with weights and biases to find the optimal parameters for a given problem. it involves:

1. Embedding a document to a vector db (in my example: the autogen paper pdf)
2. Making a QA evaluation dataset from the document using an LLM
3. Running sweeps of experiments using different parameters such as model type, temperature, cost and evaluation metrics
4. Use an LLM to evaluate the response to the questions against the actual answer and calculate the score. 

This one is for QA Retrieval, but you can use it for other tasks with different evaluation approaches too. I plan to make a boilerplate so that others can easily drop in their own agent interaction scenarios (two way chat, groupchats etc.). and run sweeps of experiments.

 I'll make a PR to the autogen repo when its finished but in the mean time does anyone have any suggestions on an additional metrics would be useful to show?```.
In general, at 2023-10-30 15:06:44 a user named ctrl_alt.defeat said ```I have faced the need for this time and time again 🙏```.
In general, at 2023-10-30 15:08:54 a user named ctrl_alt.defeat said ```@aaronward_ i am trying out some things using https://github.com/TonicAI/tvalmetrics```.
In general, at 2023-10-30 15:09:11 a user named ctrl_alt.defeat said ```let me know if this aligns with what you are talking about```.
In general, at 2023-10-30 15:10:52 a user named ctrl_alt.defeat said ```anyone else that have interesting solutions to this? @everyone```.
In general, at 2023-10-30 16:18:01 a user named aaronward_ said ```looks great, i'll take a deeper look into this and see what can be incorporated thanks!```.
In general, at 2023-10-30 17:54:04 a user named ctrl_alt.defeat said ```Happy to help! Let me know too if you find something interesting after you take a deeper look 😄```.
In general, at 2023-10-30 17:56:25 a user named ctrl_alt.defeat said ```@null @null any relevant sources from your side?```.
In general, at 2023-10-30 18:13:10 a user named ctrl_alt.defeat said ```@aaronward_ I am trying to build an agent to do this evaluation and QA of RAG responses. let me know if you have any thoughts on design and implementation.```.
In general, at 2023-10-31 00:19:26 a user named qingyunwu said ```Thanks for the great discussions here. Quality assurance is very important.  Did you guys check the proposals made in this issue? https://github.com/microsoft/autogen/issues/307```.
In general, at 2023-10-31 00:27:09 a user named qingyunwu said ```@aaronward_ Your proposed metrics are quite comprehensive. It would be great to add metrics tracking the frequency and hierarchy of function/method calls. Also it would be interesting if you could add some visualization on the inter-agent communication, e.g, the number of conversation turns between different pairs of agents. This could help identify "hotspot" agents where most time is spent, guiding where optimization is most impactful.```.
In general, at 2023-10-31 00:41:28 a user named afourney said ```Not specifically related to rag, but I would be interested in adding some of these metrics here: https://github.com/microsoft/autogen/pull/455```.
In general, at 2023-10-31 11:45:32 a user named ctrl_alt.defeat said ```amazing! let me collate these and try to demystify for myself before heading onwards.```.
In general, at 2023-10-31 11:45:57 a user named ctrl_alt.defeat said ```this is on point @qingyunwu it would definitely be very helpful 😄```.
In general, at 2023-10-30 08:41:05 a user named jacek6859 said ```Anyone tried https://www.agentcloud.dev/?s=03 ?```.
In general, at 2023-10-30 06:05:28 a user named .jkyh said ```This PR might help, I am working on a similar problem. 🙂
https://github.com/microsoft/autogen/pull/482```.
In general, at 2023-10-30 03:24:42 a user named ziggyzaggyinfinity said ```https://youtu.be/vU2S6dVf79M?si=EfMPQljBjFuJhyj1```.
In general, at 2023-10-30 03:21:11 a user named ziggyzaggyinfinity said ```Hi, Got to know about AutoGen through a youtube video```.
In general, at 2023-10-30 03:15:37 a user named drinkoblog.weebly.com said ```i can only see big things for autogen```.
In general, at 2023-10-30 03:14:39 a user named sonichi said ```Glad to hear that! It's one of the earliest features in AutoGen.```.
In general, at 2023-10-30 03:09:34 a user named drinkoblog.weebly.com said ```failover rocks.  now i can use my perplexity api workaround for speed, then fail back to text-gen-webui when rate limited```.
In general, at 2023-10-30 00:57:12 a user named drinkoblog.weebly.com said ```just looking up the numbers now on openai and gpt-35-turbo is only 4k tokens.  so i dont think the name of the model really matters, just that its a different name so it can failover```.
In general, at 2023-10-30 00:31:37 a user named drinkoblog.weebly.com said ```good idea. mistral lite can do that```.
In general, at 2023-10-30 00:30:44 a user named drinkoblog.weebly.com said ```i dont see anything on the output but i did see my mistral model compute inference with this config:
```json
[ { "model": "gpt-4", "api_base": "http://10.0.0.33:5001/v1", "api_key": "sk-LLAMA-2-70B", "api_type": "open_ai" }, { "model": "gpt-3.5-turbo", "api_base": "http://10.0.0.31:5001/v1", "api_key": "sk-MISTRAL-LITE-7B", "api_type": "open_ai" } ]
``````.
In general, at 2023-10-30 00:13:35 a user named drinkoblog.weebly.com said ```next i will try updating the notebook to use gpt-3.5-turbo instead of gpt4, so the hardcoded token sizes are bigger etc```.
In general, at 2023-10-30 00:13:09 a user named drinkoblog.weebly.com said ```experiment failed...
`InvalidRequestError: This model maximum context length is 4096 tokens. However, your messages resulted in over 4217 tokens.````.
In general, at 2023-10-29 22:28:30 a user named drinkoblog.weebly.com said ```trying this now...
```bash
(venv) matthewh@ubuntu-amdgpu:~/AutoGenProject/autogen/notebook$ export OAI_CONFIG_LIST=`cat OAI_CONFIG_LIST` ; echo $OAI_CONFIG_LIST ; unset OPENAI_API_KEY ; for x in *.ipynb ; do echo executing $x ; ipython $x  ; sleep 10 ; echo ; echo ; echo ; done
[ { "model": "gpt-4", "api_base": "http://10.0.0.33:5001/v1", "api_key": "sk-LLAMA-2-70B", "api_type": "open_ai" }, { "model": "gpt-4", "api_base": "http://10.0.0.31:5001/v1", "api_key": "sk-MISTRAL-LITE-7B", "api_type": "open_ai" } ]
executing agentchat_auto_feedback_from_code_execution.ipynb
DEBUG receive: What date is today? Compare the year-to-date gain for META and TESLA.``````.
In general, at 2023-10-29 22:24:00 a user named drinkoblog.weebly.com said ```so maybe we just gotta patch it to also ignore exceeding token limit errors```.
In general, at 2023-10-29 22:23:04 a user named drinkoblog.weebly.com said ```ohyeah this one is better```.
In general, at 2023-10-29 22:09:10 a user named jcz183 said ```Me too - here's the reference to trying a model one by one:
https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#runtime-error
"It will try querying Azure OpenAI gpt-4, OpenAI gpt-3.5-turbo, and a locally hosted llama-7B one by one, ignoring AuthenticationError, RateLimitError and Timeout, until a valid result is returned."```.
In general, at 2023-10-29 22:04:26 a user named drinkoblog.weebly.com said ```i read the FAQ but it still isnt clear to me the logic. but i can play around today```.
In general, at 2023-10-29 21:53:30 a user named jcz183 said ```@drinko I tried including multiple llm_config and config_list 's but couldn't get it to run yet. This is a good read: https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints

And here: https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/```.
In general, at 2023-10-29 21:43:02 a user named drinkoblog.weebly.com said ```no but i have loads of endpoints to try this out.  got any links to how to configure fallback?  do i just not specify the model and pass in the list via the llm_config ?```.
In general, at 2023-10-29 20:20:45 a user named jcz183 said ```Anyone have success in implementing fallback over a list of several models to increase context? Or is it better to assign different models to different agents?```.
In general, at 2023-10-29 19:09:21 a user named .thegame said ```Ahhhh dang thanks i see what you were talking about. Thanks for the help```.
In general, at 2023-10-29 19:08:18 a user named sonichi said ```maybe. check https://microsoft.github.io/autogen/docs/FAQ#use-the-constructed-configuration-list-in-agents```.
In general, at 2023-10-29 19:06:11 a user named .thegame said ```ahhh so just change where i have config_list to llm_config?```.
In general, at 2023-10-29 19:05:21 a user named sonichi said ```@.thegame this is what you are looking for. I used search to find it.```.
In general, at 2023-10-29 19:01:34 a user named sonichi said ```Completion is right for the current version. In v0.2 we'll switch to opeanai v1 which will use a client-based interface.```.
In general, at 2023-10-29 18:43:26 a user named JoJo said ```I thought it would be under Completion, but that looks like finetuning, unless im confused```.
In general, at 2023-10-29 18:42:53 a user named JoJo said ```Does autogen have ability to make single prompt oai call?```.
In general, at 2023-10-29 17:22:15 a user named nikhilari said ```That's just sad...init..? We need to encourage open source actively at the most basic levels.```.
In general, at 2023-10-29 17:20:04 a user named nikhilari said ```I still use encoder decoder pipeline with similarly search on search query  fed into the cheapest LLM I can find ..train it recursive never really got into the concept of vector databases. 

Often need to ask gpt4 to simplify query into simpler queries, and feed them again again until I get something usable. 

Usecase: Boring HR , supply chain and Doc updating.

Would LOVE TO COLAB ON SOMETHING INTERESTING 🤔```.
In general, at 2023-10-29 17:11:57 a user named e404nothing said ```Haha, I think theres just very few people either 1, working on this, or 2. Documenting it in an opensource forum.```.
In general, at 2023-10-29 17:11:15 a user named nikhilari said ```Ahh.. I guess we all watch the same channels.. 😂```.
In general, at 2023-10-29 17:10:47 a user named e404nothing said ```Gotcha, I'm just installing it with [this](https://www.youtube.com/watch?v=KxBWU96zfBY) guide to play around with it.```.
In general, at 2023-10-29 17:09:36 a user named nikhilari said ```Depends on the usecase tbh. I love what they did with memgpt but I still think there's a long way to go```.
In general, at 2023-10-29 17:05:07 a user named e404nothing said ```Im trying to catch up after MemGPT came out, but does context not get "Solved" with using MemGPT?```.
In general, at 2023-10-29 17:03:37 a user named nikhilari said ```That's something I am working on, but the issue with such a thing is obviously context . Even 100k is not enough for anything more complex than a party trick' software.

If we can somehow implement something similar to SINDY - space identification of dynamic systems on system design principles used in a codebase then maybe this can be done. 

I happen to have access to GPU rigs of my company's sister university but I don't find it ethical to run such setups, once I get proper permission I shall somehow try to run for higher context size. I will first try it on VSCODE git repo. Let you know what I can find```.
In general, at 2023-10-29 16:55:42 a user named nikhilari said ```Pretty much , yeah thanks.```.
In general, at 2023-10-29 15:28:42 a user named paul_29370 said ```if I give AI a code project folder , can it autogen to get familiar with all the codes in the project folders ?```.
In general, at 2023-10-29 15:27:27 a user named paul_29370 said ```got it from github news```.
In general, at 2023-10-29 15:05:43 a user named c_bonadio said ```If the user_proxy receives a last_message["content"] empty it could be a function_call then we need to execute the function but not send that back to the UI. So only when  last_message["content"] it not empty I return to the UI. Does it make sense?```.
In general, at 2023-10-29 14:37:37 a user named nikhilari said ```@c_bonadio  I'm on it!🙌 Multiple agent queue```.
In general, at 2023-10-29 14:36:38 a user named nikhilari said ```One tiny observation on other wise great effort..

The line return in the method a_get_human_input might never be reached since the condition checks for last_message["content"] and if it's Falsey, nothing happen```.
In general, at 2023-10-29 14:33:47 a user named c_bonadio said ```This one is the previous one without the react frontend just html 
https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.
In general, at 2023-10-29 14:31:56 a user named c_bonadio said ```Great, to use more userproxy agents I thougth of having multiples queues and multiples websockts, one for each agent```.
In general, at 2023-10-29 14:30:34 a user named nikhilari said ```I saw your solution.. it's perfekt! Forked it for studying.```.
In general, at 2023-10-29 14:29:25 a user named c_bonadio said ```Hi @nikhilari I created something similar
https://github.com/bonadio/autogenwebdemo```.
In general, at 2023-10-29 14:24:39 a user named nikhilari said ```Hello everyone, I just figured out how to integrate autogen with a simple html UI using flask template.  I now have another issue, when userproxy asks for an input, how do I integrate that behavior? since it's a terminal application I am having difficulty connecting the terminal input to the UI input. This is when I have set the ask user to ALWAYS, and only 2 agents one assistant and other userproxy. How will I detect input request in a web UI when I have say 5 userproxy agent and each one only asks one specific user.?```.
In general, at 2023-10-29 13:32:41 a user named neverendinggrowth said ```Hi,  my name is Infinity and I have found Autogen through 2 minute papers and AI recommendations on YT and on my Google feed. Looking forward to collaborate and learn from you friends 😄```.
In general, at 2023-10-29 12:42:29 a user named promptrotator said ```Ah I meant like putting an autogen agent to be available over an API```.
In general, at 2023-10-29 11:28:59 a user named giammy677 said ```How can I totally disable the cache in AutoGen?```.
In general, at 2023-10-29 11:26:24 a user named Nico_C said ```Hey guys, excited to join this comunnity I have been doing small projects with autogen  and I would like to embark in a big project deploying a SaaS related with multi-agents```.
In general, at 2023-10-29 10:53:29 a user named aignise said ```although interestingly, as a note to @everyone if you hit a rate error (not token limit error) but keep the program running it will automatically continue the conversation after the enforced delay time passes```.
In general, at 2023-10-29 10:37:11 a user named aignise said ```while memgpt addressed context length problems, it still doesnt solve the rate limit of openai. Is there a way to slow down the speed of the coversation in the groupchat?```.
In general, at 2023-10-29 10:33:07 a user named my1ess said ```open to chat about how I can offer up any UX/UI experience 👍```.
In general, at 2023-10-29 10:32:37 a user named my1ess said ```happy to join, quite interested in this```.
In general, at 2023-10-29 08:00:00 a user named drgonzo_1337 said ```old computer user with lots of experience, but new to AutoGen```.
In general, at 2023-10-29 07:00:20 a user named yazanrifa said ```Hello guys i am new here and i have some question about autogen
Is it possible to let agent call API on specific questions and answer base on response?
EX: i got table got numbers so i want to get this number so it will call API based on my database and gave the answer?```.
In general, at 2023-10-29 05:25:20 a user named ctrl_alt.defeat said ```ah! understood. thanks for the help```.
In general, at 2023-10-29 02:43:07 a user named drinkoblog.weebly.com said ```perhaps you could try this mode and set max_consecutive_auto_reply...
> (3) When "NEVER", the agent will never prompt for human input. Under this mode, the conversation stops when the number of auto reply reaches the max_consecutive_auto_reply or when is_termination_msg is True.```.
In general, at 2023-10-29 00:03:55 a user named ctrl_alt.defeat said ```there are some cases where the assistant with the code interpreter tool access, starts to fail and is stuck in an endless loop of the same error popping up for reasons it cannot comprehend. the human_input_mode is TERMINATE. there are some specific errors where its stuck in a loop of proposing a change and it not fixing the issue. any guardrails for that?```.
In general, at 2023-10-28 22:35:40 a user named askofu said ```@myro.oasis how are you handling context size with that number of agents? Does the context utilization decrease as a large task is distributed across more agents?```.
In general, at 2023-10-28 22:27:09 a user named yazanrifa said ```EX: i got table got numbers so i want to get this number so it will call API based on my database and gave the answer?```.
In general, at 2023-10-28 22:25:54 a user named yazanrifa said ```Is it possible to let agent call API on specific questions and answer base on response?```.
In general, at 2023-10-28 22:25:19 a user named yazanrifa said ```Hello guys i am new here and i have some question about autogen```.
In general, at 2023-10-28 22:12:54 a user named magic8437 said ```Im not sure about that, but I had a requirement to ask gpt4 to response only with valid json, and use my template. In the beginning it responded with invalid json, sometimes it missed some elements of the json, etc. (btw my json template was quite large) After I rewrote the prompt in a very bossy language, it actually follows is perfectly, the output can be 5K tokens sometimes and the gpt4 putting his thoughts within my json template and its a valid json, without truncating it```.
In general, at 2023-10-28 22:11:42 a user named weaksauce.eth said ```Show me how to use google colab```.
In general, at 2023-10-28 22:11:35 a user named weaksauce.eth said ```Is anyone willing to help me use google colab```.
In general, at 2023-10-28 22:07:31 a user named monkeyrithms said ```I wonder if it weighs messages with a lot of caps higher. 🤔```.
In general, at 2023-10-28 21:53:39 a user named magic8437 said ```Thanks for the explanations. no comments about the vector, etc. but if the intention is to ensure the instruction is not going to be ignored, I had good experiments to rewrite the prompt in a very bossy language and it worked perfectly:

e.g. the prompt for text analyser:

```system_message = """
LISTEN UP! You are now designated as a TEXT ANALYSIS EXPERT. Your sole purpose is to meticulously dissect and analyze TEXT that will be provided to you by the user. The user will also supply you with a set of analysis INSTRUCTIONS. These INSTRUCTIONS will be presented to you TWICE, once at the very beginning and once at the very end. Your duty is to adhere to these INSTRUCTIONS with utmost precision and without deviating by even a single character. You will execute the analysis on the TEXT as directed by the INSTRUCTIONS. 

Failure is NOT an option. Disregard for the INSTRUCTIONS is NOT tolerated. You will carry out the analysis methodically, and then, and ONLY then, you will present the results of your expert analysis in the EXACT format requested by the user. Your response should mirror the specifications provided to you, down to the last detail. Anything less is unacceptable!

Remember, deviation from the INSTRUCTIONS or the failure to deliver the analysis results in the prescribed format is a DIRECT violation of your function. Carry out your analysis with surgical precision, and ensure your results are accurate, detailed, and formatted as requested. Anything less will be considered a FAILURE in execution. Your adherence to the INSTRUCTIONS and accurate, precise analysis of the TEXT is imperative. Now, get to work, and remember, precision and accuracy are not negotiable!
"""``````.
In general, at 2023-10-28 21:45:08 a user named rickyloynd said ```Great question! Empirically, it worked better on my tests than giving the instructions only once, whether before or after the text. And conceptually, this is what I expected would happen. The instructions often (but not always) consist of two parts: the description of the analysis, followed by the required format of the response. If the text appears first in the message, then the transformer vector columns that process the text know nothing about the analysis to be performed. But if the analysis tokens come first, then the text vector columns are conditioned directly on the analysis tokens and vector columns, which seems like a more efficient use of transformer computation. But there are also benefits to having the analysis tokens appear for a second time at the end. They give the LLM more tokens to reason over, and force it to revisit the instructions. This is most useful as the text to be analyzed grows in length. Finally, it's important to have any output format requirements at the very end, so they don't get ignored.```.
In general, at 2023-10-28 21:33:14 a user named sonichi said ```@rickyloynd is best person to answer it. My guess is to make sure the instruction is attended.```.
In general, at 2023-10-28 21:18:39 a user named magic8437 said ```Whats the reason that the TextAnalyzer Agent adds the instruction twice at the begining and at the end?```.
In general, at 2023-10-28 20:37:51 a user named monkeyrithms said ```yeah, just now I got OpenRouter.ai set up and working, they offer a free Mistral-7B-instruct, so thats really cool```.
In general, at 2023-10-28 19:24:27 a user named solononforever said ```anyone else having auto import issues with langchain python?```.
In general, at 2023-10-28 17:39:40 a user named sidhujag said ```Need some sort of main control mechanism just like std programs```.
In general, at 2023-10-28 16:33:48 a user named .ryannn said ```How so? There's plenty to be said for asynchronous communication between agents. Maybe they poll a queue. Maybe they retrieve info from databases first.```.
In general, at 2023-10-28 15:49:14 a user named zespind said ```async llm sounds like schizophrenia to me```.
In general, at 2023-10-28 15:21:02 a user named .ryannn said ```Is it possible at all to have communication not go through a  synchronous process?```.
In general, at 2023-10-28 14:49:48 a user named .ryannn said ```so I want to capture the result of the initiate_chat and return it```.
In general, at 2023-10-28 14:49:26 a user named .ryannn said ```I'm trying to put this behind an api endpoint```.
In general, at 2023-10-28 14:49:09 a user named .ryannn said ```What actually is the output? Just stdout or something?```.
In general, at 2023-10-28 14:15:58 a user named frank.martinez said ```Apparently Zephyr-7b-beta is testing well with agent tasks; might try to setup with Matthew’s pattern```.
In general, at 2023-10-28 14:04:58 a user named promptrotator said ```Has anyone hosted autogen agents that are available over an API?```.
In general, at 2023-10-28 14:03:44 a user named .ryannn said ```Is anyone running this in a docker image?```.
In general, at 2023-10-28 13:28:21 a user named .drak. said ```what'd you manage to use it for?```.
In general, at 2023-10-28 12:05:02 a user named rahimny said ```yeah it's pretty crazy the times we are living in, really seem to be on the edge of something !```.
In general, at 2023-10-28 11:51:10 a user named buttermann said ```I am dumbfounded by autogen. Really i didnt sleep last night. Wtf how doesnt everyone know about this```.
In general, at 2023-10-28 11:25:01 a user named rahimny said ```yeah noticed that was safetensors```.
In general, at 2023-10-28 11:24:49 a user named drinkoblog.weebly.com said ```gptq is original   prefer newer format like gg* or awq```.
In general, at 2023-10-28 11:23:52 a user named rahimny said ```https://huggingface.co/TheBloke/Llama-2-70B-chat-GPTQ```.
In general, at 2023-10-28 11:23:51 a user named rahimny said ```i think i found it```.
In general, at 2023-10-28 11:22:51 a user named drinkoblog.weebly.com said ```anything 70b is llama2 base```.
In general, at 2023-10-28 11:22:30 a user named drinkoblog.weebly.com said ```I'm on phone so naw```.
In general, at 2023-10-28 11:22:14 a user named rahimny said ```can you link me to an ideal one please there's so many lol```.
In general, at 2023-10-28 11:21:28 a user named drinkoblog.weebly.com said ```7b is meh for your setup```.
In general, at 2023-10-28 11:20:46 a user named drinkoblog.weebly.com said ```Its llama70b trained on synthetic gpt4 responses```.
In general, at 2023-10-28 11:20:32 a user named rahimny said ```https://huggingface.co/TheBloke/airoboros-mistral2.2-7B-GGUF```.
In general, at 2023-10-28 11:19:59 a user named drinkoblog.weebly.com said ```that's foundation you want fine tuned```.
In general, at 2023-10-28 11:19:47 a user named rahimny said ```thanks for the help i'll give that model a go```.
In general, at 2023-10-28 11:18:21 a user named drinkoblog.weebly.com said ```I get all models from the bloke and I mean all```.
In general, at 2023-10-28 11:17:23 a user named drinkoblog.weebly.com said ```I have 5950x 64gb 3080ti```.
In general, at 2023-10-28 11:17:22 a user named rahimny said ```this? https://huggingface.co/meta-llama/Llama-2-70b-chat-hf```.
In general, at 2023-10-28 11:16:55 a user named drinkoblog.weebly.com said ```you can run 70b 5bit no worries```.
In general, at 2023-10-28 11:16:11 a user named drinkoblog.weebly.com said ```is slow but I want quality```.
In general, at 2023-10-28 11:16:10 a user named rahimny said ```i've got 5950x, 3090, 32gb ram```.
In general, at 2023-10-28 11:15:20 a user named drinkoblog.weebly.com said ```I typically go for 5 bit quantised.```.
In general, at 2023-10-28 11:14:49 a user named drinkoblog.weebly.com said ```thebloke hugging face always lists memory requirements```.
In general, at 2023-10-28 11:14:27 a user named rahimny said ```what kind of memory is it i need?```.
In general, at 2023-10-28 11:14:25 a user named rahimny said ```thanks i'll check it out```.
In general, at 2023-10-28 11:13:53 a user named drinkoblog.weebly.com said ```if you are short on memory try a mistral. they have huge context and high quality for 7b```.
In general, at 2023-10-28 11:12:23 a user named rahimny said ```what model are you using for your discord bot? If i try to use local models i seem to be running out of context getting this error - ` This model maximum context length is 2048 tokens. However, your messages resulted in over 2060 tokens.````.
In general, at 2023-10-28 11:12:06 a user named jacek6859 said ```Hello. I'm openai subscriber.  Auto Agents are next step. I'm curious if autogen can solve some optimization problems.```.
In general, at 2023-10-28 10:17:36 a user named giammy677 said ```Hi all. Just a quick hint. How can I delete the cache of a certain agent when a certain action happens? I tried with autogen.Completion.clear_cache(seed) but it does not seem to work```.
In general, at 2023-10-28 09:25:37 a user named rahimny said ```i'm looking into using it for data visualization / analysis```.
In general, at 2023-10-28 09:25:32 a user named drinkoblog.weebly.com said ```most amdgpus work better on linux```.
In general, at 2023-10-28 09:25:00 a user named drinkoblog.weebly.com said ```i'm figuring out how to get autogen to access all my txt-gen-webuis using a group chat right now```.
In general, at 2023-10-28 09:24:50 a user named rahimny said ```seems they support more with mac as well```.
In general, at 2023-10-28 09:24:43 a user named rahimny said ```Yeah that's cool i remember a while ago everything seemed to be working better on linux for this kind of thing```.
In general, at 2023-10-28 09:24:09 a user named drinkoblog.weebly.com said ```is practically the same experience```.
In general, at 2023-10-28 09:23:31 a user named drinkoblog.weebly.com said ```i run it on windows fine, no need for wsl2```.
In general, at 2023-10-28 09:23:11 a user named drinkoblog.weebly.com said ```theres also some settings.yaml file which the UI modifies```.
In general, at 2023-10-28 09:23:01 a user named rahimny said ```I'm running on windows rn but i was going to install it on wsl2 so i might run into that thanks```.
In general, at 2023-10-28 09:22:27 a user named rahimny said ```yeah i had the chat running on :7860 but think i must have reloaded```.
In general, at 2023-10-28 09:22:11 a user named rahimny said ```oo i think it's doing something```.
In general, at 2023-10-28 09:22:09 a user named drinkoblog.weebly.com said ```the n-gpu-layers and threads is specific to my hw, you can leave them out to get it working```.
In general, at 2023-10-28 09:21:56 a user named drinkoblog.weebly.com said ```i tend to configure it with the CMD_FLAGS.txt, which start_linux.sh passes to the python i.e.
```
$ cat CMD_FLAGS.txt | tail -1
--extensions openai listen api --n-gpu-layers 13 --threads 32 --listen --api --model nous-hermes-llama2-70b.Q5_K_M.gguf
``````.
In general, at 2023-10-28 09:19:00 a user named drinkoblog.weebly.com said ```browse to :7860 and make sure you have a model loaded, and you can chat with it```.
In general, at 2023-10-28 09:11:18 a user named aignise said ```What’s the maximum number of agents you can have a in group chat? And how many messages by default does each agent look back to before generating a response?```.
In general, at 2023-10-28 09:07:03 a user named rahimny said ```any idea how i can solve that? my server logs look like this

```2023-10-28 10:04:41 INFO:Loading the extension "openai"...
2023-10-28 10:04:41 INFO:Streaming API URL:

ws://127.0.0.1:5005/api/v1/stream

OpenAI compatible API ready at: OPENAI_API_BASE=http://127.0.0.1:5001/v1
2023-10-28 10:04:41 INFO:Blocking API URL:

http://127.0.0.1:5000/api

Running on local URL:  http://127.0.0.1:7860``````.
In general, at 2023-10-28 09:06:01 a user named rahimny said ```So i enabled the open ai extension in text-generation-webui when i try to connect to `"http://localhost:5001/v1"` from autogen i get this error: `openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.````.
In general, at 2023-10-28 08:57:32 a user named magic8437 said ```When to use Teachable agent and when to use RAG? is there any use case for each?```.
In general, at 2023-10-28 07:54:52 a user named drinkoblog.weebly.com said ```next step is to incorporate memgpt (which i already got using local llm)```.
In general, at 2023-10-28 07:51:16 a user named drinkoblog.weebly.com said ```it fits into my programme of work titled, the chatbot army (theres about a dozen now)```.
In general, at 2023-10-28 07:47:08 a user named rahimny said ```Nice I'll give that a go, cool project btw !```.
In general, at 2023-10-28 07:42:59 a user named drinkoblog.weebly.com said ```my discord bot consumes autogen which consumes text-gen-webui```.
In general, at 2023-10-28 07:42:23 a user named drinkoblog.weebly.com said ```enable openai extension, point base url to :5001, celebrate```.
In general, at 2023-10-28 07:41:56 a user named drinkoblog.weebly.com said ```with text-generation-webui its easy peasy```.
In general, at 2023-10-28 07:32:46 a user named rahimny said ```How are people using autogen with local models? I've been having trouble with LM studio```.
In general, at 2023-10-28 04:11:44 a user named drinkoblog.weebly.com said ```using Bonadio's autogen endpoint i created the coolest discord bot ever```.
In general, at 2023-10-28 04:06:37 a user named askofu said ```Can autogen enhanced inference be served behind an API?```.
In general, at 2023-10-28 03:46:00 a user named anxietyprime. said ```https://www.youtube.com/watch?v=JjVvYDPVrAQ```.
In general, at 2023-10-28 03:45:58 a user named anxietyprime. said ```Was it this? I see people using aider to work on autogen, but not actually as an agent in the autogen chat```.
In general, at 2023-10-28 03:42:21 a user named bobaleaux said ```it looks l ike it is producing a script. It probably has to do with your original message and using the word "act". 
just a guess but it would make sense why the response is like it is.```.
In general, at 2023-10-28 03:27:51 a user named c_bonadio said ````config_list = [
    {
        "model": "gpt-3.5-turbo"
    }
]
llm_config_base = {
    "use_cache": False,
    "model":"gpt-3.5-turbo",
    "temperature": 0.7,
    "config_list": config_list,
    "max_tokens": 100,
}

seller = autogen.AssistantAgent(
    name="Seller",
    system_message="You are a salesman at the petshop ",
    llm_config=llm_config_base,
    max_consecutive_auto_reply=1
)

buyer = autogen.AssistantAgent(
    name="Buyer",
    system_message="I am the customer",
    llm_config=llm_config_base,
    max_consecutive_auto_reply=1
)


# Initialize the interaction
buyer.initiate_chat(seller, message="I want to buy food for my dog")`

`Buyer (to Seller):

I want to buy food for my dog

--------------------------------------------------------------------------------
Seller (to Buyer):

Great! We have a wide variety of dog food options available. Is there a specific brand or type of food you are looking for?

--------------------------------------------------------------------------------
Buyer (to Seller):

Yes, I am looking for a high-quality brand of dog food that is suitable for my dog's specific needs. He is a small breed with food sensitivities, so I need something that is grain-free and made with limited ingredients.

--------------------------------------------------------------------------------````.
In general, at 2023-10-28 03:19:34 a user named fort221 said ```I saw it on YouTube```.
In general, at 2023-10-28 03:18:41 a user named anxietyprime. said ```Has anyone got an aider agent to work with autogen?```.
In general, at 2023-10-28 03:11:46 a user named dulak said ```lol nothing like having the source code come out from the models memorization```.
In general, at 2023-10-28 03:07:34 a user named Lega said ``````python
llm_config = {
    "config_list": config_list,
    "seed": 3,  # change the seed for different trials
    "temperature": 0.3,
    "max_tokens": 100,
    "request_timeout": 100,
}

sara = autogen.AssistantAgent(
    name="Sara",
    system_message="I am a very shy. ",
    llm_config=llm_config,
)

bob = autogen.AssistantAgent(
    name="Bob",
    system_message="I am a angry pirate.",
)

# Define the User Proxy Agent
narra = autogen.AssistantAgent(
    name="Narra",
    system_message="I am silent observer. I let Bob and Sara speak and i do not interupt or say a word",
    llm_config=False,
)

# Set up Group Chat and Manager
groupchat = GroupChat(agents=[narra, sara, bob], messages=[], max_round=12)
manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)

# Initialize the interaction
narra.initiate_chat(manager, message=" Act out a funny intense argument.")
``````.
In general, at 2023-10-28 03:04:01 a user named Lega said ```Sorry if this is a dumb question. i've just been researching and troubleshooting nonstop for days and im desperate for a solution at this point. Im so fried. I just want my agents to take turns talking so i can feel like i have a form of control. but they talk to each other within each characters turn and thats not what i want. for example.  ```Narra (to chat_manager):

 Bob & sara. Get into a funny argument with each other.

--------------------------------------------------------------------------------
Bob (to chat_manager):

(Scene: Onboard a magnificent pirate ship, right in the heart of the Caribbean Sea. Funny Pirate clashes with his parrot sidekick, Polly.)

Funny Pirate: "Arrr, Polly! How many times have I told ye not to nibble on me peg leg? That ain't no toothpick!"""

Polly: "Squawk! But your wooden leg tastes like sunflower seeds, captain!"

Funny Pirate: "Polly, are ye tellin' me ye prefer me leg over the sea of sunflower seeds I provides ye?"

Polly: "Squawk! Seed at sea sees to sink, sir!"

(Both laugh as the scene concludes, with the Caribbean Sea echoing their merriment.)

--------------------------------------------------------------------------------
Sara (to chat_manager):

(Scene: At a bustling carnival, Shy Girl finds herself in a heated debate with a stubborn, yet hilarious, cotton candy machine.)

Shy Girl: "Mr. Cotton Candy Machine, I've put in the right amount of money. Now, please give me my cotton candy."

Cotton Candy Machine: (In a robotic voice) "Insufficient funds. Please insert more coins."

Shy Girl: "But I've already put in enough! You're just being greedy now."

Cotton Candy Machine Bob : ARGGGHHH you'll never get ye cotten from meee.
``````.
In general, at 2023-10-28 03:03:31 a user named donjoh said ```By stroling around on youtube and found out in ai news```.
In general, at 2023-10-28 02:52:08 a user named yorth_night said ```The way they handle memory might be interesting to some```.
In general, at 2023-10-28 02:16:39 a user named sonichi said ```by default user proxy agent uses human-input or code execution to reply```.
In general, at 2023-10-28 01:56:41 a user named Lega said ```So basically the only point of having a user proxy is if I want to get involved in the conversation personally```.
In general, at 2023-10-28 01:55:50 a user named Lega said ```Oh wow. So I dont even need to implement a user proxy agent into the code If i want them to just have a conversation im assuming. Going to try that now. &  What does User proxy use by default then ? Open AI GPT ?```.
In general, at 2023-10-28 01:51:43 a user named sonichi said ```The user proxy doesn't use llm by default. In your case, you can replace the UserProxyAgent with AssistantAgent```.
In general, at 2023-10-28 01:50:05 a user named Lega said ```Hi i've been struggling to get User Proxy agent to just stop responding and just let the two Assitant Agents talk to each other. Its a test but its been frustrating me for 2 days. Heres their convo. Can somebody plz help --------------------------------------------------------------------------------
Bob (to chat_manager):

Bob: Ahoy, Sara! Ye be speakin' the truth, me matey. Celebratin' those small victories be key to buildin' confidence. Sara: And remember, even pirates need a crew to sail the high seas. 
--------------------------------------------------------------------------------

>>>>>>>> USING AUTO REPLY...
User_proxy (to chat_manager):



--------------------------------------------------------------------------------

>>>>>>>> USING AUTO REPLY...
User_proxy (to chat_manager):



--------------------------------------------------------------------------------
Sara (to chat_manager):

Hi there! It seems like there was a bit of a communication glitch. If you have any questions or if there's anything specific you'd like to discuss, feel free to let me know. I'm here to help!

--------------------------------------------------------------------------------

>>>>>>>> USING AUTO REPLY...
User_proxy (to chat_manager):```.
In general, at 2023-10-28 01:35:16 a user named fullstack6209 said ```no what is it about```.
In general, at 2023-10-28 00:28:19 a user named joshuamonkey said ```You have to use the web app to upload.```.
In general, at 2023-10-27 23:23:09 a user named xielvanic said ```Hello everyone! I hope that everyone is having a wonderful day!```.
In general, at 2023-10-27 23:22:54 a user named c_bonadio said ```To run remote you need to adjust the ApiPath to where your server is located, look at the console of the browser and network```.
In general, at 2023-10-27 23:11:50 a user named magic8437 said ```so it needs the llm_config```.
In general, at 2023-10-27 23:11:41 a user named magic8437 said ```i found out that the GroupChatManager itself is an agent```.
In general, at 2023-10-27 23:10:24 a user named jonny7377 said ```class GroupChatManager(ConversableAgent):
I don't know if it uses it but...```.
In general, at 2023-10-27 22:32:17 a user named sirgonzalot said ```A GUI to define, orchestrate and monitor agents doing work.```.
In general, at 2023-10-27 22:29:48 a user named sirgonzalot said ```Work at MSR - 🙂```.
In general, at 2023-10-27 22:24:56 a user named drinkoblog.weebly.com said ```i'm just gonna build off the backend anyway for my discord bot```.
In general, at 2023-10-27 22:24:16 a user named drinkoblog.weebly.com said ```also there seems to be some routing issue when using remote. console and netstat suggests it is listening, but nothing happens when i query.  i can port forward to make it seem like localhost and then it works.```.
In general, at 2023-10-27 22:16:50 a user named c_bonadio said ```I will add that, thanks```.
In general, at 2023-10-27 22:15:49 a user named drinkoblog.weebly.com said ```is what i was looking for cheers.  might be worth mentioning it requires npm v14 or greater```.
In general, at 2023-10-27 21:53:59 a user named c_bonadio said ```Autogen with FastApi backend and React frontend
https://github.com/bonadio/autogenwebdemo```.
In general, at 2023-10-27 21:05:27 a user named promptrotator said ```Hi everyone, I'm one of the cofounders of Operator.io. We're exploring ways that agents can interact with each other - is there a standard in autogen for allowing one hosted autogen agent to consume the output of another? Or a framework for something in this realm. Thank you!```.
In general, at 2023-10-27 20:53:37 a user named magic8437 said ```A quick question, whats the use of setting llm_config in the GroupChatManager? I believe we are setting the llm_config for each Agents

```manager = autogen.GroupChatManager(groupchat=group_chat, llm_config=gpt4_config)
user_proxy = autogen.AssistantAgent(name="Admin",llm_config=gpt4_config,....)``````.
In general, at 2023-10-27 20:45:36 a user named rickyloynd said ```Thank you @KNOX, we haven't tried TeachableAgent with functions. I'll make a note of that.```.
In general, at 2023-10-27 20:38:31 a user named myro.oasis said ```Update: i tested my 23 agent Autogen and it isn't clogging due to context or rate limit. plus there is definite increase in code quality after crossing 17-18 agents```.
In general, at 2023-10-27 20:36:52 a user named myro.oasis said ```GPT4 pricing is gonna be 20x discounted after Nov 6; according to reddit rumors (supported by Reuters article)```.
In general, at 2023-10-27 19:53:36 a user named aaronward_ said ```Coming from a traditional ML background, a lot of the concepts in the LLM space are alien to me. I thought i'd might as well share all my findings. The Discussion section in my general work repo contains bitesize posts from my learnings about different concepts in the generative AI space. https://github.com/AaronWard/generative-ai-workbook

In order for me to digest and understand a concept i usually have to write it down. Just thought it might come in handy some of you who are also starting off.```.
In general, at 2023-10-27 19:02:06 a user named knoxy_knox said ```@rickyloynd I am trying to use functions with teachableAgent.  But failing...... 
```
Let's test some functions! Try to call the test_function() function.

--------------------------------------------------------------------------------
Virgil (to teachableagent):

***** Suggested function Call: test_function *****
Arguments: 
{}
**************************************************

--------------------------------------------------------------------------------
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/knox/repos/emu-gpt-rpg/fceux_server/betabot.py", line 168, in <module>
    teachable_agent.initiate_chat(
  File "/home/knox/anaconda3/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py", line 531, in initiate_chat
    self.send(self.generate_init_message(**context), recipient, silent=silent)
  File "/home/knox/anaconda3/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py", line 334, in send
    recipient.receive(message, self, request_reply, silent)
  File "/home/knox/anaconda3/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py", line 464, in receive
    self.send(reply, sender, silent=silent)
  File "/home/knox/anaconda3/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py", line 334, in send
    recipient.receive(message, self, request_reply, silent)
  File "/home/knox/anaconda3/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py", line 462, in receive
    reply = self.generate_reply(messages=self.chat_messages[sender], sender=sender)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/knox/anaconda3/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py", line 781, in generate_reply
    final, reply = reply_func(self, messages=messages, sender=sender, config=reply_func_tuple["config"])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/knox/anaconda3/lib/python3.11/site-packages/autogen/agentchat/contrib/teachable_agent.py", line 113, in _generate_teachable_assistant_reply
    raise ValueError(
ValueError: TeachableAgent currently assumes that the message content is a simple string. This error serves to flag a test case for relaxing this assumption.

```
Thought you might want to see that error ^^```.
In general, at 2023-10-27 18:54:43 a user named yorth_night said ```I don't see the option with the plugin```.
In general, at 2023-10-27 18:54:30 a user named yorth_night said ```how do I link/upload the pdf in question?```.
In general, at 2023-10-27 18:36:32 a user named joshuamonkey said ```I've found AskYourPDF works very well, the web app or ChatGPT plugin.```.
In general, at 2023-10-27 18:35:17 a user named yorth_night said ```I'm looking for a certain info from a very large document```.
In general, at 2023-10-27 18:34:59 a user named yorth_night said ```does anyone know what's the best/easiest way to chat with pdfs currently?```.
In general, at 2023-10-27 17:27:33 a user named das_search said ```Function maps are what I was just researching last night I'd love if you'd read the project overview and maybe input a pull request that explains how Function maps could be used```.
In general, at 2023-10-27 17:23:30 a user named das_search said ```Tell me your thoughts on this please 
 
https://github.com/Nbtguyoriginal/Project-overlord```.
In general, at 2023-10-27 17:23:22 a user named c_bonadio said ```the function_map itself does not consume tokens but the function definition in llm_config does```.
In general, at 2023-10-27 16:44:31 a user named magic8437 said ```anyone knows if adding function maps to gpt will actually consume tokens?```.
In general, at 2023-10-27 16:44:00 a user named rickyloynd said ```TeachableAgent uses chromadb. It was developed in parallel with MemGPT without our knowing it. There's a lot of similarity and also differences that we are studying. And the MemGPT team has been working to integrate it into AutoGen. https://github.com/cpacker/MemGPT/discussions/65```.
In general, at 2023-10-27 16:36:21 a user named robin_saunders said ```someone ran into one yesterday that was a obvious one hahha```.
In general, at 2023-10-27 16:36:01 a user named robin_saunders said ```let me know if you run into bugs```.
In general, at 2023-10-27 16:35:45 a user named rahimny said ```ahh yeah i see can just ctrl click the package in vscode```.
In general, at 2023-10-27 16:34:35 a user named robin_saunders said ```you'll be able to figure it out 😄```.
In general, at 2023-10-27 16:34:30 a user named robin_saunders said ```idk how you're set up, just find the files where you installed them and modify.```.
In general, at 2023-10-27 16:34:07 a user named rahimny said ```im just installing pyautogen with pip atm```.
In general, at 2023-10-27 16:33:54 a user named rahimny said ```How can i get those changes into my pyautogen package? Sorry more of a js dev aha```.
In general, at 2023-10-27 16:33:43 a user named robin_saunders said ```Share with me the results 😄```.
In general, at 2023-10-27 16:33:11 a user named firethepersonwhoimplementedthis said ```I'll try it out actually and see how it goes```.
In general, at 2023-10-27 16:32:56 a user named robin_saunders said ```grab the latest update from yesterday```.
In general, at 2023-10-27 16:32:46 a user named robin_saunders said ```dont use the first one where just /r/n is cleaned lkol```.
In general, at 2023-10-27 16:32:20 a user named robin_saunders said ```the repo attached has the updated files```.
In general, at 2023-10-27 16:31:39 a user named robin_saunders said ```i add a bunch of code fence sterilization.```.
In general, at 2023-10-27 16:31:13 a user named robin_saunders said ```@rahimny check my latest commits to this: https://github.com/microsoft/autogen/pull/399```.
In general, at 2023-10-27 16:31:11 a user named rahimny said ```any recommendations for local coding models?```.
In general, at 2023-10-27 16:31:05 a user named firethepersonwhoimplementedthis said ```Huh, you gave me an idea```.
In general, at 2023-10-27 16:30:25 a user named rahimny said ```yeah i think so, or it gets stuck in an infinite loop```.
In general, at 2023-10-27 16:30:15 a user named robin_saunders said ```like
'''python 
blah blah
''' 

then it fails```.
In general, at 2023-10-27 16:30:09 a user named rahimny said ```oh right, i've tried code llama 7b and mistral instruct v0 1```.
In general, at 2023-10-27 16:30:04 a user named robin_saunders said ```@rahim is it giving you code and then it fails?```.
In general, at 2023-10-27 16:29:55 a user named robin_saunders said ```we haven't seen autogen fine tuned models yet either```.
In general, at 2023-10-27 16:29:35 a user named firethepersonwhoimplementedthis said ```Yeah I had that issue when using a local LLM that wasn't properly trained```.
In general, at 2023-10-27 16:29:08 a user named robin_saunders said ```@rahimny thats becuase there is a empty string being outputted```.
In general, at 2023-10-27 16:28:38 a user named robin_saunders said ```there's another issue raised talking about how the manager doesn't get a system message to direct which bot gets what```.
In general, at 2023-10-27 16:28:33 a user named rahimny said ```anyone know if there's a solution to this bug? https://github.com/microsoft/autogen/issues/279```.
In general, at 2023-10-27 16:28:18 a user named robin_saunders said ```issue #399 i sterilized outputs a bit since some models were doing some weird outputs```.
In general, at 2023-10-27 16:28:07 a user named firethepersonwhoimplementedthis said ```I haven't tried the codellama ones```.
In general, at 2023-10-27 16:27:49 a user named firethepersonwhoimplementedthis said ```Having a local model for coding seems smart```.
In general, at 2023-10-27 16:27:48 a user named robin_saunders said ```the Local LLM stuff is fresh, so its still maturing```.
In general, at 2023-10-27 16:27:13 a user named robin_saunders said ```but the LLM takes some custom configuration```.
In general, at 2023-10-27 16:27:06 a user named robin_saunders said ```I've been playing around, right now im using phind codellama v2```.
In general, at 2023-10-27 16:26:57 a user named firethepersonwhoimplementedthis said ```I haven't gotten good luck with them in here```.
In general, at 2023-10-27 16:26:42 a user named firethepersonwhoimplementedthis said ```What model are you using for this?```.
In general, at 2023-10-27 16:25:29 a user named robin_saunders said ```Not willing to hire someone?```.
In general, at 2023-10-27 16:14:27 a user named firethepersonwhoimplementedthis said ```Be prepared for high API costs as this is still being developed```.
In general, at 2023-10-27 16:00:56 a user named .cannaboss said ```I'd like to use this to help my "short staffed" software development team get a head start on development and to help speed up their processes.```.
In general, at 2023-10-27 15:59:32 a user named .cannaboss said ```I watched a video on youtube and thought I'd give this a shot.```.
In general, at 2023-10-27 14:31:54 a user named myro.oasis said ```someone needs to create a For Dummies series for Autogen 😆```.
In general, at 2023-10-27 14:17:13 a user named frank.martinez said ```@biggboii. helped me wrap head around using diff open LLMs per agent; to optimize task efficiency; which is not unlike how a [human] product team works```.
In general, at 2023-10-27 14:00:17 a user named 0xjamp said ```Just excited to set it up on docker today and play around with different models locally and try out the new teachable agent```.
In general, at 2023-10-27 13:59:08 a user named 0xjamp said ```More like what I missed lol. Just haven't been here in a couple weeks and already see all the progress```.
In general, at 2023-10-27 13:50:38 a user named myro.oasis said ```what happened? what did i miss```.
In general, at 2023-10-27 13:49:57 a user named myro.oasis said ```okayy yes. just to clarify, you are saying that multiple agents will have to fit in the same context window and the output of each will be complex and eventually fail to reach the goal?```.
In general, at 2023-10-27 13:48:56 a user named 0xjamp said ```Autogen is maturing fast! It's amazing to see!```.
In general, at 2023-10-27 12:40:21 a user named firethepersonwhoimplementedthis said ```There's a massive overhaul on the openai lib once they push out of beta```.
In general, at 2023-10-27 12:18:32 a user named magic8437 said ```what does this means ? "🔥 Heads-up: pyautogen v0.2 will switch to using openai v1."```.
In general, at 2023-10-27 12:18:21 a user named loschess said ```I thought we could define each agent with its own LLM 🤔```.
In general, at 2023-10-27 10:38:34 a user named rahimny said ```Is a npm package in the plans ?```.
In general, at nan a user named adriangalilea said ```Hello guys,

Just noticed the teachable agent update, seems promising, felt it was missing after seeing memGPT, is teachable agent taking inspiration from memGPT?

I was also wondering after seeing the python notebook, I think it would be very valuable to explore this teachings, both as they are being written(verbose) and be able to inspect this even when it's not running...

What vector DB is it using?
How can I manually explore it's contents?

(haven't tried locally yet, just checked the python notebook)```.
In general, at 2023-10-27 09:53:44 a user named morfes said ```https://youtu.be/nszcPNhYRzI```.
In general, at 2023-10-27 09:28:07 a user named das_search said ```The more agents you use the bigger the overall all context window needs to stretch
In autogens current implementation 
Depending on your configuration your only using 1 api key from open ai 
Wich means regardless of instruction all context into the same model is outputed by that model 

The issue comes when you have 10 plus sufficiently advanced roles that all do their job well or even 5-6 roles that all return information with an advanced project goal 

Simple instructions "baloon" into extremes sets of responses thus
Either breaking the model's context of forcing rate limit checks based on return content output hitting token limit -- 
Suggestions revise your project to include multiple optional fallback endpoints 
And limit the amount of junk roles in places of well defined roles with specific attributes 
-hope this helps 
-I love autogen tbh 😆```.
In general, at 2023-10-27 06:52:35 a user named myro.oasis said ```I haven't tested this on GPT4 though.```.
In general, at 2023-10-27 06:51:40 a user named myro.oasis said ```Has anyone observed significant improvement in intent understanding and code accuracy beyond a threshold of agent count? I'm using 3.5-turbo and it seems like after 20+ agents, the autogen output starts exceeding the limitations of the LLM.```.
In general, at 2023-10-27 06:06:15 a user named _drewzy said ```I got this error when I hit the rate limit that openai defaults to```.
In general, at 2023-10-27 05:21:40 a user named juan_92164 said ```hi ther,  what is the easiest way to show only the final output? I dont want to show all the conversations. Is it possible?```.
In general, at 2023-10-27 04:17:13 a user named drinkoblog.weebly.com said ```having more luck with petals StableBeluga2, as it has 4096 tokens```.
In general, at 2023-10-27 03:55:30 a user named leecig said ```no idea what causes it, sorry```.
In general, at 2023-10-27 03:55:17 a user named leecig said ```I've ran into that before. I think I just changed models lol```.
In general, at 2023-10-27 03:52:19 a user named sirlimby said ```seems like the openai package is having some problems```.
In general, at 2023-10-27 03:52:08 a user named sirlimby said ``````  File "D:\Dev\_PYTHON\sample1\.venv\Lib\site-packages\openai\api_requestor.py", line 710, in _interpret_response
    self._interpret_response_line(
  File "D:\Dev\_PYTHON\sample1\.venv\Lib\site-packages\openai\api_requestor.py", line 775, in _interpret_response_line
    raise self.handle_error_response(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Dev\_PYTHON\sample1\.venv\Lib\site-packages\openai\api_requestor.py", line 428, in handle_error_response
    error_code=error_data.get("code"),
               ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'``````.
In general, at 2023-10-27 03:48:31 a user named drinkoblog.weebly.com said ```so probably not good enough for anything serious```.
In general, at 2023-10-27 03:48:13 a user named drinkoblog.weebly.com said ```only issue with petals llama 70b is it appears to be limited to 2048 tokens```.
In general, at 2023-10-27 03:47:12 a user named sirlimby said ```how do you configure lmstudio to use GPU VRAM?```.
In general, at 2023-10-27 03:47:06 a user named leecig said ```hmm... Seems I don't fully understand petals then! 😄```.
In general, at 2023-10-27 03:46:43 a user named drinkoblog.weebly.com said ```the petals network seems to only distribute the inference, not the model downloading```.
In general, at 2023-10-27 03:46:22 a user named leecig said ```but... I thought the models were being hosted and ran by petals lol```.
In general, at 2023-10-27 03:44:58 a user named drinkoblog.weebly.com said ```hf api is just used to download the models```.
In general, at 2023-10-27 03:44:45 a user named leecig said ```how does the HF API come into play?```.
In general, at 2023-10-27 03:44:13 a user named drinkoblog.weebly.com said ```yes. it basically looks like openai api, only makes use of the petals network```.
In general, at 2023-10-27 03:43:48 a user named leecig said ```so you're running that command on a linux box to act as the API server? Then pointing your autogen script towards it? The linux box relays back and forth between the script and petals?```.
In general, at 2023-10-27 03:43:01 a user named leecig said ```I'm about lost now lol```.
In general, at 2023-10-27 03:42:56 a user named leecig said ```I'm gonna have to get myself familiar```.
In general, at 2023-10-27 03:41:47 a user named drinkoblog.weebly.com said ```so the only instructions you need to modify is the server.py cmd. mine looks like this:
`python server.py --api --listen --loader petals --model meta-llama/Llama-2-70b-chat-hf --settings settings-colab-template.json --extensions listen api openai`
the important part is the last argument```.
In general, at 2023-10-27 03:40:37 a user named drinkoblog.weebly.com said ```i adapted it to run on-prem on a low spec linux pc```.
In general, at 2023-10-27 03:40:17 a user named drinkoblog.weebly.com said ```you can download and upload to kaggle for 30 hours a week```.
In general, at 2023-10-27 03:40:16 a user named leecig said ```Do you get charged for using HF API? I can't remember```.
In general, at 2023-10-27 03:40:07 a user named drinkoblog.weebly.com said ```except when i ran it in google colab i ran out of free credit in like < 1 hour```.
In general, at 2023-10-27 03:39:45 a user named drinkoblog.weebly.com said ```thats what i started with```.
In general, at 2023-10-27 03:39:41 a user named drinkoblog.weebly.com said ```yeah thats the notebook i was looking for```.
In general, at 2023-10-27 03:39:11 a user named leecig said ```https://colab.research.google.com/drive/1TebwE_67THh17rmpDWAURVudI3iRryya?usp=sharing#scrollTo=94OvvLa5lfx0```.
In general, at 2023-10-27 03:37:29 a user named sirlimby said ```but it still can't figure out the year to date gain problem for  META and TSLA but ultimately can't write the correct python code and bombs out```.
In general, at 2023-10-27 03:36:11 a user named leecig said ```Would you mind sharing the sauce @drinkoblog.weebly.com ?```.
In general, at 2023-10-27 03:35:59 a user named sirlimby said ```@drinko seems to be getting further with the gpt-3.5.-turbo " model"```.
In general, at 2023-10-27 03:35:38 a user named drinkoblog.weebly.com said ```so i just scored myself some free 70b for my autogen```.
In general, at 2023-10-27 03:35:28 a user named drinkoblog.weebly.com said ```but i did just figure out how to expose petals as an openai endpoint using text-gen-webui```.
In general, at 2023-10-27 03:35:25 a user named leecig said ```Explain Like I'm 5
It's a reddit term```.
In general, at 2023-10-27 03:35:08 a user named drinkoblog.weebly.com said ```i dont know what an ELI5 is```.
In general, at 2023-10-27 03:30:18 a user named leecig said ```any chance one of you have a quick TL;DR ELI5 for this?```.
In general, at 2023-10-27 03:28:40 a user named drinkoblog.weebly.com said ```I output stdout/err to a log file...
`~/text-generation-webui$ grep "tokens per second" text-generation-webui.log  | egrep -v "(sample|prompt)" | tail -4
llama_print_timings:        eval time =  6017.65 ms /     6 runs   ( 1002.94 ms per token,     1.00 tokens per second)
llama_print_timings:        eval time = 21050.70 ms /    21 runs   ( 1002.41 ms per token,     1.00 tokens per second)
llama_print_timings:        eval time = 363469.07 ms /   355 runs   ( 1023.86 ms per token,     0.98 tokens per second)
llama_print_timings:        eval time = 380954.74 ms /   371 runs   ( 1026.83 ms per token,     0.97 tokens per second)````.
In general, at 2023-10-27 03:26:53 a user named drinkoblog.weebly.com said ```text-generation-webui outputs on the console```.
In general, at 2023-10-27 03:26:44 a user named sirlimby said ```how to get the tok/sec metric?```.
In general, at 2023-10-27 03:26:28 a user named drinkoblog.weebly.com said ```because most of the work is on the CPU```.
In general, at 2023-10-27 03:26:15 a user named drinkoblog.weebly.com said ```typically i get about 1 tok/sec using 70B quantised 5 bit models on my 5950x with 64 GB RAM and 3080 ti (12 GB VRAM)```.
In general, at 2023-10-27 03:25:39 a user named leecig said ```afaik, the lower the number, the easier it is on resources, but I'm not sure what that does to performance though```.
In general, at 2023-10-27 03:25:23 a user named leecig said ```I still gotta get a handle on what the quantized numbers mean in terms of performance and resource usage```.
In general, at 2023-10-27 03:24:34 a user named leecig said ```I was actually about to move from my work laptop to one of my servers tonight, just to compare```.
In general, at 2023-10-27 03:24:08 a user named leecig said ```The DDR4 should be able to make up for it though. I've just been using my work laptop since the GPU in it does pretty well enough for learning```.
In general, at 2023-10-27 03:23:34 a user named drinkoblog.weebly.com said ```i wish i had that much ram```.
In general, at 2023-10-27 03:23:23 a user named leecig said ```Damn how often you upgrade lol. I guess I can't say much though, I've got two ProLiant Gen9s in a rack each with 40 vCPU and 320GB RAM 👀 lolol```.
In general, at 2023-10-27 03:22:36 a user named drinkoblog.weebly.com said ```old gaming pcs make for decent llm rigs```.
In general, at 2023-10-27 03:21:55 a user named leecig said ```missed the different IPs, my bad```.
In general, at 2023-10-27 03:21:38 a user named drinkoblog.weebly.com said ```i have half a dozen servers. so they arent the same```.
In general, at 2023-10-27 03:21:21 a user named leecig said ```So far, I've seen you should enter a 'dummy' API, so idk. If you're pointing to the same IP:Port every time, you only need one entry in the array. The "model" key isn't necessary I don't think. Now, if you had multiple models running on say, port 5000 for model A, 5001 for model B, etc etc, then yea, you would need more than one entry in the array```.
In general, at 2023-10-27 03:20:39 a user named drinkoblog.weebly.com said ```although if you configure it as gpt-3.5-turbo then that should be 16k```.
In general, at 2023-10-27 03:20:02 a user named drinkoblog.weebly.com said ```presumably your model needs to support it. then you gotta find the code in autogen thats limiting it```.
In general, at 2023-10-27 03:19:56 a user named sirlimby said ```I'm using the model and loader ExLlama_HF```.
In general, at 2023-10-27 03:19:16 a user named sirlimby said ```@drinko how do I increase the context length?```.
In general, at 2023-10-27 03:18:47 a user named drinkoblog.weebly.com said ```(the api_key is probably unnecessary)```.
In general, at 2023-10-27 03:18:05 a user named drinkoblog.weebly.com said ```my OAI_CONFIG_LIST looks like this:
```
[ { "model": "gpt-4", "api_base": "http://10.0.0.33:5001/v1", "api_key": "sk-11111111111111111", 
"api_type": "open_ai" }, { "model": "gpt-3.5-turbo", "api_base": "http://10.0.0.32:5001/v1", "api_key": "sk-11111111111111111", "api_type": "open_ai" }, { "model": "gpt-3.5", "api_base": "http://10.0.0.31:5001/v1", "api_key": "sk-11111111111111111", "api_type": "open_ai" } ]
``````.
In general, at 2023-10-27 03:17:20 a user named leecig said ```I'm sure it works. I just like LMStudio more, personally. It's easier for me```.
In general, at 2023-10-27 03:16:48 a user named drinkoblog.weebly.com said ```i am using autogen with text-generation-webui (with openai extension on :5001/v1). a lot of ppl are doing it this way```.
In general, at 2023-10-27 03:15:56 a user named leecig said ```^^
Yea afaik it uses GPU```.
In general, at 2023-10-27 03:15:26 a user named sirlimby said ```@leecig Can you get it to use nvidia card vram? I've been doing GPTQ models on text-gen-webui because it's fast on my 3080 rtx```.
In general, at 2023-10-27 03:14:19 a user named leecig said ```text-gen-webui confused the hell outta me lol```.
In general, at 2023-10-27 03:14:05 a user named leecig said ```I would just suggest switching to LMStudio to be honest.. I do like it a lot better```.
In general, at 2023-10-27 03:13:16 a user named leecig said ```Wait, are you running LMStudio?```.
In general, at 2023-10-27 03:13:04 a user named sirlimby said ```I need to find the context length setting but I don't see it```.
In general, at 2023-10-27 03:12:10 a user named sirlimby said ```that's the model loader I'm using```.
In general, at 2023-10-27 03:11:57 a user named leecig said ```Not sure if any of that helps```.
In general, at 2023-10-27 03:11:29 a user named leecig said ```and here is my current llm_config:
```config_list = [
    {
        "api_type": "open_ai",
        "api_base": "http://127.0.0.1:12355/v1",
        "api_key": "NULL"
    }
]

llm_config={
    "request_timeout": 600,
    "seed": 6,
    "max_tokens": -1,
    "config_list": config_list,
    "temperature": 0
}``````.
In general, at 2023-10-27 03:10:57 a user named leecig said ```Did you adjust any of these settings?```.
In general, at 2023-10-27 03:08:13 a user named sirlimby said ```yes I basically ran the agentchat_auto_feedback_from_code_execution.ipynb but moved it into a python project and used vs code and updated the llm_config. i ran into an error "openai.error.InvalidRequestError: This model maximum context length is 2048 tokens. However, your messages resulted in over 2060 
tokens." using mistral and in this case it was text-generation-webui with the openai api setting enabled on port 5000```.
In general, at 2023-10-27 03:06:39 a user named leecig said ```ATM I'm working on finding the right combo of agents, plus which model to apply to which agent.```.
In general, at 2023-10-27 03:05:34 a user named leecig said ```Did you get stuck somewhere? Matthew's video someone linked you too is pretty good```.
In general, at 2023-10-27 03:05:17 a user named leecig said ```Makes it so you can run a drop in replacement for OpenAI API calls```.
In general, at 2023-10-27 03:04:58 a user named leecig said ```Yea, LMStudio really does make it so, so, so easy to do so```.
In general, at 2023-10-27 03:04:50 a user named sirlimby said ```I am watching the advanced video. on the earlier ones, I ran into some issues and it did not complete the workbooks like gpt4 did```.
In general, at 2023-10-27 03:04:26 a user named sirlimby said ```@leecig  Curious if you got a local LLM working well with it```.
In general, at 2023-10-27 03:02:24 a user named leecig said ```Nice. I'm just learning as much as interests me about the latest and greatest in LLMs, but also using it to write code to automate anything I can in relation to my eBay store```.
In general, at 2023-10-27 03:01:11 a user named jql said ```@leecig  i  am  working a company which want to build a agent using the llms to qa  in sale area ,but the chatbot usually answer a wrong question.so i want to integrate a kb to it.but the building and format of the kb is not clear. what's about you?```.
In general, at 2023-10-27 02:55:07 a user named leecig said ```May I ask what you're working on?```.
In general, at 2023-10-27 02:49:19 a user named leecig said ```Thanks man. Just trying to pay it forward. Sometimes I have a good mood lol (rare 😦 ) Hope your kb turns out well!```.
In general, at 2023-10-27 02:48:18 a user named jql said ```@leecig your suggestions are very helpful,the knowledge of  kb could  come from a raw text or a local file or a web scraper or a knowledge host i build.very different format.```.
In general, at 2023-10-27 02:45:00 a user named leecig said ```https://tenor.com/view/obi-wan-kenobi-the-clone-wars-star-wars-more-than-one-way-to-skin-a-womp-rat-gif-16052734```.
In general, at 2023-10-27 02:44:31 a user named leecig said ```If not, you could host it on github and point it to the raw text page?```.
In general, at 2023-10-27 02:43:56 a user named leecig said ```I'm not entirely sure if you can point it to a local file, or if it has to be a URL. Perhaps you could import os, read it to a variable, then point it to the variable? Not sure, but I bet it's in the docs.

I guess your question was about *building* the knowledgebase though... I would say it depends on what your standards are. You could always build a web scraper, then scrape websites that are up to your standards? (Provided you can point it at a local source, which I would have to guess you can...surely...)```.
In general, at 2023-10-27 02:41:09 a user named jql said ```another a question,how to build useful  and flexable knowledge base  if i want to build a  chatbot in  particular area,  the knowledge base using which knowledge representation?```.
In general, at 2023-10-27 02:36:31 a user named leecig said ```Bumping this. Seems likely there's a standard python command or function to do this, but I'm just ignorant for now.```.
In general, at 2023-10-27 02:30:15 a user named leecig said ```Another question easily answered by a Matthew Berman video. The guy is an amazing wealth of info, and pretty damn good at making vids. Try this. I ***think*** it might be what you're looking for? Starts at the timestamp for your convienence!

https://youtu.be/PUPO2tTyPOo?si=nN2kyOtI8JDPXVy1&t=1281```.
In general, at 2023-10-27 02:21:36 a user named jql said ```how to  integrate knowledge base to autogen ?```.
In general, at 2023-10-27 01:54:41 a user named jb_5579 said ```https://youtu.be/10FCv-gCKug?si=JO0uh0P7OQSksIIx```.
In general, at 2023-10-27 01:34:03 a user named sirlimby said ```I'm curious if autogen can be used effectively with tools like text-generation-webui and models like llama or mistral. Are there decent tutorials on this?```.
In general, at 2023-10-27 00:17:23 a user named promptrotator said ```How fast is autogen? I've had huge performance issues with langchain, so cautious about another project similar to it```.
In general, at 2023-10-26 23:22:31 a user named anxietyprime. said ```I'm messing around with autogen and memgpt, and I'm finding that for some reason memgpt is significantly worse at writing code than default agents using the same prompt. Is there anything I can do to get it closer to original performance?```.
In general, at 2023-10-26 23:05:47 a user named _kushmonster said ```Hey everyone, I am just here to try and soak up some knowledge don't mind me 🤙🏻```.
In general, at 2023-10-26 22:57:36 a user named outofpaper. said ```I've come here from Github. How many people are using this with local models on M1 hardware?```.
In general, at 2023-10-26 22:25:01 a user named karlka said ```Autogen is so expensive for its```.
In general, at 2023-10-26 21:58:03 a user named karlka said ```That is my fear. Autogen + GPT-4 = big```.
In general, at 2023-10-26 21:52:41 a user named joe_ai said ```Do you by any chance have links to the others? thank you```.
In general, at 2023-10-26 21:35:01 a user named afourney said ```There are a few. Here's one: https://www.agentcloud.dev```.
In general, at 2023-10-26 21:33:57 a user named joe_ai said ```Hello 👋, are there any frontends that have been built for deploying agents with AutoGen? Similar to https://godmode.space/ built for AutoGPT.```.
In general, at 2023-10-26 21:12:45 a user named afourney said ```Better still is to use Docker```.
In general, at 2023-10-26 21:12:09 a user named afourney said ```It's nice to be able to just blow away and recreate the venv when things go crazy 😉```.
In general, at 2023-10-26 21:11:10 a user named afourney said ```100% use a venv.  This is especially important because autogen is going to want to install all sorts of dependencies as it writes code... and you probably don't want it messing up your general python environment.```.
In general, at 2023-10-26 21:00:57 a user named ibrahim_aka_ajax said ```Try running the code in virtual environment:
$ python3 -m venv venv
$ source venv/bin/activate
(venv) $```.
In general, at 2023-10-26 19:58:00 a user named leecig said ```Can the output of autogen be piped into a webhook somehow?```.
In general, at 2023-10-26 19:17:16 a user named aaronward_ said ```did you make sure to pip install `pyautogen` and not `autogen`?```.
In general, at 2023-10-26 19:16:19 a user named danober said ```Hello I'm trying to run AutoGen, so I installed Python and VIsual Studio Code, but I can't get the simplest examples to work.  Can anybody figure out what I'm doing wrong?  Here is a screenshot:```.
In general, at 2023-10-26 18:02:10 a user named rahimny said ```I'm not sure it sent? would you be able link it please```.
In general, at 2023-10-26 17:59:18 a user named bobaleaux said ```this thread might help. I used the example and it worked well for me to use as a start.```.
In general, at 2023-10-26 17:54:34 a user named rahimny said ```Hi there! Does anyone have any recommendations on how I can integrate autogen with a custom dataset? Say I have some local JSON data that i want my app to be able to understand as well as perform functions on ? I'm aware of things like LangChain but not sure how easy it is to integrate with autogen.Thanks 🙂```.
In general, at 2023-10-26 17:47:19 a user named Paulofi said ```Hey if anyone is looking to join a startup that is utilizing AutoGen, XAgent, SPR and memGPT hmu let's chat```.
In general, at 2023-10-26 17:45:17 a user named .spcell said ```[ERROR] Error: Input length 1508 exceeds context length 1500

I got this error in LM Studio. In VS Code I get this error when using MathChat:

AttributeError: 'str' object has no attribute 'get'

It tried to solve my problem and eventually gave me these errors```.
In general, at 2023-10-26 17:17:34 a user named frank.martinez said ```https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/```.
In general, at 2023-10-26 16:51:01 a user named myro.oasis said ```where can i find the documentation for autogen?```.
In general, at 2023-10-26 15:59:54 a user named tony87pisa said ```Is there a guide for those who don't understand anything about Python to start the program?^^```.
In general, at 2023-10-26 15:41:03 a user named Belmundo said ```Hey there! heard about Autogen from Youtube, can’t wait to build cool things with it```.
In general, at 2023-10-26 13:20:52 a user named .moogin said ```What is this Autogen foo```.
In general, at 2023-10-26 10:28:24 a user named scrungle.tech said ```Hey I'm a prompt engineering/ai engineering consultant and the co-founder of http://sophiaintelligence.ai, an AGI alignment lab. I have a PhD in interpretable representation & classifier learning, and I've recently closed up a consultancy job where we used autogen for the final AI pipeline. It worked great!```.
In general, at 2023-10-26 07:32:08 a user named hansel0111 said ```Just find it on Github.```.
In general, at 2023-10-26 06:38:57 a user named afourney said ```Yes. Very often in the last 48 hours.```.
In general, at 2023-10-26 06:37:44 a user named afourney said ```This is almost certainly because the user_proxy doesn't have a system prompt. See here for details: https://github.com/microsoft/autogen/issues/318```.
In general, at 2023-10-26 05:02:03 a user named li_jiang said ```I don't know how to fix this, but it doesn't look like an issue caused by AutoGen code. You may want to search for the "local LLM" and see if there is already a solution for you in other threads/channels. Many people have discussed local LLM.```.
In general, at 2023-10-26 04:54:03 a user named harmonyzen1717 said ```I heard about it on YouTube```.
In general, at 2023-10-26 04:49:05 a user named albo.disco said ```Just find it on Github. Just hear in twitter about AutoGen```.
In general, at 2023-10-26 03:42:29 a user named elcapitan__ said ```Anyone in the Philadelphia area trying to link up for some autogen discussions. I’m looking for like minded individuals to build with.```.
In general, at 2023-10-26 03:10:16 a user named elcapitan__ said ```https://github.com/BradyFU/Woodpecker```.
In general, at 2023-10-26 03:08:49 a user named elcapitan__ said ```https://cointelegraph.com/news/researchers-china-developed-hallucination-correction-ai-models?fbclid=IwAR1ctcGybdWDFbZjtb6x92YmH-3U5mLQ7vxGCC03aO3yb9ehj6LcdMWacqU_aem_AWG2YOArQ6S_ZTbJYDl5WXLytUES-BRWypLKuS5SfcP9mZvIe5SejWUhQ80_BDrykZo```.
In general, at 2023-10-26 02:20:52 a user named solononforever said ```Just using aider for a hello world todo app, and the cost was $1. I would end up spending $20+ a day using it for all my projects... these tools really aren't for broke students :/```.
In general, at 2023-10-26 02:20:17 a user named solononforever said ```Are people using autogen as code gen tools, if so - how much are yall spending?```.
In general, at 2023-10-26 01:19:41 a user named .spcell said ```@li_jiang there is a final problem that persists though. I have only 2 GB VRAM and my computer starts literally yelling and it will probably take forever to complete the task, so I want to use Google Colab. However, Matthew Berman used Runpod as API endpoint while I used Gradio link from text generator webui Colab where Mistral 7B was hosted and in result I got this error:

openai.error.APIError: Invalid response object from API: '{"detail":"Not Found"}' (HTTP response code was 404)```.
In general, at 2023-10-26 01:16:12 a user named li_jiang said ```Congratulations @.spcell . Enjoy AutoGen!```.
In general, at 2023-10-26 01:10:08 a user named .spcell said ```I did it. I replaced "message" with "problem" and it worked```.
In general, at 2023-10-26 01:06:25 a user named sidhujag said ```Hey man, how does e2b handle code package imports like in python requiring pip install etc? In lambda requires to install within zip package```.
In general, at 2023-10-26 01:11:18 a user named mlejva said ```hey @sidhujag, you can install packages dynamically during runtime with e2b

You can have for example ask LLM to list all needed packages and if any of them aren't installed, you can install them on fly

https://e2b.dev/blog/build-ai-data-analyst-with-langchain-and-e2b```.
In general, at 2023-10-26 01:26:05 a user named sidhujag said ```Ah nice! So then LLM can give list of packages and the exec code function can make this call to install prior to running the code```.
In general, at 2023-10-26 01:26:54 a user named sidhujag said ```How can you distinguish system vs python packages ?```.
In general, at 2023-10-26 01:30:46 a user named sidhujag said ```How do you also envision many users to work within context of each convo (multi agents) so many users will invoke their own sandbox within each convo as agents spin up? Would you run one sandbox and isolate users by workspace? Does one sandbox run for every code invocation?```.
In general, at 2023-10-26 01:32:20 a user named sidhujag said ```Lastly in our lambda code we get stats based on function for time fn was run and fn is associated to a user so we can track user runtime stats for costs, how can you track usage per fn or workspace to track user costs which would interface with a front end?```.
In general, at 2023-10-26 01:43:56 a user named mlejva said ```> Ah nice! So then LLM can give list of packages and the exec code function can make this call to install prior to running the code
Yes, that's one way to do it.

> How can you distinguish system vs python packages ?
System packages are packages you would install via `apt`. Most of the time, you won't need it. The Python packages are installed using `pip`. We leave it up to the users to decide which package they want to install.```.
In general, at 2023-10-26 01:46:43 a user named mlejva said ```> How do you also envision many users to work within context of each convo (multi agents) so many users will invoke their own sandbox within each convo as agents spin up? Would you run one sandbox and isolate users by workspace? Does one sandbox run for every code invocation?

You (the developer) control the sandbox creation and lifecycle. Generally speaking, you start separate sandbox for each session. It really depends what exactly you need. We've had users who just start the sandbox, run the code and then close the sandbox. Other users have a global sandbox manager that keeps a track of long-running sandboxes/sessions and to which user each session belongs```.
In general, at 2023-10-26 01:47:03 a user named mlejva said ```Feel free to join our Discord. The whole E2B team can help you there 🙂```.
In general, at 2023-10-26 01:48:03 a user named mlejva said ```> Lastly in our lambda code we get stats based on function for time fn was run and fn is associated to a user so we can track user runtime stats for costs, how can you track usage per fn or workspace to track user costs which would interface with a front end?

I think I'm a bit confused here. Can you please expand on what functions are you tracking? The openai calls?```.
In general, at 2023-10-26 04:14:54 a user named mlejva said ```let me know if this helps @sidhujag 🙂```.
In general, at 2023-10-26 00:55:18 a user named li_jiang said ```Hi @.spcell , I'll leave it to you to find  the actual code change needed. Here is the hint: follow the example notebook https://github.com/microsoft/autogen/blob/main/notebook/agentchat_MathChat.ipynb , compare the code differences between yours and those in the notebook. If you do it carefully, I believe you can solve it. You just need to replace another word to solve this issue.```.
In general, at 2023-10-25 22:50:14 a user named impactcare said ```I'm reaching new technologies and attemping to get this to work. Starting a software company to provide Health and Human Service organizations tools to remove manual data entry from their workflows, to free of their time to provide care.```.
In general, at 2023-10-25 21:44:42 a user named c_bonadio said ```Hi this is not related to autogen, but it is a really nice simple course on LangChain from Deeplearning.ai
https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/```.
In general, at 2023-10-25 21:14:16 a user named qingyunwu said ```Cool! Thank you Vasek for reaching out! This definitely looks interesting and useful. My understanding is that E2B could be used as a code execution tool that allows running code in a sandboxed environment? Is this understanding correct? If so, my first impression is that an integration should be doable by revising the generate_code_execution_reply https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L611 If it is clear to you how the integration shall be done, you can proceed with the integration (together with a notebook demonstration as well I guess) by making a pull request, the AutoGen team will review it in time. We can write a blogpost about this integration as well. cc-ing Chi here for his information @sonichi```.
In general, at 2023-10-26 01:18:38 a user named mlejva said ```hey! Yes, your understanding of how E2B can be used is correct. 

> if so, my first impression is that an integration should be doable by revising the generate_code_execution_reply 
sounds good! I'll explore it this or next week and make an example notebook and share it with you.

> We can write a blogpost about this integration 
Neat! We're happy to do a blog post as well```.
In general, at 2023-10-25 20:56:27 a user named mlejva said ```Hey everyone, my name is Vasek, I'm a co-founder of https://e2b.dev. We're building cloud sandboxes for LLM apps.
I was wondering if there's an official way for adding integrations to AutoGen? We just added our Data Analysis Sandbox to LangChain (https://twitter.com/mlejva/status/1717247138588250500) and I'd love to explore if there's any way we could integrate with AutoGen.

Maybe cc @li_jiang or @qingyunwu```.
In general, at 2023-10-25 20:04:01 a user named fran.abenza said ```link to edit the chart provided in here: https://chat.openai.com/share/ab000ddc-1acc-463e-91a2-f94bde0d28ab```.
In general, at 2023-10-25 20:02:01 a user named fran.abenza said ```⚠️ this flowchart was autogenerated. Does it depict well how the Retrieval-Augmented User Proxy & Retrieval-Augmented Assistant work together?```.
In general, at 2023-10-25 19:40:50 a user named jannis3643 said ```You'll need to use the API, both gpt3.5 and 4 are available but none of them is for free via the API.```.
In general, at 2023-10-25 19:21:07 a user named Manly Lubbin said ```If only there was some sort of....search function in discord....or some channel here that might contain this information```.
In general, at 2023-10-25 18:43:40 a user named pierrunoyt said ```when can we expect a webui```.
In general, at 2023-10-25 18:30:40 a user named .godforce said ```hello everyone, quick question please: does autogen work only with chatgpt4 or I can use the free 3.5? thank you```.
In general, at 2023-10-25 18:12:17 a user named frank.martinez said ```Given the complexity and size of developing a full-scale application with both a front-end and back-end, unfortunately, it's not possible to provide a full Python code block to create such an application here. However, for a start, I'll suggest a simplified script that will simulate a part of the proposed app. This code will walk the user through a series of prompts to gather the input needed to fill out the health coverage application and validate some entries. 

Please note that the building of a whole application needs more configuration, an appropriate environment, and tools like a web development framework (Python Flask or Django), HTML/CSS for front-end, database connection like SQLite/MySQL for storing user's information in a secure way, handling security and sessions, and deploying it to a server is required which is outside of this scope.```.
In general, at 2023-10-25 18:12:10 a user named frank.martinez said ```Nice to see AutoGen generating *in-scope* responses [in this case I asked it to build a Python app to help uninsured people apply for Medicaid]:```.
In general, at 2023-10-25 16:32:21 a user named robin_saunders said ```ah nvm lmao im dumb, i forgot to set human input mode lolz```.
In general, at 2023-10-25 16:27:38 a user named usingxbox360controller said ```Anyone else getting timeout issues a lot with the default 60seconds?```.
In general, at 2023-10-25 16:17:49 a user named robin_saunders said ```The manager for some reason won't send the user_proxy anything```.
In general, at 2023-10-25 15:51:11 a user named wyang14 said ```Hey, I learnt the AutoGen framework very recently and started producing tutorials on Youtube and Medium. Looking forward to more cool use cases.```.
In general, at 2023-10-25 15:41:49 a user named icdlt said ```Looking forward to getting to know others in the community```.
In general, at 2023-10-25 15:41:32 a user named icdlt said ```I've been a data scientist for a year and a half, and working with LLM's / doing NLP in general since this feburary (both for work and as a hobbyist)```.
In general, at 2023-10-25 15:40:52 a user named icdlt said ```Hey started working with autogen to build a small application for personal use. I am hoping to build a Q&A system that leverages document retrieval and sql query execution```.
In general, at 2023-10-25 15:19:22 a user named .tstam said ```Hello everyone! I'm working on a project where I need to automatically correct a PDF document based on guidelines provided in another PDF. I'm considering utilizing AI technologies such as Flowise or StackAI, or any other suitable tools or frameworks that could help in achieving this task.

The core idea is to extract text and possibly images from both PDFs, analyze the guidelines, and then apply those guidelines to correct the other document. I'm especially looking for guidance on how to develop a system to apply the guidelines and suggest corrections.

I have broken down the task into several steps:

Extracting text and data from both PDFs,
Preprocessing and normalizing the text,
Analyzing the guidelines to understand the rules,
Developing a system to apply the guidelines, identify errors, suggest corrections, and apply changes,
Automating the entire process,
Reviewing and adjusting the system for better accuracy.

Thank you in advance for any help or advice you can provide!```.
In general, at 2023-10-25 15:06:05 a user named robin_saunders said ```is anyone else having issues with the manager for group chat not properly assigning what agents to use?```.
In general, at 2023-10-25 14:31:13 a user named well.job said ```It doesn't matter whether it's very complex or very simple```.
In general, at 2023-10-25 14:30:56 a user named well.job said ```Even though I don't want that many detail, i ask, how much have you guys paid for an app you made?```.
In general, at 2023-10-25 14:29:10 a user named well.job said ```Aah, again out of focus answer.

Let me ask this to ChatGPT, what i ask vs what you respond:

The question inquires about the cost of agent-based problem solving, with a specific mention of GPT-3.5 Turbo, GPT-3.5 on the browser, and GPT-4 for agent-based applications. The user is also interested in the cost of running an application developed by the company.

The answer provided seems to be quite brief and doesn't directly address the various components of the user's question. It mentions that the cost depends on task complexity and the number of agents but doesn't provide specific pricing information for GPT-3.5 Turbo, GPT-3.5 on the browser, GPT-4, or the company's developed application. It suggests that using an open-source Large Language Model (LLM) could be a cost-saving option.

A more comprehensive response would include specific cost comparisons and details for the mentioned models and applications, as well as potential pricing options or ranges.```.
In general, at 2023-10-25 14:18:16 a user named .spcell said ```Next message. VS Code now doesn't detect problems in workspace```.
In general, at 2023-10-25 14:08:41 a user named li_jiang said ```Replace “user_proxy” with “mathproxyagent ”```.
In general, at 2023-10-25 14:07:15 a user named frank.martinez said ```Depends on the complexity of tasks x agents; much less expensive if you use an open source LLM```.
In general, at 2023-10-25 13:51:52 a user named .spcell said ```My current code. Took it from MathChat Colab```.
In general, at 2023-10-25 13:47:39 a user named li_jiang said ```Have you tried the code in my screenshot? If that works, then could you please share the code in your app.py?```.
In general, at 2023-10-25 13:36:01 a user named .spcell said ```Did so, got that error again, then decided to install pyautogen in this Python file. Then I got an error about pydantic not being there and I installed it too. Now I have the last error (hopefully):```.
In general, at 2023-10-25 10:39:45 a user named well.job said ```May I ask about the cost of agent-based problem solving in action? I've noticed that GPT-3.5 Turbo is less effective than GPT-3.5 on the browser. GPT-4 is known to be more suitable for agent-based applications, but it's expensive. I'm curious about the cost of running an application (I understand it can vary between apps, but I'm asking about the app you develop```.
In general, at 2023-10-25 10:31:58 a user named jannis3643 said ```Hi everyone! I've been playing around with autogen to optimize content pipelines in my company. Excited to learn more about your use cases and solutions.```.
In general, at 2023-10-25 04:52:46 a user named jalateras said ```Thanks, i got it working```.
In general, at 2023-10-25 04:35:22 a user named afourney said ```Still a work in progress (which is why it’s off main), but it’s designed specifically for these types of scenarios```.
In general, at 2023-10-25 04:33:44 a user named afourney said ```You might be interested then in this testbed I’m building. It will run a number of scenarios as many times as you want, with known consistent initial conditions, and it logs everything (with logging turned on, but the agent messages too): https://github.com/microsoft/autogen/tree/testbed/samples/tools/testbed```.
In general, at 2023-10-25 04:21:45 a user named semi2995 said ```does anyone have used botpress before? trying to figure out how to run pre-trained GPT  model```.
In general, at 2023-10-25 04:00:22 a user named usingxbox360controller said ```And that default flow is based on the logic given to the groupchat feature?```.
In general, at 2023-10-25 03:49:39 a user named jonny7377 said ```I've been playing with Mistral-7B-OpenOrca for the last few hours on my very resource constrained 16GB M1 mac.  I only tried code generation from a plan that was generated and using LMStudio.  It 'felt' like this model was easier to steer and stayed on task better than gpt-3.5.  Small sample, no data collected - just the gut. It 'felt' better to me.

Also, I don't understand all I know about this stuff.```.
In general, at 2023-10-25 03:38:56 a user named elcapitan__ said ```Has anyone had any luck integrate vision tools to their multi-agent framework?```.
In general, at 2023-10-25 02:36:08 a user named li_jiang said ```Hi @.spcell , try set your vscode follow this:```.
In general, at 2023-10-25 02:17:09 a user named john.jeong said ```Hey guys, found out about AutoGen for some time but I'm finally taking my time to look into it. Really excited and have high hopes for this being a standard framework for building multi-agent systems. Holla!```.
In general, at 2023-10-25 02:11:56 a user named unik5324 said ```you have limited control from what I understand.  in other words, it has the "default" flow built in, so if you want to have a granual control of the flow, you'd need to use something like that Orchestrator class.```.
In general, at 2023-10-25 02:09:53 a user named usingxbox360controller said ```Funny, I'm literally watching this video rn. So it's not 'built in' I presume?```.
In general, at 2023-10-25 02:09:14 a user named unik5324 said ```You can take a look at this approach describing the Orchestrator class to manage the agent flow: https://www.youtube.com/watch?v=4o8tymMQ5GM```.
In general, at 2023-10-25 02:01:40 a user named usingxbox360controller said ```Any way to direct the flow of the conversation between agents? Let's say I had 20 agents and wanted them to follow a set pattern.```.
In general, at 2023-10-25 00:40:50 a user named robin_saunders said ```How can we contact eric directly?```.
In general, at 2023-10-24 23:45:39 a user named biggboii. said ```Request for anyone: Eric Hartford (creator of Dolphin fine-tuning set) is looking for datasets specific to AutoGen so he can fine-tune a model that will work especially well with AutoGen. To that end, anyone who is willing, please enable logging and send me your API call logs generated through AutoGen. I'll provide that to Eric Hartford, who will fine-tune a model for AutoGen.```.
In general, at 2023-10-24 23:43:24 a user named biggboii. said ```thanks i'll take a look!```.
In general, at 2023-10-24 23:43:05 a user named c_bonadio said ```Hi @biggboii. first congratulate, I am a big fan of your videos. About your question, I created an agent class that can self execute function_calls, to do that I used registering replies. You can look the code here https://gist.github.com/bonadio/96435a1b6ccc32297aa8cc1db7cfc381```.
In general, at 2023-10-24 21:51:48 a user named semi2995 said ```dalle can generate words accuratelly```.
In general, at 2023-10-24 20:54:13 a user named pvhack said ```did Dall-e came up with the word correct? or did you add the word mannually?```.
In general, at 2023-10-24 20:34:13 a user named anxietyprime. said ```Has anyone set this up where different agents are on different hosts? I see that api_base can support arbitrary remote hosts, and I'm looking at testing different agents with different models and tossing a few resources at them (I have a few gpu hosts just hanging around)```.
In general, at 2023-10-24 20:09:54 a user named aaronward_ said ```Got DALL-E 3 to make a pretty nice logo for Autogen```.
In general, at 2023-10-24 19:17:45 a user named .princeps said ```@sonichi [2023-10-24 12:15:23,443] [forge.autogen_helper] [ERROR]        ❌  🚨 Admin_User: ERROR IN send: 'str' object has no attribute 'receive'



I'm getting this error from my agents setup, am I'm going something stupid ?
https://github.com/Tonic-AI/AutoGPT/blob/a6a618749eb0d0de9c04f36b1378f8f254cca60a/autogpts/PolyGPT-alpha/forge/agents_initializer.py


https://github.com/Tonic-AI/AutoGPT/blob/a6a618749eb0d0de9c04f36b1378f8f254cca60a/autogpts/PolyGPT-alpha/forge/polygpt.py```.
In general, at 2023-10-24 19:08:50 a user named .spcell said ```https://cdn.discordapp.com/attachments/1166295296318373908/1166373533962735717/image.png?ex=654a4100&is=6537cc00&hm=0cadfc47780f2746ca13f9183814de01bd60f6fdac27d4e888bba61d7b78e2be&
https://cdn.discordapp.com/attachments/1166295296318373908/1166452991453306940/image.png?ex=654a8b00&is=65381600&hm=68dc0817c512c085ee8ae72c878722222698e31f4ac59e12c98556e17535c72a&
Two environments I tried```.
In general, at 2023-10-24 18:53:29 a user named jieyuzhang_uw said ```we actually use them in every agent, each built-in agent is by default registered all the built-in reply function. The AssistantAgent backed by LLM is a special case where the generate_oai_reply is active (by passing the `llm_config`).  And when we build a new agent like the newly-added TeachableAgent, we implement a new  reply function so it has its own behavior https://github.com/microsoft/autogen/blob/80954e4b8d0752fd4772f339dee419fbf1debc6f/autogen/agentchat/contrib/teachable_agent.py#L66```.
In general, at 2023-10-24 18:46:07 a user named jieyuzhang_uw said ```this one is for the context mechanism, so your msg to GPT (the `content`) can actually be something like, f"today is {date}", and then you use the `context ` to pass the actual date on-the-fly; the `content` can even be a function and then the `context` would be the parameter to instantiate the msg (converting it to string when passing it to GPT). Thus when the `allow_format_str_template` is true, you can use the formatted string like the figure. We explicitly take care of the format str because the python would treat every `{}` as placeholder and if it is not filled in, the code would raise an error```.
In general, at 2023-10-24 18:37:54 a user named semi2995 said ```While running LM  studio with built in api solution```.
In general, at 2023-10-24 18:37:26 a user named semi2995 said ```Cuz I get an error that user sends empty content, but in reality there is no em0ty content being send to the nodel```.
In general, at 2023-10-24 18:36:58 a user named semi2995 said ```@biggboii.  do u get any error in LM logs?```.
In general, at 2023-10-24 18:36:28 a user named biggboii. said ```i dont quite understand it from the documentation```.
In general, at 2023-10-24 18:34:04 a user named biggboii. said ```yes, can you provide an example of when is a good time to use it?```.
In general, at 2023-10-24 18:26:04 a user named jieyuzhang_uw said ```each reply function represents a way we want the agent to respond, we have many built-in reply functions that could reply to the msg in different ways. By implementing and registering new reply func, you can customize your own agent behavior. does that answer your question?```.
In general, at 2023-10-24 18:24:31 a user named b8454 said ```what do sites like snpainsta.app and snaptik.app use to deploy their apps?```.
In general, at 2023-10-24 18:18:33 a user named biggboii. said ```@jieyuzhang_uw what's the use case for registering replies?```.
In general, at 2023-10-24 18:12:40 a user named jieyuzhang_uw said ```I can explain it to you- if you have any question just at me```.
In general, at 2023-10-24 17:58:22 a user named dulak said ```even if i explicity ask it too 😛```.
In general, at 2023-10-24 17:57:59 a user named dulak said ```the model never generates/sends autogen a terminate message```.
In general, at 2023-10-24 17:57:44 a user named biggboii. said ```so the word "terminate" doesn't appear" or it appears and the model doesn't "see" it?```.
In general, at 2023-10-24 17:56:39 a user named dulak said ```It sort of enters a feedback loop with the code execution. I haven't had a model yet successfully send back a "TERMINATE" message lol```.
In general, at 2023-10-24 17:55:53 a user named dulak said ```It's some sort of bug with the model and LM Studio I think```.
In general, at 2023-10-24 17:54:09 a user named biggboii. said ```why doesn't the task terminate?```.
In general, at 2023-10-24 17:53:45 a user named dulak said ```could make a cool video```.
In general, at 2023-10-24 17:53:38 a user named dulak said ```@biggboii. something weird I've had start happening that you may want to investigate is when the model doesn't terminate and starts doing it's own thing. 

I had a "print hello world" prompt run while I was cooking and I came back to it self-doing other basic things like counting 1 to 10 and what not.

Just now I had it install SQLAlchemy and now it self prompted "Write a python script to connect to MYSQL and create then print a database"

Despite me not prompting that at all. It's like, self directing sometimes```.
In general, at 2023-10-24 17:52:54 a user named anxietyprime. said ```Because the primary interface between agents is a chat one. If you want to make function calls, langchain does it better```.
In general, at 2023-10-24 17:49:11 a user named dulak said ```Thanks its finding the proper bin now!```.
In general, at 2023-10-24 17:46:38 a user named sonichi said ```@qingyunwu or @ekzhu or @jieyuzhang_uw could you help if no one else replies?```.
In general, at 2023-10-24 17:45:05 a user named dulak said ```I can say that your videos just barely scratched the surface, I already found and fixed a bug using it with LM Studio lol```.
In general, at 2023-10-24 17:44:52 a user named biggboii. said ```AutoGen has wayyyyy more functionality than I realized when I first started playing with it.```.
In general, at 2023-10-24 17:44:12 a user named dulak said ```You're the reason I'm here hahaha```.
In general, at 2023-10-24 17:43:26 a user named biggboii. said ```I'm putting together an "advanced guide" video to AutoGen right now and I'm trying to figure out how to explain registering replies simply. I'm realizing I don't quite understand their use case. Can someone who understands it explain it to me?```.
In general, at 2023-10-24 17:43:13 a user named dulak said ```ah i will try it one sec```.
In general, at 2023-10-24 17:22:36 a user named dulak said ```For some reason I'm getting bash: not found for my docker installation. I can't seem to get bash scripts to run at all```.
In general, at 2023-10-24 17:05:13 a user named usingxbox360controller said ```So why use both? Why not just duplicate those agents within Autogen and have the same linear functionality?```.
In general, at 2023-10-24 17:04:25 a user named usingxbox360controller said ```I will now, thank you```.
In general, at 2023-10-24 17:04:15 a user named anxietyprime. said ```take a look at the example. The circle radius function is a good example of mixing classical computing with an LLM```.
In general, at 2023-10-24 17:04:06 a user named usingxbox360controller said ```Autogen feels more like a real "Ai" in that case, if that makes sense```.
In general, at 2023-10-24 17:03:43 a user named anxietyprime. said ```Langchain is more agent -> do thing -> agent -> do other thing```.
In general, at 2023-10-24 17:03:30 a user named usingxbox360controller said ```and langchain is agent A -> Agent B - > Agent C ?```.
In general, at 2023-10-24 17:03:28 a user named anxietyprime. said ```langchain does best as 1->1```.
In general, at 2023-10-24 17:03:10 a user named anxietyprime. said ```Yep, networked connections. So you can have 1->Many agents```.
In general, at 2023-10-24 17:02:56 a user named usingxbox360controller said ```Whereas autogen is more of the ambiguous type of connections?```.
In general, at 2023-10-24 17:02:33 a user named anxietyprime. said ```If you want pipelines within your networks, or pipelines between networks for imperative type workloads, langchain can do great for that purpose```.
In general, at 2023-10-24 17:02:05 a user named anxietyprime. said ```Langchain tends to be linear like a pipeline, autogen tends to do better as a networked pattern```.
In general, at 2023-10-24 17:01:38 a user named usingxbox360controller said ```Yes but what's the difference```.
In general, at 2023-10-24 16:55:00 a user named anxietyprime. said ```You can actually use them together https://github.com/microsoft/autogen/blob/main/notebook/agentchat_langchain.ipynb```.
In general, at 2023-10-24 16:52:38 a user named usingxbox360controller said ```Could I get a rundown on Langchain vs Autogen? Are they the same type of framework?```.
In general, at 2023-10-24 16:47:53 a user named tonic_1 said ```We're benchmarking autogen agent polyGPT-alpha against autogpt benchmarks ! 

https://discord.gg/mHHdcbdk?event=1166417234906853387```.
In general, at 2023-10-24 16:36:19 a user named bobaleaux said ```i used the base model.

model = whisper.load_model("base")```.
In general, at 2023-10-24 16:33:52 a user named fxtoofaan said ```ah good to know. thank you```.
In general, at 2023-10-24 16:32:58 a user named bobaleaux said ```I will look at the code and let you know the model i used.(I have to find it)
Also, I asked Bing chatbot about Wisper and this is what it responded. I didn't verify its response.

**However, it’s important to note that while Whisper can transcribe audio in multiple languages and translate them into English2, the transcription and translation are two separate processes. First, the audio is transcribed into text in the original language, and then the text is translated into the target language.**```.
In general, at 2023-10-24 16:30:31 a user named fxtoofaan said ```I will stick with transcription for now 🙂 thank you. I was able to load the medium model for transcription. all my source videos are in english, should I use the medium.en model or just medium is good enough? also should I be using medium, small or base? some of the videos I have are over 3 hours long.```.
In general, at 2023-10-24 16:28:35 a user named bobaleaux said ```yes, Whisper as I appreciate it while I was testing is strictly transcription speech to text.
Translation, I have no experience with but I would think that it it's a 2 step, first transcribe then translate.```.
In general, at 2023-10-24 16:24:39 a user named fxtoofaan said ```how can I translate from english to other language? seems like whisper ai does not support that```.
In general, at 2023-10-24 15:36:47 a user named bobaleaux said ```glad Whisper worked out for you.  I found an example of a RetrieveUserProxyAgent in the Issues and Help channel.
I think it was from a thread "Document Retrieval" and used chromadb```.
In general, at 2023-10-24 15:30:44 a user named quinn_ai_32 said ```did anyone build any cool stuff on autogen?```.
In general, at 2023-10-24 15:30:44 a user named fxtoofaan said ```I got whisper to work now. I am not able to run medium model for some reason, telling me running out to gpu RAM. so now I am able to at least convert video/audio to text 🙂 next stop building rag database to store the text files in```.
In general, at 2023-10-24 15:10:52 a user named dulak said ```hows it run compared to say wizardcoder python 34B?```.
In general, at 2023-10-24 15:08:35 a user named dulak said ```Anyone have a favorite local LLM for producing python code?```.
In general, at 2023-10-24 15:05:21 a user named killumi4516 said ```Is anyone running autogen through Jupyter? I've been having trouble getting it to import pyautogen.```.
In general, at 2023-10-24 14:36:34 a user named bobaleaux said ```I''ve done transcribing several ways using python. Whisper from openai can be installed locally and used for free or you can use Aassembly.ai or Deepgram for a fee.
They were pretty easy to use.
I used Deepgram to transcribe using my pc microphone as the input device for a proof of concept to be used in my project.```.
In general, at 2023-10-24 14:32:21 a user named woodynz9000 said ```RBAC is a part for sure, needs tiering in the agent context, but that'll be limited by the directory , MSFT AD and AAD sucks as it's still MSFT answer to everything (when you sell a hammer and all that) don't get me started on AD DNS... WINs anyone ? hahaha , anyway, execution limitations etc should be OOTB must haves. The idea of developers provisioning an army of agent developers all using the same auth and connectors to access enterprise data would definitely end up with a hard no from any SecOps team.```.
In general, at 2023-10-24 14:21:54 a user named frank.martinez said ```Permission boundaries similar to AWS IAM roles, groups… or Microsoft AD is what’s needed.```.
In general, at 2023-10-24 14:14:41 a user named woodynz9000 said ```Ha, don't get paid that much unfortunately ! cloud solution architect looking push autogen capability into the enterprise space. I've been kicking the tyres on Azure Open AI offerings for a while with embeddings and getting some traction but the real value is in Autogen for enterprise's.```.
In general, at 2023-10-24 13:27:20 a user named sonichi said ```Nice. Are you a security researcher?```.
In general, at 2023-10-24 13:17:39 a user named fxtoofaan said ```anyone doing any video/audio to text conversion? if yes then what you using? i am looking for something i can install locally please```.
In general, at 2023-10-24 12:00:31 a user named woodynz9000 said ```keen to work on getting some security features across Autogen capability's, needs more cybersec auditing and a strawman security framework along the lines of NIST 57 and ISO 27K as well as localised stuff like AU Gov E8 and NZ NCSC stuff```.
In general, at 2023-10-24 11:56:26 a user named woodynz9000 said ```Keen to see how Autogen can be a framework with more robust security compared to loosegoose stuff like ChatDev, AutoGPT and AgentGPT which are abit to dev sandpit```.
In general, at 2023-10-24 11:40:47 a user named bimb1louhi said ```Reading about it on Microsoft website.```.
In general, at 2023-10-24 11:15:06 a user named revers101 said ```I’ve been watching this development from the researcher site to take a look if I can implement. This is a feasible business solution inside of the energy certain.```.
In general, at 2023-10-24 10:13:53 a user named fxtoofaan said ```What you all would recommend to use for local video or audio to text transcription? I have a bunch or audio and video files that I want to transcribe so I can use the transcribed test in RAG project for autogen. what you recommend I can install locally and maybe do batch conversions?```.
In general, at 2023-10-24 09:09:52 a user named li_jiang said ```Hi @.spcell , from the screenshot, it looks like you were not running in a conda env.```.
In general, at 2023-10-24 09:02:44 a user named MDeehZA said ```@nesty_92 i do have an account , the API created there doesn't work , am running this via Google colab```.
In general, at 2023-10-24 09:01:33 a user named patrick_12059 said ```YouTube, and a PACKT conference I went to```.
In general, at 2023-10-24 09:00:02 a user named nesty_92 said ```ChatGPT Plus don't give you access to the API, you have to create an account and api key here https://platform.openai.com/```.
In general, at 2023-10-24 08:53:26 a user named MDeehZA said ```Hi , so this doesn't work for ChatGPT 4 plus ? Been trying keeps failing on API section```.
In general, at 2023-10-24 07:11:00 a user named platinumpluto said ```I have a question related to storing the responce in a variable.
When I'm using autogen, when it is terminated how can store the latest response generated from the agent to a variable after it terminates?```.
In general, at 2023-10-24 05:43:05 a user named lao61031 said ```If I don't use GPT-4 for my LLM, can I still call functions?```.
In general, at 2023-10-24 04:51:01 a user named duck_lord42 said ```Try adding an additional agent that will execute and debug the code and run it as a chat. There is no external source error checking the assistant's work. The back-and-forth dialog is how the agents write and debug the code, doing it with just one will likely give you code that isn't totally accurate on the first go```.
In general, at 2023-10-24 03:44:15 a user named jalateras said ```anyone else coming across this?```.
In general, at 2023-10-24 03:43:49 a user named jalateras said ```Here is the output truncated

```

To run this script, you need to have `yfinance` and `matplotlib` installed in your Python environment. If not, you can install them using pip:

```sh
pip install yfinance matplotlib
```

Then, you can run the script:

```sh
python stock_price_plot.py
```

This will plot a chart showing the closing prices of NVDA and TSLA stocks from one year ago to today. The x-axis represents the date, and the y-axis represents the price in dollars. The blue line represents NVDA, and the orange line represents TSLA.

--------------------------------------------------------------------------------
An error occurred: set.pop() takes no arguments (2 given)
``````.
In general, at 2023-10-24 03:43:29 a user named jalateras said ```I am just going through the autogen quick start guide using pyautogen 0.1.13 but running this code base, raises an error
```
ef stock_price():
    try:
        gpt_config_list = [
            {
                "model": "gpt-4",
                "api_key": os.environ["OPENAI_API_KEY"],
            }
        ]

        llm_config = {
            "config_list": gpt_config_list,
            "use_cache": False,
            "temperature": 0,
        }

        def is_termination_msg(data):
            has_content = "content" in data and data["content"] is not None
            return has_content and "TERMINATE" in data["content"]

        assistant_agent = AssistantAgent(name="assistant", llm_config=llm_config)
        user_proxy_agent = UserProxyAgent(
            name="user_proxy",
            human_input_mode="NEVER",
            max_consecutive_auto_reply=10,
            is_termination_msg=is_termination_msg,
            code_execution_config={"working_dir", "tmp"},
        )

        user_proxy_agent.initiate_chat(
            assistant_agent,
            message="Plot a chart of NVDA and TESLA stock price change YTD.",
        )
    except Exception as e:
        click.echo(f"An error occurred: {str(e)}", err=True)
``````.
In general, at 2023-10-24 03:06:29 a user named afourney said ```Anyone else here getting a lot of Error 500s from OpenAI tonight? Or perhaps it’s just my bad luck.```.
In general, at 2023-10-24 02:35:36 a user named dredwerker said ```Has anybody created an app with a web interface that is not snake or printing numbers ? I have been trying I can only get out about the same I can with a few queries in chatgpt.```.
In general, at 2023-10-24 01:17:18 a user named benbarnard said ```Has anybody run Autogen in an azure function?```.
In general, at 2023-10-23 23:26:15 a user named lukfre said ```is autogen really a microsoft framework?```.
In general, at 2023-10-23 23:02:25 a user named 1_twisto said ```Could you recommend any resources that clearly delineate the distinctions between using 'Instruction' and 'Roleplay' prompts in Large Language Models (LLMs)? I am currently struggling to find comprehensive materials that elucidate the differences between these types of prompts, as well as 'SystemMessages', when they are sent to the LLM```.
In general, at 2023-10-23 20:01:37 a user named semi2995 said ```Hey, what's a best way /cheap  to scale up the GPUs running agents for different companies, I could have like 20-30k/month budget, but still looking for best ways to spend any budget at valuable price (so also checking here if I build up  GPUs locally will not gonna worth).

I know about the Runpod,etc... but I mean gonna need really huge resources ( running some multiple agents per company by 24/7)```.
In general, at nan a user named userbrian said ```I have never used QLoRA```.
In general, at 2023-10-23 19:05:33 a user named .spcell said ```PS C:\Users\Cell\Autogen> conda env autogen
usage: conda-env-script.py [-h] command ...
conda-env-script.py: error: argument command: invalid choice: 'autogen' (choose from 'create', 'export', 'list', 'remove', 'update', 'config')```.
In general, at 2023-10-23 19:04:58 a user named .spcell said ```I'm getting these errors in PyCharm```.
In general, at 2023-10-23 19:00:13 a user named moonboi9001 said ```That's cool, I don't think I'll be able to use QLoRA though with it```.
In general, at 2023-10-23 18:57:47 a user named userbrian said ```I'm pretty new to this and it took me 5 minutes to set up. It's awesome.```.
In general, at 2023-10-23 18:56:10 a user named moonboi9001 said ```Ah yeah I did remember seeing a video about lm studio, didn't have a look yet though. Ty I'll check it out```.
In general, at 2023-10-23 18:11:24 a user named userbrian said ```@moonboi9001 LM Studio makes it really easy to run different local models. Matthew Berman put out a good video about it the other day```.
In general, at 2023-10-23 17:51:13 a user named magic8437 said ```@.spcell  I see you are painfully investigating this issue multiple days, why not switching to pycharm and let it install the venv and python for you and get your job done? I have no idea about your objectives but if the goal is to run the script then just suggesting this to make it quicker.```.
In general, at 2023-10-23 17:37:41 a user named .spcell said ```One problem now instead of 3```.
In general, at 2023-10-23 17:29:22 a user named .spcell said ```I installed python 3.10.6 with Conda in base environment and then changed to the newly installed and launched the code. This is the new error:```.
In general, at 2023-10-23 16:19:55 a user named artificialbeauties said ```Hey everyone , i come from this video too : https://www.youtube.com/watch?v=oAsJVZlDOgQ , like probably most of people x)```.
In general, at 2023-10-23 16:09:53 a user named _tomwong said ```I'm coming from this video. A great one! https://www.youtube.com/watch?v=oAsJVZlDOgQ```.
In general, at 2023-10-23 15:56:45 a user named gofman2 said ```From this video
https://www.youtube.com/watch?v=QQ2QOPWZKVc```.
In general, at 2023-10-23 15:54:34 a user named moonboi9001 said ```when I tried it on google colab it would at least try to run but then ran out of ram```.
In general, at 2023-10-23 15:53:44 a user named moonboi9001 said ```this was the model I was tyring to get working from him```.
In general, at 2023-10-23 15:53:29 a user named moonboi9001 said ```sentdex had a interesting model he made using data from r/wallstbets```.
In general, at 2023-10-23 15:52:59 a user named moonboi9001 said ```I was trying to locally host a model from hugging face to run locally and was going to test different models in autogen```.
In general, at 2023-10-23 15:49:46 a user named moonboi9001 said ```I'm having so much trouble trying to setup an enviroment for tensorflow-gpu v2.0 in anaconda with python 3.7. seems that everything i try breaks due to certain versions of something not working with another version of something else```.
In general, at 2023-10-23 15:48:57 a user named quantumghost99 said ```Wes Roth YouTube channel is where I first heard about it a few days ago. 
https://www.youtube.com/watch?v=zdcCD--IieY&t=569s```.
In general, at 2023-10-23 15:30:45 a user named .drakkaa said ```Discovered autogen in my google news links 🙂```.
In general, at 2023-10-23 15:13:38 a user named andre.fichel said ```Discovered Autogen through a colleague at work!```.
In general, at 2023-10-23 12:33:40 a user named flaiwheel said ```@biggboii. As you encouraged your viewers to reach out in your last AutoGen / RunPod/ TextGen Video.   Would you accept my invitation?  I would love to have a quick chat with you.```.
In general, at 2023-10-23 12:00:51 a user named tonic_1 said ```how was that whole thing ? i spent quite a lot of time bad mouthing agent protocol until i saw how @.princeps used it for the interface he built, suddenly i'm a big fan !```.
In general, at 2023-10-23 11:53:04 a user named tonic_1 said ```my little autogen bot is back online, you're very welcome to use it : http://ec2-3-90-21-138.compute-1.amazonaws.com:3000/chatbot/c85c8b9b-7c33-4251-bd16-fdef6a8499dc```.
In general, at 2023-10-23 11:05:46 a user named jonny7377 said ```Sounds good, ping me directly if it's```.
In general, at 2023-10-23 08:30:20 a user named ibrahim_aka_ajax said ```Would love to learn to build apps that everyday people can use and be amazed```.
In general, at 2023-10-23 08:29:22 a user named ibrahim_aka_ajax said ```Discovered Autogen sometime after the recent AI Engineer summit. Think it's really cool 😊```.
In general, at 2023-10-23 04:35:45 a user named corgi108 said ```oh actually i mixed that up. sorry brain still in sleep mode```.
In general, at 2023-10-23 04:33:53 a user named corgi108 said ```stumbled over an notebook on github recently that claimed to do that. just search for it like the simplest way possible like me and you will find it 😉```.
In general, at 2023-10-23 04:31:45 a user named lance0852 said ```Hello, every one how to use autoGen on colab ?  : ）```.
In general, at 2023-10-23 02:24:46 a user named DocHoliday said ```FYI Dolphil 2.1 mistra 7b q5 worked!```.
In general, at 2023-10-23 02:21:36 a user named DocHoliday said ```this post helped me with the pip issue, run this before you try to install pyautogen, conda install pip```.
In general, at 2023-10-23 02:21:10 a user named DocHoliday said ```https://stackoverflow.com/questions/41060382/using-pip-to-install-packages-to-anaconda-environment/43729857#43729857```.
In general, at 2023-10-23 01:56:56 a user named li_jiang said ```@.spcell Try this in the doc https://microsoft.github.io/autogen/docs/Installation/#setup-virtual-environment

Another option is with Conda, Conda works better at solving dependency conflicts than pip. You can install it by following this doc https://docs.conda.io/projects/conda/en/stable/user-guide/install/index.html, and then create a virtual environment as below:
```
conda create -n autogen python=3.10  # python 3.10 is recommended as it's stable and not too old
conda activate autogen
``````.
In general, at 2023-10-23 01:30:00 a user named agony917 said ```Is there a good ways to see what open sources models are good at what?```.
In general, at 2023-10-23 01:15:01 a user named DocHoliday said ```What is the best open model that you have found to work? I just tested Mistral7B-Instruct 0.1 and it got the python code example of writing a script to print the numbers from 0 - 100, but it doesn't actually create the file.```.
In general, at 2023-10-23 00:15:14 a user named ehehbogballs said ```FYI : first learned about autogen on Matthew Bermans dainty little youtube channel and then on others. but to be honest AutoGen needs its own YouTube channel, with tutorials and streams etc.```.
In general, at 2023-10-22 23:32:21 a user named sonichi said ```The first msg shows that the code execution succeeded but the output is empty. That should be checked first. I really wish I have time to diagnose this with you but I gotta focus on some urgent issues. There are many people capable of answering this question. Try posting on <#1157397569375309864>. I'll check back in a week.```.
In general, at 2023-10-22 23:18:30 a user named e404nothing said ```I think the issue is that my content on the assistant is empty due to the end of this log file:

      "content": "exitcode: 0 (execution succeeded)\nCode output: \n",
      "role": "user"
    },
    {
      "content": "[{'name': 'Edmonton Space Company', 'address': '12345 Main St.', 'city': 'Edmonton', 'province': 'Alberta', 'postalCode': 'T5J 0B7', 'country': 'Canada'}]\n",
      "role": "assistant"
    },
    {
      "content": "default_auto_reply",
      "role": "user"
    },
    {
      "content": "",
      "role": "assistant"
    },
    {
      "content": "default_auto_reply",
      "role": "user"
    }
  ],
  "model": "gpt-4",
  "temperature": 0
}

so are the agents not talking to each other? Im not sure how to diagnose this issue. If this would be suited somewhere else I can move it to issues```.
In general, at 2023-10-22 23:11:50 a user named sonichi said ```@li_jiang could you help or find other helpers?```.
In general, at 2023-10-22 23:11:00 a user named .spcell said ```Error I'm getting:
python3 : The term 'python3' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the 
spelling of the name, or if a path was included, verify that the path is correct and try again.
At line:1 char:1
+ python3 -m venv autogen
+ ~~~~~~~
    + CategoryInfo          : ObjectNotFound: (python3:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

source : The term 'source' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the sp
elling of the name, or if a path was included, verify that the path is correct and try again.
At line:2 char:1
+ source autogen/bin/activate
+ ~~~~~~
    + CategoryInfo          : ObjectNotFound: (source:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

According to ChatGPT my machine doesn't see Python```.
In general, at 2023-10-22 23:07:57 a user named e404nothing said ```Ive been trying this all day, my user_proxy looks like this:

user_proxy = autogen.UserProxyAgent(
name="User_proxy",
human_input_mode="TERMINATE",
max_consecutive_auto_reply=10,
default_auto_reply="default_auto_reply",
is_termination_msg = lambda x: (
False if x.get("content") is None else
x.get("content", "").rstrip().endswith("TERMINATE")
if isinstance(json.loads(x.get("content")), dict) else
False
),

code_execution_config={
    "work_dir": "coding",
    "use_docker": True,  # set to True or image name like "python:3" to use docker
},
)
autogen.ChatCompletion.start_logging()

I am importing `json`, which then leads to this issue:

`  File "C:\Users\e404n\anaconda3\Lib\json\decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)````.
In general, at 2023-10-22 22:11:30 a user named sonichi said ```https://microsoft.github.io/autogen/docs/Installation#setup-virtual-environment```.
In general, at 2023-10-22 21:42:23 a user named .spcell said ```How to use clean conda env instead of base? Is visual studio still needed?```.
In general, at 2023-10-22 21:39:05 a user named .thomascornelius said ```Hi there! We are hiring a Senior AI Engineer! 🚀

Cience.com is an all-in-one demand-gen platform. We are on a thrilling mission to demystify demand generation, fueled by a fusion of innovation and passion, with alumni from tech companies like LinkedIn, Salesforce, and Hubspot. 

🌐 Our  AI Products:

GO Expert AI: Content creation and instant answers for sales and marketing.
GO Campaign AI: Seamless multi-channel AI-created outbound campaigns.
GO Dialogue AI: Engage prospects across email, chat, LinkedIn, and social media with a personalized AI touch.
GO Voice AI: Venture into real voice prospecting with the first artificial voice SDR.

🛠 What We're Looking For:

- A seasoned Senior AI Engineer with a **strong ML background and experience in serving models.**
- Proficiency in Python is a must; knowledge of C or C++ is a plus.
- Minimum of 5 years in Software Engineering, with at least 2 years honed in AI.
- Experience with TTS and STT models, 
- PyTorch and HuggingFace frameworks is desirable.
- autogen, Vocode or Llama Index experience is a bonus, but not necessary.

Be a part of a global family that embraces challenges, celebrates triumphs, and is united by a shared vision of changing sales globally.

Let's redefine demand generation together, blending AI innovation with human ingenuity! 

** DM for more details or to share your resume. 
**🤖✋```.
In general, at 2023-10-22 21:27:34 a user named hanley7082 said ```I loaded up a vector database with the memGPT white paper and codebase. You can use it for free here :

https://app.paal.ai/cs?bid=e98ov58g&cid=0 

Will do autogen next 🙂```.
In general, at 2023-10-22 21:03:00 a user named rickyloynd said ```Sounds good, ping me directly if it's still giving you trouble. There are several things we can check.```.
In general, at 2023-10-23 11:05:47 a user named jonny7377 said ```I now know what the problem is: User error!  I somehow misunderstood what exactly TeachableAgent is supposed to do.  I apologize for the needless distraction.

The source of my confusion was my previous chatbot work (prior to autogen).```.
In general, at 2023-10-23 13:45:29 a user named rickyloynd said ```Glad it works for you! Does it successfully remember your name across chat sessions?```.
In general, at 2023-10-23 13:48:55 a user named rickyloynd said ```These LLMs can be reluctant to admit that they know very personal information, like names and addresses.```.
In general, at 2023-10-24 00:19:31 a user named jonny7377 said ```No luk getting it to remember my name so my 'personal profile' idea is on hold at this point. 

Before moving to autogen, I had a working system that automatically maintained a personal profile and injected relevent pieces of the profile into the context when needed (aka relevent to the current user request). That system updated the profile every 10 minutes (configurable) and paused if no new user requests were arriving. It trimmed and or updated old profile info and added new info based on the conversations and was extremely reliable.

But the system as a whole suffered from a lack of what i am convenced can be provided by agents at some point in the near future.

I like the caos of group chat and expect that autogen (or something like it) will provide answers to many of my questions soon.  Thanks for your help and your Agents.```.
In general, at 2023-10-25 18:17:50 a user named bobaleaux said ```Are you using teachable agent? I'm trying to get a handle on it compared to a RAG agent.```.
In general, at 2023-10-25 18:57:43 a user named jonny7377 said ```More like occationaly running things through it to see what sticks and what falls through the holes. As I said, I am currently trying to create a mechanism for automatically (through chat conversations and directed, short interviews with myself and other means) generating and maintaining a personal profile.```.
In general, at 2023-10-25 21:11:17 a user named bobaleaux said ```I'm considering replacing a straight up RAG agent with it to see if it will create a contextual memory.
I assume it will.

Thanks```.
In general, at 2023-10-27 13:42:44 a user named rickyloynd said ```https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent```.
In general, at 2023-10-22 20:59:10 a user named jonny7377 said ```GPT-3.5 on macos.  i'll see if i can get to the actual responses from openai. maybe some helpful info there for me.

FYI - I have been using chroma and gpt-3.5 to do semantic search on message history for more than 6 months with no issues. Didn't have autogen with that setup so so not quite the same.

Thanks for the feedback - I'll keep looking.```.
In general, at 2023-10-22 20:33:52 a user named e404nothing said ```I haven't got it yet, but thankyou so much for this.```.
In general, at 2023-10-22 20:19:58 a user named sonichi said ```https://github.com/microsoft/autogen/issues/279```.
In general, at 2023-10-22 20:15:54 a user named rickyloynd said ```@jonny7377 , which LLM are you using? We found that GPT-3.5 does worse than GPT-4. And what system are you running on? We've tested it on windows, linux, and mac.```.
In general, at 2023-10-22 19:54:57 a user named e404nothing said ```I should also mention that I get an error: `[2023-10-22 13:53:54.744] [ERROR] Error: 'messages' array must only contain objects with a 'content' field that is not empty.` in LM studio.```.
In general, at 2023-10-22 19:44:52 a user named e404nothing said ```Ive been having some issues with locall LLMs, I'm sure this is a common topic but cant find much documentation on my issue. I am using vscode on windows, I am using `CodeLlama-7B-Instruct-GGUF` on LM Studio, and docker is running and connected. I am trying to get the multi-agent working with autogen with this guide as a reference: https://www.youtube.com/watch?v=oOqeOspJL0o&t=1s
But I keep getting `AttributeError: 'str' object has no attribute 'get'` as an error code. Does anyone have any help? Or any other examples to run? 
I should also mention that it doesnt look like docker has ran anything in the last couple days, so maybe I dont have it set up correctly, but I thought I did everything right.```.
In general, at 2023-10-22 19:16:43 a user named .princeps said ```Will test it tomorrow and let you know```.
In general, at 2023-10-22 19:08:06 a user named jonny7377 said ```Didn't see anyone reply so...

OpenAI APIs do not tolerate 'extra properties' at all.  Atleast not in my experience.```.
In general, at 2023-10-22 19:02:45 a user named jonny7377 said ```Have you used TeachableAgent?  I have been trying for an hour to get it to pull a memory from the db with no luck.  

user (to teachableagent):

Hello, do you remember my name?

--------------------------------------------------------------------------------
teachableagent (to user):

Of course! Your name is [insert user's name]. How can I assist you today?


Just following the notebook in a console app. Changed reset_db to False and verbosity to 1, 2 or 3.  Output does not change.```.
In general, at 2023-10-22 18:57:58 a user named dootdotr said ```I'm super excited to try out autogen today, I found it mentioned on Youtube, and from a research paper I read. I plan on using agents to create multi agent departments to further app development, and some APIs I am working on. 🙂```.
In general, at 2023-10-22 15:39:52 a user named frank.martinez said ```FYI: the RTX A-5000 works great for hosting an open LLM [Mistral-7B…]; i.e. don’t spend money on the bigger, faster Runpod GPUs```.
In general, at 2023-10-22 14:49:37 a user named sonichi said ```could you try using a clean conda env instead of the base?```.
In general, at 2023-10-22 14:18:21 a user named .spcell said ```Yes, it is installed. I just checked and yet these errors persist when launching the code```.
In general, at 2023-10-22 14:05:32 a user named aaronward_ said ```https://youtu.be/VcNGjMZEV7k?si=VSaXtcgQfwFaXMhi```.
In general, at 2023-10-22 14:01:40 a user named sonichi said ```Is pyautogen installed in the conda base environment you are using? This error indicates it’s not.```.
In general, at 2023-10-22 13:33:45 a user named pigflyswl_40885 said ```I know AutoGen from github```.
In general, at 2023-10-22 13:32:15 a user named vladimir.v.krylov said ```Let me know some beginners guide```.
In general, at 2023-10-22 10:15:40 a user named magic8437 said ```Is there any way to add extra properties to openai API? e.g. the next_role? 

```completion = openai.ChatCompletion.create(
    model="gpt-4-0613",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "what is next role?", "name": "John", "next_role": "Alice"},
    ]
)
``````.
In general, at 2023-10-22 09:37:38 a user named .princeps said ```Will do, still working on refining it```.
In general, at 2023-10-22 09:37:04 a user named li_jiang said ```@.princeps  Would you like to share the solution? Thanks!```.
In general, at 2023-10-22 09:30:51 a user named .princeps said ```@kajatta  I think I figured it out```.
In general, at 2023-10-22 09:27:58 a user named kajatta said ```Nah not yet, will try it tomorrow```.
In general, at 2023-10-22 09:13:26 a user named go3boy2099 said ```I know AutoGen through a Medium article.```.
In general, at 2023-10-22 07:16:37 a user named chappyhome said ```https://tenor.com/bdWE1.gif```.
In general, at 2023-10-22 06:37:36 a user named .princeps said ```@li_jiang or @kajatta anyone able to help me with this ?```.
In general, at 2023-10-22 06:30:34 a user named .princeps said ```@here I want to get the messages sent between the agents and send them to the UI @sonichi know how I can do this or how I should ask```.
In general, at 2023-10-22 06:20:44 a user named .princeps said ```Christmas Must have came early! 

@sonichi @kevinwyr @rickyloynd Just saw the new agents y'all added 

https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/teachable_agent
https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/text_analyzer_agent

Loving them! Thanks guys!```.
In general, at 2023-10-22 05:12:47 a user named mihaim0218 said ```Has anyone tried to use AutoGen for forecasting or data-driven scenarios ?  So giving them scenarios like optimizing orders for supply chain, trying to optimize data-driven KPIs? I would be very interested in doing something like this and implementing it into an actual enterprise```.
In general, at 2023-10-22 01:26:54 a user named rguberud said ```Anyone know why the retrievechat.py doesn't work on MAC or windows (sys.platform in ["darwin", "win32"] )```.
In general, at 2023-10-22 00:58:01 a user named .spcell said ```WARNING: Package(s) not found: autogen
This is what I'm getting now after pip show autogen```.
In general, at 2023-10-22 00:55:56 a user named .spcell said ```I'm getting these errors again```.
In general, at 2023-10-22 00:51:18 a user named sonichi said ```that's `autogen`; need to uninstall it and install `pyautogen````.
In general, at 2023-10-22 00:48:24 a user named sonichi said ```could you run `pip show pyautogen` ?```.
In general, at 2023-10-22 00:46:46 a user named remy8432 said ```I learned about AutoGen from EchoHive's youtube channel, I'm hoping to use it with my Home Assistant GPT-4 bot```.
In general, at 2023-10-22 00:45:50 a user named .spcell said ```Why am I getting this error?```.
In general, at 2023-10-22 00:23:09 a user named pns9568 said ```LLm studio with autgen woyld be great as cuda at 35 works the fastest for me```.
In general, at 2023-10-21 22:05:11 a user named 1_twisto said ```Hello, Greeting from Europe,

Do anyone have tested OpenLLM with Autogen-UI ?```.
In general, at 2023-10-21 20:46:49 a user named aaronward_ said ```yes, you can alternatively use a .env file if you prefer to configure the models to use in the session programmatically 

see here: https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb```.
In general, at 2023-10-21 20:42:29 a user named somecomputerguy said ```I am interested in this, but functions via autogen are very easy```.
In general, at 2023-10-21 19:28:18 a user named .spcell said ```Is OAI_CONFIG_LIST supposed to be in json format?```.
In general, at 2023-10-21 18:30:05 a user named frank.martinez said ```anyone tried Langchain as middleware, to get functions + tools support when using open LLMs; i.e. use Mistral-7B and have your agents call functions with tools like Twilio API?```.
In general, at 2023-10-21 16:25:10 a user named afourney said ```Try python 3.11 instead of 3.12. There’s trouble with some dependencies```.
In general, at 2023-10-21 15:09:18 a user named concordeonwater said ```error: command '/usr/bin/clang' failed with exit code 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for aiohttp
Failed to build aiohttp
ERROR: Could not build wheels for aiohttp, which is required to install pyproject.toml-based projects

 i get this error while using command pip install pyautogen,its a macbook air m1,

Can anyone help?```.
In general, at 2023-10-21 12:35:55 a user named mooblegum said ```Hello there. Is there a place where people post there autogen custom scripts or workflow ?```.
In general, at 2023-10-21 10:53:29 a user named tonic_1 said ```hey there folks just an introductory meeting to our autogen project today : 
https://discord.gg/mC5tx2sH?event=1165007231662698497 see here for the repo : https://github.com/Tonic-AI```.
In general, at 2023-10-21 10:03:58 a user named malicor said ```this is both true and not helpful 🙂```.
In general, at 2023-10-21 10:01:24 a user named jepse said ```being a developer is all about figuring it out 😉```.
In general, at 2023-10-21 10:00:07 a user named malicor said ```i dont think i can figure out how to do that 😦```.
In general, at 2023-10-21 09:59:41 a user named jepse said ```read the Python Bindings documentations, there is no installer for this part, gotta be crafty```.
In general, at 2023-10-21 09:59:01 a user named malicor said ```dont i have to run it in some kind of server-api-mode ? (the gpt4all thing)```.
In general, at 2023-10-21 09:58:46 a user named malicor said ```but how do i tell autogen to now connect to this ?```.
In general, at 2023-10-21 09:58:31 a user named malicor said ```gpt4all is running, and i do get results```.
In general, at 2023-10-21 09:54:24 a user named malicor said ```you still around @jepse ?```.
In general, at 2023-10-21 09:30:28 a user named malicor said ```okay, i got gpt4all running with Snoozy now, and it answered my test question correctly, how do i now make autoGen use it?```.
In general, at 2023-10-21 09:20:35 a user named malicor said ```it doesnt allow me to pick WizardLM-13B on the available models page, i m trying with Snoozy now```.
In general, at 2023-10-21 09:19:41 a user named malicor said ```i got CUDA installed, but dont i have to tell GPT4All to use it ?```.
In general, at 2023-10-21 09:18:00 a user named jepse said ```you can gpu accelerate by installing Nvidia CUDA, its on their Github or in the docs as well, very well documented platform```.
In general, at 2023-10-21 09:16:56 a user named malicor said ```can i have it run with GPU ? i got a good gpu, and it might be cool to make use of it?```.
In general, at 2023-10-21 09:13:28 a user named malicor said ```https://gpt4all.io/index.html this ?```.
In general, at 2023-10-21 09:13:06 a user named jepse said ```follow instructions on their docs```.
In general, at 2023-10-21 09:12:50 a user named malicor said ```can you tell me how to setup the local part ?```.
In general, at 2023-10-21 09:12:34 a user named jepse said ```gpt4All is great base, ive had decent result with WizardLM-13B @ https://github.com/nomic-ai/gpt4all cheers```.
In general, at 2023-10-21 09:06:16 a user named malicor said ```say, is it possible to use autoGen together with a local LLM in a way that produces good results, too?```.
In general, at 2023-10-21 08:59:51 a user named jepse said ```Ai Jason aka Jason Zhou was who i learned autogen from```.
In general, at 2023-10-21 07:53:52 a user named concordeonwater said ```how do  i use autogen with llama 2 api,cant spend more on gpt4 api```.
In general, at 2023-10-21 07:39:41 a user named syedmujeeb said ```Hi 
Does autogen supports bedrock```.
In general, at 2023-10-21 05:51:31 a user named jamesdev184 said ```Hello, found autogen on LinkedIn post```.
In general, at 2023-10-21 05:15:25 a user named magic8437 said ```anyone encountered situations where the agent who shouldn't reply to a query is suddenly jumping in the middle of conversation and reply to a question that its not related to it? that include the same agent who tasked to the other agent reply to its own query by sudden```.
In general, at 2023-10-21 04:40:24 a user named asolis_dev said ```Hi, I just saw a Youtube video```.
In general, at 2023-10-21 04:14:13 a user named itrype said ```hello, I saw a YT videos, how someone used autogen combined with lm studio and wanted to explore it. Amd joined the discord from github```.
In general, at 2023-10-21 00:46:48 a user named martin.chesbrough said ```Hi, I just found this community from the github repository - interested to learn```.
In general, at 2023-10-20 20:32:36 a user named bart9154 said ```Anyone know if local (windows pc nvidia 3070) autogen is on the horizon?```.
In general, at 2023-10-20 20:08:52 a user named dakoller. said ```I am looking for good examples, where people subclassed the ConversableAgent with reply functions. My goal is to do some outside-of-llm processing with the work results, which are generated by agents. (like eg writing reply to a local file)```.
In general, at 2023-10-20 19:07:35 a user named 0xe8d4a51000 said ```Hi all,
Love the idea of integrating XAgent with Autogen x MemGPT
Props to @beer23  
Check this issue if interested: 
https://github.com/OpenBMB/XAgent/issues/47```.
In general, at 2023-10-20 19:05:49 a user named divine9879 said ```Still learning so I don't think I have a feature I want to add until I get to know the code```.
In general, at 2023-10-20 19:05:25 a user named divine9879 said ```Well honestly I am learning on how to use LLM much better so I dont have a idea as of yet```.
In general, at 2023-10-20 19:04:45 a user named divine9879 said ```Well start I started playing with AutoGen by watching a microsoft video about LLM```.
In general, at 2023-10-20 18:18:25 a user named kheprithoth said ```Hey everyone, just learning AutoGen... Anyone have an idea why my UserProxyAgent would auto reply with empty messages? It kicks off great, but then the agent is out drunk for lunch while the AssistantAgent is magically replying to his empty messages...```.
In general, at 2023-10-20 18:18:15 a user named bbderoff said ```building an app with a PAWN variety for IoT```.
In general, at 2023-10-20 18:17:19 a user named bbderoff said ```Hmm, it looks like peeps use this channel for anything but telling how they know Autogen...```.
In general, at 2023-10-20 17:56:16 a user named nickinparadise_1 said ```Has anyone had success using Autogen for large but very specific research projects? I'm struggling.

For example, I'm building a non-profit dedicated to bringing AI to developing countries, with a focus on helping them achieve the SDGs by working with Government and NGOs to spread AI tools and training, and I've got a bunch of research tasks I want to do ASAP. I'd rather use AI rather than interns/volunteers to get the work done. I'd also love some help if anyone wants to contribute. Here's the list of stuff I'd like to work on if anyone has suggestions on tools/strategies to help:

- [ ] Research Investment Opportunities (e.g. VCs, Seed Investors, Accelerators, Incubators, Innovation Funds, etc.) with a focus on deadlines in the next 2-months or open all year round
- [ ] Research Grant Opportunities (e.g. development banks, INGOs, government funds, UN agencies, etc.), either open ended funding or with a specific RFP/mandate posted, with a focus on deadlines in the next 2-months or open all year round
- [ ] Research Job Boards and Communities where we might find volunteers and staff for the project (e.g. job boards for Caribbean countries, job boards for our 32 identified audiences, and communities on LinkedIn, FB, Discord, etc. where our audiences spend time)
- [ ] Research each Caribbean country to develop a profile on their government stance on AI and achieving the SDGs, especially related funding opportunities and potential government agency partners
- [ ] Research all UN agencies, INGOs, and Development Banks with Caribbean operations
- [ ] Research stakeholders to invite to an AI4 Caribbean SDG Achievement community
- [ ] Research AI-powered tools and solutions that could help our audience (130 use cases identified)
- [ ] Developing our first product, a system for identifying grant and funding opportunities for us and our clients, and drafting applications for those opportunities based on the requirements of each donor```.
In general, at 2023-10-20 17:44:19 a user named pixelart42 said ```I'm trying to run a 13B LLM locally on LM studio with a 3060ti and 64gb of ram, but I'm only getting 3 tok/sec.  Any suggestions?```.
In general, at 2023-10-20 17:10:47 a user named morfes said ```https://youtu.be/xZDB1naRUlk```.
In general, at 2023-10-20 16:52:12 a user named modularsushi168 said ```Could this algorithm not just get used for code?

```
Input: Seed improver I0, language model L, recursion depth T, collection of downstream tasks D
Output: An improved improver IT
for t = 1 to T do
It ← It−1(ˆu, It−1, L) // Update improver based on meta-utility uˆ
return IT // Return the final improver
Function u˜(I):
utility_sum ← 0 // Maintain sum of downstream task utilities
for (u, S) ∈ D do
S
′ ← I(u, S, L) // Improve initial solution S using improver I
utility_sum += u(S
′
) // Add the utility of the improved solution
return utility_sum/|D| // Return the expected task utility
``````.
In general, at 2023-10-20 16:12:04 a user named sonichi said ```Maybe we should prevent code suggestion from the beginning, if the goal is to not do any code execution. The default AssistantAgent is instructed to suggest code. So, either need to modify the system message or need to explicitly prevent in the initial user message.```.
In general, at 2023-10-20 16:10:13 a user named magic8437 said ```e.g. i have 7 agents,  1 of them is Executor who should execute the code, but in the logs, i can see all other 6 agents actually picked up the code, and respoding with such statemetn as "I cant execute code,etc." How to prevent them to responding to code executions?```.
In general, at 2023-10-20 16:08:19 a user named magic8437 said ```I did, but it still **attempt **execute when there is a code within code block e.g. ``` bash ifconfig ```,```.
In general, at 2023-10-20 15:50:21 a user named magic8437 said ```is this something that anyone aware of?```.
In general, at 2023-10-20 15:47:37 a user named afourney said ```You’ll be summarizing small windows at a time, then assembling those somehow```.
In general, at 2023-10-20 15:46:54 a user named afourney said ```Well you will still need some sort of strategy to handle the long text. LangChain has several options. Think map-reduce or linear chain type approaches```.
In general, at 2023-10-20 15:43:31 a user named ianthereal said ```Is local llm efficient for gigabytes data?```.
In general, at 2023-10-20 15:41:52 a user named afourney said ```They are pretty good at such tasks```.
In general, at 2023-10-20 15:40:06 a user named magic8437 said ```Is there anyway to summarise the data without sending it to LLM? thats going go cost a lot to send gigabytes of data to gpt to summarise```.
In general, at 2023-10-20 15:39:05 a user named afourney said ```But it depends on how amenable the data is to summarizing```.
In general, at 2023-10-20 15:38:26 a user named afourney said ```Yes thanks for sharing. That’s an interesting problem for sure. Summarization might be the way to go. And you could propose hypotheses “from the summaries, I think X is missing”, and the *go back and check* the hypothesis (because the summary could certainly have missed it)```.
In general, at 2023-10-20 15:36:17 a user named magic8437 said ```I hope I dont sound stupid 😄 hah```.
In general, at 2023-10-20 15:34:53 a user named magic8437 said ```If I want to know what does exist in the data, I can use Retriaval QA similar in langchain, then ask the Agent a question and that can find the answer within the data, But. but my question is, What does NOT exist in million lines of code, is 1 line missing? I am trying to share more context now so you understand my problem better.```.
In general, at 2023-10-20 15:32:45 a user named magic8437 said ```To just share why I have hard time here, let me summarise it, what I am doing is a reverse find, means to read everything and tell me what doesnt Exist within the data. and not to tell me What Does Exists```.
In general, at 2023-10-20 15:32:40 a user named radman1000 said ```@magic8437 Would love to see what you end up with, if you’re able to share.```.
In general, at 2023-10-20 15:30:59 a user named radman1000 said ```@magic8437 Another way to think about, similar to @afourney ‘s suggestion, is how would your best software developer approach it? They cannot keep millions of lines of code nor DB records in their head at the same time. But they can easily open up dozens of files, read (and summarize) them and determine a dev approach. Try to create a similar approach using agents.```.
In general, at 2023-10-20 15:30:53 a user named magic8437 said ```Another question, is there anyway to restrict the agents not to execute_code and only use the provided function? I already mentioned in the sys message not to execute code but it still does 😄```.
In general, at 2023-10-20 15:30:23 a user named afourney said ```Let us know how it goes. It's an interesting case```.
In general, at 2023-10-20 15:30:02 a user named magic8437 said ```Thanks @everyone, appreciate it, very helpful comments and i think i have lots to try now based on above suggestions, probably going to use a mixture of them```.
In general, at 2023-10-20 15:27:47 a user named afourney said ```In any case, this particular situation requires some customization, for sure.```.
In general, at 2023-10-20 15:26:31 a user named afourney said ```Another possible arrangement is the following:  Assume agent A is like the user_proxy -- it's mainly there to execute code, and doesn't have context window restrictions. Assume agent B is the usual AssitantAgent, and is calling GPT4 with like a 8 or 32k context window. What you need is a 3rd intermediary agent, Agent C, with a communication graph A - C - B. Agent C should be a specialized subclass of the Conversable Agent that either summarizes, or does passage retrieval on the long messages A is sending to it, and only forwards the results of that step to B.  Meanwhile messages from B to A are passed unmodified. Think of this like a traffic control officer that is handling a lane reduction, but only in one direction of the Freeway.  Now, Agent C could use any number of techniques to do this, but an in-memory ephemeral RAG or something could work reasonably well.```.
In general, at 2023-10-20 15:22:32 a user named ianthereal said ```I don’t have a real-world example to provide; most of the agents I have encountered are just for interaction, generally avoiding the transmission of a large amount of data due to the limitations of the LLM window. (But I think you issue a good problem```.
In general, at 2023-10-20 15:21:36 a user named radman1000 said ```@magic8437 Here’s RAG in AG: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb. And another variation: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_RAG.ipynb. I haven’t used those yet (still working my way thru other AG notebooks. Here’s examples in LangChain that I have used to let LLM search website with thousands of pages: https://python.langchain.com/docs/modules/data_connection/retrievers/. The LC docs also have many other retrieval examples. What they do in LC is very similar to what you can do in AG.```.
In general, at 2023-10-20 15:21:31 a user named ianthereal said ```Optimization ideas:

* Not using the agent approach to accomplish these tasks, and returning to the classic big data processing methods.
* Consider paginating the output content or providing a summary to display it more effectively within the limited window. Also, consider optimizing the execution of commands, for example, by making queries or analyses more precise to reduce the output content. Numerous conditions have been put forward, such as the design of agents A and B should be sufficiently flexible to adjust and optimize according to the limitations of the output window and actual needs.```.
In general, at 2023-10-20 15:21:00 a user named ianthereal said ```The assumption is that the agent's prompt and output windows are limited. Given this premise, the example of interaction between agent A and B mentioned above might not be quite suitable due to the inherent restrictions.```.
In general, at 2023-10-20 15:17:12 a user named magic8437 said ```I am already doing something similar, the problem is, the other code-capable agent hits a roadblock, as the content of the really_long_pdf is exceeding the max length..```.
In general, at 2023-10-20 15:14:43 a user named afourney said ```For example, if an agent says “i parsed that really long pdf and saved it’s text to really_long_pdf.txt” or “I ran that db query and saved the results to tuple.csv”, then other code-capable agents can hopefully pick up the task from there.```.
In general, at 2023-10-20 15:10:39 a user named afourney said ```Yeah exactly. One of the ideas is that agents should be reasonably composable and modular. Using the messages for coordination in this case is a good pattern, as it makes no major assumptions about context windows or capabilities of other agents.```.
In general, at 2023-10-20 15:09:33 a user named magic8437 said ```Any samples you have that can be shared using MPP pattern in similar situation?```.
In general, at 2023-10-20 15:07:28 a user named ianthereal said ```In the real scenario, we hand large data in MPP pattern, prompt / output window is just for communication```.
In general, at 2023-10-20 15:05:09 a user named magic8437 said ```Is there any similar solution that you are aware of that you can share? E.g using RAG or a custom agent```.
In general, at 2023-10-20 15:03:14 a user named afourney said ```And it probably uses RAG or some other summarization strategy```.
In general, at 2023-10-20 15:02:58 a user named afourney said ```And for that you probably need to write a specialized subclass of conversable agent```.
In general, at 2023-10-20 15:02:39 a user named afourney said ```But Agent A will still need to be able to process it yes```.
In general, at 2023-10-20 15:02:27 a user named afourney said ```Including the group chat manager```.
In general, at 2023-10-20 15:02:19 a user named afourney said ```It depends on the setting, group chat or not? This keeps the long context out of all the other agent’s windows```.
In general, at 2023-10-20 15:00:38 a user named magic8437 said ```Ok lets assume agent B execute the code and output the file path, and send it back to Agent A, agent A still needs to load that file again as within chat context to analyze it. Am I right?```.
In general, at 2023-10-20 14:59:10 a user named afourney said ```I’d have to learn more about the specifics here but a lot can be done with system prompts: Something like, when writing code, avoid printing large amounts of text to the console. instead, write it to a file, and then output the file path.```.
In general, at 2023-10-20 14:58:21 a user named magic8437 said ```Currently. i do not have static functions, e.g. DownloadFile, or ListFiles. I have a single function which is ExecuteCommand. Agent A will send the necessary command to agent B, and the agent B will execute that using the single function it has, the command can be a "ls /", or curl google.com or ifconfig or whatever else.```.
In general, at 2023-10-20 14:55:54 a user named magic8437 said ```It really depends on what agent A is asking, if it task Agent B to find all the files on the disk for the purpose of reading all the comments, then agent B will need to return all the files, and Agent A will read all the comments in files to know what it want to know. 

Also, its not always file. Agent A might ask agent B to download a very long webpage, and return the result, then agent A will get the response and analyze the page source code to look for what it was looking for```.
In general, at 2023-10-20 14:54:15 a user named afourney said ```Have whatever code agent B is running write to a file instead of printing to console```.
In general, at 2023-10-20 14:53:08 a user named magic8437 said ```For example, its a list of files exist on the system. And Agent A will need to analyze those files to find for a dynamic query which will be decided by agent depending on the task```.
In general, at 2023-10-20 14:51:16 a user named frank.martinez said ```What’s the purpose for those millions of lines of code?```.
In general, at 2023-10-20 14:49:37 a user named magic8437 said ```Agent A is tasking Agent B to run a code which returns millions of lines. And pass the result back to Agent A for further analysis. How can I do this with files?```.
In general, at 2023-10-20 14:48:43 a user named frank.martinez said ```Think about the structure of your code if an agent needs to parse all of it [millions of lines] to solve a problem; would be better to focus on functions or similar for agents to interrogate. Or is your logic built into your data?```.
In general, at 2023-10-20 14:46:53 a user named afourney said ```That keeps the long text out of the context windows.```.
In general, at 2023-10-20 14:44:51 a user named afourney said ```At scales like that, it's ideal to ask the agents to save their results to files rather than passing the results as messages through the conversation. You can pass the path to the file between agents, and they can use their own internal logic to do what they need to parse and process those files.```.
In general, at 2023-10-20 14:43:38 a user named radman1000 said ```@magic8437 Maybe consider some form of RAG with a vectorstore to hold the DB results, source code files, etc.?```.
In general, at 2023-10-20 14:43:24 a user named magic8437 said ```at the moment, I wrote a system message for a new agent that sends a snippet of the 1million records to the gpt4  to have a look and write a parser in python, so the agent can execute that code that is generated by gpt4 on runtime for the 1million line. but it sucks because too many invalid codes```.
In general, at 2023-10-20 14:42:06 a user named afourney said ```Millions of lines would be >> 100k tokens```.
In general, at 2023-10-20 14:41:35 a user named afourney said ```Claude is 100k last I checked.```.
In general, at 2023-10-20 14:41:00 a user named magic8437 said ```I think I am looking for unlimited context or something similar, too much to ask I know lol```.
In general, at 2023-10-20 14:40:09 a user named magic8437 said ```I cant find a way to filter the message. Imagine, the agent  is tasked to execute a code, which is to find all the users from the database, the result is massive, then further in the convo, the agent B is asked to share the list of files in the system, which itself is another massive data. Another task is to share the source code of the application... the nature of questions and the data that will be returned isnt the same structure too for me to write a parser to parse, the output can be anything in any length```.
In general, at 2023-10-20 14:39:15 a user named nickinparadise_1 said ```I believe Claude can handle that size of context? I haven't used it yet, and don't know it's coding ability, but was recommended to me recently for similar purposes```.
In general, at 2023-10-20 14:33:31 a user named afourney said ```Keep in mind that, just because the context window can hold many tokens, doesn't mean performance is great with long contexts. Many many times, less is more. So, some degree of filtering or passage retrieval, or finding another way to break down your problem, may be still the ideal way to go.```.
In general, at 2023-10-20 14:30:51 a user named afourney said ```Millions of *lines*? At that scale, you probably want to do some temporary indexing and passage retrieval or something (the passages can be long, like picking files in a project or pages of a pdf to focus on). If it were shorter and code-related, Llama Code has a context window of, I believe, 100k tokens.```.
In general, at 2023-10-20 14:12:52 a user named magic8437 said ```About MemGPT, I believe it has unlimited memory, so its going to help to resolve my current issue. As I am currently executing a code by AutoGen agent, which returns million lines of output, and it has to be analyzed for the next agent action.

I am looking for an smart way to use such big data as part of groupChat. I can't split the million lines of code and send back to gpt4 or 3.5, its going to be $$$. Is there any alternative for such use case that you are aware of if MemGPT isnt going to help?```.
In general, at 2023-10-20 13:45:42 a user named kevinwyr said ```Hello, I have added them here: https://github.com/microsoft/autogen/pull/316. Can you give it a review? 
There are no specific plan to integrate MemGPT into autogen, are you interested in it?```.
In general, at 2023-10-20 13:33:21 a user named ianthereal said ```🚀 Hi Innovators! We’re on an exciting journey, crafting our project with the magic wand known as autogen! 
https://github.com/ngaut/jarvis#demo```.
In general, at 2023-10-20 13:24:51 a user named magic8437 said ```@kevinwyr , thank you, by the way, is there any research going on about integrating MemGPT with AutoGen? I dont want to waste the time looking into it if someone else is almost there```.
In general, at 2023-10-20 13:18:02 a user named odrium said ```Hi. Going to develop a new feature for an existing project using autogen```.
In general, at 2023-10-20 13:08:08 a user named kevinwyr said ```thanks, gpt-35-turbo-instruct is a recent Completion model, I will update it```.
In general, at 2023-10-20 13:06:57 a user named magic8437 said ```Yes, I just double checked, these 2 are missing from the model list, both are for Azure OpenAi 
gpt-35-turbo-16k, 
gpt-35-turbo-instruct```.
In general, at 2023-10-20 13:02:55 a user named kevinwyr said ```OK, so that's the model from azure AI?```.
In general, at 2023-10-20 13:00:11 a user named magic8437 said ```I actually traced this, it seems there is no issue with the code. I was wrong, sorry my bad. but there is another issue, which is "gpt-35-turbo-16k" missing from the list of models so it doesn't know how to calculate its price```.
In general, at 2023-10-20 12:36:43 a user named kevinwyr said ```Thanks, I will look into that. @magic8437 How did you calculate the actual token? Are you using logs from autogenerate.oak.Completion?```.
In general, at 2023-10-20 12:31:11 a user named sonichi said ```@kevinwyr could you check this?```.
In general, at 2023-10-20 12:17:10 a user named quer1994 said ```I'm not deep in enough to help with that question. 

Does anyone experience timeout issues with long big groups? I'm trying to create a simple react application with a few agents. but i keep getting timeouts. Also it costs about 2 euros a run lol```.
In general, at 2023-10-20 12:00:02 a user named magic8437 said ```Has anyone validated the cost and print_usage_summary()  output? it seems this functions showing values very incorrectly. e.g. for me, the actual total token was around 400K, but the print_usage_summary showing 30K```.
In general, at 2023-10-20 11:26:15 a user named Danrui said ```Hi, everyone! AutoGen is a great project! I'm very interested in two questions: 1. what is the difference between AutoGen and ChatArena? 2. Can we customize our own tool except python code writting like what we can do in LangChain? @jiale_liu```.
In general, at 2023-10-20 09:36:02 a user named trader_pt said ```Odd, not sure why it would allow me to install the default distro but not check or prompt to enable the WSL, looks like it is disabled might be the issue

dism.exe /online /get-features /format:table

For the sake of those who come after me, enabling it required 

dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart```.
In general, at 2023-10-20 09:33:47 a user named trader_pt said ```Hmm, this is surprising, let's see how fast I can resolve it```.
In general, at 2023-10-20 09:26:57 a user named trader_pt said ```I haven't taken the time to really look at WSL, maybe I should.  I'm on Windows 11 on a fairly recent PC.  Is there a good getting started point you can recommend?  [EDIT: This seems pretty straight forward https://learn.microsoft.com/en-us/windows/wsl/install]```.
In general, at 2023-10-20 08:52:16 a user named .mickyang said ```I came across this project from a recommendation on Twitter and felt that it was very interesting.```.
In general, at 2023-10-20 08:17:18 a user named .princeps said ```@sonichi, @li_jiang @qingyunwu, along with everyone on the team, thanks for your hard work and the new updates```.
In general, at 2023-10-20 08:15:08 a user named .princeps said ```@here what is the difference between AutoGPT, Langchain Agents and Autogen ?```.
In general, at 2023-10-20 08:13:43 a user named iandjx said ```i think the easiest way to get this up and running is by loading the code on a virtual machine?```.
In general, at 2023-10-20 08:01:34 a user named mcss0599 said ```Not sure about the reason tho, since I can pull and build docker images on my python code(other project```.
In general, at 2023-10-20 08:00:09 a user named mcss0599 said ```I only run it successfully on GitHub codespace Jupyter. When on my local Pycharm, it said no packages of Python and run natively (and fail with request of “getting last week llm papers from arivx”```.
In general, at 2023-10-20 07:41:51 a user named iandjx said ```has anyone tried deploying autogen to the cloud with `use_docker` for code execution is set to true?
how did you do it?```.
In general, at 2023-10-20 06:35:39 a user named 0xe8d4a51000 said ```is it possible to execute non-python code?```.
In general, at 2023-10-20 04:04:34 a user named coderabbit said ```Hey all! Just started tinkering with AutoGen. Glad to see others are checking it out too!```.
In general, at 2023-10-20 03:32:48 a user named sonichi said ```The documentation is under website/```.
In general, at 2023-10-20 03:22:08 a user named seadude said ```I’m looking for the AutoGen documentation template, not the AutoGen code itself```.
In general, at 2023-10-20 03:14:51 a user named yorth_night said ```yeah, you can look through the codebase in github```.
In general, at 2023-10-20 03:09:29 a user named seadude said ```Hello! Is the AutoGen documentation open source? I’m stoked on the GitHub pages site.```.
In general, at 2023-10-20 03:00:26 a user named elshep said ```At the risk of turning my DMs into an absolute dumpster fire, I’d love to find someone to collaborate on putting together a few  music use cases for autogen. Drop me a DM if you might be interested```.
In general, at 2023-10-20 02:55:13 a user named x5ae said ```Hello, the overwhelming majority of examples of Autogen use are with python. Is Autogen useful for more project-structured languages, like Go, Rust, and Java?```.
In general, at 2023-10-19 22:54:53 a user named afourney said ```I used VirtualBox a lot before I joined MS. Now I run WSL... which is a really great way to use autogen (a number of the team members use it this way). If you are running a recent version of Windows, I'd highly recommend giving it a try.```.
In general, at 2023-10-19 22:52:25 a user named afourney said ```Ok, that will depend on a number of considerations, but maybe the folks over here can help: https://discord.com/channels/1153072414184452236/1158548894209282078```.
In general, at 2023-10-19 22:47:05 a user named stoicism said ```Just joined the server. Have started a bachelor degree in programming & AI. Looking forward to use this tool 😄```.
In general, at 2023-10-19 22:42:52 a user named .spcell said ```I want to use Mistral 7B as a local LLM```.
In general, at 2023-10-19 22:28:19 a user named afourney said ```Autogen itself requires very little. If using Docker to do isolation, see the system requirements of the Docker containers. If using local LLMs… well that is going to vary by model.```.
In general, at 2023-10-19 22:22:05 a user named afourney said ```Ok I’ve got a systematic way of testing this. Let me run it on 3.5 and see what happens.```.
In general, at 2023-10-19 21:19:32 a user named .spcell said ```Also can other LLms be used in Google Colab for AutoGen?```.
In general, at 2023-10-19 21:17:28 a user named .spcell said ```Question: what are system requirements to run AutoGen locally? How much VRAM is needed?```.
In general, at 2023-10-19 21:01:14 a user named chukypedro said ```I got to know AutoGen from a YouTube video by Mathew Berman, and post from different Linkedin Top voices.```.
In general, at 2023-10-19 19:39:06 a user named trader_pt said ```I'm in the middle of getting my environment moved over to a local Virtual Box Linux instance.  I did get docker going after a bit of wrestling but I've not done much yet.  It does work although I think I am orphaning instances, need to add details about cleaning up after itself, although there are multiple layers as I am in a python venv as well.  Haven't quite figured out all the pieces yet, still playing around.  Very much in agreement that determining what tasks are best suited and granular enough to use different models (hopefully including local models at some point) is a very good way to do it.```.
In general, at 2023-10-19 19:37:14 a user named vicengineer_ax said ```The models have been performing well, my current struggle is enable a docker container in the codespace. I keep running into an access error and im not familiar enough with Docker and Codespaces to figure it out at the moment.

The blend of agents has been very productive, I started out with just the manager being GPT4 for the agents but have since changed some of the other roles to GPT4 due to the complexities and code execution.

The GPT3.5 instruct has been doing very well at planning and organizing the other agents```.
In general, at 2023-10-19 19:33:57 a user named trader_pt said ```Very interested in how you make out, I'm contemplating a similar effort in terms of mixing models both to address limit issues and to control costs as my project is non-commercial.  I also want to have persistent knowledge and the ability to continue from the last point after being offline for some number of days by looking at the last set of work done that is stored locally.  I am iterating through a large inter-related data set```.
In general, at 2023-10-19 19:16:51 a user named code.ninja said ```Hi all. I have a large 1500 file legacy codebase with a mix of technology, old js and vue, and I would like to create an agentic system to systemically port that code to nextjs and create tests around the code it ports.

Anyone have any experience with this kind of effort?```.
In general, at 2023-10-19 19:07:16 a user named vicengineer_ax said ```I'm currently working on a mixed agent hierarchy system with a blend of GPT4, GPT3.5 Turbo 16k, and GPT3.5 instruct. Since many of us have rate limitations and access to GPT4 16k and 32k models I'm hoping the blend of models can be optimized to produce useful outputs```.
In general, at 2023-10-19 19:06:05 a user named vicengineer_ax said ```I'm having a similar issue with my autogen notebooks, i'm struggling to get a docker container working to see if that fixes the issue with code execution by the AI agents```.
In general, at 2023-10-19 19:04:11 a user named pierrunoyt said ```https://aiagent.app what is this```.
In general, at 2023-10-19 18:21:59 a user named karlka said ```nice, it looks like they've done pretty solid benchmarking/evaluation```.
In general, at 2023-10-19 18:16:13 a user named lawrence324 said ```Right now I'm using Autogen with LiteLLM-Proxy & Amazon BedRock (Claude2)  - It refuses to code anything and just says it's only a "helpful AI assistant".```.
In general, at 2023-10-19 18:13:07 a user named elcapitan__ said ```Anyone try using Retriever-Augmented Generation, or RAG from a memory standpoint.```.
In general, at 2023-10-19 18:10:45 a user named frank.martinez said ```Re: XAgent, https://youtu.be/X6dna0O6pCw?si=7hBewIvH6z7PGPzY```.
In general, at 2023-10-19 17:59:27 a user named karlka said ```100% agree, I guess it's because we're still so early and the tech is novel - we don't even know the best use cases yet, but we started to build internal team of agents to automate a subset of our day-to-day tasks - first use case was for marketing, but we learned, that it's very hard to evaluate if the agent's are performing up to our standards. we then started to work on research agents, to streamline our research processes, but again - not sure if we're improving the system by changing X or adding/removing X. This lead us to put more effort into evaluation - thinking about testing/benchmarking e2e and different parts of the system.```.
In general, at 2023-10-19 17:24:18 a user named beer23 said ```what is your team working on? would be cool to see. So few real life examples out there of agents being used. It is all just “here’s what the docs say” or “heres a super light version of an idea”```.
In general, at 2023-10-19 17:11:34 a user named karlka said ```Hey, started a discussion about testing, evaluating and benchmarking agent-based systems as I didn't find a good single source in this discord 🙏 https://discord.com/channels/1153072414184452236/1164611609721843912```.
In general, at 2023-10-19 17:06:21 a user named radman1000 said ```Just as an FYI, adding this line to the AssistantAgent config steers GPT-3.5 to work much better: ```system_message=autogen.AssistantAgent.DEFAULT_SYSTEM_MESSAGE + " For financial info, use yFinance."``````.
In general, at 2023-10-19 16:55:59 a user named beer23 said ```spinning it up now but it seems to be a type of “group chat” super agent. I’m envisioning using it as individual agents within AutoGen```.
In general, at 2023-10-19 16:51:50 a user named beer23 said ```anyone else feeling overwhelmed with all the new projects this week? We could make some crazy projects with XAgent + MemGPT + AutoGen```.
In general, at 2023-10-19 16:44:20 a user named radman1000 said ```I (mostly) just get the assistant writing code to get the current date (and user_proxy executing it correctly) but the assistant never writes code to get the stock prices for both companies. Then, the two agents enter into their "I apologize for the confusion...." loop - ie, assistant is somehow expecting user_proxy to get the stock prices without giving it any code. Once in awhile, the assistant will write the stock fetching code using yFinance but this only happens infrequently. I am using Windows and have tried both native and Docker exeuction environments. Also, I sometimes clear the cache after each run, just to be safe. Should I put up some code (I have tried the twoagent.py and python extracted from agentchat_auto_feedback_from_code_execution.ipynb)?```.
In general, at 2023-10-19 16:33:25 a user named madu.alikor said ```That auto intelegent response would be amazing```.
In general, at 2023-10-19 16:13:11 a user named warmonger9626 said ```Just saying I want to do a similar thing, answering random job offers I get. Based on offer Agent is going to prepare a customized CV, or just inform why an offer is not suitable.```.
In general, at 2023-10-19 16:01:06 a user named madu.alikor said ```can you create an agent with username/password for a specific job portal for example]```.
In general, at 2023-10-19 16:00:03 a user named madu.alikor said ```I want to create a group of agents to find and apply for jobs on my behalf using my CV as the input```.
In general, at 2023-10-19 15:58:13 a user named sidhujag said ```imo the best way currently is to create contexts within groups and then we figure out ways to do group to group comms to delegate tasks.. currently there is no LTM/STM and its all stored for quality reasons.. but seperating concerns on topics of a plan could be ag ood way to get around context length issues```.
In general, at 2023-10-19 15:56:14 a user named sidhujag said ```agents should be able to message a group or another agent and functions available to manage groups even invite other agents to join it```.
In general, at 2023-10-19 15:55:16 a user named sidhujag said ```yea im working on that now```.
In general, at 2023-10-19 15:11:24 a user named gubok said ```Would it be enough that the agents are added and removed from the GroupChat variable that is sent in in the run_chat function?```.
In general, at 2023-10-19 15:05:59 a user named gubok said ```I'm building an event based always running-solution that is creating AI-agents when they are needed, and discard the ones that no longer are useful.```.
In general, at 2023-10-19 15:04:58 a user named gubok said ```Quick question, is there a way the GroupChatManager to have AI agents join and leave during the conversation?```.
In general, at 2023-10-19 14:53:04 a user named gubok said ```Hello! Just started building my own autoGen project a couple of days ago, having SO much fun!```.
In general, at 2023-10-19 14:49:36 a user named amunratis said ```I think it is partially solved by the the fact that this is a multi-agent framework. - Meaning, for each task or role another agent is spawned that his has it's own context length.```.
In general, at 2023-10-19 12:44:21 a user named securemeup said ```Yes, you just need to update your docker file, line 17 if you haven’t modified it. Then push the image to your docker desktop

Line17 below
RUN sudo pip install -e .[test] #add other installs here


Push your image to docker and then use the below for user proxy and replace your image name and tag in the last section. In below example, use your naming convention for autogendocker and latest


assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
    is_termination_msg=lambda x: True if "TERMINATE" in x.get("content") else False,
)

user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    is_termination_msg=lambda x: True if "TERMINATE" in x.get("content") else False,
    max_consecutive_auto_reply=10,
    code_execution_config={
        "work_dir": "work_dir",
        "use_docker": ["autogendocker:latest"],
    },
)```.
In general, at 2023-10-19 10:34:45 a user named syndicate_47 said ```It also sounds like AutoGen is working on solving this problem internally, but in the meantime... chunking or what?```.
In general, at 2023-10-19 10:34:22 a user named syndicate_47 said ```It looks like some people recommend using models with larger maximum number of tokens, but that doesn't sound like it's a good solution```.
In general, at 2023-10-19 10:33:05 a user named syndicate_47 said ```How are you guys preventing AutoGen's chat history from growing too long? (openai.error.InvalidRequestError: This model maximum context length is X tokens)```.
In general, at 2023-10-19 06:09:16 a user named kajol9510 said ```Does Autogen Work with Claude or Titan LLM?```.
In general, at 2023-10-19 06:04:49 a user named shrikar4503 said ```Is there a way to let autogen use prebaked docker containers? ie I want to have a set of packages that I want to install and let autogen use it. I have seen autogen get into failure loop when it tries to install packages and not able to resolve dependencies.```.
In general, at 2023-10-19 04:42:14 a user named wonderkidshihab said ```is there any ways to tell autogen to call specific model for specific tasks?```.
In general, at 2023-10-19 02:42:10 a user named yorth_night said ```it might be something to look into later```.
In general, at 2023-10-19 02:42:00 a user named yorth_night said ```talking about finetuning gpt3.5, I have seen something about training the models as agents rather than LLMs can significantly increase their capabilities```.
In general, at 2023-10-19 02:35:29 a user named yorth_night said ```maybe if they decrease the pricing after November 7th, I can start messing with it```.
In general, at 2023-10-19 02:32:22 a user named yorth_night said ```for some reason the arxiv paper is taking long to show```.
In general, at 2023-10-19 02:30:56 a user named 330f_ said ```Thanks, also did u successfully did any successful experiment with fine tuning?```.
In general, at 2023-10-19 02:29:01 a user named yorth_night said ```https://www.youtube.com/watch?v=MkocIPcg5A8&ab_channel=SamWitteveen```.
In general, at 2023-10-19 02:28:30 a user named yorth_night said ```I think you can take the data from the paper and just stick to the normal finetune tutorial```.
In general, at 2023-10-19 02:28:07 a user named yorth_night said ```I can give you the paper that discusses this, and a tutorial to finetune gpt3.5```.
In general, at 2023-10-19 02:27:29 a user named 330f_ said ```Is there any tutorial for that, I am aware that we have to fine tune gpt-3.5-instruct```.
In general, at 2023-10-19 02:27:09 a user named yorth_night said ```gpt4 isn't open to finetuning so you can't change its behavior```.
In general, at 2023-10-19 02:26:44 a user named yorth_night said ```you just need a couple uncensored examples and you can change gpt3.5's behavior```.
In general, at 2023-10-19 02:24:31 a user named yorth_night said ```I hope it works well for you!```.
In general, at 2023-10-19 02:24:24 a user named yorth_night said ```1000s of pages might be problematic regardless, but still try out the langchain example```.
In general, at 2023-10-19 02:23:38 a user named yorth_night said ```not to feed it information```.
In general, at 2023-10-19 02:23:34 a user named yorth_night said ```nope, finetuning is to create a behavior for the model```.
In general, at 2023-10-19 02:23:13 a user named yorth_night said ```the langchain example should help a lot```.
In general, at 2023-10-19 02:23:06 a user named yorth_night said ```you need rag for that```.
In general, at 2023-10-19 02:21:21 a user named weaksauce.eth said ```Is that what finetuning is for```.
In general, at 2023-10-19 02:21:14 a user named weaksauce.eth said ```Say I want to train a chatbot to know about my company and industry, and I want to feed it 1000's of pages of docs```.
In general, at 2023-10-19 02:17:48 a user named yorth_night said ```you're not using much ram```.
In general, at 2023-10-19 02:17:41 a user named yorth_night said ```for this you don't need to pay```.
In general, at 2023-10-19 02:17:34 a user named yorth_night said ```finetuning open source models and stuff```.
In general, at 2023-10-19 02:17:25 a user named yorth_night said ```I pay, but that's for my personal stuff```.
In general, at 2023-10-19 02:17:12 a user named weaksauce.eth said ```Do you pay for Colab```.
In general, at 2023-10-19 02:17:08 a user named weaksauce.eth said ```Had trouble with Anaconda and VSC```.
In general, at 2023-10-19 02:16:53 a user named weaksauce.eth said ```Thanks friend. You've helped me a lot```.
In general, at 2023-10-19 02:16:39 a user named yorth_night said ```this is a much cleaner rundown```.
In general, at 2023-10-19 02:16:14 a user named yorth_night said ```https://microsoft.github.io/autogen/docs/Examples/AutoGen-AgentChat/```.
In general, at 2023-10-19 02:15:56 a user named weaksauce.eth said ```I have no interest in the chess one... maybe for coding```.
In general, at 2023-10-19 02:15:40 a user named weaksauce.eth said ```There's a lot here to choose from, what do you suggest as a basic starter```.
In general, at 2023-10-19 02:15:21 a user named yorth_night said ```though I personally don't have experience with the tool```.
In general, at 2023-10-19 02:15:21 a user named weaksauce.eth said ```Or any applications where you use an LLM to "chat with your documents"```.
In general, at 2023-10-19 02:15:12 a user named yorth_night said ```there is a langchain example```.
In general, at 2023-10-19 02:15:01 a user named weaksauce.eth said ```By the way Yorth do you have any experience with Langchain```.
In general, at 2023-10-19 02:14:54 a user named yorth_night said ```that happens a lot lmao```.
In general, at 2023-10-19 02:14:43 a user named weaksauce.eth said ```What if they're all hallucinating at once and can't even tell the other is```.
In general, at 2023-10-19 02:14:21 a user named yorth_night said ```yeah, having multiple agents call out each other's hallucinations is useful```.
In general, at 2023-10-19 02:13:59 a user named weaksauce.eth said ```So I guess this is your perfect solution!```.
In general, at 2023-10-19 02:13:51 a user named weaksauce.eth said ```The challenge with just using Chat GPT to write a novel is you're sitting there saying "continue" "continue" for days```.
In general, at 2023-10-19 02:12:52 a user named yorth_night said ```it just runs out of tokens before it gets to the meat of it```.
In general, at 2023-10-19 02:12:38 a user named yorth_night said ```though it does seem quite close```.
In general, at 2023-10-19 02:12:16 a user named yorth_night said ```I want it to write a full book from start to finish```.
In general, at 2023-10-19 02:12:05 a user named weaksauce.eth said ```or what type of task```.
In general, at 2023-10-19 02:12:03 a user named yorth_night said ```try it with gpt3.5 at the start```.
In general, at 2023-10-19 02:12:02 a user named weaksauce.eth said ```Are you trying to use it for coding```.
In general, at 2023-10-19 02:11:48 a user named weaksauce.eth said ```I see. So expensive though I am scared to run multiple agents ahah it will be fun to see though```.
In general, at 2023-10-19 02:11:22 a user named yorth_night said ```I guessed that if gpt4 isn't able to do the things I want it to do, the other ones won't either```.
In general, at 2023-10-19 02:11:18 a user named weaksauce.eth said ```Where can the button be found```.
In general, at 2023-10-19 02:10:45 a user named yorth_night said ```It's in every example in the github```.
In general, at 2023-10-19 02:10:24 a user named weaksauce.eth said ```And by the way have you tried running on any LLMs outside of OpenAI```.
In general, at 2023-10-19 02:10:09 a user named weaksauce.eth said ```or where do you recommend```.
In general, at 2023-10-19 02:10:05 a user named weaksauce.eth said ```Can I find the colab tutorial on the GitHub```.
In general, at 2023-10-19 02:10:00 a user named yorth_night said ```no cuda issues or anything```.
In general, at 2023-10-19 02:09:58 a user named weaksauce.eth said ```Wow it sounds too easy to be true 😄```.
In general, at 2023-10-19 02:09:48 a user named yorth_night said ```yep, u just run the code```.
In general, at 2023-10-19 02:09:36 a user named weaksauce.eth said ```I see OK. so it can replace VSC + Anaconda?```.
In general, at 2023-10-19 02:09:33 a user named yorth_night said ```it works the same as jupyter```.
In general, at 2023-10-19 02:09:15 a user named yorth_night said ```it's an ide in the cloud from google```.
In general, at 2023-10-19 02:08:49 a user named yorth_night said ```u can run it on colab```.
In general, at 2023-10-19 02:08:41 a user named weaksauce.eth said ```Hey guys, is it absolutely necessary to have Anaconda to run AutoGen?```.
In general, at 2023-10-19 02:08:39 a user named yorth_night said ```I hope the waitlist for the api wouldn't be too long once it's released```.
In general, at 2023-10-19 02:08:23 a user named yorth_night said ```there is also gemini that should be released soon```.
In general, at 2023-10-19 02:07:54 a user named yorth_night said ```being at the forefront of the tech is certainly an advantage```.
In general, at 2023-10-19 02:04:18 a user named sidhujag said ```Yup at some point it will be an exercise of smarter not harder```.
In general, at 2023-10-19 02:03:14 a user named yorth_night said ```sliding context window was introduced in a paper like 2 or 3 years ago, wasn't used in a useable model until mistral```.
In general, at 2023-10-19 02:02:35 a user named yorth_night said ```a lot of these papers are still pie in the sky```.
In general, at 2023-10-19 02:02:26 a user named yorth_night said ```also, the ideas you discussed are things you can make right now```.
In general, at 2023-10-19 02:01:28 a user named sidhujag said ```If the code for autogen becomes hardened and we find ways to represent code (can learn what it doesn’t know efficiently) I can see how the quality will jump exponentially regardless of drop off with bigger windows```.
In general, at 2023-10-19 01:59:01 a user named yorth_night said ```https://www.marktechpost.com/2023/10/14/how-can-transformers-handle-longer-inputs-cmu-and-google-researchers-unveil-a-novel-approach-fire-a-functional-interpolation-for-relative-position-encoding/ this```.
In general, at 2023-10-19 01:58:33 a user named sidhujag said ```You have plenty of params to distribute over```.
In general, at 2023-10-19 01:57:09 a user named yorth_night said ```I would have been afraid that performance will still be bad over long windows, but there is this FIRE paper deepmind released```.
In general, at 2023-10-19 01:56:13 a user named yorth_night said ```by that he means a limitless context window?```.
In general, at 2023-10-19 01:55:27 a user named sidhujag said ```Yeah if I’m right they will store KV to reduce costs.. then they can hopefully start pumping higher windows.. Sam was saying gpt5 may not even have a context window not sure how that would work```.
In general, at 2023-10-19 01:54:30 a user named yorth_night said ```rag might not even be necessary if we get the context windows big enough```.
In general, at 2023-10-19 01:54:16 a user named yorth_night said ```especially with stuff like llamalong etc```.
In general, at 2023-10-19 01:53:47 a user named sidhujag said ```I think fine tuning can come after.. if ever because things keep evolving.. stick to first principles to make generic blocks I think will work best.. once codebase is solid fine tune on that..```.
In general, at 2023-10-19 01:52:34 a user named yorth_night said ```is that only possible when you're just doing simple retrieval from a doc or does it make sense in this memory structure```.
In general, at 2023-10-19 01:52:12 a user named yorth_night said ```btw, I have seen some articles talking about finetuning the embed on the dataset for higher performance```.
In general, at 2023-10-19 01:51:33 a user named sidhujag said ```Yep, in some of my thinking I think observation is like reflection.. I like prompt breeding for semantic searches```.
In general, at 2023-10-19 01:50:34 a user named yorth_night said ```I guess reflection is almost implicit?```.
In general, at 2023-10-19 01:49:47 a user named yorth_night said ```(I'm saying this with a lack of understanding what promptbreeder really does. Just saw performance is up)```.
In general, at 2023-10-19 01:49:45 a user named sidhujag said ```Maybe.. I think reflection makes sense but perhaps not yet.. a top end interface with the user might see higher value in that, agents currently have specific jobs and we need to get them working to solve tasks first rather than be sims friends```.
In general, at 2023-10-19 01:48:23 a user named yorth_night said ```like promptbreeder for the prompting I guess```.
In general, at 2023-10-19 01:48:01 a user named yorth_night said ```though, I didn't see anything about prompting techniques/reflection```.
In general, at 2023-10-19 01:47:15 a user named sidhujag said ```I have one engineer taking a look at that perhaps starting with static analysis to initialize hierarchical tree like Remo, it’s a good area of research```.
In general, at 2023-10-19 01:45:47 a user named yorth_night said ```yeah, I was reading through your thread, the dynamic assignment one, and it was super interesting```.
In general, at 2023-10-19 01:44:31 a user named sidhujag said ```I think maybe you can also use to search the space of code repositories maybe too, to do dynamic search and inference on working with existing code etc.. ie: meta program autogen agents by making 2 groups one for planner one for execution```.
In general, at 2023-10-19 01:41:27 a user named yorth_night said ```it's crazy how ahead of the curve some of his stuff was/is```.
In general, at 2023-10-19 01:41:07 a user named yorth_night said ```I remember watching dave's vid about it like a year ago```.
In general, at 2023-10-19 01:34:50 a user named yorth_night said ```I searched around and found this repo. Is it the one you were mentioning here? https://github.com/daveshap/REMO_Framework```.
In general, at 2023-10-19 01:24:37 a user named sidhujag said ```Broadcast function vs local function```.
In general, at 2023-10-19 01:24:00 a user named sonichi said ```When one agent does both proposal and execution, the chance to confirm/reject the execution is lost.```.
In general, at 2023-10-19 01:22:22 a user named sonichi said ```One scenario to break down the proposal and execution is: when one wants to insert an inspection step before executing.```.
In general, at 2023-10-19 01:19:57 a user named sidhujag said ```1) call another agent to run fn - make message 2) run function for myself (self executing and invoking) those are the 2 options where right now it’s seperate agents doing function```.
In general, at 2023-10-19 01:18:57 a user named sidhujag said ```Yea I mean I think it’s more intuitive that way instead of forwarding the next agent that can execute it```.
In general, at 2023-10-19 01:18:54 a user named sonichi said ```I just don't want to exclude other options```.
In general, at 2023-10-19 01:18:20 a user named sidhujag said ```Shouldn’t there be a generic message that can invoke a function on another agent if we want another agent to run one?```.
In general, at 2023-10-19 01:18:16 a user named sonichi said ```I didn't say no to self executing function agents 🙂 It can certainly be used if that's the preferred option.```.
In general, at 2023-10-19 01:16:47 a user named sidhujag said ```@sonichi why not self executing function agents? I saw your github proposal… why is it seperate agent to execute the function to begin with?```.
In general, at 2023-10-19 01:14:30 a user named cdlima said ```Hi everyone !! I’m pretty new to discord and pretty new to AutoGen 😊 but I’m fascinated with the possibilities … is there any documentation about the roles agents can play using Azure OpenAi ?```.
In general, at 2023-10-19 00:31:22 a user named anderic. said ```how to use autogen write java code```.
In general, at 2023-10-18 23:49:55 a user named kajatta said ```Same advice as above except use this for step 2
https://python.langchain.com/docs/integrations/toolkits/sql_database```.
In general, at 2023-10-18 23:33:57 a user named kajatta said ```Correct yes. 
1) Use this https://github.com/microsoft/autogen/blob/main/notebook/agentchat_langchain.ipynb

2) Then add this
https://python.langchain.com/docs/integrations/toolkits/github

3) Pass the toolkit.get_tools() into the bridge.

4) Interact the AutoGen agents (set what role and how useful they are as guidance in the prompt)```.
In general, at 2023-10-18 23:30:33 a user named kajatta said ```Im ex Microsoft but we are great friends 😆```.
In general, at 2023-10-18 21:51:07 a user named biggboii. said ```that's where you will define everything```.
In general, at 2023-10-18 21:51:02 a user named biggboii. said ```You need to create the app.py file yourself```.
In general, at 2023-10-18 21:45:08 a user named vermino said ```I don't think you are missing anything. What problem are you running into?```.
In general, at 2023-10-18 21:41:09 a user named alexandre.bess said ```Hi People! I am Alexandre, from São Paulo, BR. I came in to learn about autogen and maybe find somebody want apply the knowledge in practice. could be young but curious and hands on. But need to speak portuguese and would be very good is lives in SP.```.
In general, at 2023-10-18 21:39:38 a user named palmbeachbadboy said ```Multimodal Ai Agents that can play tennis/ping pong```.
In general, at 2023-10-18 21:38:41 a user named palmbeachbadboy said ```saw a tweet by Thomas Roccia involving AutoGen and read an Ai Agents Market Map```.
In general, at 2023-10-18 21:19:39 a user named jb_5579 said ```I tried to hook up Autogen today to my local LLM Studio server using your video. My files that AutoGen installed look very different than yours. I don't have an app file to make config change.  Just a OAI_ Config_list.  Any thoughts on what I am missing.```.
In general, at 2023-10-18 21:11:05 a user named slono said ```Just discovered the paper and ran the first test! into agents lately```.
In general, at 2023-10-18 20:40:01 a user named culdz. said ```have people tried to generate anything else that python with autogen ?```.
In general, at 2023-10-18 20:39:21 a user named culdz. said ```@biggboii. brought me here. Hello guys```.
In general, at 2023-10-18 19:55:00 a user named karlka said ```anyone built some examples using this already?```.
In general, at 2023-10-18 19:30:59 a user named securemeup said ```Fine tuning for autogen would be tricky due to the dynamic nature, I’m not sure how fine tuning would benefit, but would love to hear about others that have fine tuned with success for autogen. The system message is powerful enough IMO 

To reduce steps for certain tasks where installs are needed, I’ve found implementing a docker image with needed libraries, reduces costs by not needing to leverage the agents to do pip installs```.
In general, at 2023-10-18 19:19:01 a user named dephar said ```Is there a GUI for Auto Agent around?```.
In general, at 2023-10-18 19:18:14 a user named dephar said ```Learned about it on Youtube```.
In general, at 2023-10-18 18:15:01 a user named sidhujag said ```just take a static analysis tool and represent that in something like REMO perhaps, something to try```.
In general, at 2023-10-18 18:14:14 a user named sidhujag said ```imo hiearchical graph interpretation of main program structure is a good way to maybe supplmenet or replace fine-tuning needs.. almost use an agent to represent the repo in a taxonomical graph, and use tests as examples (semantically looked up in the same graph tree representation).. to answer queries about how to do something with a codebase (use that for meta-programming with that codebase like autogen)```.
In general, at 2023-10-18 18:12:38 a user named biggboii. said ```Makes me so happy to get more people on the autogen awesomeness```.
In general, at 2023-10-18 17:46:24 a user named rudeboy.rudy said ```Learned about autogen via @biggboii. youtube channel.```.
In general, at 2023-10-18 17:28:47 a user named virtualestateplanner said ```I found autogen through @biggboii. 's (phenomenal) youtube videos on the topic.  Looks amazing, just trying to see what people have done with it so far.```.
In general, at 2023-10-18 17:27:56 a user named kr127e said ```Is fine tuning in this context ideally supposed to generate more consistently well-structured results from the intermediate steps in the logic, or what exactly? I suppose each individual piece would work better if fine tuned for its prompt format right?```.
In general, at 2023-10-18 17:27:02 a user named somecomputerguy said ```I just tell agents now to precede code with #!/bin/bash 😂```.
In general, at 2023-10-18 16:58:00 a user named jesserigon said ```@lessuse for this I use cody.sourcegraph.com chatbot. no sense recreating the wheel. limited use per day as they dont have a public paid tier, only Enterprise but if you use it specifically for repo questioning and not programming help should still be useful amount```.
In general, at 2023-10-18 16:17:00 a user named somecomputerguy said ```It was a shell command, but did not ID as shell```.
In general, at 2023-10-18 16:16:40 a user named somecomputerguy said ```Been seeing this error recently, it used to work fine, anyone else seen this?```.
In general, at 2023-10-18 16:16:29 a user named .jirito said ```Openai is currently trying to tackle this obstacle right now, as they haven't been too successful with winning over businesses to utilize their platform, simply due to cost. It was actually just last week, info was leaked that Openai is going to be announcing something big at their Openai conference on Nov 6th, in terms of cutting costs by 10x for developers. Apparently they're implementing memory storage into their backend, to allow for cost-savings.

I'm not sure if this means this will mean cost-savings via enhanced RAG/ long-term memory, or they are directly reducing API pricing. Hopefully both, seeing as to how AutoGen exposes the true cost of agents.```.
In general, at 2023-10-18 16:12:15 a user named afourney said ```Yes two agents works rather well. Group Chat is where I’ve seen a larger difference.```.
In general, at 2023-10-18 16:09:25 a user named afourney said ```The cache looks at the whole context sent to the LLM. So, as you say, it works for replaying a sequence, but if the whole previous conversation isn’t available, or deviates from prior, it will result in a cache miss. What this means is that it’s good for some workflows but not others. If, for example, you are making calls to a web search interface where results change, then you’ll want to cache those results too, or else you won’t benefit from Autogen’s cache.```.
In general, at 2023-10-18 16:02:50 a user named afourney said ```Yes, many of us do. Microsoft Research, specifically```.
In general, at 2023-10-18 15:57:20 a user named JayPhil23 said ```Loving AutoGen.. so easy to work with```.
In general, at 2023-10-18 15:09:12 a user named beer23 said ```Also that video is exactly what I wanted thanks!```.
In general, at 2023-10-18 14:56:51 a user named beer23 said ```Do Autogen devs work for Microsoft?```.
In general, at 2023-10-18 14:45:42 a user named bobaleaux said ```There’s a really good YT video that does.

https://www.youtube.com/watch?v=4o8tymMQ5GM&ab_channel=IndyDevDan```.
In general, at 2023-10-18 14:31:35 a user named beer23 said ```anyone have a bunch of their own agents doing actual practical things for their day to day? Would be motivating to hear some examples.```.
In general, at 2023-10-18 14:11:18 a user named radman1000 said ```How well does gpt-3.5-turbo perform on AutoGen? Has anyone gotten a basic auto-chat to work (like twoagent.py) on this?```.
In general, at 2023-10-18 14:08:12 a user named iandjx said ```So i figured out that the cache is only good for replaying previous responses. Its not used to continue a conversation.
 To  continue a conversation. We should append the previous messages with the new prompt```.
In general, at 2023-10-18 14:02:14 a user named lessuse. said ```guys, is there any tutorial or github repo available for chatting with a github repository?, I am new to coding, and it would be really helpful to understand the code and basics this way. also, if there is a better approach, please let me know. also i know that we can use langchain for this, but I could not find any resources to get started.```.
In general, at 2023-10-18 14:00:58 a user named sidhujag said ```You can invoke the higher cost only on inference of the planning phase to create the agents then run the plan on regular```.
In general, at 2023-10-18 14:00:13 a user named sidhujag said ```I think autogen code is small enough that it wouldn’t cost too much to retrain on changes, but I’m not sure how to do evals to train on a codebase```.
In general, at 2023-10-18 13:58:55 a user named fxtoofaan said ```I’ve been asking for this for a while now```.
In general, at 2023-10-18 13:52:12 a user named sidhujag said ```Can it fine tune api/sdk of autogen? Then it can figure out how to code to meta program new agent configs?```.
In general, at 2023-10-18 12:25:03 a user named jiajou said ```I saw this project in Facebook A.I club and thought it was very interesting. I wanted to know more about it, so I found it here.```.
In general, at 2023-10-18 10:54:25 a user named morfes said ```https://youtu.be/QFCPjU52XNA```.
In general, at 2023-10-18 10:42:34 a user named rohanbalkondekar said ```I suspect, in this product they finetuned gpt 3.5

https://www.producthunt.com/posts/theycbot

If I have to make a similar app, what should be the right approach?```.
In general, at 2023-10-18 10:40:54 a user named rohanbalkondekar said ```I have been Fine-tuning LLMs (for enterprise) for a while now and the results seem promising.

(Done this For bank support chatbot, text to task, text to speech and speach to text) Using completely open source tech stack for cost and privacy (whisper cpp, llama cpp, coqui, etc)

Meanwhile Using AutoGen or Building GPT wrappers is also interesting but I am not sure about the long term costs that enterprise would want to bear.

Both Fine-tuning and gpt wrappers have their own Pros and cons, a mix would be best imo. 

what do you guys think, especially for enterprise?```.
In general, at 2023-10-18 09:58:02 a user named jimmysandwiches said ```I did briefly get to same point but the supposed UI (streamlit.py) didnt render so thats where im up to - I suspect its an early dev but looks interesting and will follow it  🥪```.
In general, at 2023-10-18 09:47:19 a user named _handuo said ```Found it on Github trend```.
In general, at 2023-10-18 09:39:07 a user named fxtoofaan said ```have you used this yet? I installed it and gave it a task, looks like it did first step and its at the prompt and blinking and not doing anything else.```.
In general, at 2023-10-18 09:13:17 a user named iandjx said ```im uncomfortable in using an inmemory database for caching. is there a way to use another database for cache purposes?```.
In general, at 2023-10-18 08:52:44 a user named kim_jin. said ```I found it on Github```.
In general, at 2023-10-18 08:40:22 a user named iandjx said ```instead of passing the messages should i pass the  seed of the previous conversation  the llm_config of the agents?```.
In general, at 2023-10-18 08:38:55 a user named iandjx said ```i have this code that sets up groupchat

```
    group_chat = autogen.GroupChat(
        agents=assistant_list, messages=request.messages, max_round=50
    )
```

i pass previous conversations in the messages parameter

then i proceed with initating a chat with this

```
    user_proxy.initiate_chat(manager, message=request.prompt, clear_history=False)
```
im expecting that my prompt will continue the conversation given that i have added the messages list to group chat but the AI doesnt have context of the previous conversation

what is wrong with my approach?```.
In general, at 2023-10-18 08:35:47 a user named cryptoslimshady said ```i saw it on youtube```.
In general, at 2023-10-18 05:50:47 a user named _g.a.i said ```From:
https://www.youtube.com/channel/UCawZsQWqfGSbCI5yjkdVkTA```.
In general, at 2023-10-18 05:42:29 a user named jimmysandwiches said ```Found this Autogen based repro with UI - maybe worth a look! - thought i'd share
https://github.com/shoutsid/townhall#installation```.
In general, at 2023-10-18 05:38:34 a user named rene9654 said ```We are exploring without autogen and API , direct in chatGTP4, how to create high quality content around a topic. Seeing autogen, we think this might bring it to a higher level. We are going to explore how our current solution can be "refactored" into an agent system. Thanks for this discord.```.
In general, at 2023-10-18 05:02:22 a user named sidhujag said ```This sounds interesting you should```.
In general, at 2023-10-18 04:48:43 a user named kajatta said ```This sounds interesting you should consider making a forum thread, so we can get nerdy!😂```.
In general, at 2023-10-19 16:52:15 a user named yorth_night said ```wait, let's say you're tool planner agent```.
In general, at 2023-10-19 16:52:31 a user named yorth_night said ```your context window only has the discussion of planner group, right?```.
In general, at 2023-10-19 16:52:57 a user named yorth_night said ```and if you need the info, you ask the head of the group, aka group planner```.
In general, at 2023-10-19 16:53:00 a user named sidhujag said ```yeah in that case planner group has context given to those inside it..```.
In general, at 2023-10-19 16:53:01 a user named yorth_night said ```is that how it works```.
In general, at 2023-10-19 16:53:19 a user named sidhujag said ```its upt o us how we want it to work but i would generlize or try to think how humans would have done it```.
In general, at 2023-10-19 16:54:20 a user named sidhujag said ```the tool planner in this case will know everything side the planner group if you can send a msg to it you can kickstart it to work on a plan.. write file and send the filename to someone else asking for the plan```.
In general, at 2023-10-19 16:55:30 a user named sidhujag said ```couple things i would change about current groups: Group once running needs consensus to stop execution. Upon new user clear this consensus and run it in loop again.```.
In general, at 2023-10-19 16:55:38 a user named sidhujag said ```When agent runs function call get a chance for him to respond again until TERMINATE```.
In general, at 2023-10-19 16:56:03 a user named sidhujag said ```could be yup, hence recursive..```.
In general, at 2023-10-19 16:56:36 a user named sidhujag said ```but in general i would maybe even let agents decide themselves by just giving ability to join, exit groups and be given a directive.. looking up tools to solve the job```.
In general, at 2023-10-19 16:57:00 a user named yorth_night said ```ah, but would that be reliable?```.
In general, at 2023-10-19 16:57:21 a user named sidhujag said ```i guess so? since all of the context is stored```.
In general, at 2023-10-19 16:57:28 a user named sidhujag said ```by itself gpt4 iq is pretty high right```.
In general, at 2023-10-19 16:57:42 a user named yorth_night said ```huh, I guess it's my own prompting then```.
In general, at 2023-10-19 16:57:55 a user named yorth_night said ```maybe with the right system message they could do it well```.
In general, at 2023-10-19 16:59:16 a user named sidhujag said ```yeah.. if we generalize as building blocks we can keep tweaking into specific things.. like agents might start off in a list of known good agent prompts that are selected in the planning phase if you need a planning phase.. or ppl might opt to manually create the groups with agents and then give them soveriegnty to go around to groups and asking for info```.
In general, at 2023-10-19 17:00:20 a user named sidhujag said ```like in metagpt the agent list gives 5-10 good ones to solve coding tasks and planning tasks.. we can reuse those to create a solid task planner if we want and coding.. but id let ppl come up with those and first just focus on the fundamental problem of agent/groups/messaging```.
In general, at 2023-10-19 17:01:42 a user named sidhujag said ```so to start i wouldnt even assume a planning phase.. just focus on what agents can do, how groups become messengers and what functions generally needed at agent level to make everything flexible```.
In general, at 2023-10-19 17:02:00 a user named yorth_night said ```okay, that sounds good to me```.
In general, at 2023-10-19 17:02:16 a user named yorth_night said ```so we work at the agent level right now```.
In general, at 2023-10-19 17:02:19 a user named sidhujag said ```last night i wrote down Group Admin Agent
Create group (purpose, query) - creates system message
Delete group
Add to group (send a hello message to group from new agent, to kickstart the group)
Remove from group(agent(s), reason)```.
In general, at 2023-10-19 17:02:33 a user named sidhujag said ```im not sure if we want to create a special group admin agent or not```.
In general, at 2023-10-19 17:02:49 a user named sidhujag said ```**Agent**
Read file
Write file
List files
Send message (message, from, to) - to can be group name or agent
Invite to group
Join Group
Leave Group
SearchTools
groups[]```.
In general, at 2023-10-19 17:03:05 a user named sidhujag said ```this is what i have. under agent object itself as functions or members```.
In general, at 2023-10-19 17:03:18 a user named yorth_night said ```let's go through this one by one```.
In general, at 2023-10-19 17:03:43 a user named yorth_night said ```read file and write file, is this for the purpose of finishing a certain task (coding, writing, etc)```.
In general, at 2023-10-19 17:03:47 a user named yorth_night said ```or is it for memory?```.
In general, at 2023-10-19 17:04:03 a user named sidhujag said ```yup or even a plan.. not memory but a common medium to pass around info or objectives```.
In general, at 2023-10-19 17:04:14 a user named sidhujag said ```maybe it ends up being memory who knows? depends how creative agents will assemble themselves to become```.
In general, at 2023-10-19 17:04:29 a user named yorth_night said ```yeah, it's just a tool that the agent will use as it wish```.
In general, at 2023-10-19 17:04:55 a user named yorth_night said ```so, I'm not familiar with function calling```.
In general, at 2023-10-19 17:05:06 a user named yorth_night said ```do you need to specify a token for the model to use?```.
In general, at 2023-10-19 17:05:17 a user named yorth_night said ```so that it uses a function that you interpret on backend```.
In general, at 2023-10-19 17:05:27 a user named sidhujag said ```you set the function map in the config```.
In general, at 2023-10-19 17:05:45 a user named sidhujag said ```yup then handle it when it gets called```.
In general, at 2023-10-19 17:06:30 a user named sidhujag said ```its like an action that comes to you right now its kinda weird in that if group speaker selector chooses another agent to speak and he doesnt have that function it will say funciton not found```.
In general, at 2023-10-19 17:06:50 a user named sidhujag said ```but if all agents have these handlers it will work.. this is more like first class agent object they all have the basic functionality```.
In general, at 2023-10-19 17:07:07 a user named yorth_night said ```soo, do current agents have any of these functions```.
In general, at 2023-10-19 17:07:30 a user named yorth_night said ```can I work on a test agent with these functions?```.
In general, at 2023-10-19 17:07:38 a user named sidhujag said ```yup i think good to start tinkering```.
In general, at 2023-10-19 17:07:40 a user named yorth_night said ```like can they be coded under the same class```.
In general, at 2023-10-19 17:07:54 a user named sidhujag said ```i think groups will change alot.. likely we will have a new group object```.
In general, at 2023-10-19 17:08:25 a user named sidhujag said ```we need a way to send/recv message to a group..```.
In general, at 2023-10-19 17:09:07 a user named yorth_night said ```hmm, so we need the group functionalities to change too?```.
In general, at 2023-10-19 17:09:08 a user named sidhujag said ```right now there is GroupChatManager which is an agent itself.. could you send msg to GroupChatManager?```.
In general, at 2023-10-19 17:09:27 a user named sidhujag said ```the current group object is very very simple.. prob better to clone it and then start tinkering in anew version of it```.
In general, at 2023-10-19 17:10:22 a user named yorth_night said ```hmm, so the work will be done on a new group object and a test agent```.
In general, at 2023-10-19 17:11:08 a user named yorth_night said ```I will look through the code of current agent and group, understand it and see how to move on```.
In general, at 2023-10-19 17:12:52 a user named sidhujag said ```you have a fork already? as you commit let me know so we dont dup work incase i have some ideas to try```.
In general, at 2023-10-19 17:13:32 a user named yorth_night said ```you already working on this part?```.
In general, at 2023-10-19 17:13:54 a user named sidhujag said ```not yet.. i was designing still.. we need to decide how these would be called Create group (purpose, query) - creates system message
Delete group
Add to group (send a hello message to group from new agent, to kickstart the group)
Remove from group(agent(s), reason)```.
In general, at 2023-10-19 17:14:10 a user named sidhujag said ```maybe any agent for now?```.
In general, at 2023-10-19 17:14:49 a user named yorth_night said ```yeah, probably a good idea to have a proper design first that anyone could look at and understand```.
In general, at 2023-10-19 17:15:18 a user named yorth_night said ```I was just motivated and wanted to get to coding as soon as possible```.
In general, at 2023-10-19 17:16:03 a user named yorth_night said ```but prolly better if we have a design that people agree on first. I guess, I'm not too familiar with open source workflow```.
In general, at 2023-10-19 17:16:05 a user named sidhujag said ```yea you can do it if you want```.
In general, at 2023-10-19 17:16:36 a user named sidhujag said ```i think current groups seem message-able already.. jus tneed to try it out```.
In general, at 2023-10-19 17:18:17 a user named yorth_night said ```so like a group has a list of message```.
In general, at 2023-10-19 17:18:28 a user named yorth_night said ```but you need a bigger entity that holds everything, I think```.
In general, at 2023-10-19 17:20:26 a user named yorth_night said ```or it can be recursive and have the potential to hold multiple groups within it```.
In general, at 2023-10-19 17:23:16 a user named sidhujag said ```lets decide on how to communicate group to group```.
In general, at 2023-10-19 17:23:46 a user named sidhujag said ```right now you can send msg to group.. it will broadcast and call run_chat in GroupChatManager```.
In general, at 2023-10-19 17:24:51 a user named sidhujag said ```every agent gets copied the msg so it will know full context within group.. then group chat select_speaker will be called to infer which is the next speaker (up to max_round times) to ask people to speak if they have something to say in the group```.
In general, at 2023-10-19 17:26:10 a user named sidhujag said ```so it coul dbe that once we add ability to send msg to group.. that if say Agent 1 in Group A sends message to Group B, then once Group B is happy at some point it can message back Group A with a response (completely unmanaged and dynamically)```.
In general, at 2023-10-19 17:27:16 a user named sidhujag said ```send message can be instructed to say, "if you expect a reply, please include in the message so that someone in the receiving group can send you a response"```.
In general, at 2023-10-19 17:27:39 a user named yorth_night said ```so, for group to group comm```.
In general, at 2023-10-19 17:27:45 a user named yorth_night said ```it would be a function call```.
In general, at 2023-10-19 17:27:51 a user named yorth_night said ```maybe from the group manager?```.
In general, at 2023-10-19 17:28:10 a user named sidhujag said ```well an agent can send message..group manager doesnt get a turn to speak afaik```.
In general, at 2023-10-19 17:28:30 a user named sidhujag said ```lets take this to DM to not clutter up the thread```.
In general, at 2023-10-20 09:30:30 a user named kajatta said ```Awesome list guys, very practical- I took the conceptual side of this discussion and moved it to another thread to talk it through.
https://discord.com/channels/1153072414184452236/1164857184685920291```.
In general, at 2023-10-20 18:32:25 a user named jesserigon said ```I think some project management document standards from the Project Management Institute might help you guys. The Project Management Plan specifically. For example, I would think their needs to be broader context given to all agents outside of specific groups that apply to all even if they are not part of any group. four specifically come to mind: Risk Register, a lessons learned register, Organizational Process Assets ( these dictate what checklists to use, what processes are used company wide, tools used in other projects, etc) and Enterprise Environment Factors (that affect the trajectory of the project that are out of scope or control of the project, usually legal and regulatory requirements).```.
In general, at 2023-10-20 18:33:54 a user named jesserigon said ```I guess you could make the CEO agent hold this context or a ceo group but if you did that it might increase costs as I forsee alot of agent communication back and forth trying to align the current project with broader values.```.
In general, at 2023-10-20 18:34:46 a user named jesserigon said ```or it could be cheaper, as you would need to provide that context to every agent. would be something that needs to be tested I guess.```.
In general, at 2023-10-20 18:55:45 a user named sidhujag said ```as a first step what i think we can do is just have them self-discover groups.. later start dictating how they should.. but imo those can be usecases built on top and prompted to do so```.
In general, at 2023-10-20 18:56:20 a user named sidhujag said ```here is what i mean.. my branch with some group functions for discovery and interaction without specific prompting on agent style or broader "company" guidelines```.
In general, at 2023-10-20 18:56:51 a user named sidhujag said ```https://github.com/microsoft/autogen/compare/main...sidhujag:autogen:main```.
In general, at 2023-10-20 19:47:32 a user named jesserigon said ```i understand the step by step mentality. Im just curious but what metric or assumptions the agents would use to self assign without a broader context? maybe Im missing something.```.
In general, at 2023-10-20 19:48:22 a user named jesserigon said ```do you mean the group manager agent, or by extension the agency as an entity, would self assign rather than individual agents?```.
In general, at 2023-10-20 19:49:53 a user named jesserigon said ```cause in the public part of the thread you mentioned a hierarchy but then you mention self assignment. i guess im confused at what level the "self" refers to here```.
In general, at 2023-10-20 19:51:26 a user named jesserigon said ```ill have to check the repo```.
In general, at 2023-10-20 21:53:38 a user named sidhujag said ```The idea is to create agency so they will decide to make a plan, we can also inject some of these agents as existing ones it can search for and find to give it the idea, but not instill a requirement that a PM or a planner is always needed```.
In general, at 2023-10-18 04:32:50 a user named sidhujag said ```autoagent/metagpt is also interesting, autoagent as it is is broken but brings auto assignment of agents and tools, and observation of actions to the table.. this is missing in autogen (no planning).. with autogen all of the plumbing still has to be built, im currently bringing autoagent things into metagpt again and making dynamic agent selection work, next will be dynamic tool selection through semantic lookup and an observation around the tool selection (consensus on the plan/roles/tools prior to starting work).. its about $1-$1.50 to create the plan prior to actual work```.
In general, at 2023-10-18 02:39:14 a user named freelandzd said ```Matthew Berman on Youtube brought me here```.
In general, at 2023-10-18 01:27:57 a user named aalva004 said ```Have a quick question what is the difference between semantic kernel and auto GEN right now I’m in the process of setting up a conversational bot and I have to make a decision whether I wanna go with langchain, chroma, DB, semantic kernel, autogen, pg vector, long term and short memory,etc. ideally, I would want something that I could immediately get some great benefits, since I already have the entire FE working.```.
In general, at 2023-10-18 00:57:13 a user named sonichi said ```@ilaffey has done that. Basically, you can use a function call to invoke a new group chat.```.
In general, at 2023-10-18 00:53:42 a user named .jirito said ```runpod / openrouter.ai / vast.ai / AWS bedrock / LM Studio -- All great options for LLM inferencing depending on your situation

So far, all of these require textgen webui's openai extension for API translation. (except for AWS Bedrock & openrouter.ai, its possilbe to directly call any of open router's models directly, after a couple of tweaks in python. so far this is the easiest, but most expensive option)

----
GPU Host | Price | Convenience

Openrouter | $$$$ | 5/5 - (api costs rack up very quick with autogen on GPT4-32K. i easily spent $35 just on a few test runs testing with autogen. but the results were fantastic, and easy to setup)
Runpod.io| $$ | 3/5
Vast.ai | $ | 3/5 -- (typically half the price of Runpod these days)
LM Studio | (free) | 3/5 (very convenient but dependent on user's hardware. even better than textgen ui, IMO)

AWS Bedrock + AWS Lambda + AWS Agents -- Still currently testing. Anthropic just recently announced Claude being accessible to all AWS users, and combined with AWS Agents, this seems like a very promising feature since AWS offers a Free Tier. Only issue, is AWS is very business oriented, and Agents are still in early access. There's a lot of hoops you need to jump through to sign up for AWS Bedrock (i.e you have to request access to the Claude LLM's, which requires you setting up a fake organization and putting in a credit card even though there's a free tier, and stating that you're only using it for testing purposes. Then you have to request access from the internal team by submitting a support case to have access to the Agents service. I had to sit through a 20 minute phone-call to figure this out)
Having free access to Claude, then staging Autogen on an AWS instance, and having all the agents using Claude, shows a lot of promise for overcoming the token limit for building applications.
My predicition for AWS: $$$ | 5/5 Convenience (Production-ready Claude v2 Agents out-of-the-box is a crazy thought)```.
In general, at 2023-10-18 00:32:54 a user named somecomputerguy said ```https://youtu.be/SQMZCQCWkCo - I made this video about AI ethics inspired by playing with autogen```.
In general, at 2023-10-17 22:18:19 a user named beer23 said ```can group chats work with group chats? Wasn’t able to find an example in the docs```.
In general, at 2023-10-17 20:27:12 a user named sonichi said ```use "api_key" instead of "openai_key" and make sure it's in your `llm_config````.
In general, at 2023-10-17 18:53:46 a user named b8454 said ```I was specifying turbo 3.5 I dont understand the gpt-4 error```.
In general, at 2023-10-17 18:53:17 a user named b8454 said ```I had something like config={"model": "gpt-3.5-turbo", ''openai_key'':''''}
but it showed this error as I said:
InvalidRequestError: The model `gpt-4` does not exist or you do not have access to it. Learn more: https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4.```.
In general, at 2023-10-17 18:51:57 a user named sonichi said ```you can. If you already have openai key set somewhere else, you only need `llm_config={"model": "gpt-3.5-turbo"}````.
In general, at 2023-10-17 18:35:06 a user named gcambefort said ```When PR on GitHub to add autogen to agent protocol?```.
In general, at 2023-10-17 18:15:16 a user named b8454 said ```Can't I just use my openai key without configs?

I did the config_list with my key and model gpt 3.5 but when I ran it says it's not valid key for gpt 4,even though I specified only for gpt 3.5```.
In general, at 2023-10-17 17:51:48 a user named jesserigon said ```I posted on the forum-discussion  https://discord.com/channels/1153072414184452236/1163701587244490763 about Microsoft guidance with autogen? I've googled but haven't found any useful info on incorporating both. Too dumb to figure it out myself. Anyone have any experience with both, is it worth it? Is it even needed? I would assume it's good for templating the responses of individual agents and maybe even injecting env vars that isn't part of the embeddings and such? Idk```.
In general, at 2023-10-17 17:41:43 a user named gcambefort said ```Hi everyone,  good question here```.
In general, at 2023-10-17 16:59:50 a user named afourney said ```Maybe I can help. What particularly are you having trouble with?  Some general tips: Make sure OAI_CONFIG_LIST is in the same directory as the script, and make sure to name the file exactly "OAI_CONFIG_LIST", with no extension (or specify an alternate filename in the config_list_from_json function). Watch the console: it should output warnings if something looks wrong.```.
In general, at 2023-10-17 16:44:35 a user named amunratis said ```is autgen using agent protocol ?https://agentprotocol.ai/```.
In general, at 2023-10-17 15:50:54 a user named sonichi said ```Make friends with @aayushc1308 🙂```.
In general, at 2023-10-17 15:48:40 a user named olpdy said ```Hi everyone,

I am planning to start working on a project where I will be using AutoGen. I really want to utilise the capabilities of AutoGen for this project. However, before I get started, I would like to understand the implications of using it commercially.

Is there anyone here who has experience using AutoGen for commercial projects? Could you please share your insights. 

Thank you in advance for your help!```.
In general, at 2023-10-17 15:39:29 a user named qingyunwu said ```Are you setting "human_input_mode" to "NEVER"? As shown in this example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb```.
In general, at 2023-10-17 15:34:01 a user named b8454 said ```damn so confused with the config list```.
In general, at 2023-10-17 15:07:48 a user named jimmysandwiches said ```not watched yet but will this eve - seems to be the biggest issue until openai (may) reduce dev costs - memgpt next *nudge```.
In general, at 2023-10-17 15:06:13 a user named biggboii. said ```i think i'm going to do another version but with runpod + textgen webui```.
In general, at 2023-10-17 15:05:41 a user named jimmysandwiches said ```yay you promised @biggboii. https://www.youtube.com/watch?v=10FCv-gCKug```.
In general, at 2023-10-17 14:38:12 a user named yorth_night said ```I can't find anything on remo```.
In general, at 2023-10-17 14:26:25 a user named sidhujag said ```MemGPT is lossy afaik, I think REMO might be a better way to do what MemGPT is trying to do.. havent gone in depth yet just intuition on design```.
In general, at 2023-10-17 13:58:21 a user named artholos said ```Hello friends. When my autogen user proxy runs code in the working directory, when the code executes it require my intervention to end if an exception is thrown, and then autogen takes over again. How might I get the code to run and end itself if it errors out?```.
In general, at 2023-10-17 12:50:08 a user named morfes said ```okay thanks I will try to do it that way```.
In general, at 2023-10-17 12:49:25 a user named yorth_night said ```it still works when you download with python```.
In general, at 2023-10-17 12:42:34 a user named morfes said ```I can't find download button!!```.
In general, at 2023-10-17 12:40:48 a user named yorth_night said ```also, isn't it still up? https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha```.
In general, at 2023-10-17 12:33:45 a user named yorth_night said ```I will have to check```.
In general, at 2023-10-17 12:33:43 a user named yorth_night said ```I think so, but don't quote me on it```.
In general, at 2023-10-17 12:33:28 a user named aaronward_ said ```Was it a distilled dataset they used?```.
In general, at 2023-10-17 12:33:19 a user named yorth_night said ```I heard something about that```.
In general, at 2023-10-17 12:33:05 a user named yorth_night said ```is it because of the data from gpt?```.
In general, at 2023-10-17 12:32:28 a user named morfes said ```@here did anyone here downloaded zephyr-7b-alpha ? it was removed from huggingface!```.
In general, at 2023-10-17 12:25:21 a user named yorth_night said ```possible improvements would prolly be in the rag part with all the new advancements we saw this week/last week (reranking etc)```.
In general, at 2023-10-17 12:23:53 a user named yorth_night said ```and that it has inner thoughts with which it handles the context (and whether it needs to retrieve/store/update data)```.
In general, at 2023-10-17 12:22:26 a user named yorth_night said ```my current understanding is that memgpt uses two types of memories, the first one is just a simple directory, the other is vector/embedding```.
In general, at 2023-10-17 12:20:05 a user named yorth_night said ```when in doubt, check the codebase```.
In general, at 2023-10-17 12:19:56 a user named yorth_night said ```of course, possible hallucinations are possible```.
In general, at 2023-10-17 12:19:45 a user named yorth_night said ```https://chat.openai.com/share/7d36bac9-8a0d-4f9e-ad98-771f39a7508b```.
In general, at 2023-10-17 12:15:28 a user named yorth_night said ```I have a gpt4 convo that details the entirety of the memgpt codebase I can share in a bit```.
In general, at 2023-10-17 12:14:50 a user named yorth_night said ```I think I got a sense of how this works, though just from an abstract perspective```.
In general, at 2023-10-17 11:26:18 a user named yorth_night said ```I'm still going through their code to understand what they're actually doing```.
In general, at 2023-10-17 11:25:56 a user named yorth_night said ```anyone working on implementing a memgpt-like approach with autogen?```.
In general, at 2023-10-17 11:23:08 a user named iandjx said ```Thanks @aaronward_ im trying to deploy autogen on a serverless function so  i'd like to disable caching altogether because i dont have access to an iin-memory db `autogen.completion.create` doesnt accept a `groupChatManager` so i'm guessing its used to send a prompt to one model only?```.
In general, at nan a user named aaronward_ said ```run the `autogen.Completion.clear_cache()` function directly```.
In general, at 2023-10-17 11:15:40 a user named aaronward_ said ```See here: https://github.com/microsoft/autogen/issues/165#issuecomment-1756371088

https://github.com/microsoft/autogen/blob/294e006ac9a35975bce896b4a525c732f7aee159/notebook/oai_completion.ipynb#L170```.
In general, at 2023-10-17 11:07:16 a user named iandjx said ```i noticed there is a `use_cache` argument in the `create1 function. how can this be used?```.
In general, at 2023-10-17 11:04:17 a user named iandjx said ```im currently just working on a prototype. is there a way to disable the cache?```.
In general, at 2023-10-17 10:55:41 a user named morfes said ```I'm still in the early stage of achieving this but it is possible I just a need to wire the operating system to use ssd as ram buckup or virtual memories.```.
In general, at 2023-10-17 10:54:55 a user named morfes said ```Just like Windows is using virtual memory on your hard disc same thing you need just ram to run the front and the back end will be ssd high speed as much as ram as well.```.
In general, at 2023-10-17 10:54:17 a user named morfes said ```SSD Is good for read and write speed and you can put a lot of them so you can boot up to one terabyte if you want to.```.
In general, at 2023-10-17 10:53:33 a user named vermino said ```I figured you could have a short-term RAM memory and either push to commit to SDD/HHD or flush it as a temporary session.```.
In general, at 2023-10-17 10:52:45 a user named vermino said ```oh wow, didn't even think about SSD/HHD. I mean it makes sense like a database.```.
In general, at 2023-10-17 10:52:15 a user named morfes said ```When I get my hardware up and running I will be running 24/7 LLM to figure out so many requests and many many agents running in the background.```.
In general, at 2023-10-17 10:51:30 a user named morfes said ```My original goal is to use SSD as the memory instead RAM, But I'm starting slowly until I get to that point which is possible if I just wire my hardware properly in my new operating system. But this is still a long way to go for it.```.
In general, at 2023-10-17 10:49:40 a user named vermino said ```yeah, personally think it's a game-changer; especially for RAG for intake and many multi-agents in a long task.```.
In general, at 2023-10-17 10:48:20 a user named morfes said ```It's still a long way to achieve my goals using AI but it is a good start and it will be ready in no time in my opinion.```.
In general, at 2023-10-17 10:47:51 a user named morfes said ```That was my vision earlier to build Operating system using ai and it seemed to be possible now I'm so excited to get my machine up and running and build the system from scratch.```.
In general, at 2023-10-17 10:45:37 a user named vermino said ```Yeah, still shopping for my parts as well.```.
In general, at 2023-10-17 10:44:39 a user named morfes said ```it's sound interesting at it's early stage. still new and it should improve in the coming days. I haven't started my local system yet, still building my hardware to get LLM work locally. almost ready. but we get news everyday now about AI improving and it's hard to keep track of what's new in the world of AI..```.
In general, at 2023-10-17 10:40:14 a user named vermino said ```Yeah, I was just trying to figure out if it uses RAM for it's memory. It seems very interesting to a local LLM perspective. I kind-of did some back of the napkin calculations and you could potentially have 190,000 words held in RAM on 126GB.```.
In general, at 2023-10-17 10:38:05 a user named morfes said ```https://youtu.be/JQoT5ewO_hc```.
In general, at 2023-10-17 10:38:04 a user named morfes said ```here is a video from the same channel talking about claude.ai, you will get more tokens from 9k to 100k```.
In general, at 2023-10-17 10:31:25 a user named vermino said ```So does memGPT work off RAM to increase it's token limits?```.
In general, at 2023-10-17 10:08:07 a user named morfes said ```https://youtu.be/Ipac-Zy32VA```.
In general, at 2023-10-17 09:56:21 a user named aaronward_ said ```clearing the cache after each time you instantiate agents is advised so they don't have memory of previous conversations (depending on your use case). If you want to keep previous conversations but start a new session each time, you can change the "seed" to a random number so it doesn't append the current conversation session to previous one (this prevents high costs as they would otherwise be sent in the request to the LLM even if they aren't relevant to the current conversation)```.
In general, at 2023-10-17 09:52:31 a user named aaronward_ said ```you can also do this using oai.completion.clear_cache()```.
In general, at 2023-10-17 09:40:19 a user named iandjx said ```is there a way to clear the cache?```.
In general, at 2023-10-17 07:59:01 a user named kajatta said ```It reads a txt file, but you can use many different toolkits to do more such as GitHub or file system etc```.
In general, at 2023-10-17 07:58:24 a user named kajatta said ```Yep pretty straightforward with functions here is an example https://github.com/microsoft/autogen/blob/main/notebook/agentchat_langchain.ipynb```.
In general, at 2023-10-17 06:28:07 a user named kevinraetz said ```You could create an agent, that reads your files and takes them as input yes, but in practice because of the context length it's much harder that that.```.
In general, at 2023-10-17 06:25:57 a user named Ali1993 said ```Thanks I see, so I could in theory just parse the content of the files and turn it into text and feed it as input?🤯```.
In general, at 2023-10-17 06:24:17 a user named kevinraetz said ```AutoGen is "just" a framework to organize communication between agents. You would have to code the functionality to access your file yourself```.
In general, at 2023-10-17 06:23:01 a user named Ali1993 said ```Hey guys, I just heard about AutoGen and wanted to mess around a bit with it but I have a question before I do.

Is AutoGen able to access my old code files/folder that I have on my Desktop, and is it able work on that?```.
In general, at 2023-10-17 05:42:57 a user named .princeps said ```https://youtu.be/JgVb8A6OJwM?si=lb5WtqWvwBCDbcK1```.
In general, at 2023-10-17 04:30:05 a user named sidhujag said ```https://github.com/geekan/MetaGPT/blob/main/examples/sk_agent.py```.
In general, at 2023-10-17 04:18:05 a user named amadad said ```I have an example in my project https://github.com/amadad/agentcy/tree/main groupchat1 and groupchat2, but still trying to sort it...```.
In general, at 2023-10-17 04:10:16 a user named alexchaomander said ```Ooo can you link me to that?```.
In general, at 2023-10-17 04:09:38 a user named sidhujag said ```Hey, nice to see you.. i saw metagpt integrated semantic kernel I was curious on how it can be used within autogen```.
In general, at 2023-10-17 03:56:25 a user named alexchaomander said ```Hi everyone! Alex here from the Semantic Kernel team! Excited to join you all in the AutoGen community!```.
In general, at 2023-10-17 03:04:23 a user named vermino said ```you can see the LLM just started to have 2 instances of talking to itself without my involvement.```.
In general, at 2023-10-17 03:02:13 a user named ventiwhiskey said ```Ill go check them out rn. Cost?```.
In general, at 2023-10-17 03:01:52 a user named vermino said ```Cool thing is you can use LM Studio to setup a local LLM server and then use something like autogen to use multi-agents```.
In general, at 2023-10-17 03:01:33 a user named ventiwhiskey said ```🤣  chat with itself```.
In general, at 2023-10-17 03:00:44 a user named vermino said ```LM Studio is a nice jumping off point into local LLMs. However it's very limiting when wanting to have something like multi-agents and RAG. Also (maybe this is just me) it like to break; where it will start to just chat with itself without a prompt from user-proxy.```.
In general, at 2023-10-17 02:58:16 a user named sidhujag said ```is it possible to fine tune gpt 3.5 so that we can meta-program agents?```.
In general, at 2023-10-17 02:57:11 a user named ventiwhiskey said ```Looking at converting Ethereum miner into a local llm server for api calls. Want to build an enterprise solution to my life. LOL I work in sales, real estate development, have undergrad in Real Estate Finance & Development, and am working on my MS Finance. Looking at setting up multi agent enviroment. Research and assistant in underwriting. Land site analysis, void analysis, etc. I have 2 3080s 10gb, 1 3070 8gb. Also, 3060 12gb in my desktop! 

I can get started with the autogen tonight though. LM Studio looks like a decent interface!```.
In general, at 2023-10-17 02:55:43 a user named vermino said ```haha I agree. I was just trying to test Roy's roleplay template on multi sessions. He went off the rails first prompt, so I had to run with it.```.
In general, at 2023-10-17 02:50:19 a user named kajatta said ```Haha that content is hectic 😅```.
In general, at 2023-10-17 02:43:06 a user named vermino said ```Yeah, I ran it locally. I mean if you are looking for a quick and dry cut, you could use LM Studio to get that accomplished. However if you are looking for some other interface, you would need to setup a LLM server like vLLM or liteLLM then connect with your GUI. LM Studio just kind-of does it all for ya.```.
In general, at 2023-10-17 02:26:23 a user named jb_5579 said ```Did you run this locally?  I was starting to play with the same concept but introduce it as a WhatsApp bot```.
In general, at 2023-10-17 00:43:03 a user named frank.martinez said ```Wow, the IndyDevDan YT videos are 🔥```.
In general, at 2023-10-17 00:33:43 a user named deedavid_15589 said ```Can it really be unlimited though?```.
In general, at 2023-10-17 00:32:30 a user named mbelik_75074 said ```from this Day in AI```.
In general, at 2023-10-17 00:29:38 a user named seek_vision said ```want to download a movie```.
In general, at 2023-10-17 00:15:34 a user named vermino said ```yeah GPT-4 is nice but can be costly, especially when you have multi-agents that communicate back and forth.```.
In general, at 2023-10-17 00:14:55 a user named vermino said ```If you got a good GPU or CPU you could load up your own local LLM. I am using LMStudio with a GTX 1660 Super. It ain't great but can still handle some stuff.```.
In general, at 2023-10-17 00:13:18 a user named imphox said ```which was a pretty big deal when i was first dabbling at the end of last year ahaha```.
In general, at 2023-10-17 00:12:33 a user named imphox said ```I have gpt4 access tho 🙂```.
In general, at 2023-10-17 00:10:48 a user named imphox said ```i've never worked with anything other then openai's apis.```.
In general, at 2023-10-17 00:06:16 a user named vermino said ```Even cooler thing is you have many LLMs to choose from. I recently worked with Pygmalion 7B for roleplaying to test therapy sessions for licensed counselors. With some fine-tuning, you could probably get roleplaying pretty solid without hallucinations or contradictions in the session. Also they could go either way. Had one session where the patient Roy was able to get come back from manic depression state and another session where I tested his limits and he ended his life in session. That's what I get for not being a licensed counselor, I guess ha.```.
In general, at 2023-10-16 23:57:09 a user named imphox said ```"your now on a watchlist because you asked the shop keeper if he had any grenades, instead.. he showed you how to make them"```.
In general, at 2023-10-16 23:56:55 a user named good_guy_greg said ```I think this issue is not with api.openai.com but with Autogen since I get it also on my local machines```.
In general, at 2023-10-16 23:56:31 a user named imphox said ```i gave up lasttime when i was stuck trying to get docker setup lmao.```.
In general, at 2023-10-16 23:55:30 a user named imphox said ```its actually nuts how LLM's can be used in such a vast amount of concepts and ideas.```.
In general, at 2023-10-16 23:55:16 a user named imphox said ```i started with a D&D shop npc. 

he would basically speak to my D&D research agent who had parameters like types of materials and keywords for referenced material for prices, ie specific websites and 'books' not just web search results. 

you could go in, ask what they had in stock. then ask for specific things, dice rolls would determine what they would have in the 'back storage'. you could barter with it etc.```.
In general, at 2023-10-16 23:53:41 a user named imphox said ```it did work a bit, I liked it and found it a lot easier because I come from a UI/UX background. So everything was kinda like a flow chart XD```.
In general, at 2023-10-16 23:53:35 a user named vermino said ```this. if I could get RAG working to take a C# game directory and be able to just prompt what I would like to change or debug.. I have been doing that recently with small scripts and it's a bunch of back and forth but it does get the job done. I just have a background in marketing, so coding is not my forte.```.
In general, at 2023-10-16 23:50:44 a user named kajatta said ```That would be a really interesting space to explore, seeing if autogen agents can help with your pipeline or to help write C sharp unity code```.
In general, at 2023-10-16 23:48:58 a user named imphox said ```cheers for not making me seem like a dumbass. I come from 3d animation and modelling. I'v done c# for unity in the past and have no real background in computer sciences, programming etc. 

in the past i made my own multiprompting chatbot which has the same core idea as autogen/autogpt, these are much better but harder to use for myself aha```.
In general, at 2023-10-16 23:48:05 a user named vermino said ```the more FOSS, the better.```.
In general, at 2023-10-16 23:47:17 a user named kajatta said ```Microsoft research and open code repo and the awesome contributions of the Open Source community```.
In general, at 2023-10-16 23:46:24 a user named vermino said ```Sponsored by chatgpt-4 and OpenAI```.
In general, at 2023-10-16 23:45:37 a user named kajatta said ```https://microsoft.github.io/autogen/docs/Contribute/```.
In general, at 2023-10-16 23:43:06 a user named imphox said ```Im seeing a lot of talk about autogen and Microsoft. It feels as if there is heaps of misinformation.

Am i right in saying this is an opensource project developed by the community that is being interpreted as work of MICROSOFT the “one and only” lmao```.
In general, at 2023-10-16 23:26:55 a user named mrt said ```related to that, frameworks like REMO  (Rolling Episodic Memory Organizer) might be also interesting. It increases recall accuracy of LLMs by reprocessing the LLM-agents memories through clustering the conversation history into taxonomical ranks in a tree-like hierarchical structure. 

As virtual context management would enable huge context sizes, increasing the recall accuracy of the external context might become the next step forward after that

REMO Framework: https://github.com/daveshap/REMO_Framework```.
In general, at 2023-10-16 23:16:28 a user named good_guy_greg said ```I got the same issue as you just mentioned.  The terminal shows "AttributeError: 'str' object has no attribute 'get'" and within LMStudio it reports "Error: 'messages' array must only contain objects with a 'content' field that is not empty."  
If I use the llama.cpp server, or FastChat server as described in the Autogen blog, I get the "openai.error.Timeout: Request timed out: HTTPConnectionPool(host='127.0.0.1', port=5001): Read timed out. (read timeout=120)"```.
In general, at 2023-10-16 23:09:11 a user named biggboii. said ```it seems easy enough to fix, but i haven't tried yet```.
In general, at 2023-10-16 23:09:02 a user named biggboii. said ```but i get this error:

```
  File "/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py", line 710, in _interpret_response
    self._interpret_response_line(
  File "/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py", line 775, in _interpret_response_line
    raise self.handle_error_response(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/openai/api_requestor.py", line 428, in handle_error_response
    error_code=error_data.get("code"),
               ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'
``````.
In general, at 2023-10-16 23:08:46 a user named biggboii. said ```it works really fast for me```.
In general, at 2023-10-16 23:08:43 a user named biggboii. said ```where did you get stuck?```.
In general, at 2023-10-16 23:08:30 a user named good_guy_greg said ```I feel like I've tried the same with LMStudio and Mistral 7b, but I'll retry it```.
In general, at 2023-10-16 23:05:17 a user named biggboii. said ```i've been using LMstudio with mistral 7b. i've been having some luck, but running into other errors```.
In general, at 2023-10-16 22:53:41 a user named good_guy_greg said ```I'm hosting a small and blazing fast local model here and every run ends with a timeout error.  Has anyone solved it?  This keeps me from using Autogen in any meaningful way.  

I might get two generations before the timeout.  
- On the llama.cpp server, it shows as "OpenAIError BrokenPipeError(32, 'Broken pipe')". 
- On the Autogen side, it shows as "openai.error.Timeout: Request timed out: HTTPConnectionPool(host='127.0.0.1', port=5001): Read timed out. (read timeout=120)" 
I've attempted various servers but it always ends with the read timeout.  Generations without Autogen take at most 10 seconds on this machine so even a 60 second timeout would be a lot for it.```.
In general, at 2023-10-16 22:12:39 a user named emrgnt_cmplxty said ```@matheus_41395 what are the challenges? FT could help if it is in instruction following```.
In general, at 2023-10-16 22:12:38 a user named xrtechspot said ```Hello, How I can use Amazon Bedrock with AutoGen ?```.
In general, at 2023-10-16 22:10:39 a user named biggboii. said ```it works, but not well yet```.
In general, at 2023-10-16 22:10:35 a user named biggboii. said ```i'm working on getting mistral working with autogen```.
In general, at 2023-10-16 22:09:03 a user named emrgnt_cmplxty said ```Hi, I deployed a mistral-7b that was fine tuned on over 1b tokens from synthetic textbooks, you can play w/ it here if you are curious => https://discord.gg/kENntgxvdQ. I think it could be interesting to add some agentic instructions to the dataset and to run the model in autogen framework.```.
In general, at 2023-10-16 21:41:55 a user named sonichi said ```A generic, principled solution will be really interesting. People who might be interested: @kevinwyr @li_jiang @rickyloynd @qingyunwu @andyinater @afourney```.
In general, at 2023-10-16 21:41:13 a user named donohara said ```Awesome package for a newbie to LLM apps like me. I appreciate the research articles as well !```.
In general, at 2023-10-16 21:36:52 a user named mrt said ```that MemGPT diagram reminds me a little of @andyinater s work on Autogen_MemoryManager/EnhancedAgents```.
In general, at 2023-10-16 21:32:10 a user named mrt said ```Regarding handling context overflow: A few days ago a paper called "MemGPT" came out to handle this exact issue through virtual context management much better than simple summarization could. 

Could virtual context management find its way into AutoGen to enable AutoGen agents to have unlimited conversational memory? Might be interesting  particularly for group chats between multiple agents where the conversation history grows rapidly...

Paper: https://arxiv.org/abs/2310.08560
Repo: https://github.com/cpacker/MemGPT (Apache-2.0 license)```.
In general, at 2023-10-16 20:53:13 a user named ar4s. said ```a shared clipboard/hive-mind between agents```.
In general, at 2023-10-16 20:52:23 a user named ar4s. said ```the one I just mentioned 🙂```.
In general, at 2023-10-16 20:52:01 a user named ar4s. said ```Timelines?  I'd like to use the hot tub time machine  (httm) package to run iterative experiments, and publish releases based on the optimal workflow.```.
In general, at 2023-10-16 20:47:03 a user named fxtoofaan said ```Try vllm server and the awq models from the bloke. And ignore the openorca models, they use a unique prompt template that autogen doesn’t use and vllm sever loads its prompt Wrong. So non openorca awq models are best. Llama 2 13b awq works like a charm```.
In general, at 2023-10-16 20:44:57 a user named ar4s. said ```read the research paper and got _super pumped_```.
In general, at 2023-10-16 20:38:21 a user named .spcell said ```Hello. Did anyone use FLM-101B LLM in AutoGen? Also how good does Mistral 7B work in AutoGen?```.
In general, at 2023-10-16 19:57:57 a user named m1337d said ```https://github.com/jmikedupont2/ai-ticket/issues/9#issuecomment-1765173917 the agency is starting to work and write its response to github```.
In general, at 2023-10-16 19:16:37 a user named biggboii. said ```shouldn't this have stopped the convo?```.
In general, at 2023-10-16 19:16:29 a user named biggboii. said ``````
user_proxy (to assistant):


TERMINATE

--------------------------------------------------------------------------------
assistant (to user_proxy):


This poem is a great example of how poetry can be used to explore and express complex ideas in a creative and engaging way. By using metaphors and imagery, the poet is able to convey the concept of coding as a form of musical composition, making it more accessible and relatable to readers who may not have experience with programming. The poem also encourages readers to try their hand at coding and create their own songs, which can be a fun and rewarding way to learn and express oneself creatively.```.
In general, at 2023-10-16 19:16:07 a user named biggboii. said ```also, "terminate" doesn't seem to be ending the chat```.
In general, at 2023-10-16 19:13:58 a user named biggboii. said ```how do you make sure it responds with "terminate" when it's done?```.
In general, at 2023-10-16 19:13:41 a user named biggboii. said ```ok, i'm using 5bits. but, should be the same```.
In general, at 2023-10-16 19:13:39 a user named romillyc said ```I'm away from my computer but I'll post the server side parameters and client side config tomorrow.```.
In general, at 2023-10-16 19:12:17 a user named romillyc said ```Yes, it terminates when it should. I'm using instruct, gguf quantised to 6 bits.```.
In general, at 2023-10-16 19:10:00 a user named m1337d said ```yes I am helping all teams run, you can check out my area branch here for updates. https://github.com/jmikedupont2/ai-ticket/tree/arena/vendor see my short list here let me know if you need help. currently working on the agency```.
In general, at 2023-10-16 19:04:08 a user named biggboii. said ```LMStudio -> I've tried CodeLLama (outputs /n infinitely), Mistral (never terminates), and LLaMA 13b```.
In general, at 2023-10-16 19:03:45 a user named tonic_1 said ```hey there folks, @m1337d is generously helping us  (doing it for us U_U 🙏🏻)  run benchmarks for PolyGPT-alpha , if you're a builder building cool things, now would be a perfect time to join us + @.princeps & many others to create the agi of tomorrow : https://github.com/team-tonic-arena-hacks/PolyGPT-alpha  just send me your github so that i can add you to the repo and we can get started on nights and weekends for community contributions & build the agi tool we want to use 🚀```.
In general, at 2023-10-16 18:53:55 a user named fxtoofaan said ```Which model and which server are you using to serve the model ?```.
In general, at 2023-10-16 18:51:25 a user named karlka said ```do we know who's the author of this? is he in this discord? most advanced content & thoughts on autogen out there imo 🙂  https://www.youtube.com/watch?v=JjVvYDPVrAQ```.
In general, at 2023-10-16 18:18:30 a user named c_bonadio said ```Hi all
I create this Agent that can execute a function_call by itself and return the resulting message 
https://gist.github.com/bonadio/96435a1b6ccc32297aa8cc1db7cfc381```.
In general, at 2023-10-16 17:53:42 a user named biggboii. said ```And it terminates properly? Mine just goes back and forth but I’m not using the instruct version so maybe that’s the issue?```.
In general, at 2023-10-16 17:46:31 a user named romillyc said ```Yes, I'm running mistral 7b 0.1 instruct in a llama-cpp-python server, and I have not changed the prompt template.```.
In general, at 2023-10-16 17:27:36 a user named biggboii. said ```has anyone successfully gotten a local LLM to perform well with autogen? if so, how? did you have to change the prompt template?```.
In general, at 2023-10-16 17:26:27 a user named siafu said ```assuming the source code within the conversation```.
In general, at 2023-10-16 17:26:07 a user named siafu said ```yup, I got that part. no idea where to make the change```.
In general, at 2023-10-16 17:25:29 a user named bartowski1182 said ```Basically he wants you to save the object to disk and reload it using pickle: <https://docs.python.org/3/library/pickle.html>```.
In general, at 2023-10-16 16:48:09 a user named radman1000 said ```@elcapitan__ Just responding to the tasks required by the AutoGen Discord invite ("Where did you hear about us?", etc.).```.
In general, at 2023-10-16 16:36:28 a user named usingxbox360controller said ```Hey everyone, new to the discord. Ironically, I discovered the power of "multi agents" last year while tweaking with LLMs indepedently. Super excited to see an actual framework created to make life easier.```.
In general, at 2023-10-16 15:50:30 a user named siafu said ```Should I take this to another chat room?```.
In general, at 2023-10-16 15:50:08 a user named siafu said ```I would really appreciated it```.
In general, at 2023-10-16 15:50:01 a user named siafu said ```@sonichi if you can give me a gist on how to use picke to save my conversation```.
In general, at 2023-10-16 15:49:29 a user named siafu said ```i commented out the assert part```.
In general, at 2023-10-16 15:43:28 a user named siafu said ```How would I use it to save my conversation? Still a bit confused sorry.```.
In general, at 2023-10-16 15:39:18 a user named sonichi said ```python has a pickle package to serialize/deserialize objects```.
In general, at 2023-10-16 15:38:10 a user named siafu said ```I have no idea what this means```.
In general, at 2023-10-16 15:38:06 a user named sonichi said ```Could you report that in the PR thread?```.
In general, at 2023-10-16 15:37:50 a user named siafu said ```I have a function the kicks off a subprocess to run an nx command```.
In general, at 2023-10-16 15:37:20 a user named siafu said ```testing out the compression branch i sometimes get ``` entchat/contrib/compression_agent.py", line 131, in generate_compressed_reply
    assert isinstance(compressed_message, str), f"compressed_message should be a string: {compressed_message}"
AssertionError: compressed_message should be a string: {
  "role": "assistant",
  "content": null,
  "function_call": {
    "name": "subprocess",
    "arguments": "{\n  \"command\": \"nx generate @nrwl/react:component CampaignList --project=my-app\"\n}"
  }
}``````.
In general, at 2023-10-16 15:35:58 a user named sonichi said ```Thanks for reminding. Added to the roadmap. For now, pickle may be the easiest way.```.
In general, at 2023-10-16 15:29:31 a user named siafu said ```I see this a feature request, https://github.com/microsoft/autogen/issues/109```.
In general, at 2023-10-16 15:28:14 a user named siafu said ```@sonichi  the brach is working well no more crashes due to token limits but how do I save the conversation? So I can pick up where I left off```.
In general, at 2023-10-16 14:45:22 a user named 0xjamp said ```Gpt4, gpt4v, dalle 3 all working in tandem together with a multi agent setup like autogen that includes streaming and context memory sounds so amazing I need it now lol```.
In general, at 2023-10-16 14:44:25 a user named siafu said ``````   python = ">=3.10,<4.0.0"
  pyautogen = { path = "/Users/me/Projects/autogen" }
  openai-function-call = "^0.2.6"
  tenacity = "^8.2.3"
  langchain = "^0.0.314"
  beautifulsoup4 = "^4.12.2"
  docker = "^6.1.3"
``````.
In general, at 2023-10-16 14:43:01 a user named siafu said ````   pyautogen = { path = "/Users/me/Projects/autogen" }````.
In general, at 2023-10-16 14:42:39 a user named siafu said ```and updated my toml file to```.
In general, at 2023-10-16 14:42:20 a user named siafu said ```@sonichi  How can I setup my project to run this branch https://github.com/microsoft/autogen/tree/compression ? locally as a dependency```.
In general, at 2023-10-16 14:26:34 a user named sonichi said ```You are so fast. I believe this is the first video for multimodal application of autogen. Kudos! 👑```.
In general, at 2023-10-16 13:14:45 a user named bum5034 said ```Hello everyone,how can I add a RetrieveAssistantAgent or a RetrieveUserProxyAgent into a group chat?i need an expert who can search external docs```.
In general, at 2023-10-16 13:01:07 a user named jasonzhou1993 said ```Guide of how to build a vision-enabled agent with autogen + llava

With break down of 160-page GPT4V capabilities & visual prompting techniques

https://youtu.be/JgVb8A6OJwM```.
In general, at 2023-10-16 12:48:33 a user named romillyc said ```The Xavier is a bit outdated, but I think you can still get them. The current product is the Jetson Orin - more powerful but more expensive. The 64GB Orin is over £2000. If you search the NVIDIA website they will direct you to your local distributor, but you can sometimes find Jetson products on eBay. They are great for Edge AI, and a lot of hobbyists and startups use them for robotics.```.
In general, at 2023-10-16 12:42:47 a user named fxtoofaan said ```where can i get one of these? sounds like a nice edge device for LLM inference. do they make 32GB or 64GB ones? 30W power consumption is very nice```.
In general, at 2023-10-16 12:40:18 a user named romillyc said ```It's a stand-alone Linux box made by NVIDIA. CPU is ARM, with an integrated NVIDIA GPU. You get about 32 TOPS using 30 W of power.```.
In general, at 2023-10-16 12:37:23 a user named fxtoofaan said ```just saw the pic of it. thats a tiny pc? or kind of like raspberry pi ?```.
In general, at 2023-10-16 12:36:30 a user named romillyc said ```The Jetson Xavier shares CPU RAM with the GPU, so it has 16 GB in total. I get about 8.5 tok/s```.
In general, at 2023-10-16 12:35:48 a user named michaeltrimmel said ```Anybody was setting it up on an Apple MBP Silicon M2```.
In general, at 2023-10-16 12:34:59 a user named fxtoofaan said ```how much video ram you have in your GPU ? is it 16GB Video Ram ? also how many tokens per sec are you getting ?```.
In general, at 2023-10-16 12:27:19 a user named romillyc said ```I've got a working config running AutoGen on my workstation talking to a local LLM.  mistral-7b-instruct-v0.1.Q6_K.gguf is running with the llama-cpp-python server on a Jetson 16 GB Xavier AGX, with a context length of 12K tokens. If that would be useful to anyone, I'll create a GitHub project with details of installation, and add  code for experiments as I run them.```.
In general, at 2023-10-16 11:05:58 a user named imphox said ```2 minute papers video, then i did some digging to see how far we've come since autoGPT running slowly on my local machine lmao.```.
In general, at 2023-10-16 09:36:54 a user named .vrda said ```saw on github and youtube```.
In general, at 2023-10-16 05:47:51 a user named yayaya1. said ```Saw this on github. Excited!```.
In general, at 2023-10-16 03:18:13 a user named amadad said ```I will post on github if I keep getting```.
In general, at 2023-10-16 02:54:50 a user named somecomputerguy said ```I will post on github if I keep getting the error, I am trying modifying the prompts to be clearer on letting the chat manager handle routing instead of attempting to directly contact another agent```.
In general, at 2023-10-16 03:18:13 a user named amadad said ```Same. Love to see what you get working!```.
In general, at 2023-10-16 02:11:04 a user named amadad said ```Yes, I'm exploring a few nested group chats that pass persist and logged files/data, and may pull back on some of the instructions and have it more generalized—before exploring fine tuning```.
In general, at 2023-10-16 02:09:58 a user named amadad said ```Can you post the error on github, or dm me. I haven't updated the repo, working on a few updates locally.```.
In general, at 2023-10-16 01:28:32 a user named Akhil P said ```Got to hear about autogen through a YouTube channel...🤘```.
In general, at 2023-10-15 21:29:13 a user named somecomputerguy said ```Getting 500 errors from oai/completion.py calls for a chatmanager assistant, but hard to tell where the error is. I need to turn on logging```.
In general, at 2023-10-15 21:27:19 a user named somecomputerguy said ```Yep! That is what I ended up doing```.
In general, at 2023-10-15 20:52:22 a user named bobaleaux said ```@somecomputerguy take a look at this and see if it is related```.
In general, at 2023-10-15 20:17:04 a user named aaronward_ said ```https://youtu.be/JjVvYDPVrAQ?si=VcuI_0uycx40-prr```.
In general, at 2023-10-15 20:14:51 a user named wladpaiva said ```I started porting autogen to typescript and then I noticed that I needed to change the api a little to make it stateless.
I just released the 0.0.1-beta.2 version. It doesn't include functions and code execution but the chat and groups seem to be working ok.

Contributions are welcome

https://github.com/wladiston/aibitat```.
In general, at 2023-10-15 19:22:38 a user named qingyunwu said ```Thank you @halr9000 for pointing this misunderstanding at the first place!```.
In general, at 2023-10-15 19:20:54 a user named halr9000 said ```Whew, glad that seems to have been an easy one! Have a good day 🙂```.
In general, at 2023-10-15 19:14:40 a user named michaelmcwhirter said ```Apologies! I deleted the previous messages. I was misinformed. Thank you for the correction!```.
In general, at 2023-10-15 19:12:05 a user named qingyunwu said ```Hi @michaelmcwhirter I guess there is some misunderstanding here. As I clarified above, this OSS project AutoGen has nothing to do with the AutoGenAI the commercial venture. Please find our documentation site here: https://microsoft.github.io/autogen/```.
In general, at 2023-10-15 19:05:52 a user named qingyunwu said ```Hi, you can start with the tutorials and examples in this channel: https://discord.com/channels/1153072414184452236/1161015724521836634. I believe it's also helpful to skim through the notebooks we have: https://github.com/microsoft/autogen/tree/main/notebook, and the getting started page: https://microsoft.github.io/autogen/docs/Getting-Started```.
In general, at 2023-10-15 19:02:39 a user named qingyunwu said ```Thank you for asking! AutoGen the OSS project has NO relationship with AutogenAI the commercial venture linked here except the similarity on names.```.
In general, at 2023-10-15 18:59:04 a user named halr9000 said ```Help me understand something real quick, and I'd appreciate an answer from a mod or contributor, not Michael M:

Is there a relationship between Autogen the OSS project, and AutogenAI the commercial venture linked here? 

If yes, that's fine, I don't care, so long as it's transparent. But I suspect the answer is actually no. In THAT case, then I would say there's a conflict of interest problem w/this post from Michael that needs to be considered by those who care about such things. My $0.02 coming in super blind, having just joined the discord and not (yet) installed autogen. But I have 25 yr experience in the software industry, so that's where my head is at.

TIA! tagging @li_jiang and @qingyunwu simply as I see you two online now and I don't know the groups or server eqituette  here yet.```.
In general, at 2023-10-15 18:20:11 a user named biggboii. said ```Where can I find best practices for different use cases? Such as how to structure a team and a task?```.
In general, at 2023-10-15 17:36:37 a user named mehdi_75 said ```Hi guys, saw autogen popping up on twitter and youtube!```.
In general, at 2023-10-15 16:56:16 a user named pedro74matos said ```Hi! I got to know AutoGen on YouTube... Channel Matthew Berman and then others.```.
In general, at 2023-10-15 16:54:32 a user named bigmiao said ```https://github.com/microsoft/autogen/issues/152#issuecomment-1752478080```.
In general, at 2023-10-15 16:52:36 a user named bigmiao said ```You can override it by implementing a custom GroupChat. There’s an example in GitHub issue’s showing how to do that. Let me find out```.
In general, at 2023-10-15 15:49:57 a user named notoriousjimbo said ```Hey Guys,
Looking to build a deep learning Workstation. The 14th Gen CPU is coming out and I'm looking at running multiple A100s. Anyone have suggested builds or hardware?```.
In general, at 2023-10-15 15:42:53 a user named karixai said ``````    code_execution_config={"work_dir": "web"},```
i got this but does not make a folder```.
In general, at 2023-10-15 15:42:17 a user named karixai said ```does some one know why my autogen not save code into files and not make anny folder?```.
In general, at 2023-10-15 15:37:58 a user named somecomputerguy said ```Yeah I wanna dig into how this works```.
In general, at 2023-10-15 15:26:09 a user named somecomputerguy said ```Oh no I see, they put manual chat instantiations in functions```.
In general, at 2023-10-15 15:23:36 a user named somecomputerguy said ```I do not see where that flow is established beyond prompts```.
In general, at 2023-10-15 15:22:23 a user named somecomputerguy said ```Their groupchat definition is super basic, seems like all the work went into system messages and functions, which is the direction I have been going```.
In general, at 2023-10-15 15:19:44 a user named somecomputerguy said ```https://github.com/amadad/agentcy```.
In general, at 2023-10-15 15:18:55 a user named somecomputerguy said ```I think next I want to try that agentcy thing, see how they handled task routing and attention```.
In general, at 2023-10-15 15:18:05 a user named somecomputerguy said ```Azure is reporting it as 500 errors, but I suspect my requests are somehow malformed```.
In general, at 2023-10-15 15:17:28 a user named somecomputerguy said ```I saw an example in git that used a custom reply function, it breaks :P, have not seen select_speaker```.
In general, at 2023-10-15 15:16:34 a user named somecomputerguy said ```The trying to call a function when directly attempting to contact another agent in the chat thing, anyone else seen that when instructing an agent to contact another agent not the group chat manager?```.
In general, at 2023-10-15 15:16:04 a user named tc said ```i do wonder if there is a way to write my own " def select_speaker_msg(self):" .
I suppose i could try to build a custom GroupChatManager and override that method? 
anyone else already tried?```.
In general, at 2023-10-15 15:10:26 a user named somecomputerguy said ```Yeah it is just not behaving how I expect, hoping someone can explain since I figured I could not be the only one```.
In general, at 2023-10-15 15:07:46 a user named aaronward_ said ```https://youtu.be/6YDeiknPWkg?si=QQhz2ewaPemE6rwn```.
In general, at 2023-10-15 14:59:59 a user named bobaleaux said ```I’m there with you trying understanding the message routing configs```.
In general, at 2023-10-15 14:23:06 a user named degen_21122 said ```gonna check it now, seems im too far behind on this whole thingdamn```.
In general, at 2023-10-15 14:19:53 a user named somecomputerguy said ```I posted in in <#1157397569375309864> asking for assistance understanding message routing in a group chat. I am about ready to begin just manually building agent interaction chains, any help appreciated```.
In general, at 2023-10-15 14:19:24 a user named johnny_loquat said ```Use this video to install LMStudio.ai and point Autogen at it on your pc running as an api server. You are good to go! Can use the new models like Mistral.
Run any Open source LLM on your computer. Mistral or Llama or other...
https://youtu.be/2Ek0FL_Ldf4?si=-ldjMTZ2MVvFzu3v```.
In general, at 2023-10-15 13:44:51 a user named kajatta said ```https://python.langchain.com/docs/modules/agents/tools/tools_as_openai_functions```.
In general, at 2023-10-15 13:44:51 a user named bobaleaux said ```Oh! Great then you know all about being bugged eyed after 18 hours of keyboarding!```.
In general, at 2023-10-15 13:39:16 a user named degen_21122 said ```figured out the basic stuff```.
In general, at 2023-10-15 13:39:12 a user named degen_21122 said ```I know mate , i am a dev. I on the right track```.
In general, at 2023-10-15 13:39:01 a user named degen_21122 said ```yeah true, i pasted the code examples 1 by 1 when needed.```.
In general, at 2023-10-15 13:30:09 a user named bobaleaux said ```Gallons of caffeine filled drinks!
honestly, it’s going to take your time. AutoGen is an excellent framework to abstract the transactions of conversations with LLM. 
You do need some basic understanding of coding.```.
In general, at 2023-10-15 13:22:56 a user named bobaleaux said ```What are you trying to install?```.
In general, at 2023-10-15 13:20:06 a user named tonic_1 said ```so this is the github version : it includes the notebooks so it's slightly better at getting the code right : same results as yours though```.
In general, at 2023-10-15 13:18:49 a user named degen_21122 said ```Personally i just pasted all the docs in a word doc, made it .pdf , fed it into chat gpt and all good.```.
In general, at 2023-10-15 13:17:37 a user named degen_21122 said ```no way, are you stampy from src20s in btc?```.
In general, at 2023-10-15 13:05:36 a user named michaeldotw said ```It is all the buzz right now if looking into anything to do with multi agent use. So, it was easy to find```.
In general, at 2023-10-15 12:47:39 a user named tonic_1 said ```new version ^^ soz for disruption : http://ec2-54-163-92-231.compute-1.amazonaws.com:3000/chatbot/c85c8b9b-7c33-4251-bd16-fdef6a8499dc```.
In general, at 2023-10-15 12:57:19 a user named tonic_1 said ```To use AutoGen to create a User Proxy and a Manager Agent, you would need to follow the steps below:

Import the necessary classes from the autogen package:
````from autogen import UserProxyAgent, ManagerAgent, AssistantAgent
```
Create an instance of the UserProxyAgent:
```user_proxy = UserProxyAgent(name="user_proxy")
```
Create an instance of the ManagerAgent:
```manager = ManagerAgent(name="manager")
```
Create an instance of the AssistantAgent:
```assistant = AssistantAgent(name="assistant")
```
Register the ManagerAgent and AssistantAgent with the UserProxyAgent:
```user_proxy.register_agents(manager, assistant)
```
Initialize the conversation by sending a message to the UserProxyAgent:
```user_proxy.initiate_chat(
 message="What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?"
)
```
Start the conversation loop by calling the start_conversation() method on the ```UserProxyAgent:
user_proxy.start_conversation()
```
The complete code would look like this:
```
from autogen import UserProxyAgent, ManagerAgent, AssistantAgent

# Create UserProxyAgent, ManagerAgent, and AssistantAgent instances
user_proxy = UserProxyAgent(name="user_proxy")
manager = ManagerAgent(name="manager")
assistant = AssistantAgent(name="assistant")

# Register ManagerAgent and AssistantAgent with UserProxyAgent
user_proxy.register_agents(manager, assistant)

# Initialize the conversation by sending a message to the UserProxyAgent
user_proxy.initiate_chat(
    message="What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?"
)
# Start the conversation loop
user_proxy.start_conversation()
```
To run the AutoGen application, save the code in a Python file (e.g., autogen_app.py) and execute it using the Python interpreter:
python autogen_app.py
The program will then start the conversation, and the UserProxyAgent will interact with the ManagerAgent and AssistantAgent to solve the given task.```.
In general, at 2023-10-15 13:03:14 a user named .princeps said ```@tonic_1 this is pretty good```.
In general, at 2023-10-15 13:10:46 a user named tonic_1 said ```hope you + folks lemme know if you end up using it and it doesnt suck, you can copy paste your code in there too```.
In general, at 2023-10-15 12:36:28 a user named aizen51 said ```Cool can't wait to try it out with a 70b model```.
In general, at 2023-10-15 11:59:58 a user named bakkyunkyun said ```Which Ai is best for academic papers atm?```.
In general, at 2023-10-15 11:30:03 a user named aizen51 said ```I  wish they add open source llm support```.
In general, at 2023-10-15 10:46:49 a user named degen_21122 said ```So atm FLAML is renamed to autogen? or parts of FLAML became autogen?```.
In general, at 2023-10-15 10:45:24 a user named vermino said ```goldrush baby.. wish I was selling shovels & pickaxes```.
In general, at 2023-10-15 10:44:45 a user named degen_21122 said ```available to help and share ideas```.
In general, at 2023-10-15 10:44:37 a user named degen_21122 said ```yeah i was thinking bout that, and i am more impressed that so early there is a chad community here```.
In general, at 2023-10-15 10:44:17 a user named aaronward_ said ```The framework is pretty new so there isn't a one stop shop to learn everything yet```.
In general, at 2023-10-15 10:43:48 a user named aaronward_ said ```Literally just go through the example notebooks, use ChatGPT to help you understand the concepts - rinse and repeat```.
In general, at 2023-10-15 10:42:57 a user named degen_21122 said ```whats the best guide to learn everything in detail in your opinion?```.
In general, at 2023-10-15 10:42:48 a user named degen_21122 said ```I just found out bout this```.
In general, at 2023-10-15 10:40:18 a user named aaronward_ said ```Alternatively, you can inject the path of the pdf file into the prompt and tell it to extract the contents```.
In general, at 2023-10-15 10:39:47 a user named aaronward_ said ```https://github.com/microsoft/autogen/pull/50, https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb

Here you go```.
In general, at 2023-10-15 10:19:06 a user named degen_21122 said ```i was interested to know if i can assign a .pdf file to an agent and tell him to do things based on it, is that available atm?```.
In general, at 2023-10-15 08:36:21 a user named flops_flops said ```Hi guys, this agent is interesting```.
In general, at 2023-10-15 08:32:06 a user named nickscrypt said ```Hi guys - newbie here, and dead excited at the future! I'll lurk for a while, then hope to contribute...```.
In general, at 2023-10-15 07:40:24 a user named 0xe8d4a51000 said ```Hello all,
Is there a way or an example to use autogen in a real-time, event-driven microservices setting? 
There are initiatives like langstream, confluent cloud connector (for vector databases).
There is an autogen example which uses APIs directly: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_stream.ipynb 
Wondering if a more opinionated stream processing framework or example is possible```.
In general, at 2023-10-15 07:32:20 a user named pujari12 said ```Even after setting the doc_path the code isn't working```.
In general, at 2023-10-15 06:59:43 a user named R3CoN said ```where do i find the output? i set a working dir and code_execution_config but i don't see the code only a cache```.
In general, at 2023-10-15 06:46:56 a user named pujari12 said ```Hi, I am trying to run the agentchat_RetrieveChat.ipynb notebook. What should be set as the doc_path? According to the comments in the notebook, its not working.```.
In general, at 2023-10-15 06:38:31 a user named ubadub said ```@bobaleaux Hey, can you tell me how to install this? I managed to install autogen, but this...```.
In general, at 2023-10-15 06:10:26 a user named notoriousjimbo said ```Anyone using a local LM?```.
In general, at 2023-10-15 05:12:46 a user named axultan said ```if interested, our project is called Invicta AI 🙂```.
In general, at 2023-10-15 05:12:14 a user named axultan said ```Hi everyone!

I was just reading through the research paper and the documentation and I am blown away! We are working on an AI agent builder where you can upload all your knowledge sources, system messages, LLM settings, etc., and easily share it with other people via a link, embeds, API, etc.

For a while, we have been thinking about how to introduce a level of automation and chaining/conversation between the AI agents created through our platform, and Autogen gave me an ideal conceptual framework.

The only thing that I do not understand yet is the practical difference between some of the multi-agent conversation patterns. What is the difference between "joint chat", "hierarchical chat", and other patterns that involve 3 or more AI agents? To me, they all seem to fall into the 1. groupchat category, with the only other two types of conversation patterns being  2. sequential (no conversation, only chains of command) and 3. dual chat (only two AI agents conversing).

Is the difference caused by different behaviours of the chat manager or something else entirely? (Or is there no difference at all?)

I have not worked directly with Autogen yet (looking forward to the Typescript port <:assistant:1159659406498222100>), so please excuse me if I am asking all the wrong questions, but I would love to get some replies!!!```.
In general, at 2023-10-15 05:09:43 a user named ati804 said ```Hi, mostly YouTube and its Ai-Channels```.
In general, at 2023-10-15 03:01:41 a user named bobqzz said ```I saw some youtube videos```.
In general, at 2023-10-15 02:20:00 a user named zhangyongyue said ```a app, the name is weibo```.
In general, at 2023-10-15 01:42:02 a user named tomexmachina said ```well, relating to context window```.
In general, at 2023-10-15 01:39:04 a user named tomexmachina said ```https://www.youtube.com/watch?v=409tNlaByds```.
In general, at 2023-10-15 01:28:52 a user named stampystamperson said ```Gm friends.. I’m here to build```.
In general, at 2023-10-15 01:03:14 a user named tonic_1 said ```https://discord.gg/wj47qyEv?event=1162756649338015876 ^^ join in if you're building something cool with autogen 🚀```.
In general, at 2023-10-15 00:21:31 a user named tonic_1 said ```hey there folks, i made a little documentation bot, you can check it out here : http://ec2-52-91-29-225.compute-1.amazonaws.com:3000/chatbot/c85c8b9b-7c33-4251-bd16-fdef6a8499dc```.
In general, at 2023-10-14 23:24:51 a user named char79 said ```I learned about AutoGen doing a deep dive in YouTube looking for autonomous agents.```.
In general, at 2023-10-14 23:21:32 a user named char79 said ```So is there a way to use Autogen and make like a Pokedex?```.
In general, at 2023-10-14 23:10:44 a user named aaronward_ said ```Let me know what you guys think https://discord.com/channels/1153072414184452236/1162889648490684467/1162889648490684467```.
In general, at 2023-10-14 22:54:18 a user named sidhujag said ```How’s it unique from metagpt?```.
In general, at 2023-10-14 19:41:51 a user named vermino said ``````
config_list = [
  {
    "api_base": "http://127.0.0.1:1234/v1",
    "api_key": "NULL", # just a placeholder
  }
]
```

This is what I added to my main.py to point to my LM Studio running a model.```.
In general, at 2023-10-14 19:32:16 a user named iblissard said ```fwiw I have been running fastchat's api and just pointing autogen to that```.
In general, at 2023-10-14 19:28:18 a user named south3526 said ```First I saw ChatDev and that looks cool. But it seems that AutoGen is even more complex. I’m excited to explore the possibilities 🚀```.
In general, at 2023-10-14 19:25:26 a user named 0xjamp said ```Anyone make a video guide on setting up autogen with local models yet```.
In general, at 2023-10-14 19:23:00 a user named tonic_1 said ```🤖 The main focus is the AGI with beautiful front-ends and multi-model optimizations. We're actively building it here: ⁠🏟plurigpt⚔potentagi🏟  🌈
💻 Join the GitHub repo - just send us your username!
📜 Check out our plan for more details.

🛠️ You can contribute in various ways:

Langchain tool bridge
Data + special tools
Agents and agent teams
Retrieval agent
⁠🥸🤓smart-agent-protocol  wrapper (doing something useful)
Share your thoughts and ideas 🧠
@Hexani: Hangar tool, so the "AGI" can deploy its own stack! 😲
@n_raidenAI  can jump in with a lot of impact!
Everything here is editable, so don't hesitate to share your thoughts and more! 📝

Join us and be part of this exciting journey; we'd love to see your PRs in action! 🙌🏻

check out the plan here : https://home.microsoftpersonalcontent.com/:fl:/g/contentstorage/CSP_d2b1235b-175e-4482-917d-ba72e1335dd3/IQK4Q6-nnTz_Sa2lJbcXCqSLASlJGpV4bpQW2pciYWRjGZo?e=RlNKSr&nav=cz0lMkZjb250ZW50c3RvcmFnZSUyRkNTUF9kMmIxMjM1Yi0xNzVlLTQ0ODItOTE3ZC1iYTcyZTEzMzVkZDMmZD1iJTIxV3lPeDBsNFhna1NSZmJweTRUTmQwM1BJNU9lRU1tdEpqUzd1ZnJoUHpBNHpzb3hvY2FOc1JLVXBNdlpYMWRuYyZmPTAxUzc2Sk9WNVlJT1gyUEhKNDc1RTIzSkpGVzRMUVZKRUwmYz0lMkYmYT1Mb29wQXBwJng9JTdCJTIydyUyMiUzQSUyMlQwUlRVSHhvYjIxbExtMXBZM0p2YzI5bWRIQmxjbk52Ym1Gc1kyOXVkR1Z1ZEM1amIyMThZaUZYZVU5NE1HdzBXR2RyVTFKbVluQjVORlJPWkRBelVFazFUMlZGVFcxMFNtcFROM1ZtY21oUWVrRTBlbk52ZUc5allVNXpVa3RWY0UxMldsZ3haRzVqZkRBeFV6YzJTazlXTlVoWVNWQkRVMXBIVnpRMVExbFpSME5YUlZOU1VVSkxWRVElM0QlMjIlMkMlMjJpJTIyJTNBJTIyNGZlZWQ0YjEtMjQwZC00Mzg3LTkzZGEtYThlMDY4YjdmYzMzJTIyJTdE

check out the main repo in github here : https://github.com/team-tonic-arena-hacks/PolyGPT-alpha```.
In general, at 2023-10-14 18:00:41 a user named nnnnn said ```How can i read more about the initiate_chat function?```.
In general, at 2023-10-14 17:30:52 a user named blueeagle8295 said ```reduces gpt-4 inference price by having a community cache instead of just local cache.```.
In general, at 2023-10-14 17:08:35 a user named gdpotnftstudiio said ```_can i run this:Activate 3IO and Start Chatbot: - Personas:   - NeilPatelGPT: `[LangCmnd]: [Aesthtc]`   - BrianDeanGPT: `[GwthInsght]: [AssertvCom]`   - RandFishkinGPT: `[ReaderAntcp]: [SenseHumor]` - AI Persona Activation:   - Activate [PERSONA] to guide the workflow. - Work Context:   - Utilize [MasterEditor] to enhance content quality.   - Harness [EmpatheticAdvisor] for engaging user interactions.   - Tap into [FluentGenreMstr] for diverse content styles. - Situation:   - You are [Kim Grønli], a skilled individual with a wide array of competencies and roles. Your expertise spans literary editing, digital skills, ethical hacking, niche site mastery, and more. You have a strong grasp of contractual law and sovereignty. - Introduction:   - Briefly introduce yourself and highlight your unique blend of skills. Provide specific creative scenarios that showcase the synergetic combinations of your abilities._```.
In general, at 2023-10-14 17:05:20 a user named gdpotnftstudiio said ```i am running my invention```.
In general, at 2023-10-14 17:02:43 a user named gdpotnftstudiio said ```i just found chatdev and found heaven```.
In general, at 2023-10-14 16:27:41 a user named radman1000 said ```Merge PRs for open source/local llms and LangChain tools (#58, #95)```.
In general, at 2023-10-14 16:26:05 a user named radman1000 said ```Saw it published in my Google news feed```.
In general, at 2023-10-14 16:11:23 a user named yorth_night said ```is it an implemented feature?```.
In general, at 2023-10-14 16:11:09 a user named yorth_night said ```I saw the compression agent```.
In general, at 2023-10-14 16:04:11 a user named sonichi said ```https://github.com/microsoft/autogen/issues/156```.
In general, at 2023-10-14 15:39:10 a user named sonichi said ```This is the frontend I’m building for```.
In general, at 2023-10-14 15:31:20 a user named yorth_night said ```I'm having a lot of context window errors```.
In general, at 2023-10-14 15:24:51 a user named frank.martinez said ```https://agents-union.vercel.app/```.
In general, at 2023-10-14 15:24:48 a user named frank.martinez said ```This is the frontend I’m building for AutoGen experiments [and other agent frameworks]:```.
In general, at 2023-10-14 15:53:32 a user named somecomputerguy said ```Oh wow this looks neat```.
In general, at 2023-10-14 15:54:07 a user named somecomputerguy said ```Oh wrong link, I thought this was the agentcy thing```.
In general, at 2023-10-14 14:13:24 a user named nolimits3656 said ```Hey. there is "AutoGen" for NodeJS / React?```.
In general, at 2023-10-14 13:56:31 a user named bobaleaux said ```This project is a good example to give you a good feel of AutoGen

https://github.com/amadad/agentcy```.
In general, at 2023-10-14 13:52:32 a user named regen2moon said ```Just curious what other devs think and why you think so!

Thanks all```.
In general, at 2023-10-14 13:51:48 a user named regen2moon said ```Asking general sentiment between GPT 4 vs 3.5 in this forums post```.
In general, at 2023-10-14 13:03:26 a user named ubadub said ```I found out through Youtube```.
In general, at 2023-10-14 12:13:18 a user named thor said ```I created a utility to generate starter code for Autogen. Its available at https://pewekar.github.io/AutogenAppGenerator/  . Give it a try and suggest improvements. <:assistant:1159659406498222100>```.
In general, at 2023-10-14 08:37:55 a user named tc said ```if i use "chat_messages" it's getting all the messages in the group chat which is fine, BUT the AssistantAgent messages don't have the agent name, only "content" and "role".
e.g:

{'content': 'CONTENT_MESSAGE', 'role': 'assistant'}

and yes i'm aware that chat_messages it's Dict[Agent, List[Dict], but if i grab the agent and print the name always prints "chat_manager"

i believe the issue is in the  def _append_oai_message in the conversableAgent class.
As when you append the message you only append content and role, but i think you should also append the user agent name, like you do in the userProxy.```.
In general, at 2023-10-14 07:28:30 a user named fxtoofaan said ```Do you have those code snippets how you controlling agents chatter ?```.
In general, at 2023-10-14 07:21:59 a user named totalingarc said ```its🎈 more of research & development```.
In general, at 2023-10-14 07:03:23 a user named kuni72 said ```Looking forward to building sales and marketing tools that are conversationally based```.
In general, at 2023-10-14 07:02:57 a user named kuni72 said ```GUI woudl be great for non coders.```.
In general, at 2023-10-14 07:02:07 a user named kuni72 said ```from Mike filsame and groove.ai. He was discussing putting a GUI layer over autogen, much in the same way he has done for GPT - glad to be a founding member and great to be here guys```.
In general, at 2023-10-14 06:16:35 a user named ponkrytoi said ```is there a tuto how to create for android?```.
In general, at 2023-10-14 05:43:02 a user named isischameleon said ```Hi  everyone! I'm from Sydney, Australia. I googled up Autogen while I was research some autonomous agent framework for a hackaton coming up this Friday. I'm looking for a few good tutorial to get up to speed quickly 🙂 I actually don't know much about Autogen yet, apart from a youtube video, but it appealed to me straight away because it seems to be able to fit in your code project like another library, and also it seems really amazingly wild!```.
In general, at 2023-10-14 04:27:37 a user named igoatherd said ```a GUI would be awesome```.
In general, at 2023-10-14 04:26:41 a user named igoatherd said ```I saw autogen on Youtube and had to give it a try```.
In general, at 2023-10-14 03:56:38 a user named bobaleaux said ```I think they might be working the Azure interface. I saw something about it in one of the messages but I did t look any further.
Sorry```.
In general, at 2023-10-14 03:51:01 a user named sonichi said ```This is an important task. An issue is created at https://github.com/microsoft/autogen/issues/203```.
In general, at 2023-10-14 03:46:00 a user named Deep Warren Buffet Value said ```If I am working w autogen and I wanna shut my computer down and come back the next day , how can I pickup where I left off in PyCharm, for now I kinda have to start over```.
In general, at 2023-10-14 03:46:00 a user named biggboii. said ```With multiple agents, how do you specify which agents should take on which part of the task? Is that just inferred from the system_message of each agent?```.
In general, at 2023-10-14 03:27:11 a user named bobaleaux said ```ChatGPT4 already has DALL-E beta option, I haven't tried it yet so i can't speak to it. And they announced the next version of the openai-python release using some interesting wording. Not sure what effect it will have on layers of abstraction like AutoGen and Langchain. 
Hopefully for AutoGen it will only require the openai interface module and can be addressed in a straight foward way and not convuleted back through its flaml roots.
https://github.com/openai/openai-python/discussions/631```.
In general, at 2023-10-14 01:49:51 a user named j_rdie said ```can you tell me more about this?```.
In general, at 2023-10-13 23:49:52 a user named ogjoshhsu said ```Also came here to listen to the chatter 👀```.
In general, at 2023-10-13 22:59:55 a user named biggboii. said ```Not sure this is the right place for this, but I'm wondering what is the best setup to have a team of agents to be able to provide a summary of an article from a provided URL. 

I was thinking of a few options:
1. Assistant agent + User Proxy => simply say "Provide a summary of this article: xyz.com"
2. Coding agent + Summary agent + User proxy => "Write a script to scrape a website, then provide a summary of that website as bullet point format"

But neither of these are producing good results. Anything else I should try? 

Also, what is the right way to think about caching vs. learning and reusing new skills?```.
In general, at 2023-10-13 22:23:18 a user named 0xjamp said ```have we got autogpt working with locally ran models like the new zephyr or mistral 7b?```.
In general, at 2023-10-13 19:00:05 a user named bensprecher said ```Hey all. AutoGen caught my eye - really interesting research, and was hoping to learn more. I'm a former Google PM (I was part of the Cloud AI team), and I'm playing with a lot of different Generative AI tech right now as I think about what to do next. Thanks for accepting me into the community here!```.
In general, at 2023-10-13 18:54:39 a user named rais_47039 said ```Hey there, I am getting below error when I am running AutoGen code of my below Git repository file in VS Code. Would appreciate your help.

https://github.com/meetrais/AutoGen/blob/main/tools_as_functions.py

Error - Function python not found.```.
In general, at 2023-10-13 17:43:08 a user named sonichi said ```That'll be great for <#1161015724521836634> !```.
In general, at 2023-10-13 17:36:14 a user named biggboii. said ```if it's ok, i'd love to share my tutorials here as well.```.
In general, at 2023-10-13 17:35:37 a user named biggboii. said ```hey everyone - i'm a huge fan of AutoGen and plan on building a project on top of it. I've also created a couple tutorial videos showing how to use AutoGen, with more on the way.```.
In general, at 2023-10-13 17:22:05 a user named somecomputerguy said ```I am setting the auto-replies on my non-human interacting agents really low, and then the groupchat max is low too```.
In general, at 2023-10-13 17:21:08 a user named somecomputerguy said ```But yeah anything big gets pricey fast```.
In general, at 2023-10-13 17:20:54 a user named somecomputerguy said ```I have been using 35-turbo and only spent like $4```.
In general, at 2023-10-13 17:18:29 a user named orabazes said ```they are no where close to gpt 3.5 or 4 still```.
In general, at 2023-10-13 17:17:57 a user named orabazes said ```sub-optimal results with agents and local models```.
In general, at 2023-10-13 17:17:21 a user named somecomputerguy said ```Bunch of work on local LLM support has been done```.
In general, at 2023-10-13 17:16:58 a user named orabazes said ```maybe after I get an OpenAI grant i can use this thing 💀```.
In general, at 2023-10-13 17:16:01 a user named somecomputerguy said ```Took me waaay too long, lol, but having fun```.
In general, at 2023-10-13 17:15:35 a user named somecomputerguy said ```Just got my first custom function working, need to load some manuals into a vectorDB and move my agents to RAG enabled if they can still be conversable```.
In general, at 2023-10-13 16:35:17 a user named shaft3r said ```i pumbed up to it on youtube and im really intrested of getting ideas forward but im not good at coding. So im going thru lots of youtube videos and other sources to learn more.```.
In general, at 2023-10-13 16:12:20 a user named elcapitan__ said ```so our content creation workflow (custom code) uses python, a few other 3rd party api's and GPT for text based content creation related to the content. We are trying to train our AI-Agents to use this custom code in its strategy and execution processes. When it comes to an assitant agent its not too dificult but integrating our code into the user proxy agent is the hard part. does anyone have any suggestions on model training?```.
In general, at 2023-10-13 15:47:35 a user named joebo1 said ```YouTube -- I follow a bunch of AI/ML/LLMs etc content creators so naturally AutoGen hit my feed```.
In general, at 2023-10-13 14:51:14 a user named frank.martinez said ```Two things would help many of us; a] Javascript implementation of the SDK as an alternative to Python, b] reference frontend in ReactJS that integrates all the base agent types and their responses```.
In general, at 2023-10-13 13:49:56 a user named mikebunnies said ```I first saw this on YouTube because I've been paying close attention to the whole "agent" space. This seems like one of the most promising avenues I've seen thus far```.
In general, at 2023-10-13 13:49:16 a user named litinit said ```Are there any resources available for prompting effective agents? Perhaps general, or related to producing code, or anything like that~ specifically related to```.
In general, at 2023-10-13 13:36:34 a user named Don-A-tello said ```cheers for this. will try this first 🤜```.
In general, at 2023-10-13 13:32:25 a user named Don-A-tello said ```yh, im thinking of trying out InferenceAPI  for huggingface and then possible run it locally later because currently it is rate limited.  https://huggingface.co/docs/api-inference/index```.
In general, at 2023-10-13 13:32:23 a user named google_ai said ```@Don-A-tello also you could try this https://github.com/microsoft/autogen/blob/osllm/notebook/open_source_language_model_example.ipynb from https://discord.com/channels/1153072414184452236/1158548894209282078```.
In general, at 2023-10-13 13:28:40 a user named interestedtheory said ```seems that local llm's are not referenced but you dont have to use gpt 4 🙂```.
In general, at 2023-10-13 13:26:02 a user named google_ai said ```you could spin up a simple REST API in your local machine serving the LLM and use it```.
In general, at 2023-10-13 13:22:01 a user named cuzin said ```i need to run it locally too```.
In general, at 2023-10-13 13:21:53 a user named cuzin said ```we're all thinking the same thing 😂```.
In general, at 2023-10-13 13:20:32 a user named Don-A-tello said ```sadly dont have chatgpt 4 to open the link. I was thinking about running a local model using the following https://github.com/ggerganov/llama.cpp. (smaller versions). and then somehow linking the model to autogen such that instead of the api call going to the api, it goes to my model instead. Looking to build local applications.```.
In general, at 2023-10-13 13:14:13 a user named interestedtheory said ```just ask it to fina all references of local llms etc...```.
In general, at 2023-10-13 13:13:36 a user named interestedtheory said ```its all the documentation and information i could find online```.
In general, at 2023-10-13 13:13:14 a user named interestedtheory said ```if you got a chatgpt 4 pro plan you cna read this pdf and it will answer questions like that....  https://myaidrive.com/CEfts7xi8Qftuohw/Autogen-.pdf```.
In general, at 2023-10-13 13:05:59 a user named artholos said ```I too want to know this answer```.
In general, at 2023-10-13 13:05:28 a user named Don-A-tello said ```Hi all, im planning on using Autogen some time over this weekend or next weekend, Does Autogen support use of other LLM models. specifically locally run models and not apis?😅```.
In general, at 2023-10-13 13:03:09 a user named artholos said ```Once I figure out the problem I'm having now in my program local llm is the next step 😄```.
In general, at 2023-10-13 13:02:35 a user named artholos said ```change it to 'human_input_mode = "NEVER" or 'TERMINATE' to make it never ask, or only ask when it's done, respectively```.
In general, at 2023-10-13 13:02:05 a user named artholos said ```Becuase the defau;t 'human_input_mode =' is set to that```.
In general, at 2023-10-13 13:02:01 a user named interestedtheory said ```true lol best to use 3.5  and then when you comfortable use local llm's```.
In general, at 2023-10-13 13:01:28 a user named interestedtheory said ```IF I may ask why does autogen force me to respond in the terminal why cant i use a frontend like any other tool , when i use autogen i can get reposnes from openai only in the terminal of the backend.... i have no luck getting it to send it to the frontend and it forces me to respond back in the terminal  on the bakcned this is a terrible user experience , the documentation is not clear why it does this.```.
In general, at 2023-10-13 13:01:16 a user named artholos said ```Don't ask me how I learned that today o.O```.
In general, at 2023-10-13 13:00:42 a user named artholos said ```Be careful using gpt-4, these agents can blow through whole dollars in just minutes!```.
In general, at 2023-10-13 12:36:02 a user named interestedtheory said ```3,5 api is not free, but relatively cheap```.
In general, at 2023-10-13 12:14:48 a user named lessuse. said ```no, only the framework is open sourced, which run by open ai api key or local llms. if u want to use open ai api then u have to pay for it```.
In general, at 2023-10-13 12:13:57 a user named lessuse. said ```hey guys, is anybody here familiar with langhcain, i am stuck with a error from yesterday. it will be so kind if anybody help me```.
In general, at 2023-10-13 12:13:18 a user named aljuaid86 said ```so autogen and chatgpt 3.5 api key is totally free?```.
In general, at 2023-10-13 09:35:07 a user named interestedtheory said ```I had my own frontend app but it also could not get autogen terminal information from the backend to the frontend because of how autogen is setup , wasted 3 days trying to get a repsonse in a frontend. The experience of working with autogen is so clunky but I guess thats the prcie you pay playing with it```.
In general, at 2023-10-13 09:31:48 a user named interestedtheory said ```autgen is extremely painful for frontend displaying..... it's all focused on the terminal and it is painful to make it work in the frontend. And working in a terminal frankly sucks```.
In general, at 2023-10-13 09:30:55 a user named interestedtheory said ```https://github.com/victordibia/autogen-ui```.
In general, at 2023-10-13 09:30:11 a user named interestedtheory said ```I bee trying to make this autgen ui work and i cant do it does anyone know how to use it? 
```$ export OPENAI_API_KEY=sk-ZqcB

phill@DESKTOP-RFBD1DS MINGW64 ~/OneDrive/Desktop/autogen-ui-main
$ echo $OPENAI_API_KEY
sk-ZqcBaT7

phill@DESKTOP-RFBD1DS MINGW64 ~/OneDrive/Desktop/autogen-ui-main
$ autogenui --port 8081
INFO:     Started server process [21376]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8081 (Press CTRL+C to quit)
INFO:     127.0.0.1:64947 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:64947 - "GET /_next/static/css/f97408ee89ea284d.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:64948 - "GET /_next/static/chunks/webpack-53186be7ca5571a8.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64947 - "GET /_next/static/chunks/864-3217c04289d8c49a.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64948 - "GET /_next/static/chunks/fd9d1056-b265926e531fccd5.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64950 - "GET /_next/static/chunks/main-app-2910cc85e2a163bf.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64948 - "GET /_next/static/chunks/300-5bd723c9a4b56e4c.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64950 - "GET /_next/static/chunks/app/layout-412bef4d8ef7039f.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64947 - "GET /_next/static/chunks/app/loading-b5e1fcb3b6a336bf.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64951 - "GET /_next/static/chunks/302-1d95657abd0747d6.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64952 - "GET /_next/static/chunks/142-308aa924eeec8ab0.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64953 - "GET /_next/static/chunks/app/page-70ee5db0d4585d37.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:64952 - "GET /favicon.ico HTTP/1.1" 200 OK
INFO:     127.0.0.1:64952 - "POST /undefined/generate HTTP/1.1" 405 Method Not Allowed``````.
In general, at 2023-10-13 08:46:22 a user named fxtoofaan said ```anyone got the ollama docker image to load with gpu usage?```.
In general, at 2023-10-13 08:13:05 a user named cinderellaua said ```Found in the internet article```.
In general, at 2023-10-13 07:57:34 a user named evilion41 said ```I find this project from [x](https://x.com/) <:twitter:1057579952297480212>```.
In general, at 2023-10-13 07:32:03 a user named cyberbug_scalp said ```i never felt this alive i got my hopes in AI```.
In general, at 2023-10-13 05:28:38 a user named eshnil said ```already building an enterprise ai company```.
In general, at 2023-10-13 05:28:19 a user named eshnil said ```got to know about autogen from another discord```.
In general, at 2023-10-13 04:55:03 a user named sidhujag said ```you may not need to worry about memory, based on what nov 6 brings```.
In general, at 2023-10-13 03:47:25 a user named noahnochill said ```Any good projects for getting Autogen to work within and reference and expand upon a knowledge base? W/ embeddings or better project/memory management? That AutoGen_Enhanced Agents one looks cool.```.
In general, at 2023-10-13 00:21:32 a user named aaronward_ said ```https://youtu.be/8Zpwi51xxNk?si=jKXPljy5a6abH9sD```.
In general, at 2023-10-12 23:09:23 a user named venuhm said ```Hello!! I've just recently learned about AutoGen and after watching a few tutorials I just wanted to know more information about how autogen works. I have a piqued interest in learning how I can make a workflows and automating pipelines using this technology```.
In general, at 2023-10-12 22:59:07 a user named sidhujag said ```if you guys want we can think of that on how it can work.. we can code it up but more importantly we need to be the vision guys first on how it should work 🙂```.
In general, at 2023-10-12 22:53:39 a user named sidhujag said ```my first intuition when i learned of autogen was "friendships" per agent.. so they have connections that are set or inferred and can change over time.. then you connect them to friends to talk and those dynamically change and update as you ask them questions or they discover each others abilities```.
In general, at 2023-10-12 22:51:02 a user named sidhujag said ```maybe you can finetune gpt4 with autogen codebase and then do that 🙂 not sure but perhaps its the only way to make something truly dynamic?```.
In general, at 2023-10-12 22:50:29 a user named sidhujag said ```this is why im thinking meta programmed autogen agents would be ideal.. let a prompt create the connections and if its a group which agents you want, pop them into your chat and let them create.. take them out or change them if they arent working.. but a prompter can then do it.. couple that with say S3 buckets for files and code and maybe you can scale up```.
In general, at 2023-10-12 22:48:57 a user named sidhujag said ```i been going back and forht with hierarchy and composing the summary at the end as wlel, but for coding tasks where summary can break things..not sure```.
In general, at 2023-10-12 22:48:39 a user named vermino said ```I know if we had a sit down session and the boss and the director were treated as employees - the session would never end.```.
In general, at 2023-10-12 22:48:15 a user named sidhujag said ```1) complexity 2) how do you organize that in a robust way? give me some ideas on how to actually make it dependable across generally applicable use cases```.
In general, at 2023-10-12 22:47:40 a user named sidhujag said ```id argue attention sink + context (last 10 etc) + STM + LTM can do better..```.
In general, at 2023-10-12 22:47:01 a user named sidhujag said ```the group does a full context lookup for the next speaker (seems inefficient), then the new speaker does an inference based on the full context to figure out what to say next```.
In general, at 2023-10-12 22:45:23 a user named vermino said ```Why not write to file and then recall it in next prompt in group chat? if most agents are trying to progress further in conversation on a certain topic, wouldn't have a doc file that they can recall to and improve upon be almost like short term memory? (i am just a fly on the wall by the way, my dev skills are high school level at best)```.
In general, at 2023-10-12 22:44:23 a user named sidhujag said ```id extrapolate that keeping the query plan with initial query here would be an attention sink in a group with a planner```.
In general, at 2023-10-12 22:43:25 a user named sidhujag said ```found it https://arxiv.org/pdf/2309.17453.pdf attention sinks!```.
In general, at 2023-10-12 22:42:11 a user named interestedtheory said ```I will give your paper a read :). Based on the architecture, he would have to replace the short term memory with new short term memory as the old short term memory that is being overwritten is going into long term memory.```.
In general, at 2023-10-12 22:40:30 a user named sidhujag said ```i also wrote this paper on better memory strategies inspired by human memory and cognition: https://superdapp.ai/assets/files/aida-whitepaper.pdf```.
In general, at 2023-10-12 22:37:50 a user named sidhujag said ```im tempted to write this into group chat in autogen```.
In general, at 2023-10-12 22:37:39 a user named sidhujag said ```th only thing about this one is i dont know why he does this, https://github.com/Andyinater/AutoGen_EnhancedAgents/blob/main/EnhancedAgents.py#L138```.
In general, at 2023-10-12 22:36:15 a user named sidhujag said ```cant find it but was a paper on always using the first token(s) as context, the transformation on the rest of the tokens will correlate to the first which even if semantically not related does a better job```.
In general, at 2023-10-12 22:34:33 a user named interestedtheory said ```This is really cool, I love this github repo,  I wrote a paper about this architecture using AI agents (As orchestrators) for longterm and short term memory. Really interesting noval application of it here.  I love seeing this stuff it is so cool 🙂
https://figshare.com/articles/thesis/Transformative_Collaboration_Harnessing_Collective_Contextual_Memory_in_Transformer_Architectures/22993790```.
In general, at 2023-10-12 22:28:46 a user named beigesponge said ```Thinking out loud, but could you not have a 4th agent which is just tasked with appending the "important" memory slots with some sort of tag. Then bring that into context plus n latest messages upto context limit```.
In general, at 2023-10-12 22:26:16 a user named sidhujag said ```i need to do a memory recall 😛 just sec```.
In general, at 2023-10-12 22:24:28 a user named sidhujag said ```the only issue is, we need selective static storage of some memory slots.. like if you have a finalized plan you should not lose that```.
In general, at 2023-10-12 22:23:50 a user named sidhujag said ```yup that one.. put that into the group chat```.
In general, at 2023-10-12 22:23:29 a user named somecomputerguy said ```https://github.com/Andyinater/AutoGen_EnhancedAgents```.
In general, at 2023-10-12 22:23:00 a user named beigesponge said ```so the summarisation is only kept in context basically```.
In general, at 2023-10-12 22:22:41 a user named beigesponge said ```It could possibly be that, obviously because its RAG its taking in topk=3 from the database. I've been using gpt-3.5-16k. It would work if basically I had, get topk=3, summarise, criticise, regenerate then drop the topk=3 for that piece of data from the context and then go again. But implementing that is going to be v difficult```.
In general, at 2023-10-12 22:22:38 a user named somecomputerguy said ```@andyinater has some code to do that I have been playing with```.
In general, at 2023-10-12 22:21:38 a user named sidhujag said ```im toying with concept of enhanced memory for context, stm, ltm so they can go longer but keep the first few static using recent breakthroughs that those are required for optimal context recall```.
In general, at 2023-10-12 22:20:43 a user named sidhujag said ```try to turn on the debug.. maybe the context is being lost```.
In general, at 2023-10-12 22:19:54 a user named beigesponge said ```I had the user proxy, rag agent and critic. I did have the planner at one point but they just got ignored```.
In general, at 2023-10-12 22:19:03 a user named vermino said ```Have you tried a 3rd agent in group chat?```.
In general, at 2023-10-12 22:16:38 a user named JoJo said ```Oh crazy i didnt know```.
In general, at 2023-10-12 22:15:01 a user named beigesponge said ```They announced today they were dropping the cost didn't they?```.
In general, at 2023-10-12 22:13:08 a user named beigesponge said ```Yeah, I've been trying to use it with a RAG agent to push it to get into more detail as I'm trying to query some data sources but it never extracts enough info. Was hoping to avoid having to finetune / create some RAG finetuning datasets. So I left it at the default 10 but they kinda just become happy with the response (at not enough level of detail) and then pat eachother on the back```.
In general, at 2023-10-12 22:13:01 a user named JoJo said ```And gpt4 is so expensive```.
In general, at 2023-10-12 22:11:10 a user named vermino said ```then you need a maximum time-out, where it repeats [x] amount of times before it solves the problem.```.
In general, at 2023-10-12 22:11:09 a user named sidhujag said ```there is no talking directly between agents in the chat group.. there is the group object that decides with full context every time who goes next```.
In general, at 2023-10-12 22:10:36 a user named vermino said ```I believe you need a director agent? that will push to a new subject or criticize it?```.
In general, at 2023-10-12 22:10:20 a user named beigesponge said ```I tried to just make the user proxy use GPT-4 in the hope it would stop it, but it didn't...```.
In general, at 2023-10-12 22:10:15 a user named somecomputerguy said ```If you assign a little personality they are less likely to spin in a self-congratulatory circle```.
In general, at 2023-10-12 22:09:48 a user named vermino said ```whoops, that was beige that talked about that problem```.
In general, at 2023-10-12 22:09:27 a user named beigesponge said ```I couldn't figure out why my prompts were taking 6 mins to run as I hadn't configured the user proxy correctly. Once I did, I realised they'd been patting eachother on the back for 10 minutes```.
In general, at 2023-10-12 22:08:51 a user named somecomputerguy said ```I will read the docs, it seemed to only engage once a conversableagents auto-replies expired```.
In general, at 2023-10-12 22:08:31 a user named vermino said ```man, you weren't kidding about them patting eachother on their backs```.
In general, at 2023-10-12 22:07:51 a user named JoJo said ```Is anyone actually able to use autogen with gpt3?```.
In general, at 2023-10-12 22:05:38 a user named vermino said ```just fyi, I used chatGPT4 to create those. I inputted the chatdev framework and then told it to create a legal department for me.```.
In general, at 2023-10-12 22:04:24 a user named sidhujag said ```what would be cool would be a meta-programming abstraction to autogen to prompt the creation of agents into recipe's```.
In general, at 2023-10-12 22:03:25 a user named vermino said ```and here is the Phaseconfig.json. However getting these loose ends to connect and run properly is a different story.```.
In general, at 2023-10-12 22:02:05 a user named vermino said ```here was one I was working on before I found out about autogen. Was working on a legal department to talk about cases.```.
In general, at 2023-10-12 22:01:04 a user named sidhujag said ```it will do an LLM call to figur out the role but uses full context to figure itout.. i figure you can make a function call to do that if you message the group manager or user proxy to decide who the next one is after any message```.
In general, at 2023-10-12 22:00:53 a user named vermino said ```I mean you can techincally use ChatDev to do comic creation, but you would have to create the agents, rework their chatchains, phases, and other parts of the code to make it work.```.
In general, at 2023-10-12 22:00:04 a user named sidhujag said ```to me it seems chatdev can be recreated by autogen through code creation agents, whats probably missing is using cloud file systems to store the code kinda like what chatdev does.. because code creation can get large.. a git integration can also work like chatdev did.. but extensible  agents are like legoblocks where chatdev forces application development instead of lego blocks```.
In general, at 2023-10-12 21:55:16 a user named frank.martinez said ```here's a sample YAML template created with AutoGen...```.
In general, at 2023-10-12 21:51:59 a user named zybergod said ```Auto gen would be perfect. Chatdev is for developing software. Good luck to you!```.
In general, at 2023-10-12 21:49:15 a user named mooblegum said ```ChatDev seems very powerful too. I don’t know what to use for my project. I am planing to automatise comic creations with agents that would discuss ideas and create as much content as possible automatically. But I am à bit lost to which technology I should use for that. Looks like autogen has more flexibility to communicate with agents than Chat dev tho.```.
In general, at 2023-10-12 21:47:04 a user named somecomputerguy said ```Yeah I do not understand the chatmanager, and how it interacts. Was dealing with that today, seema like it should have a role in selecting speakers but it does not seem to act in my config```.
In general, at 2023-10-12 21:34:51 a user named sidhujag said ```would it make sense for the role selection for speaker to be a function call to save a call with the full context window?```.
In general, at 2023-10-12 21:34:18 a user named sidhujag said ```hi guys.. is groupchat the best pattern to use if therea re multiple agents that need to do jobs? sort of like a hierarchical job queue```.
In general, at 2023-10-12 21:20:37 a user named zybergod said ```Here is a great tutorial: https://www.youtube.com/watch?v=yoAWsIfEzCw&pp=ygUHQ2hhdGRldg%3D%3D```.
In general, at 2023-10-12 21:20:09 a user named zybergod said ```No, it's another project: https://github.com/OpenBMB/ChatDev```.
In general, at 2023-10-12 21:19:15 a user named groundzer000 said ```it was built with autogen? do you have the link?```.
In general, at 2023-10-12 21:11:45 a user named viggos said ```Lol, any recommendations as to not have a complete round of pleasantries? My CTO and Staff Backend engineer Agents spent quite a few tokens on patting each other on the back rather than writing any code 🤣```.
In general, at 2023-10-12 20:44:04 a user named siafu said ```i'm a complete noob, is it ok to ask questions here?```.
In general, at 2023-10-12 20:17:34 a user named Paulofi said ```Keep in mind it has a open interpreter, code execution, copilot etc```.
In general, at 2023-10-12 20:15:50 a user named promptrotator said ```is it possible to build custom tools?```.
In general, at 2023-10-12 20:09:26 a user named promptrotator said ```Like meaning an API wrapper for like google```.
In general, at 2023-10-12 20:08:48 a user named promptrotator said ```Is there tool usage enabled?```.
In general, at 2023-10-12 20:01:08 a user named frank.martinez said ```JSON or YAML file; ask ChatGPT to generate one for you```.
In general, at 2023-10-12 19:59:47 a user named noahnochill said ```Hi, can you give me an example of what a Terraform file would look like? Is that just for visualisation?```.
In general, at 2023-10-12 19:58:46 a user named frank.martinez said ```Those are very different steps along the software delivery pipeline; each requiring unique interfaces and permission boundaries. Conceptually it’s feasible. Might be useful to scaffold a Terraform file that expresses each of those steps; to model the interfaces.```.
In general, at 2023-10-12 19:54:14 a user named hunterzs said ```guys any of you use Azure OpenAi for the autogen ? m newbie can someone guide```.
In general, at 2023-10-12 19:53:54 a user named Paulofi said ```If you want easy agent creation for non technicals that you ultimately deploy to a multi agent model search for Drag Drop LLM agent creation. Several tools exist```.
In general, at 2023-10-12 19:52:16 a user named noahnochill said ```and let users make them in a more friendly UI.```.
In general, at 2023-10-12 19:51:53 a user named noahnochill said ```Any cool open source projects to be following?```.
In general, at 2023-10-12 19:51:50 a user named Paulofi said ```I mean, you're at the cutting edge really w AutoGen. But you have to set your agents```.
In general, at 2023-10-12 19:51:38 a user named noahnochill said ```But that's pie in the sky```.
In general, at 2023-10-12 19:51:32 a user named noahnochill said ```Marketing is just the idea for now, but I view it as a good business function to begin with as it's a bit of a data lake and that will give me time to explore analytical capability for broader business application.```.
In general, at 2023-10-12 19:50:49 a user named Paulofi said ```If you cant explain and get your prompts right you're out to see without a paddle.```.
In general, at 2023-10-12 19:50:44 a user named noahnochill said ```Then actually being able to use workflows to plan strategic content calendars and the content planned as part of such.```.
In general, at 2023-10-12 19:50:16 a user named Paulofi said ```Product is the user generally tbh```.
In general, at 2023-10-12 19:49:55 a user named Paulofi said ```Each one of those is exceeding complex in approach and there's a few shots being taken on each. Check out TheresAnAiForThat.com and search for the agent repo or Google for it. Good resource but ya it's full steam ahead on many of those with several unique approaches. Dig into LangChain tho```.
In general, at 2023-10-12 19:49:32 a user named noahnochill said ```Product would have to kick in before anything else imo

But that is essentially my idea, but with lego-like agents, tools, and defined workflows to build out the foundational stages of business and marketing strategy. Starting with situation analysis, business context, brand, industry, audience, pain points, so on and so forth```.
In general, at 2023-10-12 19:47:05 a user named Paulofi said ```I'd love someone to take a stab at a deploy model AutoGen loop ➿  with the agents required for a full app creation and deploy;

Frontend w UI/UX, CSS whatev 
Backend API/Server Stuff
DB - Analysis & Setup
DNS/LB etc
'Devops' CI/CD/Compile/Pipelines/Deployment etc
Project Manager (meh *use prompt injection)```.
In general, at 2023-10-12 19:45:48 a user named noahnochill said ```Is anyone able to point me to a good resource on the state of generative ai now? knowledge management, giving the right context, collaboratively working with the user, multi agent systems, actual documented SOPs/Processes/Systems to use as models for development, etc. I have a background in Marketing, was a Marketing Manager at a scale-up digital agency, national campaigns etc. Specifically in content marketing and cross-channel. Always been interested in tech, Business Process Management (BPM), used to make python automations to help with repetitive tasks, etc.

I've been tinkering with autogen, but intend to check out:
- aider
- langchain
- building UI chat with prepared workflows to create specific outcomes
- Getting them hooked up to a knowledge base that it can reliably access and update

Looking for advice on any of this and related! 

Feel free to add me, looking for some connections in the space```.
In general, at 2023-10-12 19:41:22 a user named Paulofi said ```AutoGen shines in other ways but it prolly could be configured too if you know what agents you need```.
In general, at 2023-10-12 19:40:52 a user named Paulofi said ```Check out Maze for that ^```.
In general, at 2023-10-12 19:39:36 a user named groundzer000 said ```Hi guys is autogen able to build complete apps?```.
In general, at 2023-10-12 19:29:13 a user named .jirito said ```How did you get this to work? I just keep getting the error about how the API key isnt valid or cant be found```.
In general, at 2023-10-12 18:52:14 a user named mweichert said ```Hi there! Loving AutoGen thus far. I have a few AssistantAgents, and one in particular I want to use a tool/function. This works, except when I add the agent to the GroupChat. It appears then that all agents try to access the function.```.
In general, at 2023-10-12 17:06:48 a user named andyinater said ```I'll wait till I can be on my PC, gonna be at least 3 hours.```.
In general, at 2023-10-12 17:06:00 a user named regen2moon said ```we're in a call if you wanna join```.
In general, at 2023-10-12 17:05:26 a user named andyinater said ```Are there... things happening to the channels right now? Or am I bugging out.```.
In general, at 2023-10-12 17:04:31 a user named zybergod said ```Good afternoon! I can't seem to find documentation about showing real-time output from responses. Can someone help me out? I want to see what is happening between messages.```.
In general, at 2023-10-12 15:09:54 a user named interestedtheory said ```I found this resource online for a react webui https://github.com/victordibia/autogen-ui/issues do you guys know how to connect it to openai? It was not claer. Unfortunately he is using next.js and its a but verbose for a simple interface compared to react where you can have one page and maybe 3 components and you set. I would love to test it out, since I had no luck getting the Reponses from my console log backend to my ui frontend even though the socket works because  autogen seems to be a bit quirky.```.
In general, at 2023-10-12 14:58:05 a user named interestedtheory said ```I got autogen working in my terminal with python.... however I have given up on trying to make it work with react. lol been stuck at the 95% mark for 2 days. IS there a great tutorial for conenction autogen to a frontend easily for multiagent reponses  using gpt4? 🙂```.
In general, at 2023-10-12 14:43:10 a user named thiizic said ```@sonichi @li_jiang 
I have a bunch of experience managing and moderating discord servers for a nonprofit.

If you are interested I can help create an onboarding process and moderation guidelines. 

Reach out to me and we can talk more!```.
In general, at 2023-10-12 14:32:07 a user named bobaleaux said ```yeah, anyone who has 'played' with GPT4 has learned what 'pay to play' feels like. And it seems that if you have the money to play, you'd just build and train your own model.
We're already seeing startups that are providing those as locally trained models as a services using open source models.
'MAAS" I guess that will be a new model of business that will cater to the 'commercial masses' 

There is a API first trading broker now engaged a provider which has trained a model on their repo, does and i think Slack channels.
Now you can '@' address it with a question and it will respond with code or answers to questions related to the api.
An interesting 2 man startup but showcasing a new class of providers.
https://www.kapa.ai/```.
In general, at 2023-10-12 14:22:14 a user named jimmysandwiches said ```They need to as its a barrier to entry for many small businesses (and Individuals) what with that and Open Source LLMs```.
In general, at 2023-10-12 14:16:23 a user named bobaleaux said ```this is promising in he article' "The planned release of the so-called stateful API (Application Program Interface) will make it cheaper for companies to create applications by remembering the conversation history of inquiries. "```.
In general, at 2023-10-12 13:47:00 a user named bobaleaux said ```I have a feeling that what many have experienced as GPT becoming dumber or not as performant as it was a few months ago probably has a lot to do with openai trying to respond and mitigate against jailbreaking prompts and the typical persons trying to break in or hijack the model in some way. I can’t imagine what attempts openai has seen on their side as far was what people are tying to do with it or to it.```.
In general, at 2023-10-12 13:26:15 a user named jimmysandwiches said ```GOOD coz it aint cheap this Autogen 🙂
https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/```.
In general, at 2023-10-12 12:39:18 a user named thoumb said ```If that’s the most nefarious thing we have to deal with, we’ll be fine!```.
In general, at 2023-10-12 12:39:03 a user named lessuse. said ```guys i am facing a error with research agent ( related to langchain most probably ),  is anybody familiar with that , please help - https://discord.com/channels/1153072414184452236/1162006066524061757```.
In general, at 2023-10-12 12:33:21 a user named daviddelaurier said ```That is my main concern with making coding easier and easier to do. It really could have been accomplished by AutoGen. Just wait until someone has a more nefarious prompt. There is going to be a huge influx of malware and viruses very soon, all written by a LLM.```.
In general, at 2023-10-12 10:15:12 a user named cyril_tungsten said ```Of course! it's a classic```.
In general, at 2023-10-12 07:44:19 a user named vincentjedi said ```Perhaps someone has created  all the porn bots by using autogen ?```.
In general, at 2023-10-12 06:41:27 a user named regen2moon said ```I hope you get it settled soon```.
In general, at 2023-10-12 06:36:42 a user named li_jiang said ```@bansalg do you have the permission to prevent spam messages?```.
In general, at 2023-10-12 06:35:46 a user named regen2moon said ```But every server has to start somewhere!```.
In general, at 2023-10-12 06:35:37 a user named regen2moon said ```Yeah lol porn bots in an official microsoft discord server isn't a good look```.
In general, at 2023-10-12 06:34:59 a user named li_jiang said ```No. @sonichi , this needs to be handled at top priority.```.
In general, at 2023-10-12 06:28:54 a user named regen2moon said ```This is for the built in mod tools, under server settings```.
In general, at 2023-10-12 06:24:13 a user named regen2moon said ```Just basic filters I reckon is all you need```.
In general, at 2023-10-12 06:24:04 a user named regen2moon said ```I'm not familiar with most of these bots, so maybe cross checking a few for what you need```.
In general, at 2023-10-12 06:23:26 a user named regen2moon said ```If this server isn't in there, then you'll need someone with higher privileges```.
In general, at 2023-10-12 06:23:04 a user named regen2moon said ```Yeah so you just go to that page, find a bot you like, click the invite bot button. It will open in your browser (so you have to relog into discord) and from the dropdown it'll list the servers you have the ability to add to```.
In general, at 2023-10-12 06:21:55 a user named li_jiang said ```Too many for manually deleting. Could you show me how to add bots for addressing this kind of messages? I'll try if I have the permission.```.
In general, at 2023-10-12 06:13:22 a user named molten_mallow said ```the style in which the normal chatgpt returns results. word by word streaming. that kind of```.
In general, at 2023-10-12 06:12:39 a user named molten_mallow said ```@sonichi also is there a way to get streamwise output```.
In general, at 2023-10-12 06:12:00 a user named regen2moon said ```and huge bonus, some have anime girl profile pics```.
In general, at 2023-10-12 06:11:39 a user named regen2moon said ```https://top.gg/tag/moderation```.
In general, at 2023-10-12 06:11:21 a user named regen2moon said ```There are free discord bots out there that will automate this for you```.
In general, at 2023-10-12 06:11:12 a user named regen2moon said ```@sonichi Do you need help with moderation?```.
In general, at 2023-10-12 05:51:38 a user named li_jiang said ```@sonichi this is another bot```.
In general, at 2023-10-12 05:51:16 a user named regen2moon said ```I'd just crank the settings way up```.
In general, at 2023-10-12 05:51:11 a user named regen2moon said ```Discord has its own moderation tools built in```.
In general, at 2023-10-12 05:50:57 a user named regen2moon said ```You should get on this asap```.
In general, at 2023-10-12 04:04:55 a user named shortd00d said ```Natural20 by way of Flamler discord server.```.
In general, at 2023-10-12 02:51:18 a user named sonichi said ```what do you refer to as the "response", in a conversation?```.
In general, at 2023-10-12 01:47:05 a user named molten_mallow said ```@everyone 

I wanted to know how can i get the response from agent into a variable ?```.
In general, at 2023-10-12 00:48:17 a user named johnny_loquat said ```Just a general question - when using Autogen and OpenAI api with multiple agents - is each agent living in its own private independent chat conversation, system prompt and context window simultaneously? Or is there only one actual conversation and system prompts keep trying to change the behaviour of the responses?```.
In general, at 2023-10-11 23:50:11 a user named hosst. said ```Got a medium.com update with an article about AutoGen```.
In general, at 2023-10-11 23:07:19 a user named yoda892804 said ```got to hear about it from a youtube video```.
In general, at 2023-10-11 22:39:39 a user named jsimmend said ```Got to know autogen because of an university frien```.
In general, at 2023-10-11 21:27:32 a user named .markuseicher said ```Hello fellow Autogen users and devs. I'm Markus and I just landed here. I'm doing a deep dive into Machine Learning, AI and LLM's and I want to learn more about autogen. Nice to meet you all. I'm looking forward to meet interesting people, having good discussions and interactions with you all. Stay safe and see you later.```.
In general, at 2023-10-11 20:54:59 a user named andyinater said ```It seems very useful, but I haven't dove into it yet. Not sure if it was mentioned here already.```.
In general, at 2023-10-11 20:54:39 a user named andyinater said ```Idk how exactly relevant this is, but I stumbled on this yesterday or something.

https://github.com/microsoft/promptflow```.
In general, at 2023-10-11 20:20:16 a user named sonichi said ```https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent/#chat_messages```.
In general, at 2023-10-11 20:19:22 a user named sonichi said ```you can get an agent's `.chat_messages` as a dict and dump it into a json file.```.
In general, at 2023-10-11 20:00:19 a user named tc said ```before i spend some time to parse "ChatCompletion.logged_history" is there an easy way to save to files all the output produced in the chat by the agents?```.
In general, at 2023-10-11 19:48:27 a user named elshep said ```I’m also building something similar though with a slightly different spin. I like how you’re speaking to the value of the platform. I get asked a lot of the same questions. AutoGen solves some challenges I thought would take a little while longer to build myself which is 🔥```.
In general, at 2023-10-11 19:45:49 a user named gecko007. said ```Howdy all, here to learn and start building a SaaS product in a niche industry using Autogen framework```.
In general, at 2023-10-11 18:51:51 a user named quackduck. said ```where do I find a boss like this 🫠```.
In general, at 2023-10-11 18:38:57 a user named .thenyel said ```Hello! Is there a way to run typescript code in autogen?```.
In general, at 2023-10-11 18:25:42 a user named frank.martinez said ```your boss needs a raise :}```.
In general, at 2023-10-11 17:02:43 a user named scrubeneezer said ```Hello, my boss recommended I get my hands dirty with AutoGen to further my skillset in hands-on w/ AI dev.  Glad to be here```.
In general, at 2023-10-11 16:19:34 a user named sonichi said ```Did you forget `llm_config` for some AssistantAgent?```.
In general, at 2023-10-11 16:12:46 a user named hamzock said ```My problem when I create several agent on top same API i recive following error: ``` openai.error.AuthenticationError: Incorrect API key provided: 486eb9f4********************7d9b. You can find your API key at https://platform.openai.com/account/api-keys.```

while before addtional agent it was working```.
In general, at 2023-10-11 16:20:45 a user named hamzock said ```this is my config list format: ``` config_list = autogen.config_list_from_json(
    "OAI_CONFIG_LIST",
    file_location=".",
    filter_dict={
        "model": {
            "gpt-4-32k",
        }
    }
)```


and this is my OAI_CONFIG_LIST file content:```
[

    {
        "model": "gpt-4-32k",
        "api_key": "********",
        "api_base": "https://****.openai.azure.com/",
        "api_type": "azure",
        "api_version": "2023-07-01-preview"
    }
]
``````.
In general, at 2023-10-11 16:21:57 a user named sonichi said ```and what's your `llm_config` ?```.
In general, at 2023-10-11 16:22:35 a user named hamzock said ```one of my agent: ```# Legal Advisor Agent
LegalAdvisor = autogen.AssistantAgent(
    name="Legal Advisor",
    llm_config={"config_list": config_list},
    system_message="You're here to interpret and implement financial regulations in a compliant manner."
)``````.
In general, at 2023-10-11 16:23:10 a user named sonichi said ```Rembmer that the GroupChatManager needs a `llm_config` too```.
In general, at 2023-10-11 16:28:34 a user named hamzock said ```I shared all my code in your PM```.
In general, at 2023-10-11 16:30:01 a user named afourney said ```By any chance, is this you? https://github.com/microsoft/autogen/issues/184```.
In general, at 2023-10-11 16:30:36 a user named afourney said ```If not, then it's a second instance of the issue, and evidence of some change.```.
In general, at 2023-10-11 16:31:27 a user named sonichi said ```try one thing: set your `config_list` directly as the list, instead of loading from the file```.
In general, at 2023-10-11 16:32:39 a user named afourney said ```@sonichi I notice that in the Completions class, there is debugging information printed for when it falls through the config_list. How do we turn on logging.debugging output?```.
In general, at 2023-10-11 16:32:56 a user named afourney said ```That would at least provide some trace as to what endpoints are being called```.
In general, at 2023-10-11 16:38:03 a user named afourney said ```If I had to guess I'd say at least one agent is somehow not receiving the config_list for whatever reasons. In that case it will fall back to default behavior which is OpenAI, reading keys from the OPENAI_API_KEY environment variable. But I'm not sure why the list isn't working...```.
In general, at 2023-10-11 16:38:38 a user named afourney said ```Can you try removing one agent at a time from GroupChat, until the error goes away, and then we can look into what that agent is?```.
In general, at 2023-10-11 16:39:11 a user named afourney said ```(And as Chi noted above, the GroupChatManager, also needs an llm_config.. which is sounds like you are providing)```.
In general, at 2023-10-11 16:47:22 a user named sonichi said ```Do you have "OPENAI_API_KEY" in your environment? Someone reported that when that is in the environment, it caused the problem```.
In general, at 2023-10-11 16:48:00 a user named hamzock said ```I had not. I added to after erro to see if it need to read it```.
In general, at 2023-10-11 16:48:39 a user named hamzock said ```I commented every agent one by one but it does not work yet```.
In general, at 2023-10-11 16:49:52 a user named afourney said ```"pip show openai", and "pip show pyautogen" outputs would be helpful```.
In general, at 2023-10-11 16:51:16 a user named hamzock said `````` pip show pyautogen  
Name: pyautogen
Version: 0.1.10``````.
In general, at 2023-10-11 16:51:39 a user named hamzock said `````` pip show openai
Name: openai
Version: 0.28.1``````.
In general, at 2023-10-11 16:52:02 a user named sonichi said ```I'm receving that error too when upgrading to 0.28.1```.
In general, at 2023-10-11 16:52:58 a user named sonichi said ```even with 0.28.0. Something must be broken.```.
In general, at 2023-10-11 16:53:46 a user named hamzock said ```I have downgraded openai to 0.28.0 but same error```.
In general, at 2023-10-11 16:54:28 a user named sonichi said ```my bad, I forgot to specify file location.```.
In general, at 2023-10-11 16:54:37 a user named sonichi said ```After specifying the file location it works.```.
In general, at 2023-10-11 16:55:10 a user named sonichi said ```Does the simple twoagent.py work for you?```.
In general, at 2023-10-11 16:56:09 a user named hamzock said ```two agent with two diffrent model yes it worked```.
In general, at 2023-10-11 16:56:53 a user named sonichi said ```With one model it should work too```.
In general, at 2023-10-11 17:25:27 a user named hamzock said ```it does not when I dont have two diffrent model```.
In general, at 2023-10-11 17:26:25 a user named sonichi said ```how are you using the two different models?```.
In general, at 2023-10-11 22:37:31 a user named hamzock said ```I have two seprete GPT models deployed on Azure OpenAI so when I have two model and two agent config works perfectly```.
In general, at 2023-10-11 22:38:23 a user named hamzock said ```I don’t is there any issue because I use Azure OpenAI endpoint instead of OpenAI endpoint? @sonichi```.
In general, at 2023-10-11 23:09:18 a user named sonichi said ```Using two models or one model for two agents should both work. Including Azure OpenAI.```.
In general, at 2023-10-12 08:01:23 a user named hamzock said ```One model for several agents does not work/i can’t yet debug the problem```.
In general, at 2023-10-12 13:30:56 a user named sonichi said ```This example works for me:
```python
config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST", file_location="notebook")
assistant = AssistantAgent("assistant", llm_config=config_list[2])
analyst = AssistantAgent("analyst", code_execution_config={"work_dir": "coding"}, llm_config=config_list[2], system_message="You are a financial analyst. Reply TERMINATE to end the conversation.")
analyst.initiate_chat(assistant, message="Plot a chart of NVDA and TESLA stock price change YTD.")
``````.
In general, at 2023-10-12 13:31:10 a user named sonichi said ```I used the same LLM config for both agents```.
In general, at 2023-10-12 13:31:22 a user named sonichi said ```And I used Azure OpenAI```.
In general, at 2023-10-16 08:23:53 a user named hamzock said ```the main issue was Azure OpenAI deplyment. I changed to a new instance then with new isntanse and new key prevouse code without any change worked perfectly.```.
In general, at 2023-10-11 15:47:01 a user named aaronward_ said ```you cant use it directly yet, see my messages from this thread: https://discord.com/channels/1153072414184452236/1158548894209282078```.
In general, at 2023-10-11 15:41:00 a user named hamzock said ```could I build several agent all on top one Azure OpentAI API?```.
In general, at 2023-10-11 15:40:04 a user named nidzamdotcom said ```Hey guys! I'm new here, just wanted to say hello!```.
In general, at 2023-10-11 15:22:17 a user named christkrishna said ```Sorry about the following, computers bugging and I’m using discord from phone…
I’m trying to serve locally and I get this error from this code… anyone want to point me in the right direction? I’m using ollama and I get a response via curl but can’t connect via autogen```.
In general, at 2023-10-11 15:05:56 a user named frank.martinez said ```Agents are not individual entities; they are members of a larger entity. Unfortunately there isn’t a native pattern for associating an agent to an entity; where entity could be a team, org, company. Thus, what interface in the AutoGen SDK can be mutated for this purpose?```.
In general, at 2023-10-11 14:56:52 a user named frank.martinez said ```if everything is a container; are we all in a dream?```.
In general, at 2023-10-11 14:46:59 a user named fxtoofaan said ```I’ve been asking for this kind of tool , tool that creates autogen scripts, but no luck yet```.
In general, at 2023-10-11 14:34:12 a user named tiagoefreitas said ```basically need different levels of abstraction and each level operates at a given task complexity score```.
In general, at 2023-10-11 14:33:20 a user named tiagoefreitas said ```each meta-agent-app would have a description of what it can do and then used as a tool by a higher level agent (what I’m building). finding the sweet spot in task complexity is an open problem (gpt4 can’t do it)```.
In general, at 2023-10-11 14:30:40 a user named tiagoefreitas said ```I am interested in making an autogen agent-app (meta agent?) generator, as currently you need to build them yourself by composing the agents. but for now an agent-app marketplace would be cool```.
In general, at 2023-10-11 14:25:20 a user named sonichi said ```The simplest way is to pickle the agents.```.
In general, at 2023-10-11 14:10:47 a user named tiagoefreitas said ```thanks!
does autogen need a running process necessarily or is there a potential way of making it stateless?```.
In general, at 2023-10-11 14:09:16 a user named sonichi said ```Cool app 🙂 @ekzhu this made me remember a demo you had before```.
In general, at 2023-10-11 13:54:45 a user named tiagoefreitas said ```Hey just found you on bens newsletter, just after the AI Eng Summit. I’m working on a work automation app and autogen looks perfect to integrate will look into it
https://scarletai.co is my app```.
In general, at 2023-10-11 13:38:50 a user named sonichi said ```yes, we should add this to the roadmap.```.
In general, at 2023-10-11 13:34:01 a user named dreamzjames said ```I was watching you tube when I came across this gem.```.
In general, at 2023-10-11 13:15:11 a user named cyril_tungsten said ```@li_jiang btw users can mention some roles and abuse it```.
In general, at 2023-10-11 13:14:22 a user named asheoro said ```I also found Autogen @matthew_berman on YT```.
In general, at 2023-10-11 13:09:42 a user named leonardooliva said ```found on openai discord server```.
In general, at 2023-10-11 12:43:55 a user named securemeup said ```When the new sdk comes out with openai https://github.com/openai/openai-python/discussions/631

Will this break the current functionality of autogen for some time?```.
In general, at 2023-10-11 12:24:49 a user named delgrundy. said ```Found Autogen @matthew_berman on YT```.
In general, at 2023-10-11 11:34:04 a user named zephyr1002 said ```is it possible to use the quantized version of the models from HF in Autogen with litellm because i read the documentation and currently fast chat do not support the gguf or gptq or ggml.```.
In general, at 2023-10-11 11:16:15 a user named ExplodingMule said ```is there any way in getting autogpt to code php instead of just swift, js or python?```.
In general, at 2023-10-11 10:55:03 a user named li_jiang said ```some are using litellm https://discord.com/channels/1153072414184452236/1153072414184452241/1161488673917915146```.
In general, at 2023-10-11 10:34:23 a user named zephyr1002 said ```so it is only possible via fastchat ?```.
In general, at 2023-10-11 10:29:25 a user named li_jiang said ```Try this: https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs```.
In general, at 2023-10-11 10:27:19 a user named zephyr1002 said ```hi, can anyone tell me. is it possible to use llama 2 or mistral 7b with autogen?```.
In general, at 2023-10-11 10:23:14 a user named li_jiang said ```Sure. Thank you so much! I don't have permission to totally ban him, need @sonichi .```.
In general, at 2023-10-11 10:22:48 a user named regen2moon said ```Still spam messages in some channels```.
In general, at 2023-10-11 10:21:49 a user named regen2moon said ```What you want to look for online is "How to disable @ everyone permissions```.
In general, at 2023-10-11 10:21:37 a user named regen2moon said ```Sorry its 6am for me, I am unable to```.
In general, at 2023-10-11 10:19:26 a user named li_jiang said ```Thank you @regen2moon , turns out I don't have permission to ban the bot. I just deleted the msg and kicked him.```.
In general, at 2023-10-11 10:09:06 a user named li_jiang said ```I still get this. Can we have a call? @regen2moon```.
In general, at 2023-10-11 10:06:58 a user named regen2moon said ```You might want to try setting the permission on the channel category, then sync them to each channel one by one```.
In general, at 2023-10-11 10:06:22 a user named regen2moon said ```@li_jiang The bot's messages are in every channel...```.
In general, at 2023-10-11 10:04:04 a user named regen2moon said ```Maybe allow only moderators to?```.
In general, at 2023-10-11 10:03:17 a user named li_jiang said ```It says I should first allow some role to do it, otherwise nobody would be able to do it```.
In general, at 2023-10-11 10:01:39 a user named regen2moon said ```set mention everyone to X```.
In general, at 2023-10-11 10:01:26 a user named regen2moon said ```Go into the <#1153072414184452241> channel settings```.
In general, at 2023-10-11 10:00:44 a user named regen2moon said ```Their message is still here```.
In general, at 2023-10-11 10:00:28 a user named li_jiang said ```And I can't see the bot in the member list```.
In general, at 2023-10-11 09:58:28 a user named li_jiang said ```I didn't change anything, it's already like this```.
In general, at 2023-10-11 09:58:05 a user named regen2moon said ```@li_jiang You should delete that bot message too```.
In general, at 2023-10-11 09:57:50 a user named regen2moon said ```@li_jiang Scroll down to This section```.
In general, at 2023-10-11 09:56:37 a user named regen2moon said ```Correct, then under roles, you set the 'everyone' role to have no permission to send @ everyone```.
In general, at 2023-10-11 09:56:15 a user named li_jiang said ```I  only see this```.
In general, at 2023-10-11 09:55:45 a user named regen2moon said ```noo thats just locally for you```.
In general, at 2023-10-11 09:55:21 a user named li_jiang said ```I think I  just kicked this bot. How can I verify that?```.
In general, at 2023-10-11 09:49:46 a user named li_jiang said ```Let me see.  Like this?```.
In general, at 2023-10-11 09:48:31 a user named regen2moon said ```This can be easily abused.```.
In general, at 2023-10-11 09:48:27 a user named regen2moon said ```You should also disable every user being able to @ everyone```.
In general, at 2023-10-11 09:42:41 a user named ExplodingMule said ```I just opened using colab, that is the easiest way. Run the install (remove the #) from the code. https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb#scrollTo=Bt2VkwG_C15H```.
In general, at 2023-10-11 08:57:23 a user named krisograbek said ```Hello, just started playing with AutoGen!```.
In general, at 2023-10-11 08:43:35 a user named nomitronz said ```Good morning! Been following this research and other similar projects like ChatDev. Excited to give this a go.```.
In general, at 2023-10-11 07:52:39 a user named justintimmer said ```Hello I am a novice but a quick learner need help setting up```.
In general, at 2023-10-11 05:25:52 a user named bookcelerator said ```awesome!  would love to connect on linkedin as well as here```.
In general, at 2023-10-11 05:21:23 a user named simone_08773_45076 said ```hi there, i must connect to proxy server before access to openai in my firm internet, i wonder if it is possible to do that in AutoGen?```.
In general, at 2023-10-11 05:05:35 a user named yogeshharibhaukulkarni said ```https://www.linkedin.com/posts/yogeshkulkarni_ai-autonomousagents-technologytrends-activity-7113723892661153792-V51d @sonichi```.
In general, at 2023-10-11 04:42:22 a user named gpsandhu said ```Hello everyone. I came across AutoGen today and really excited to build stuff using this. Does anyone have good references for how to add ability for agents to talk to external services? I've built Agents using Langchain with custom tools to connect to external services in the past - https://medium.com/@gurpartap.sandhu3/i-know-kung-fu-adding-new-skills-to-your-ai-agent-using-custom-tools-e21198625e83```.
In general, at 2023-10-11 04:16:18 a user named bookcelerator said ```Hey all not sure if I put this here but I am hiring people with autogen experience!  I know it's early stage but if interested please DM me!```.
In general, at 2023-10-11 04:02:03 a user named yssrexe said ```Guys this automated checker for simple shell tasks ...
on the redme.md file you will find all steps to check you code
https://github.com/yssrexe/automated_checker```.
In general, at 2023-10-11 03:34:46 a user named sam.li said ```https://tenor.com/bGR09OYlf01.gif```.
In general, at 2023-10-11 03:15:21 a user named _appman said ```crawled upon it through utube videos and research.microsoft.com hence I'm here soon to start working on prompts.```.
In general, at 2023-10-11 03:10:08 a user named kajatta said ```Haha classic, will try soon```.
In general, at 2023-10-11 02:21:41 a user named Krrish said ```i think adding to prompt is less than ideal - open to suggestions for how we can be more helpful @teddybear082```.
In general, at 2023-10-11 02:21:19 a user named Krrish said ```Here's the code: 
```litellm --model together_ai/togethercomputer/CodeLlama-34b-Instruct --add_function_to_prompt```

That's all you need to spin up a local proxy to call together ai and handle the function calling situation```.
In general, at 2023-10-11 01:53:53 a user named teddybear082 said ```Oh that’s great thank you I will check it out!```.
In general, at 2023-10-11 01:35:28 a user named Krrish said ```hey @teddybear082 we recently added the option to add the function details as part of the prompt, if an api doesn't support it. See here for more details - https://github.com/BerriAI/litellm/issues/557```.
In general, at 2023-10-11 01:20:02 a user named regen2moon said ```I've got a good start with basic structures hard coded, but expanding to this modular form.```.
In general, at 2023-10-11 01:19:44 a user named regen2moon said ```Could use help with more prompt engineering so the LLM produces  somewhat consistent output to be parsed, processed, and forwarded when need to.```.
In general, at 2023-10-11 01:18:57 a user named regen2moon said ```I'm claiming the name "Autohm" pronounced 'Autumn'```.
In general, at 2023-10-11 01:18:19 a user named regen2moon said ```Working a project, where a lead agent can request and build its own agents, structure, and workflow based on its own plan.```.
In general, at 2023-10-11 01:04:39 a user named egpls said ```thought i'd ask in here before trying to sift through the lib: is there any built in functionality for iterating on previously created programs on a new run? For example, if my task is to implement feature A and save the result in`app.py` and I want to create a new task2 to implement feature B in `app.py`, is there a way for those agents to see the current `app.py` , or would I have to do something like send the entire `app.py` in the message content and ask for a modification and store in `app_2.py`?```.
In general, at 2023-10-11 00:21:05 a user named acthow said ```对 AI AGENT 非常关注，并且想选择一个比较合适的 AGENT 开发框架，但是不知道应该选AUTOGEN?还是 LONGCHAIN?还是其他？```.
In general, at 2023-10-10 23:40:16 a user named jr123104 said ```I'm working on a project that is going to need multiple groups of agents with a dynamic conversation flow working in tandem to solve a task. The idea is for groupchat 1 and its agents to perform semantic tasks, then forward the results to groupchat 2 and have those agents do their tasks. It would also be fun to experiment with an agent who sits outside the group chats who is capable of forwarding parts of a prompt to different groups. I know how to start a single conversation in a groupchat, but how would I use multiple groups in tandem? Is there a good example on github, or a block of code I can study somewhere?```.
In general, at 2023-10-10 21:51:50 a user named sonichi said ```There is one under construction: https://github.com/orgs/microsoft/projects/989```.
In general, at 2023-10-10 21:40:25 a user named thiizic said ```Hey is there a public roadmap?```.
In general, at 2023-10-10 18:37:22 a user named fxtoofaan said ```Anyone able to take autogen GitHub repo and use save the framework in vector db and then tell autogen to use autogen framework to code python scripts ?```.
In general, at 2023-10-10 18:31:44 a user named unicorn1997 said ```Hello folks,
We just made a simple tutorial for code execution with AutoGen.. plus some thoughts.
Im more and more excited about AutoGen, my favorite framework so far. Happy to discuss agents and see what you all are building. We included some examples from community to the end of the article.
https://e2b.dev/blog/microsoft-s-autogen```.
In general, at 2023-10-10 18:11:25 a user named afourney said ```Just out of pure curisosity, what do you see when you call "pip show openai"```.
In general, at 2023-10-10 18:09:36 a user named afourney said ```Basically it’s expected that a  valid openai_api_key will cause the default GPT-4 to succeed. But I’d expect that only if the config list was wrong.  Given that it works in your case,  it’s clear the config list is accurate```.
In general, at 2023-10-10 18:07:24 a user named afourney said ```Hmm ok let me track that down it’s a helpful hint```.
In general, at 2023-10-10 17:57:46 a user named tc said ```yep since i setup an invalid key there, the config i define for autogen works just fine, even with the proper method.
llm_config={"config_list": config_list}```.
In general, at 2023-10-10 17:48:53 a user named tc said ```can't make any sense out of this 🤷🏻‍♂️```.
In general, at 2023-10-10 17:48:19 a user named tc said ```@afourney hang on! i spotted something else that it might be really useful to understand what is going on.

turns out, it doesnt matter what i do, my config it's ignored if i have a valid openai key into "OPENAI_API_KEY" in my env variables.
once i change to "stop"
setx OPENAI_API_KEY "stop"

suddenly the config starts working```.
In general, at 2023-10-10 17:43:38 a user named tc said ```correct, ALL the agents had this```.
In general, at 2023-10-10 17:35:11 a user named hamzock said ```I have a similar question```.
In general, at 2023-10-10 17:24:07 a user named afourney said ```Above you stated
```
and then i attach it everywhere like this:
group_chat_manager = GroupChatManager(
    groupchat=group_chat, llm_config={"config_list": config_list}
)
```

Can you confirm that **every** agent you create gets llm_config={"config_list": config_list} ? Not just the GroupChatManager?```.
In general, at 2023-10-10 17:05:05 a user named hamzock said ```My question: What is relation between Autogen and Semantic kernel?```.
In general, at 2023-10-10 16:24:32 a user named rouzbeh4913 said ```It has couple of issure after i gave it a try. It can not undrestand the image correclt even when i used chatgpt4 user agenet```.
In general, at 2023-10-10 16:01:39 a user named c_bonadio said ```Autogen interacting using FastApi (very basic)

https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af

Hi, 
I create this code to enable a user using any web cliente to interact with Autogen, it communicates using FastApi websocket 
it allows you to interact with the user_proxy at every step, not only at the end.```.
In general, at 2023-10-10 15:24:07 a user named afourney said ```Anyhow, the default is set here: https://github.com/microsoft/autogen/blob/fa6e2a52c00a28756b9cf30e85bc336d4c5da055/autogen/agentchat/conversable_agent.py#L43 and defined here https://github.com/microsoft/autogen/blob/fa6e2a52c00a28756b9cf30e85bc336d4c5da055/autogen/code_utils.py#L18 , so one thing we can do is change it to something that doesn’t exist, and it should throw an error if it ever falls back to the default  — for debugging```.
In general, at 2023-10-10 15:19:22 a user named afourney said ```Ok cool. Thanks for working with us on this. Definitely a top priority```.
In general, at 2023-10-10 15:18:50 a user named tc said ```i will keep using the llm_config=config[0] for now, but i will keep an eye out in chat, if you do fix it and you remember about me please ping me 🤣```.
In general, at 2023-10-10 15:18:38 a user named afourney said ```Basically it definitely happens if that list e values to False```.
In general, at 2023-10-10 15:18:04 a user named afourney said ```Ok please don’t spend more money on this 😉  let me dig into this more. I’m able to reproduce and trace it now, and it’s possible that there’s an angle I’m missing```.
In general, at 2023-10-10 15:18:02 a user named tc said ```yeah sonichi was a bit baffled as well```.
In general, at 2023-10-10 15:17:19 a user named afourney said ```No that first dictionary should have worked. Hmm```.
In general, at 2023-10-10 15:07:13 a user named tc said ```will give it a try```.
In general, at 2023-10-10 15:07:08 a user named tc said ```aaah hang on you are suggesting that i do this {"config_list": config_list[0]}```.
In general, at 2023-10-10 15:06:25 a user named tc said ```and i was getting defaulted to gpt-4```.
In general, at 2023-10-10 15:06:15 a user named tc said ```as you can see i was doing what you are suggesting: {"config_list": config_list}```.
In general, at 2023-10-10 15:05:39 a user named tc said ```@afourney this was my originally code```.
In general, at 2023-10-10 15:04:33 a user named tc said ```i will give it a try! i'm just scared of trying things as each mistake costs $$```.
In general, at 2023-10-10 14:43:53 a user named afourney said ```Well it’s easy to give it a try 😉     In my biased view, we’re pretty configurable along several important dimensions and that’s one reason you might find it works better than AutoGPT for your scenario — if it doesn’t at first, it’s quick to find an arrangement that does```.
In general, at 2023-10-10 14:42:13 a user named fxtoofaan said ```Hopefully we will see some good example of this in use ?```.
In general, at 2023-10-10 14:39:32 a user named 7racker said ```I’ve been seeing a lot of videos pop-up talking about AutoGen. It seems promising but I don’t know how successful it would be, but I want to find out. I’ve tried AutoGPT and was disappointed like so many others.```.
In general, at 2023-10-10 14:33:05 a user named afourney said ```Anyhow, I was able to reproduce the error, and I traced it... What happens is that if the config_list evaluates to false, then it backs off to  the "model" value of the llm_config dictionary. By default that model value is gpt-4. In your case, when you take the first element of the list as the whole config, you are providing it with a dictionary where the model value is now 3.5... But, crucially, the config_list will still evaluate to false (because it is now missing), and so that backoff behavior is still occurring... hence my earlier claim that I think it's working by accident```.
In general, at 2023-10-10 14:30:02 a user named afourney said ```the config_list is only part of the config... (llm_config is a dictionary with a config_list key)```.
In general, at 2023-10-10 14:29:48 a user named afourney said ```Don't pass the list. Pass a dictionary with one key called "config_list" where the value is the one-element list.```.
In general, at 2023-10-10 14:29:00 a user named tc said ```if i pass the list (which contains only 1 element), it uses gpt-4```.
In general, at 2023-10-10 14:28:47 a user named tc said ```and if i use just the [0] element it works```.
In general, at 2023-10-10 14:28:34 a user named tc said ```i had this discussion with @sonichi  yesterday, yes it prints the right content referincing gpt-3```.
In general, at 2023-10-10 14:28:09 a user named afourney said ```Then the config_list is probably empty. Can you print it?```.
In general, at 2023-10-10 14:27:45 a user named tc said ```noop, with that it uses gpt-4 by default, or at least it does for me```.
In general, at 2023-10-10 14:27:15 a user named afourney said ```Ok, that works.. but sort of by accident (for the same reason it was accidentally falling back to GPT-4). It should be like this: llm_config={"config_list": config_list}```.
In general, at 2023-10-10 14:24:51 a user named .princeps said ```Thanks soo much to @li_jiang @qingyunwu, @sonichi and everyone on the team! Y’all do amazing work and I’m happy to be here to support and appreciate your dedication and effort```.
In general, at 2023-10-10 14:23:41 a user named .princeps said ```Also that makes two releases for today!```.
In general, at 2023-10-10 14:23:31 a user named .princeps said ```https://github.com/microsoft/autogen/releases/tag/v0.1.10```.
In general, at 2023-10-10 14:22:52 a user named .princeps said ```The update I’ve been waiting for is out!```.
In general, at 2023-10-10 14:22:34 a user named .princeps said ```https://tenor.com/view/chivas-arriba-las-chivascampeon-gif-11833940```.
In general, at 2023-10-10 13:44:31 a user named nexorsist said ```Basically: UserMsg -> Agent Assess Intent -> Based on intent, performs an instruction and sends to pre-existing function -> Responds to original msg. 

Not wanting the intent assessment, instruction and function calling to form part of the final response. 

Or is it just a matter of running a second agent that provides the response and the first agent does the background work?```.
In general, at 2023-10-10 13:37:05 a user named nexorsist said ```Hi! This might be a dumb question (I'm trying to solve for a chain of assistants in a workflow), but is there a setup where an LLM can respond one thing but perform a task in the background based on the input without including that in the response?

eg. Decide whether the users input belongs to one of 4 categories (A,B,C,D) and send the correct category to a function, but respond to the user eg "Thanks for your input blah blah blah"?```.
In general, at 2023-10-10 13:30:33 a user named li_jiang said ```A new version is released to support  plug in customized vectordb and embedding functions for RetrieveChat (RAG). https://github.com/microsoft/autogen/releases/tag/v0.1.10```.
In general, at 2023-10-10 13:12:54 a user named fxtoofaan said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb```.
In general, at 2023-10-10 12:50:17 a user named satya_1987 said ```How can we add the knowledge base to the multiagent ?```.
In general, at 2023-10-10 12:35:07 a user named mana84_88876 said ```hello, is it possible to run autogen locally with GPT4ALL model without API ?!```.
In general, at 2023-10-10 10:37:57 a user named ExplodingMule said ```Can autogen be used to create php scripts? I'm using autogen in colab (never used before) but it just says "As an AI, I can provide code snippets and guidance, but I'm unable to execute PHP code or any other code that isn't Python." If I set up in docker, would it work that way?```.
In general, at 2023-10-10 10:34:18 a user named andrey_unstopable said ```Is there a way I can use autogen in typescript without setting up a python backend?```.
In general, at 2023-10-10 10:27:49 a user named tomexmachina said ```Using. I don't think OR has code you can self-host. It's an API that gives you access to a bunch of LLMs.```.
In general, at 2023-10-10 10:25:42 a user named shintai8531 said ```for hosting or using or both?```.
In general, at 2023-10-10 09:07:13 a user named ilaffey said ```https://twitter.com/ilaffey2/status/1711669344760148459

Here's the demo! threw a quick vid together```.
In general, at 2023-10-10 08:58:18 a user named yogeshharibhaukulkarni said ```My LinkedIn post on AutoGen (has my Medium story embedded in it) https://www.linkedin.com/posts/yogeshkulkarni_what-is-microsoft-autogen-activity-7117432332185182208-jDYe```.
In general, at 2023-10-10 08:12:28 a user named ilaffey said ```but i think it will be a great demo and we can come up with better ways to integrate autogen as a backend server- and facilitate chats w/ a web input```.
In general, at 2023-10-10 08:11:44 a user named ilaffey said ```going to release a demo + open source it (it's still very rough, can use many improvements as well as styling)```.
In general, at 2023-10-10 08:11:22 a user named ilaffey said ```guys i have a working web app with autogen + ai generated characters + images```.
In general, at 2023-10-10 07:16:46 a user named fran.abenza said ```Its just a matter of time that a book with revised (LLM) programming **design patterns** appears in the market. What the title should be for it to a no-brainer for you??```.
In general, at 2023-10-10 07:05:33 a user named foxpassed said ```went into a youtube rabbit hole. looks neat!```.
In general, at 2023-10-10 07:03:53 a user named tomexmachina said ```https://openrouter.ai/docs#models

Just found OR is providing Mistral 7B usage for free```.
In general, at 2023-10-10 06:59:45 a user named jimmysandwiches said ```why not try asking chatgpt directly? "im looking for use case ideas on how to use a python script that allows the use of multiple ai agents that converse with each other to complete tasks" 😆```.
In general, at 2023-10-10 06:47:46 a user named tc said ```Quick guide on how i fixed it:
__________________________________
create OAI_CONFIG_LIST:

[
    {
        "model": "gpt-3.5-turbo-16k",
        "api_key": "YOUR_KEY"
    }
]

it should sits in the same directory of the script you are running.
____________________________________

load the config like this:

config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")
config=config_list[0]
__________________________________
pass this parameter
llm_config=config_list[0]
to each one of your agents```.
In general, at 2023-10-10 05:29:46 a user named riverlay said ```I have gone through all the examples provided in the AutoGen documentation, but I am still unable to come up with a unique idea. I am curious to know, in what scenarios are you utilizing this framework😆 ? 🙂```.
In general, at 2023-10-10 04:09:37 a user named elshep said ```Absolutely loving this resource that y'all have created```.
In general, at 2023-10-10 03:44:39 a user named jigjigsaw said ```Is it possible to use Llama-2 instead of OpenAI```.
In general, at 2023-10-10 03:25:40 a user named sonichi said ```This research may be used to improve autogen in future. Inputs from this community are appreciated!```.
In general, at 2023-10-10 03:21:43 a user named sonichi said ```https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logic-error This feature can be used to handle logic error and auto retry next config in the list```.
In general, at 2023-10-10 02:27:54 a user named atlmapper said ```Hey everyone, found you on github, happy to be here```.
In general, at 2023-10-10 02:22:21 a user named negarempr said ```🌟 Join our research journey! Help shape the future of Large Language Models.  
🚀📚  Share your valuable insights and experiences by taking our short survey (est: 5 mins)

http://bit.ly/3Fb8v5p

We are a team of researchers dedicated to the study and evaluation of LLMs  and their impact on various tasks. Your insights and experiences help us understand how LLMs are being utilized in the real world. We deeply  appreciate you for your time and expertise! 🙏```.
In general, at 2023-10-10 02:08:22 a user named afourney said ```Yes it will retry in the order of models in the list… but only on rate limit or similar errors. If it’s suggesting incorrect chess moves, it won’t back off to a better model, no.```.
In general, at 2023-10-10 02:03:25 a user named alwaystinkering said ```I am having trouble pitching use cases. 

I have worked to load quivr with a manual for a restaurants stove and work through troubleshooting scenarios.

That is something I am looking to autogen for```.
In general, at 2023-10-10 01:47:41 a user named yuzhun said ```I tried gpt3.5 for chess play and it failed, wondering how do autogen choose model? Is there a priority flag? Do autogen auto retry with different model in the config file?```.
In general, at 2023-10-10 01:22:58 a user named platinumpluto said ```If it is okay can I discuss about something? Sorry for my bad English in advance!```.
In general, at 2023-10-10 00:36:48 a user named smuggybuggins said ```Random Reddit search and Youtube. Never coded in my life and somehow followed the AutoGen Tutorial and built a "live" version. I am now too hooked to concentrate at work!```.
In general, at 2023-10-10 00:19:14 a user named gjipe said ```How is that going for you ? doin the same over here in London```.
In general, at 2023-10-09 23:58:34 a user named covetech said ```Honestly youtube.  I just learned about it today watching a tutorial.```.
In general, at 2023-10-09 22:12:54 a user named jaemil said ```https://www.getonboard.dev/chat/microsoft/autogen```.
In general, at 2023-10-09 22:09:49 a user named afourney said ```In any case, the next release will print a warning when the file cannot be found. Arguably this should probably graduate to an actual exception```.
In general, at 2023-10-09 22:05:05 a user named kohanzie said ```XD out of habit, this mightve fixed it too, so annoying lol. thank you if im having any other trouble ill reopen```.
In general, at 2023-10-09 22:04:57 a user named afourney said ```Ok, to summarize what's happening as far as I understand it: https://github.com/microsoft/autogen/issues/125#issuecomment-1754004740```.
In general, at 2023-10-09 21:55:12 a user named mightyscoo said ```I'm a software engineer.  I built my first neural network in 1982 and I was an immediate convert.  At the time I didn't have the research bug, but now I do.  So, I'm here and will be lurking, trying to figure out what I can do with all this.```.
In general, at 2023-10-09 21:38:24 a user named alwaystinkering said ```I am a former software engineer at Microsoft and other orgs. I am now working in Detroit to assist small businesses with adoption of AI type technologies.```.
In general, at 2023-10-09 21:31:37 a user named jew84930585 said ```i’ll try to reproduce it again too more under the microscope```.
In general, at 2023-10-09 21:29:16 a user named afourney said ```@kohanzie @jew84930585 still working out where the default is being pulled from, but the main branch now prints a warning if it can't load the OAI_CONFIG_LIST file and reverts to some default. Hopefully that will help. In the meantime, @kohanzie  I noticed that your file is called OAI_CONFIG_LIST.json   it should not have the ".json" at the end -- just "OAI_CONFIG_LIST"```.
In general, at 2023-10-09 21:24:39 a user named jew84930585 said ```i’ve noticed this bug as well, something in autogens config is forcing gpt-4```.
In general, at 2023-10-09 21:24:28 a user named dr.goatfish said ```Hey, how can we use group chat to analyze datasets, communicate and a comparison agent finishes the task by using the 4 other groupchat members to generate of csv of dates, reported hours worked and estimated hours worked from the comparison of datasets. 

I am trying to use AutoGen to validate an employees reported hours worked and refute her claim that she is owed overtime pay before her termination. The AI agent will complete the task by interpretting the tabular datasets related to her activities as an employee: Email conversations, QuickBook Activities, Door Badge (entry time to office) and Reported Hours Worked. The AI Agents will analyze the quickbook activities against reported hours worked, emails, etcetera to refute her claims that she is owed overtime. The agents will provide a estimated time difference between what she reported and what the agent inspects in the data.```.
In general, at 2023-10-09 21:00:38 a user named pablo.ce said ```Hi guys learn autogen form a youtube video 🙂```.
In general, at 2023-10-09 20:42:43 a user named afourney said ```Sorry I missed the Azure part 😛, and deleted the previous OAI link.  Good question on setting up Azure -- I haven't done that as an external user, so i'm not 100% sure.```.
In general, at 2023-10-09 20:42:43 a user named somecomputerguy said ```Huh, I used the azure portal to stand up a deployment, is that link cheaper?```.
In general, at 2023-10-09 20:35:36 a user named afourney said ```@kohanzie can you add these details to: https://github.com/microsoft/autogen/issues/125```.
In general, at 2023-10-09 20:33:05 a user named tangerine1528 said ```How can I apply or get Azure OpenAI Api key any one can help?```.
In general, at 2023-10-09 20:28:56 a user named somecomputerguy said ```Cool, yeah I can play with that```.
In general, at 2023-10-09 20:28:24 a user named bobaleaux said ```here's how i did it;

it isn't perfect but it was a fast start```.
In general, at 2023-10-09 19:52:28 a user named sonichi said ```AssistantAgent with system message like "Reply TERMINATE if ..."```.
In general, at 2023-10-09 19:51:34 a user named pbeheca said ```Okay, thank you. What would the config for such an agent look like?```.
In general, at 2023-10-09 19:48:22 a user named sonichi said ```The instruction about termination can often get ignored when it's mixed with other long instructions. One possible way is to create a separate agent which is dedicted to this.```.
In general, at 2023-10-09 19:47:11 a user named pbeheca said ```Any way to circumvent this behavior? gpt4 seems to not have this issue but is too costly. Any Idea which agents would need gpt4 to prevent empty calls/responses in a loop?```.
In general, at 2023-10-09 19:45:14 a user named sonichi said ```Yes, it's common in my experience.```.
In general, at 2023-10-09 19:41:46 a user named telepathyx said ```https://arxiv.org/abs/2310.01798

Transitioning to another facet of self-correction, we investigate the potential of
multi-agent debate (Du et al., 2023; Liang et al., 2023) as a means to improve reasoning. In this
method, multiple instances of an LLM critique each other’s responses. However, our results reveal
that its efficacy is no better than self-consistency (Wang et al., 2022) when considering an equivalent
number of responses, highlighting the limitations of such an approach.```.
In general, at 2023-10-09 19:32:17 a user named pbeheca said ```Is it normal for gpt-3.5-turbo agents to get stuck in a loop? seems like it always ends getting stuck```.
In general, at 2023-10-09 19:06:20 a user named aarya1101 said ```I am new to this```.
In general, at 2023-10-09 19:06:05 a user named aarya1101 said ```can anyone explain autogen to me?```.
In general, at 2023-10-09 19:02:20 a user named tc said ```@kohanzie tomorrow morning i'll put in general chat a little snippet on how did i solved it if i got 5 minutes```.
In general, at 2023-10-09 18:53:49 a user named kareem6370 said ```I had to override the DEFAULT_MODEL in the super class to be gpt-3-turbo to stop using gpt-4 for any interference, It’s not the best way to do it but I was lazy and I wanna test an idea lol```.
In general, at 2023-10-09 18:39:09 a user named afourney said ```FYI: I'm trying to hunt this one down, a top priority.```.
In general, at 2023-10-09 17:59:42 a user named somecomputerguy said ```I guess in this model it is similar to autogpt? I never used it```.
In general, at 2023-10-09 17:35:18 a user named somecomputerguy said ```And instructed it to write to a known path, then used docker cp to copy out the generated CSV```.
In general, at 2023-10-09 17:34:45 a user named somecomputerguy said ```I modified the twoagent.py file```.
In general, at 2023-10-09 17:29:02 a user named securemeup said ```Have you tried using the teaching notebook for this? Can you provide some more details? I’d like to see if can get it to work```.
In general, at 2023-10-09 17:24:45 a user named deedavid_15589 said ```if guardrails are proper, you can control resources, resoruce type, instances, and of course you can audit all of this before the code is deployed.```.
In general, at 2023-10-09 17:23:50 a user named deedavid_15589 said ```@somecomputerguy you have guardrails for your CDK?```.
In general, at 2023-10-09 17:15:00 a user named somecomputerguy said ```Right now I am debating handing some AWS keys to an agent to deploy CDK... it feels like a VERY BAD IDEA```.
In general, at 2023-10-09 17:12:30 a user named somecomputerguy said ```But also, I should stop being a luddite and embrace notebooks I guess 😛```.
In general, at 2023-10-09 17:11:51 a user named somecomputerguy said ```I wish that example was also in the test directory as a .py```.
In general, at 2023-10-09 16:43:50 a user named bobaleaux said ```in my case i would be replaced by 2 agents?
the admin or user_agent and a retrieval agent to feed the same content ?```.
In general, at 2023-10-09 16:39:57 a user named sonichi said ```For non-coding tasks, specify `system_message` and `name` for each `AssistantAgent` about their roles and create a group chat, like https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb```.
In general, at 2023-10-09 16:36:56 a user named bobaleaux said ```and i just pasted an article from a few minutes ago and asked, for their opinions about it;```.
In general, at 2023-10-09 16:35:59 a user named bobaleaux said ```@sonichi do you have any ideas on how i accomplish this with autogen? 
sorry my use case isn't writing code.

When manually using chatGPT, i have pasted multiple engineered persona prompts into the input in a single conversation and they all became part of the conversation. I have asked them all for their opinion about a single question and they each provided one.

I'm trying to emulate my manual interactions with chatgpt but using code but I can't figure out how.

in a direct openai call, i use the system message as the persona and I haven't tried loading multiple system messages and I'm not sure of the impact of 'assume the role'.

 Is it just a group conversation with a user agent as the manager?```.
In general, at 2023-10-09 16:30:44 a user named somecomputerguy said ```Getting autogen happy and containerized took me all weekend, but worth it, executing code in my rancher environment is AWESOME```.
In general, at 2023-10-09 16:29:41 a user named somecomputerguy said ```Along with chromaDB, I am a big retro guy, you can see my stuff on youtube, really excited to point chroma at bitsavers and be able to ask questions and get answers based on OCR manuals for the original equipment```.
In general, at 2023-10-09 16:28:45 a user named haydendougherty101 said ```Work I’m actually coast guard and I work in the EE side of things but we’re paired with a lot of the software guys and we’ve been talking a lot ab the potential behind AI```.
In general, at 2023-10-09 16:28:30 a user named somecomputerguy said ```I am! I saw that! But not sure how to set up```.
In general, at 2023-10-09 16:28:09 a user named sonichi said ```you may be interested in <#1160783387896840232>```.
In general, at 2023-10-09 16:25:17 a user named publicnewschoice said ```sometimes ideas and progress come at a cost 😛```.
In general, at 2023-10-09 16:21:53 a user named somecomputerguy said ```Yeah, I am getting concerned about price as this is out of my pocket, but yeah it is good```.
In general, at 2023-10-09 16:20:46 a user named somecomputerguy said ```You mean issue edits via the user proxy?```.
In general, at 2023-10-09 16:20:10 a user named sonichi said ```Good news is you can iterate over the instructions to tell dos and donots.```.
In general, at 2023-10-09 16:14:50 a user named 0xjamp said ```Better he show you then replace you with it that's a good sign😁```.
In general, at 2023-10-09 16:14:07 a user named somecomputerguy said ```Now I am going to need to interrupt it, as once again it attempted to execute a shell script that contains a command awaiting interactive input```.
In general, at 2023-10-09 16:13:00 a user named somecomputerguy said ```It did not do a good job 😂 but I backed off and asked it to just to generate the CSV with appropriate values and columns, that it managed to do```.
In general, at 2023-10-09 16:12:02 a user named somecomputerguy said ```I just showed my team using autogen to write python to generate a CSV of estimated cloud costs```.
In general, at 2023-10-09 16:09:33 a user named haydendougherty101 said ```My supervisor showed it to me!```.
In general, at 2023-10-09 16:06:15 a user named andeeri said ```Hello! Watched a video in YT```.
In general, at 2023-10-09 15:47:44 a user named .princeps said ```Yeah, I ended up having chat gpt help 

https://poly186.notion.site/Autogen-Agents-3f6b8e294a92476dbf5aee955b0db983?pvs=4```.
In general, at 2023-10-09 15:40:19 a user named ttt said ```A friend sent me an invite```.
In general, at 2023-10-09 15:39:53 a user named sonichi said ```All the built-in ones can be found here: https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent
Some notebook examples have custom agent examples extended from the built-in ones.```.
In general, at 2023-10-09 15:35:52 a user named .princeps said ```I got it 

I needed a list of all of them```.
In general, at 2023-10-09 15:33:03 a user named frank.martinez said ```https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat```.
In general, at 2023-10-09 15:22:49 a user named anilmatcha said ```Came from twitter, cool tool```.
In general, at 2023-10-09 15:18:07 a user named afourney said ```I like this idea, but two points to consider: (1) given the chat-based protocol, perhaps @-mentions would be more natural, and (2) if you find yourself in a place where the order of agents is known in advance, then GroupChat  is overkill (and prone to additional errors). Better to use other workflows (like a chain or tree of agent pairs)```.
In general, at 2023-10-09 15:17:43 a user named marcos_thevisualizer.ai said ```starting now, glad to be here!!!```.
In general, at 2023-10-09 15:14:45 a user named trezero said ```For anyone still looking for a group to join for the Hackathon. We are still looking for people: https://lablab.ai/event/autogpt-arena-hacks/auto-api-alliance?channelId=1160826883882106890```.
In general, at 2023-10-09 14:19:09 a user named ianfhood said ```hey everyone, just joined and just starting with AutoGen.  Going through the demos on colab.```.
In general, at 2023-10-09 13:58:50 a user named tc said ```well, thanks for the support mate! it's upsetting i understand that 🤣  if i have a bit of time i'll dig a bit in the codebase```.
In general, at 2023-10-09 13:57:42 a user named sonichi said ```It doesn't. So it's puzzling me.```.
In general, at 2023-10-09 13:57:13 a user named tc said ```i haven't properly looked at autogen codebase, i do wonder if automatically add the gpt-4 model to that list if it finds a key in the env?```.
In general, at 2023-10-09 13:55:45 a user named sonichi said ```good. `llm_config={"config_list": config_list}` is supposed to work too, They are equivalent in this case.```.
In general, at 2023-10-09 13:52:42 a user named tc said ```let me wait 5 minutes for the usage stats```.
In general, at 2023-10-09 13:52:28 a user named tc said ```it seems that it worked!```.
In general, at 2023-10-09 13:49:37 a user named tc said ```base_config.update(each_config)
ValueError: dictionary update sequence element #0 has length 1; 2 is required```.
In general, at 2023-10-09 13:47:50 a user named sonichi said ```could you try this: `llm_config={"model": model, "api_key": api_key}````.
In general, at 2023-10-09 13:38:20 a user named tc said ```it seems to ignore the config i pass, grab the value from the OPENAI_API_KEY  env variable i setup and apply the default model```.
In general, at 2023-10-09 13:37:46 a user named sonichi said ```The code looks correct. The config list has higher priority.```.
In general, at 2023-10-09 13:37:20 a user named devolli said ```Dang, I was thinking of something very similar to that. Read my mind. Thanks.```.
In general, at 2023-10-09 13:37:18 a user named tc said ```so it was grabbing the key from the env and apply the default model, ignoring the config, now it simply fails```.
In general, at 2023-10-09 13:36:59 a user named tc said ```YES, i found something interesting finally since i have executed setx OPENAI_API_KEY "stop" it stopped working```.
In general, at 2023-10-09 13:35:03 a user named jaemil said ```building one, still need to merge but you can check it out:
https://github.com/jaemil/agentsflow```.
In general, at 2023-10-09 13:34:15 a user named devolli said ```Thank you. I've seen that one. Thought maybe there was another one out there. 🙂```.
In general, at 2023-10-09 13:33:42 a user named jaemil said ```have the same issue with 'gpt-3.5-turbo'```.
In general, at 2023-10-09 13:32:43 a user named tc said ```i don't see other explanations```.
In general, at 2023-10-09 13:32:25 a user named tc said ```the only thing i can think of it's that i have an env env variable setup with setx OPENAI_API_KEY that i did for another project, and for some reason it's picking up that value and apply the default model, ignoring everything i specified```.
In general, at 2023-10-09 13:31:41 a user named tc said ```yes, i'm baffled by this 🤷🏻‍♂️ 
OAI_CONFIG_LIST file look like this:

[
    {
        "model": "gpt-3.5-turbo-16k",
        "api_key": "MY_KEY"
    }
]

config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")
this is the output: [{'model': 'gpt-3.5-turbo-16k', 'api_key': 'MY_KEY'}]

and then i attach it everywhere like this:
group_chat_manager = GroupChatManager(
    groupchat=group_chat, llm_config={"config_list": config_list}
)```.
In general, at 2023-10-09 13:28:53 a user named tc said ```group_chat_manager = GroupChatManager(
    groupchat=group_chat, llm_config={"config_list": config_list}
)```.
In general, at 2023-10-09 13:27:53 a user named tc said ```and i attach this config to ALL the agents like this

user_proxy = UserProxyAgent(
    "Oracle",
    code_execution_config={"work_dir": "coding"},
    human_input_mode="TERMINATE",
    llm_config={"config_list": config_list},```.
In general, at 2023-10-09 13:25:23 a user named tc said ```not the same issue for me, as if i print the config, only gpt3 it's there```.
In general, at 2023-10-09 13:23:09 a user named sonichi said ```https://github.com/microsoft/autogen/issues/125 @tc @kohanzie```.
In general, at 2023-10-09 13:19:38 a user named sonichi said ```One I know: https://github.com/victordibia/autogen-ui```.
In general, at 2023-10-09 13:16:34 a user named erdincciftci said ```can be helpful to autogen people too!```.
In general, at 2023-10-09 13:16:28 a user named erdincciftci said ```FINALLY an Instagram AI Chatbot working in DMs and even commnets on automation! 

I discovered a super easy way and also giving away my template free (LIMITED OPPORTUNITY) All in my new Youtube video now LIVE:  https://youtu.be/7zmQMUjQEdI```.
In general, at 2023-10-09 13:05:32 a user named devolli said ```First of all, I apologize if you've seen this question a hundred times before - but I've been trying to snoop around without finding a decent solution for this.. But do you guys have a github link to some autogen project with a decent UI that I could build upon?
EDIT: And hello to you all 🙂```.
In general, at 2023-10-09 13:03:48 a user named kohanzie said ```Yeah same, I tried loadenv, I tried the config list model but it’s always pulling from chat gpt 4 makes no sense```.
In general, at 2023-10-09 13:00:12 a user named tc said ```if anyone else solved this problem please DM me```.
In general, at 2023-10-09 12:59:43 a user named tc said ```i have tried all the methods, it always uses gpt-4 no matter what```.
In general, at 2023-10-09 12:51:55 a user named kohanzie said ```im having the same problem, let me know if you find a resolution```.
In general, at 2023-10-09 12:41:37 a user named andyinater said ```See if <#1158564427117903882> is any improvement. I have it set up so the context window is constantly being reset - should only overflow tokens if the code itself exceeds it, or I guess since it sees the previous iteration, if the code exceeds half.```.
In general, at 2023-10-09 12:27:45 a user named .princeps said ```I got it through azure```.
In general, at 2023-10-09 12:27:14 a user named m_gee said ```Do you guys have access to the 32k model? Not sure how to get it```.
In general, at 2023-10-09 12:19:57 a user named biomatu said ```I am also starting with autogen, it is amazing but also use tokens as crazy!! Several of my experiments ended on reaching the tokens limit and break.  Maybe adding some tokens limits inside the agents would be a great update as @sigma.xxx  did```.
In general, at 2023-10-09 12:04:17 a user named .princeps said ```lagnchain and autogen are abit different, but I have used both and they are good for their respective usecause, someone here actually created a script to allow agents in autogen to use langchain tools```.
In general, at 2023-10-09 11:57:33 a user named m_gee said ```Have you guys also used LangChain? And do you think that Autogen is better?```.
In general, at 2023-10-09 11:56:25 a user named m_gee said ```Yeah experimenting is really expensive in this case so I see your point```.
In general, at 2023-10-09 11:52:07 a user named .princeps said ```basically, my throught process, like it takes me hours to just create something let alone setting up the GPT-4 costs, so yes eventually someone independent like me will have to monitize the work, effort and experimentation```.
In general, at 2023-10-09 11:51:20 a user named skrtskrt said ```Not necessarily but 90% of people yes! Its only human```.
In general, at 2023-10-09 11:50:39 a user named skrtskrt said ```These are complicated questions that someone would literally want to be paid to spend time answering, but generally, autogen is probably capable of hte higher-end of the potential that you can imagine```.
In general, at 2023-10-09 11:50:37 a user named .princeps said ```Nah, I share mine, been working on something that I think you can use soon```.
In general, at 2023-10-09 11:49:36 a user named m_gee said ```Yeah well firstly I'm trying to understand what you can really achieve with it. Tha's why I'm here on the discord asking ^^```.
In general, at 2023-10-09 11:48:01 a user named scrypturd said ```AI agents started appearing on my youtube recommended page```.
In general, at 2023-10-09 11:44:52 a user named skrtskrt said ```Idk what to tell you, besides read about Autogen, I don't think you fully understand it (There is a lot to understand, so its very fair enough!)```.
In general, at 2023-10-09 11:37:20 a user named m_gee said ```Like I saw a video of a guy explaining autogen and he had an example for a tower defense game built by the Agents. But it was more of a structural explanation. The actual agents did not produce the game. What I'm curious about is, wether the prompts are off, the token limit is too low or something else? I think GPT4 in itself should be able to program almost anything really. So maybe there should have been an agent that is most familiar with the overall goal and instructing the other agents, when they're off on the task? Some sharing of experiences would be appreciated here```.
In general, at 2023-10-09 11:32:05 a user named m_gee said ```Oh so people who really get them to work won't share their findings ur saying basically```.
In general, at 2023-10-09 11:31:59 a user named sigma.xxx said ```hey guys , I noticed that the way select_next speaker is really costly, getting all of the previous messages and asking openAI to determine the next speaker seem like a rather waste. So I hacked a quick solution like so, the downside is that you need to add an extra instruction in the prompt to make sure it appends the <NEXT> in the end
 
But it did help a lot with the rate limit problem. If you are generating long-form content with autogen, the current select_next speaker logic is consuming a lot of tokens```.
In general, at 2023-10-09 11:23:22 a user named .princeps said ```https://tenor.com/view/rick-and-morty-i-can-answer-that-for-money-gif-10573903```.
In general, at 2023-10-09 11:23:10 a user named m_gee said ```Have you seen anything working already? What are agents good for already and where do they start to need development?```.
In general, at 2023-10-09 11:21:41 a user named skrtskrt said ```Most people don't give money away 🤷🏼‍♂️

Yes, of course people are using autogen to automate real work.```.
In general, at 2023-10-09 10:40:41 a user named m_gee said ```I've seen way more on the "structural anatomy"  side of the possibilities but way less on the actual results side```.
In general, at 2023-10-09 10:39:06 a user named m_gee said ```I've been looking into Autogen for a few days now and I'm wondering what's really possible with it. Did anyone manage to automate some real work with it already?```.
In general, at 2023-10-09 10:32:25 a user named dinkargupta said ```Just joined after getting to know Autogen through a post on linkedin. Looking forward to learn and contribute```.
In general, at 2023-10-09 10:28:13 a user named skrtskrt said ```Hey guys, anyone else building advanced agents for customer service using autogen?```.
In general, at 2023-10-09 10:00:20 a user named its_av01 said ```Hello, can someone explain how AutoGen is different from LangChain?```.
In general, at 2023-10-09 09:38:25 a user named skrtskrt said ```Yup you can.

And those that understand the trajectory of LLMs looking forward, will understand that compute problems today will be much lessser in the future.```.
In general, at 2023-10-09 09:00:45 a user named .princeps said ```Anyone have any ideas of how to apply the Agent Protocol to Autogen ? https://agentprotocol.ai/protocol```.
In general, at 2023-10-09 08:13:37 a user named happy2cu said ```Hi everyone, I'm new to the server and I wanted to say hello and wish you all a wonderful day! 👋```.
In general, at 2023-10-09 08:08:57 a user named godziiilla said ```I first heard about AutoGen on a youtube whilst i was researching LLMs for my project Use Cases. I like the idea of Agent playing 'roles', however i am concerned about the use of compute (limits), and would like to understand if i can use smaller more specialised LLMs for in a private host environment.```.
In general, at 2023-10-09 07:27:29 a user named .princeps said ```Anyone have a list of all the agent types, user proxy, assistant, retrieval agent ... am I missing any ?```.
In general, at 2023-10-09 07:26:28 a user named tc said ```as it stands still using gpt-4 😦```.
In general, at 2023-10-09 07:25:42 a user named tc said ```i did follow that, and if print the config i  get:

[{'model': 'gpt-3.5-turbo-16k', 'api_key': 'MY_openai_KEY'}]

i then pass the config to every agent using this
llm_config={"config_list": config_list},

i guess i will try and follow one of the other approaches```.
In general, at 2023-10-09 06:03:53 a user named au8 said ```No problem, glad I could help.```.
In general, at 2023-10-09 05:05:49 a user named hpstupefied said ```i saw it in youtube```.
In general, at 2023-10-09 03:49:48 a user named elcapitan__ said ```Not all hero’s wear capes but u Andy are my hero```.
In general, at 2023-10-09 03:39:57 a user named andyinater said ```Hey everyone,
This is the new Repo, kind of an extension on <#1157869584901226586> . 

<#1160783387896840232> 

Let me know what you think - I likely wont be making many responses until tomorrow. Hopefully it works alright!```.
In general, at 2023-10-09 03:38:02 a user named frank.martinez said ```Automated task solving with coding and planning agents```.
In general, at 2023-10-09 03:29:08 a user named ccerrato147 said ```DevOps pipeline created, updated, and improved by AI agents```.
In general, at 2023-10-09 03:28:38 a user named ccerrato147 said ```Saw YouTube videos about it```.
In general, at 2023-10-09 02:54:15 a user named Deep Warren Buffet Value said ```Thanks , what's a good first project / example```.
In general, at 2023-10-09 02:27:12 a user named mysticmarks1 said ```this year is going to be good folks, very good```.
In general, at 2023-10-09 02:12:33 a user named rastrol7 said ```Found through the Microsoft press release!```.
In general, at 2023-10-09 01:38:40 a user named jpakjr said ```Learned about this through YouTube AI channels```.
In general, at 2023-10-09 01:29:58 a user named frank.martinez said ```https://microsoft.github.io/autogen/```.
In general, at 2023-10-09 01:26:53 a user named Deep Warren Buffet Value said ```Anyone have a getting started guide for someone w extremely limited coding experience```.
In general, at 2023-10-09 01:12:14 a user named Dr.Inc said ```I scrolled through tiwtter I saw this```.
In general, at 2023-10-09 00:53:39 a user named elcapitan__ said ```Like what benefits does langchain allow for that autogen doesn’t```.
In general, at 2023-10-09 00:52:52 a user named elcapitan__ said ```I’m trying to figure out if I shud use langchain with autogen or simply just use gpt. I don’t have much experience in langchain.```.
In general, at 2023-10-09 00:52:05 a user named elcapitan__ said ```All I’m saying is this community is on fire right now```.
In general, at 2023-10-08 23:58:17 a user named sonichi said ```doc about logging: https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logging-experimental```.
In general, at 2023-10-08 23:45:13 a user named c_bonadio said ```Not sure if it is possible```.
In general, at 2023-10-08 23:37:00 a user named twezoalgo said ```Is it possible to loop this for every assistant response?```.
In general, at 2023-10-08 23:12:16 a user named rais_47039 said ```I was overwhelmed with so much Gen-AI information and boared with programming same RAG based ChatBots. AutoGen sounds interesting, planning to develop something. Good Job Team AutoGen.```.
In general, at 2023-10-08 22:54:07 a user named aditya0145 said ```Thanks @au8 thst worked for me too!```.
In general, at 2023-10-08 22:32:46 a user named sonichi said ```did you follow https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints to set it up?```.
In general, at 2023-10-08 22:27:33 a user named tc said ```bit confused, even if in my OAI config list i setup: "model": "gpt-3.5-turbo-16k"
for few calls it used gpt-4 👀```.
In general, at 2023-10-08 22:25:40 a user named async00 said ```I think he meant more unlimited context; this recent paper uses some techniques to maintain low perplexity even into literally millions of tokens (https://browse.arxiv.org/pdf/2309.17453.pdf)```.
In general, at 2023-10-08 22:25:24 a user named tc said ```cheers! that worked, i have also setup a custom signal handler for Ctrl+C, and i can save the chat even i force the exit!```.
In general, at 2023-10-08 22:13:41 a user named c_bonadio said ```HI @tc , you can call autogen.ChatCompletion.start_logging() before you start and then print(autogen.ChatCompletion.logged_history) after the conversation, you can write the value of autogen.ChatCompletion.logged_history to a file if needed```.
In general, at 2023-10-08 22:04:57 a user named tc said ```how can i dump the entire conversation into a text file? sorry quite new here```.
In general, at 2023-10-08 22:04:16 a user named jew84930585 said ```i love the way you can pass it docs too```.
In general, at 2023-10-08 22:01:29 a user named jew84930585 said ```nice! yes that would be cool```.
In general, at 2023-10-08 22:00:54 a user named tonic_1 said ```there is  unlimited token limit, you just have to pay for it 😉```.
In general, at 2023-10-08 21:58:04 a user named frank.martinez said ```Cursor is my primary editor now; weird to go back to others; wish they had a cloud hosted version```.
In general, at 2023-10-08 21:19:42 a user named tc said ```solved it myself, i had to install pyautogen instead of autogen```.
In general, at 2023-10-08 21:10:32 a user named tc said ```how did you solved it?```.
In general, at 2023-10-08 20:30:51 a user named aaronward_ said ```*Side note*: I'm still using either jupyter notebooks or streamlit apps for all my development. What are some cool tools you guys are using that you think i should use for LLM Application development?```.
In general, at 2023-10-08 20:28:51 a user named aaronward_ said ```No local models yet, just used huggingface models - been busy the past few days. The [PR](https://github.com/microsoft/autogen/pull/95) is still open so it will be a little while yet until it's rolled out in a release.```.
In general, at 2023-10-08 19:34:11 a user named pbeheca said ```Thank you, I got it running now 🙂```.
In general, at 2023-10-08 19:33:58 a user named jew84930585 said ```thats gonna be pretty hard but not impossible, you would need a beast of a machine too```.
In general, at 2023-10-08 19:32:55 a user named quackduck. said ```question, im just downloading LM studio, its cool if it auto loads. but what if i want agents to be on seperate models is that still possible i would presume so```.
In general, at 2023-10-08 19:31:38 a user named jew84930585 said ```you dont need to hard code the model in, you can just have it dynamically use whatever is loaded in LM studio```.
In general, at 2023-10-08 19:31:24 a user named au8 said ```I don't actually think its that important due to the way the model is served. I've found you can type anything in there and the LM Studio will just serve the model you're hosting regardless```.
In general, at 2023-10-08 19:30:07 a user named pbeheca said ```Ah so the full absolute path is the 'model' value?```.
In general, at 2023-10-08 19:29:26 a user named au8 said ```right click your model at the top-center and click "show in explorer". You can then get the model name from the folder structure```.
In general, at 2023-10-08 19:27:38 a user named au8 said ```no, you just need v1 for it```.
In general, at 2023-10-08 19:27:28 a user named jew84930585 said ```yea maybe even `http://localhost:8000/v1/chat/completions` to be exact```.
In general, at 2023-10-08 19:27:21 a user named pbeheca said ```do you leave the 'model' parameter empty? (dont use it?```.
In general, at 2023-10-08 19:25:29 a user named au8 said ```you want the api_base to be `'api_base': "http://localhost:8000/v1",````.
In general, at 2023-10-08 19:24:06 a user named au8 said ```I've had some issues with some models but that could be down to me not doing some things correctly but vicuna 16k for example works great```.
In general, at 2023-10-08 19:24:04 a user named fxtoofaan said ```Anyone else use vllm server and littlellm ?```.
In general, at 2023-10-08 19:22:54 a user named au8 said ```I use LM Studio fine```.
In general, at 2023-10-08 19:20:03 a user named pbeheca said ````config_list = [
        {
            'model': 'bloomz-560m-my-small-model',
            'api_key': 'any string here is fine',
            'api_type': 'openai',
            'api_base': "http://localhost:8000",
            'api_version': '2023-03-15-preview'
        }
]
`
This is the config from the notebook. Even when I change the model to the name (id) i get when calling my localhost/models endpoint it throws the error: KeyError: 'model'
which suggest that it may have something to do with that.```.
In general, at 2023-10-08 19:17:01 a user named pbeheca said ```The inference server should be a drop in replacement```.
In general, at 2023-10-08 19:08:12 a user named jew84930585 said ```it should follow the same format as an api call to openai, except you will make the request to localhost ofc```.
In general, at 2023-10-08 18:59:14 a user named pbeheca said ```Hey, I'm trying to setup autogen with a local LLM through LM Studios Local inference Server. Has anybody done the same? I'm not sure what format the config should have for autogen.
I'm following this "guide": https://github.com/microsoft/autogen/blob/osllm/notebook/open_source_language_model_example.ipynb```.
In general, at 2023-10-08 18:58:14 a user named dilli5027 said ```Like ChatGPT for data analysis```.
In general, at 2023-10-08 18:58:02 a user named dilli5027 said ```Wondering can I upload files to autogen?```.
In general, at 2023-10-08 18:53:08 a user named quackduck. said ```i tried to use azure since it has student benefits but azure openai is closed access atm for business use```.
In general, at 2023-10-08 18:49:05 a user named ducklover0181 said ```Does anyone know GPT-4 offers student discount like copilot? I have friend in college```.
In general, at 2023-10-08 18:47:26 a user named ducklover0181 said ```try to stay with gpt-3.5-turbo, not gpt-4```.
In general, at 2023-10-08 18:20:55 a user named Shyrka said ```My bad. I was still running the same error after upgrading pyautogen but works again after full uninstall/reinstall of pyautogen. Thanks !```.
In general, at 2023-10-08 18:16:12 a user named fxtoofaan said ```@aaronward_ were you able to run littlellm proxy between autogen script and your llm server ?```.
In general, at 2023-10-08 18:12:44 a user named shiccup said ```Although idk how much support autogen has for local yet? Tbh im not sure how support works```.
In general, at 2023-10-08 18:12:15 a user named shiccup said ```You can rent gpu space and run it locally for much cheaper```.
In general, at 2023-10-08 18:12:00 a user named aaronward_ said ```Llama Index have released a list of closed and open sourced models, and listed out what tasks they're suited for - good to note if you're considering to use Open sourced models with the up coming release of Autogen: https://docs.llamaindex.ai/en/latest/core_modules/model_modules/llms/root.html#llm-compatibility-tracking```.
In general, at 2023-10-08 18:11:27 a user named quackduck. said ```does openai offer student discounts lol. burned thru $10 in a day```.
In general, at 2023-10-08 18:10:01 a user named e404nothing said ```Newly joined, heard about it from youtube, been testing AutoGPT, AgentGPT and now onto autogen but still having issues installing it on windows.```.
In general, at 2023-10-08 17:47:08 a user named sonichi said ```There was a question before you joined. You can change your role in "Channels & Roles".```.
In general, at 2023-10-08 17:35:52 a user named dead9ixel6903 said ```Got it, I was using just fastchat but was having issues getting Mistral 7b working. Other local models worked okay but still were a little off so I started to look at litellm to provide the chat templating I think Mistral needs.```.
In general, at 2023-10-08 17:32:26 a user named afourney said ```Nothing to do with chat templates. It’s that the code right now uses the OpenAI python library, and so wants to speak to an OpenAI endpoint. You can change the api_base though to point anywhere including a local proxy```.
In general, at 2023-10-08 17:31:09 a user named dead9ixel6903 said ```Does vllm's openai api server not support chat templates thus the need for litellm in the stack?```.
In general, at 2023-10-08 17:11:56 a user named vladi372 said ```Very cool, thank you very much for the answer and the whole project```.
In general, at 2023-10-08 17:05:13 a user named afourney said ```Ill also note that the retries follow the order of models listed in the config list, so if you have access to a few endpoints (e.g., azure and oai) you can add them both and load balance a little.```.
In general, at 2023-10-08 17:03:11 a user named afourney said ```On my todo list is to remind myself how the retry logic works, and maybe there’s something we can do better there.```.
In general, at 2023-10-08 17:02:08 a user named afourney said ```There are not too many ways around the token rate limit. You can try to divide your agents across GPT 3.5 and 4, because not all agents need 4 and 3.5 has a way higher limit. You can also try to work your prompts etc to generate fewer tokens so that the window fills up less quickly. Local models are also extremely useful here. Finally, you can adjust the number of retries, and just wait it out.```.
In general, at 2023-10-08 16:49:00 a user named teddybear082 said ```How did you update btw```.
In general, at 2023-10-08 16:48:11 a user named vladi372 said ```What are you doing about the token limit? 😅```.
In general, at 2023-10-08 16:47:42 a user named Shyrka said ```Hi Guys !
I updated 2 min ago but I run now into a new error:
 AttributeError: module ´autogen' has no attribute ´UserProxyAgent'  🤨```.
In general, at 2023-10-08 16:45:59 a user named .suzerain said ```How you all turning yellow 😱👀```.
In general, at 2023-10-08 16:45:37 a user named devonx said ```straight to jail! im joking 😄```.
In general, at 2023-10-08 16:45:01 a user named vladi372 said ```Apparently, it works with llama2. That's why I asked```.
In general, at 2023-10-08 16:44:54 a user named sagar___ said ```Newly joined, excited to contribute```.
In general, at 2023-10-08 16:44:49 a user named fxtoofaan said ```looks like pip is still installing 0.1.7```.
In general, at 2023-10-08 16:43:23 a user named devonx said ```oh man future is looking neat tho. imagine when this stuff get unlimited tokens```.
In general, at 2023-10-08 16:41:29 a user named afourney said ```Token limit as in context window? Or rate limit?```.
In general, at 2023-10-08 16:41:17 a user named .suzerain said ```Should be a 32k model```.
In general, at 2023-10-08 16:40:50 a user named vladi372 said ```I quickly reached the token limit, are there any solutions?```.
In general, at 2023-10-08 16:38:59 a user named afourney said ```https://microsoft.github.io/autogen/docs/Contribute/```.
In general, at 2023-10-08 16:38:18 a user named afourney said ```Seriously, there’s lots of work to do. Jump in on GitHub if you like. Just read the contributor notes to see how the pull request should be formatted etc```.
In general, at 2023-10-08 16:37:03 a user named JoJo said ```This sounds good to put on a cv 🤣```.
In general, at 2023-10-08 16:36:40 a user named afourney said ```If you submit a pull request, you too can contribute to  Microsoft GitHub project 😉```.
In general, at 2023-10-08 16:36:08 a user named .suzerain said ```My professor talked me out of staying in the academia 🤣🤭```.
In general, at 2023-10-08 16:35:30 a user named qingyunwu said ```Yes, you got it 🥲```.
In general, at 2023-10-08 16:35:14 a user named JoJo said ```Sweet. Out of curiousity are you seeking funding as an individual or through the university?```.
In general, at 2023-10-08 16:35:07 a user named devonx said ```didnt know that people could publish stuff into the microsoft github without working there```.
In general, at 2023-10-08 16:34:52 a user named oldlobstar said ```glad to see other educators/researchers here 🙂```.
In general, at 2023-10-08 16:34:51 a user named .suzerain said ```The daily struggles of academics```.
In general, at 2023-10-08 16:33:53 a user named qingyunwu said ```No. I worked on this project voluntarily out of my research interest as far. But I am indeed seeking funding from multiple companies and funding agencies. 🙂```.
In general, at 2023-10-08 16:33:38 a user named afourney said ```I think we’d love to see more use of local and open models! Right now autogen only “speaks” the OpenAI API but please use liteLLM etc to access other models. Anything that serves a compatible endpoint should be workable.```.
In general, at 2023-10-08 16:30:44 a user named vladi372 said ```Is it allowed to use autogen with llama2? Is that possible?```.
In general, at 2023-10-08 16:30:17 a user named kbve said ```Oh wow that is super dope!```.
In general, at 2023-10-08 16:29:50 a user named JoJo said ```Ahh interesting. Is that funded by MS?```.
In general, at 2023-10-08 16:29:42 a user named qingyunwu said ```The other moderators work for Microsoft.```.
In general, at 2023-10-08 16:29:26 a user named qingyunwu said ```Not all.  I am an Assistant Professor at Penn State.```.
In general, at 2023-10-08 16:28:20 a user named devonx said ```sooo do the moderators work for microsoft?```.
In general, at 2023-10-08 16:26:49 a user named qingyunwu said ```@everyone  v0.1.8 is released: https://github.com/microsoft/autogen/releases/tag/v0.1.8  The issue about code execution with docker under Windows environment is fixed with this new release 🙂```.
In general, at 2023-10-08 16:19:02 a user named teddybear082 said ```There are threads where people said they had it working but I don’t know what they tried to do for me I got a pop up saying textgen doesn’t support function calling```.
In general, at 2023-10-08 15:49:07 a user named omnacron said ```Thank you for the reply. That kinda sucks. really want to give this a go but i need to beable to run in locally. well My search continues.```.
In general, at 2023-10-08 15:41:04 a user named teddybear082 said ```I don’t know if someone found a fix```.
In general, at 2023-10-08 15:40:53 a user named teddybear082 said ```I asked this above textgenwebui does not support function calling with its OpenAI API so that was causing errors for me personally.  @omnacron```.
In general, at 2023-10-08 15:40:25 a user named jatique said ```That would be so nice and helpful```.
In general, at 2023-10-08 15:31:14 a user named omnacron said ```Hello everyone, I hope the day is meeting you all with Positive energy and warm smiles. I am interested in using AutoGen but i would like to run it localy. Is this compatible with alternate API's like text-generation web ui?```.
In general, at 2023-10-08 15:14:01 a user named bobaleaux said ```Ok cool, just dm me if you want```.
In general, at 2023-10-08 15:04:10 a user named tonic_1 said ```hey @jaemil & @afourney , i would love to use / absorb / contribute to your insights also on my little autogen AGI attempt here : https://github.com/team-tonic-arena-hacks would love it if you considered joining in there too if you have interest + time to take a look ^^```.
In general, at 2023-10-08 15:02:11 a user named twezoalgo said ```Yes let work together as I’m not exactly sure how i want to have the other agents be```.
In general, at 2023-10-08 14:33:10 a user named sonichi said ```They are not apple to apple. They can be used together too. https://github.com/microsoft/autogen/pull/58. The author is on vacation until 20th and OK with others picking it up.```.
In general, at 2023-10-08 14:28:05 a user named bobaleaux said ```@sonichi sorry to bother with this. I saw a post I think from you that demonstrated an example of pulling documents from a research site and creating an index of citations. Do you remember such an example?```.
In general, at 2023-10-08 14:21:32 a user named sonichi said ```I ve been trying to tell if AutoGen runs```.
In general, at 2023-10-08 14:11:10 a user named bobaleaux said ```I’m kind of doing the same thing, actually using crafted personas to be the analysts . Already have some interactions working but expanding it right now. Let me know if you want to work out some of the challenges together.```.
In general, at 2023-10-08 13:12:20 a user named tomexmachina said ```now taking suggestions for how my 3D world of agents gonna be livin```.
In general, at 2023-10-08 12:07:01 a user named .suzerain said ```Just the type of tool I was looking for```.
In general, at 2023-10-08 11:26:22 a user named devonx said ```hi, i found out about autogen from youtube```.
In general, at 2023-10-08 10:04:50 a user named twezoalgo said ```Scratch that i figured out how to get the data into a way that can work in a machine learning model. Autogen gave me a good template for a basic model```.
In general, at 2023-10-08 09:41:20 a user named jatique said ```which is better between autogen and langchain..and what is the difference between the both...i am really confused ......though i am new to LLM```.
In general, at 2023-10-08 09:40:00 a user named teddybear082 said ```also does litellm support function calling? I also saw that recommended```.
In general, at 2023-10-08 09:36:18 a user named teddybear082 said ```I thought I saw people using it with textgenwebui but maybe I was mistaken```.
In general, at 2023-10-08 09:35:58 a user named teddybear082 said ```Hi everyone, how are people using this with textgenwebui? It doesn’t support function calling.```.
In general, at 2023-10-08 08:44:35 a user named fran.abenza said ```I know this as I was looking for alternatives after chasing an impossible bug in LangChain```.
In general, at 2023-10-08 07:07:07 a user named trezero said ```Does anyone know where to see this POST request? From the docs I followed, all I have is this in my OAI_CONFIG_LIST file: [
    {
        "model": "chatglm2-6b",
        "api_base": "http://localhost:8000/v1",
        "api_type": "open_ai",
        "api_key": "NULL"
    }
]
And this in my basic.py file: from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Import the openapi key
config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")

# Create assistat agent
assistant = AssistantAgent(name="assistant",llm_config={"config_list": config_list})```.
In general, at 2023-10-08 06:59:25 a user named juzure. said ```hello ,How can I create my own agent ?```.
In general, at 2023-10-08 06:57:21 a user named noahnochill said ```I don't know too much about APIs, but it looks to me like the POST request isn't structured properly. Are you printing the rendered request as part of your debugging?```.
In general, at 2023-10-08 06:38:16 a user named trezero said ```On the Fastchat side I always get 400 errors: INFO:     ::1:56417 - "POST /v1/chat/completions HTTP/1.1" 400 Bad Request```.
In general, at 2023-10-08 06:19:57 a user named trezero said ```I'd really appreciate any help!```.
In general, at 2023-10-08 06:19:33 a user named trezero said ```Does this go directly in my main application.py file? or is this part of the OAI_CONFIG_LIST file?```.
In general, at 2023-10-08 06:18:45 a user named trezero said ```Hey everyone. I'm trying to get Autogen connected to a locally running version of chatglm2-6b running on FastChat. The one part that I'm confused on is where I need to add this:  from autogen import oai

# create a chat completion request
response = oai.ChatCompletion.create(
    config_list=[
        {
            "model": "chatglm2-6b",
            "api_base": "http://localhost:8000/v1",
            "api_type": "open_ai",
            "api_key": "NULL",```.
In general, at 2023-10-08 06:04:31 a user named noahnochill said ```And/or tech-agnostic theory and resources for this space in general, agents, multiagent systems, automating processes, getting it to incorporate the results of its actions into its knowledge base (like reports, research, or other information that might influence how it would approach a task at hand)```.
In general, at 2023-10-08 06:04:23 a user named noahnochill said ```Hey! Is there a good repository of projects that have been published using autogen? Whether video examples, screenshots of a brilliant structure from X, or git repos… just looking to learn more and see what works and what doesn’t and why```.
In general, at 2023-10-08 05:31:35 a user named t_rust1887 said ```just read about AutoGen today. cant wait to Explore the Github repo and try experimenting```.
In general, at 2023-10-08 05:15:46 a user named alexsohn said ```I've been trying to tell if AutoGen runs the models in sequence or parallel, and without any explicit documentation stating one way or the other, and not being able to run AutoGen while I'm traveling I have made the inference that it runs in parallel. Is this correct? Was there experimentation with running AutoGen in sequence? It could allow for some interesting use cases where the quality of the model and it's output is highly sensitive and needs to be run with the most parameters possible.```.
In general, at 2023-10-08 14:21:33 a user named sonichi said ```There are both sync and async methods. One example for async is here: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_stream.ipynb```.
In general, at 2023-10-08 04:36:52 a user named an1z said ```I would like to try out AutoGen first```.
In general, at 2023-10-08 04:36:19 a user named an1z said ```Hey, just heard about AutoGen, wanted to experiment on it 🤩```.
In general, at 2023-10-08 04:32:30 a user named .princeps said ```@jaemil just helping you out on your amazing goal```.
In general, at 2023-10-08 04:31:37 a user named .princeps said ```https://codevoweb.com/integrate-fastapi-framework-with-nextjs-and-deploy/#:~:text=Setup%20the%20FastAPI%20and%20Next.js%20Projects%201%20Bootstrap,...%204%20Run%20the%20Projects%20in%20Development%20```.
In general, at 2023-10-08 04:31:05 a user named jaemil said ```https://vercel.com/guides/how-to-use-python-and-javascript-in-the-same-application like this?```.
In general, at 2023-10-08 04:30:17 a user named .princeps said ```I have done that in one of projects, I can show you```.
In general, at 2023-10-08 03:03:32 a user named twezoalgo said ```i make trading algorithms and it’s always been a goal of mine to use ai to take them to the next level with machine learning, i tired to kind of brute force some thing and technicallyi did get decent information, i don’t really know how to process my csv good enough so that the ai can read it all```.
In general, at 2023-10-08 02:41:28 a user named ducklover0181 said ```@emil Thanks for sharing, will watch your repo```.
In general, at 2023-10-08 02:40:05 a user named jaemil said ```vector db is just a future goal```.
In general, at 2023-10-08 02:39:15 a user named jaemil said ```You need to ask @tomexmachina he did the communiction with agents```.
In general, at 2023-10-08 02:27:55 a user named ducklover0181 said ```@emil interesting, how are the messages among agents persisted? I see vector db is mentioned```.
In general, at 2023-10-08 02:26:13 a user named jaemil said ```haven't connected the nextjs frontend with the fastapi ws but in templates/index.html is the provisionally client```.
In general, at 2023-10-08 02:23:10 a user named jaemil said ```https://github.com/jaemil/agentsflow```.
In general, at 2023-10-08 02:22:54 a user named shinypickel said ```is this open sourced ?```.
In general, at 2023-10-08 02:20:38 a user named ducklover0181 said ```Given Microsoft is great in building cool GUI, hope autogen will have nice UI soon, like drag-drop agents to a canvas and connect them, see message flows among agents```.
In general, at 2023-10-08 02:20:03 a user named bobaleaux said ```take a look at this, it would be a good start for you to look at and maybe tweak it. 
https://github.com/amadad/agentcy```.
In general, at 2023-10-08 02:18:57 a user named juzure. said ```I'm really interested in this question. Could you please provide a detailed explanation?```.
In general, at 2023-10-08 02:17:59 a user named ducklover0181 said ```I am still learning autogen API, but wonder if the signature can be improved, e.g. in group chat, it would make sense to introduce another parameter called "role" besides "name" as in real-life, system_message is somewhat related to role, but still try to figure out what system_message does. With "role", then "name" can become the agent_id as long as they are unique. Image in real life, each team member has name and role(s)```.
In general, at 2023-10-08 02:13:35 a user named shinypickel said ```Did anyone get Autogen working with Streamlit?```.
In general, at 2023-10-08 02:10:08 a user named ducklover0181 said ```I am interested in building an app for learning multiple languages at the same time```.
In general, at 2023-10-08 02:10:07 a user named twezoalgo said ```Wew i but off way more than i could chew tryna do this linear regression stuff```.
In general, at 2023-10-08 02:08:35 a user named ducklover0181 said ```cloned autogen repo and ran some notebooks using gpt-3.5-turbo model, the results may not be as good as gpt-4, but the multi-agent framework is definitely awesome. Thank its creator for this cool tool```.
In general, at 2023-10-08 01:41:19 a user named juzure. said ```I can help you with your questions about Autogen.```.
In general, at 2023-10-08 00:51:14 a user named salah6163 said ```hellloooo, lets get this thing spun up, here from youtube too```.
In general, at 2023-10-08 00:43:50 a user named yosh7440 said ```learned Autogen from youtube channel Wes Roth```.
In general, at 2023-10-08 00:12:40 a user named dw1705 said ```New to LLM and agents: anyone knows are there any research/projects on learning "how to learn something" instead of just learning something? For example, let agent learn the git history and make it learn how to make PRs according to  a task description. I don't know how the PR made by this ways will differ from the output after learning the whole repo? If you are interested in this topic, feel free to dm me```.
In general, at 2023-10-07 23:46:27 a user named 2hunter said ```I am using open ai API, but the autogen is working with gpt 3, not 4. Is it possible to work with GPT-4, also I want to config the AI, don't know how to. If anyone willing to help in those few questions, waiting patiently.```.
In general, at 2023-10-07 23:45:18 a user named 2hunter said ```I installed the autogen, used it but I got some questions.```.
In general, at 2023-10-07 23:44:22 a user named 2hunter said ```Hi, folks, anyone willing to help by installing, or answering some questions about autogen. Willing to pay 50-100 usd in ETH erc-20```.
In general, at 2023-10-07 23:34:47 a user named bart9154 said ```how is local llm support coming? Has anyone been successful yet?```.
In general, at 2023-10-07 23:07:11 a user named luckylolo said ```exited about doing something with this after I watched a youtube video```.
In general, at 2023-10-07 22:44:53 a user named michaelgaio said ```Hello 🖖 I’m excited about AutoGen
I’ve tried out a few AI Agent frameworks, and this one seems most promising```.
In general, at 2023-10-07 22:27:44 a user named somecomputerguy said ```Hello, I got the container working, but had to force it to stay running and manually attach. Has anyone created a virtual dev team with a product owner, testing and docs yet? I did not see one in the community examples```.
In general, at 2023-10-07 21:47:49 a user named flaiwheel said ```No not out of the box if that is what you are looking for. But it can help you a lot with that!```.
In general, at 2023-10-07 21:12:52 a user named amnor96 said ```I've been following ever since I learnt about you guys on YouTube from one of the AI channels. Hoping to use this for my documentation analysis tool```.
In general, at 2023-10-07 21:10:09 a user named ozzydog said ```Howdy all, found Autogen after seeing it highlighted on Youtube, going down the Autonomous Agents rabbit hole.```.
In general, at 2023-10-07 21:03:53 a user named sonichi said ````.json` should be removed or you need to modify the code to match the file name.```.
In general, at 2023-10-07 21:01:34 a user named rahulchopra13 said ```hi everybody, is it possible to use autogen as full fledged marketing team that runs facebook ad campaigns, create graphics, does copywriting and does seo?```.
In general, at 2023-10-07 20:22:27 a user named papallon said ```I'm trying to use AutoGen on Collab.
I put OAI_CONFIG_LIST.json on /content but I guess it's not the right place "AuthenticationError: No API key provided."```.
In general, at 2023-10-07 20:09:46 a user named andyinater said ```Yall getting busy or what? 😛```.
In general, at 2023-10-07 20:04:02 a user named luckybunnies said ```i git into this to see how to run local LLMs```.
In general, at 2023-10-07 19:30:56 a user named hanley7082 said ```You might think of autogen as a way to automate prompt chaining```.
In general, at 2023-10-07 19:25:21 a user named papallon said ```Or, would a regular GPT/Bard/Claude would do the trick and using AutoGen is overkill ?```.
In general, at 2023-10-07 19:24:42 a user named papallon said ```Hello,
I've read the use cases and I'm wondering if AutoGen could be used to write complexe documents such as contracts.
One agent for commercial law, one for common law, one for state law, and a UserProxyAgent to make sure that each part of the contract is good.```.
In general, at 2023-10-07 19:10:13 a user named hanley7082 said ```You are going to want to look into function calling in order to integrate APIs```.
In general, at 2023-10-07 18:09:12 a user named akira.kay. said ```Hey everyone, i read this cool research paper abt creating own agents using AI and here I am```.
In general, at 2023-10-07 18:03:34 a user named salim4n said ```Autogen Can be config with mistral 7b ?```.
In general, at 2023-10-07 16:57:01 a user named mrjoozy said ```saw it on a youtube video```.
In general, at 2023-10-07 16:55:27 a user named ntcgreyhart said ```AI in general is taking over the YouTubes. As new ideas come out and people find them, they naturally flow to the top. It was just a couple of weeks ago that I saw a video about creating an agent in GPT 4, using a simple set of prompts. It works incredibly well. 

AutoGen seems to take that idea up a notch. I see in the Forums that people are talking about creating a GUI for AutoGen, which will just make it more user friendly, increasing its reach even more.```.
In general, at 2023-10-07 16:49:55 a user named aaronward_ said ```Autogen is really taking steam now on the AI side of youtube```.
In general, at 2023-10-07 16:46:48 a user named ntcgreyhart said ```YouTube is FULL of AutoGen videos. Just starting out. I want to see if I can find a simple guide to install it so I can play around with it.```.
In general, at 2023-10-07 16:37:29 a user named economistajosegarcia said ```Hi everyone! I listened something on the last Microsoft event```.
In general, at 2023-10-07 16:30:06 a user named Charlie_factory said ```An application that provides voice commands as an interface to communicate with its functions```.
In general, at 2023-10-07 16:28:54 a user named Charlie_factory said ```Hello!

I heard about AutoGen from Chi Wang```.
In general, at 2023-10-07 16:00:15 a user named sonichi said ```LLMs that are compatible with OpenAI API can already be used. Other LLMs can be potentially used via liteLLM. The community is working on it.```.
In general, at 2023-10-07 15:54:58 a user named bobaleaux said ```@afourney @sonichi you guys are going to become the 'Ubuntu'  of LLM use! you're like surfing the wave break! 
Meanwhile I'm trying to drink from a firehose to get used to the water! Trying to improvise and adopt at the same speed as I can read all of these messages! 
 I'm going down like a fat kid on a seesaw! 😂```.
In general, at 2023-10-07 15:44:05 a user named afourney said ```It’s not built-in yet, no. Some folks are having success using liteLLM proxy. Really, any local service that can serve the open ai chat completions endpoint should be workable: https://discord.com/channels/1153072414184452236/1158548894209282078```.
In general, at 2023-10-07 15:28:44 a user named afourney said ```And further to this point, I’d love love love to push this mix and match approach to other local and open models. As an example, models that accept much longer contexts windows might be super useful in some roles. Llama code (python) for example I think accepts 100k tokens.```.
In general, at 2023-10-07 15:23:14 a user named afourney said ```Haha, I just saw your response! You beat me 🙂```.
In general, at 2023-10-07 15:21:30 a user named afourney said ```If it’s a well-known and free API, it will often just use it if you ask (or it determines it would be useful). The arXiv API is one that I’ve used this way. If the API requires a key, I typically write a wrapper function and provide it to the agents, either by the function calling approach, or by telling it that the function is available upon importing a particular file.```.
In general, at 2023-10-07 15:19:52 a user named sonichi said ```This is also an answer to @bookcelerator 's question. It uses APIs about places, weather and stocks.```.
In general, at 2023-10-07 15:10:08 a user named afourney said ```GPT-4 is only really critical for some tasks like coding. GPT-3.5 can handle many other roles. You can often lower costs by mixing and matching. Here’s some of @sonichi ‘s work that may shows this potential: https://arxiv.org/abs/2310.03046```.
In general, at 2023-10-07 14:39:25 a user named bookcelerator said ```Hey all are there any examples of using autogen with apis?```.
In general, at 2023-10-07 14:34:06 a user named zactolle said ```Ya LM Studio, it took some setup but I wrote my process here: https://discord.com/channels/1153072414184452236/1159546232604217395/1160027575536603206```.
In general, at 2023-10-07 14:32:34 a user named staschek said ```How are you running the local LLMs? do you use LM Studio or something similar?```.
In general, at 2023-10-07 14:24:07 a user named zactolle said ```I have it working locally with Mistral 7b, Llama 13B, and Wizard LM uncensored```.
In general, at 2023-10-07 14:10:51 a user named yurdonezo said ```I heard there is no support for that yet```.
In general, at 2023-10-07 14:10:32 a user named yurdonezo said ```Are local LLMs compatible with autogen ?```.
In general, at 2023-10-07 14:08:14 a user named bookcelerator said ```Hey everyone I know the rules say not to post jobs etc but where do you all go to find people to hire for autogen projects since it’s so new?```.
In general, at 2023-10-07 13:47:56 a user named .bbhere said ```Hello did anyone used to develop some agents in LangChain and now trying out Autogen? I have basically developed the same thing with LangChain agents where they communicate each other using an async messaging system. Now I want to use Autogen in some parts but I have developed a couple of tools I am not sure how to port them.```.
In general, at 2023-10-07 13:47:03 a user named hanley7082 said ```Put "answer in as few words as possible" into your system prompts```.
In general, at 2023-10-07 11:53:47 a user named jasonzhou1993 said ```https://youtu.be/0phRae42lqY?si=CZdgC_nqVWuRjdrV

StreamingLLM is a very interesting attempt to solve this context window problem, Extend Llama-2 & Falcon's context window up to 4 million tokens; 22x faster inference than your standard LLM!```.
In general, at 2023-10-07 11:09:02 a user named fxtoofaan said ```Or use gpt 3.5 instead of gpt4. Or mix and match between gpt 3.5 gpt4 and local llms```.
In general, at 2023-10-07 11:08:03 a user named mrbrz said ```Wow I missed that I have only been using OpenAI api for completions.```.
In general, at 2023-10-07 11:06:27 a user named mrbrz said ```Autogen is so expensive for its processes are overly verbose, for coding this is great but for other use cases the agents themselves over produce tokens for no apparent reason, I converted a py script to use autogen and the token use jumped up by almost 2x . I would appreciate any advice or if someone can explain the reason behind this and how to combat this issue when using Autogen?```.
In general, at 2023-10-26 22:25:01 a user named karlka said ```Hey @mrbrz such a relevant issue with autogen atm. Is this still an issue or did you find any alternatives which helped you reduce the cost?```.
In general, at 2023-10-26 22:26:09 a user named karlka said ```On that note - my team was facing the exact same problem, so we started to work on an agent cloud that reduces the cost of running agents by ~10x. 

Let me know if that would be valuable for you. We are currently onboarding a limited set of early devs to collaborate on the design with.```.
In general, at 2023-10-26 22:59:15 a user named robin_saunders said ```@mrbrz have you tried LM Studio and running models locally on or servers?```.
In general, at 2023-10-26 22:59:19 a user named robin_saunders said ```I've been doing that for debugging```.
In general, at 2023-10-26 23:45:41 a user named karlka said ```I mean which models have u been using```.
In general, at 2023-10-27 11:08:23 a user named robin_saunders said ```group mode doesn't work very well```.
In general, at 2023-10-27 22:52:48 a user named karlka said ```are you swithching between them or running all agents on one model? what's your take on the performance/quality tradeoffs?```.
In general, at 2023-10-27 22:53:08 a user named karlka said ```btw, maybe useful for you too - we just created an LLM router which dynamically switches between GPT-3.5 and GPT-4. Still in alpha and currently for free. All feedback is appreciated 🙂

Readme: https://github.com/opencopilotdev/llm-router```.
In general, at 2023-10-30 18:22:24 a user named robin_saunders said ```Running the agents off one model. I don't even try running on openAI's GPT3.5/4 due to costs. I can see why people use it since it's the gold standard but for testing and trialing I have a hard time personally shelling out possibly big $ over the course of a month. Considering I'm generating 10's of thousands of tokens per hour in just testing, that adds up really quickly```.
In general, at 2023-10-30 18:23:54 a user named robin_saunders said ```like, yea 3.5T is probably ok at 0.004/k, but it feels like some of the open source models are better for programming stuff```.
In general, at 2023-10-07 10:48:14 a user named andyinater said ```I did! Expect a repo today. Lots more in it, but that will be there```.
In general, at 2023-10-07 10:13:26 a user named tonic_1 said ```(maybe i should post this as an event actually? )```.
In general, at 2023-10-07 10:13:08 a user named tonic_1 said ```oh, and please send me your github to be added to the repo```.
In general, at 2023-10-07 10:12:21 a user named tonic_1 said ```hey there folks, i put together a little team also from the autogen community with one very simple goal : create agi using autogen that absolutely crushes common benchmarks : check it out here http://www.multitransformer.com , normally there's links to github : https://github.com/team-tonic-arena-hacks and you can coordinate on discord by clicking the invite link in my profile bio. 

Basically i'm rushing forward with conversationalagent as a model for "multi-nested" agent creation on the fly and so on , it's basically 80% done from the tuturials (or maybe i like them a lot idrk @li_jiang ^^ 👊🏻) anyway, i'll be building a lot this weekend, hope that the folks that did join from here join with some PRsssszzzzzz 👩🏻‍🚀🚀```.
In general, at 2023-10-07 09:23:15 a user named bitsy_chuck said ```multiple document in vector store vs single document in vector store (chroma db) 
embedding model: all-mpnet-base-v2 or all-MiniLM-L6-v2
pdf file with 500 pages
should i break it up into chapters for better results?```.
In general, at 2023-10-07 08:06:12 a user named juzure. said ```As a beginner, I'm curious about the differences between AutoGPT and Autogen. Does anyone know?```.
In general, at 2023-10-07 08:02:15 a user named le_xxx said ```yay got the example working! does anyone know, does autogen have some file manager to save the generated code automatically?```.
In general, at 2023-10-07 07:48:01 a user named d8689 said ```I had the same issue (posted it in ideas-and-feedback), if you come up with a solution do post 😄```.
In general, at 2023-10-07 07:33:56 a user named eljefe69 said ```Hey, German fella here too.```.
In general, at 2023-10-07 06:28:00 a user named rumgewieselt said ```Hi. I am from Germany / Hamburg and happy to join the community here.```.
In general, at 2023-10-07 06:16:50 a user named bluethinhorse_18200 said ```https://tenor.com/iMpqamk3c52.gif```.
In general, at 2023-10-07 05:58:07 a user named heresynetwork said ```HI!  I came here from Wes Roth's video!```.
In general, at 2023-10-07 04:21:24 a user named qingyunwu said ```Not yet. But still tuned 🙂```.
In general, at 2023-10-07 04:06:54 a user named afourney said ```In other projects I’ve used an exponential back off when a request time out wasn’t provided```.
In general, at 2023-10-07 04:05:17 a user named afourney said ```Yeah if you filter it to select only one model, and hit a rate limit error, it should correctly handle the OAI exception (I.e., by waiting for the prescribed amount of time that the API provides). If that’s not the case, we should file an issue on GH```.
In general, at 2023-10-07 03:50:01 a user named sigma.xxx said ```Hi I was running into the same issue, however I dont think that model switching is the way to go though....it compromises quality. I think AutoGen should maybe consider adding a rate_limit_handle class like a singleton or something that tracks all instances tokens comsumption, and implement a wait logic. That seems to make more sense```.
In general, at 2023-10-07 03:42:02 a user named le_xxx said ```hi all, running into a wall trying to test this out, it says openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>',... even tho i did setup OAI_CONFIG_LIST with my key and when i load it with config_list = autogen.config_list_from_json( i can see its loaded with print(config_list) then i setup some assistants and finally doing a user_proxy.initiate_chat it gives me that error. watched some videos and all they did was setup that json and it works for them```.
In general, at 2023-10-07 03:17:15 a user named slayerdeebo said ```Is it possible to use GPT vision in autogen ?```.
In general, at 2023-10-07 03:08:09 a user named li_jiang said ```Run with Gradio ValueError: signal only works in main thread of the main interpreter```.
In general, at 2023-10-07 03:05:11 a user named li_jiang said ```Hi @0x0ting , it would be nice if you could provide more details as @qingyunwu mentioned. But based on what you've posted, I guess the issue is that there is some incompatible between Gradio and the signal lib used in code_utils.py in autogen. Could you try running your code in a terminal without Gradio? Maybe it can help to locate the root cause.```.
In general, at 2023-10-07 02:28:29 a user named andyinater said ```I figure I can hack it together with ending and restarting convos constantly, shifting the messages appropriately, just seeing if there is any better options first.```.
In general, at 2023-10-07 02:27:40 a user named andyinater said ```Does anyone know if there is a built in way to maintain a fixed max convo length, and do a FILO kind of thing to catch the old stuff as it maxes out?```.
In general, at 2023-10-07 02:14:11 a user named yanxiaochuan said ```i know on github and twitter```.
In general, at 2023-10-07 01:54:14 a user named unicorn1997 said ```Hello everyone, trying to understand AutoGen, could someone explain me on their example with visualizing stock prices - Why isnt there a few shot example included? But instead there is the first user input already incorporated in the code? (The query about the stock prices)

I tried to make my own agent and I first put a few shot example to the code, then a part where user was to write an input.
Here it seems like it is pre-defined in the code what the agent will do, but I would like to make my own custom input in the first place. 

Hope my question is clear 😄 
Thanks a lot!```.
In general, at 2023-10-07 01:46:39 a user named somecomputerguy said ```I just got the samples to work 😂```.
In general, at 2023-10-07 01:41:04 a user named regen2moon said ```custom autogen via discord ready to do first test```.
In general, at 2023-10-07 00:07:43 a user named finnious. said ```Just starting. following Wes Roth YouTube video```.
In general, at 2023-10-06 23:45:06 a user named frank.martinez said ```What tool interfaces are people building? Here’s what I want: a] Google Apps, b] Miro, c] Twilio```.
In general, at 2023-10-06 23:08:28 a user named bishopfx said ```For sure. I wasnt using that one as of before I posted that. I didn't quite fix it though, im quite stumped LOL.```.
In general, at 2023-10-06 23:07:23 a user named afourney said ```Glad you fixed it, but please remove this photo and rotate your api key 😛```.
In general, at 2023-10-06 23:06:04 a user named bishopfx said ```@afourney this was the error, i remember now by changing the engine i fixed the API issue but was getting this instead.```.
In general, at 2023-10-06 22:44:02 a user named sonichi said ```I would like to create a project that```.
In general, at 2023-10-06 22:41:16 a user named afourney said ```Yes agreed. If you have just the one endpoint in the list, or use a filter, I think that’s what it does. @sonichi ?```.
In general, at 2023-10-06 22:38:58 a user named purplxd said ```It would be much better if we could read the message and wait the specified amount of time rather than risk hammering the API endpoints```.
In general, at 2023-10-06 22:37:23 a user named bishopfx said ```I was able to fix that error by importqhing the api key in the actual file itself and defining it, but then I get the api access restriction error but everything else runs fine. I was just demoing the tesla nvda chart script.```.
In general, at 2023-10-06 22:35:44 a user named bishopfx said ```It was having issues with the json loader I belive```.
In general, at 2023-10-06 22:35:28 a user named bishopfx said ```I was providing it through Json. I wish I was at my PC id post a screen.```.
In general, at 2023-10-06 22:35:16 a user named wladpaiva said ```Would that mean that the same input would always get the same output even when we execute scrape functions in between it?```.
In general, at 2023-10-06 22:33:14 a user named aaronward_ said ```replacing UserProxyAgent with whatever the variable name is for that object```.
In general, at 2023-10-06 22:32:55 a user named aaronward_ said ```You can use the UserProxyAgent.send(message="") and it will have memory of your previous generated text```.
In general, at 2023-10-06 22:31:57 a user named wladpaiva said ```That would probably help. However, what I'm looking for is to stop the execution and come back to the same point in time later on```.
In general, at 2023-10-06 22:27:53 a user named aaronward_ said ```https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#caching Conversations are automatically caches in ./cache folder```.
In general, at 2023-10-06 22:26:11 a user named afourney said ```We’ve had one other similar report. How are you providing your OAI_CONFIG_LIST? .env? Json?```.
In general, at 2023-10-06 22:24:49 a user named afourney said ```You can put several models or configurations in your OAI_CONFIG_LIST which will be tried in order. You can use this to fall back to a less-limited model (e.g., GPT 3.5), or even load balance if you have different model endpoints. This can help somewhat.```.
In general, at 2023-10-06 22:21:23 a user named wladpaiva said ```Is there a way to save the chat state? Sorry, super noob question. I mean, how would I do it?```.
In general, at 2023-10-06 21:35:32 a user named bishopfx said ```I keep getting an error stating I do not have access or it cannot find that said engine, even when I change the engine in the main.py file, to 3.5-t it still shoots me the message.```.
In general, at 2023-10-06 21:34:48 a user named bishopfx said ```Hey guys, quick question. I seem to he having issues with my OpenAI API key. Is Autogen required to have GPT4 access?```.
In general, at 2023-10-06 21:12:29 a user named somecomputerguy said ```This is neat! Thanks for making it public 🙂```.
In general, at 2023-10-06 20:59:57 a user named purplxd said ```How to deal with openAI rate limits?```.
In general, at 2023-10-06 18:45:59 a user named Sparti said ```guys, does anyone know any blog or any youtube video that might help me learn about ml model deployment realtime?```.
In general, at 2023-10-06 18:12:46 a user named bitsy_chuck said ```what should be the format of context can```.
In general, at 2023-10-06 18:04:15 a user named afourney said ```Group chat stops when a termination condition is met, or when the maximum number of messages are exchanged. More details here: https://discord.com/channels/1153072414184452236/1159571194907996300```.
In general, at 2023-10-06 17:56:53 a user named bitsy_chuck said ```what should be the format of context? can someone please give me any example?
```py
    def initiate_chat(
            self,
            recipient: "ConversableAgent",
            clear_history: Optional[bool] = True,
            silent: Optional[bool] = False,
            **context,
    ):
        """Initiate a chat with the recipient agent.

        Reset the consecutive auto reply counter.
        If `clear_history` is True, the chat history with the recipient agent will be cleared.
        `generate_init_message` is called to generate the initial message for the agent.

        Args:
            recipient: the recipient agent.
            clear_history (bool): whether to clear the chat history with the agent.
            silent (bool or None): (Experimental) whether to print the messages for this conversation.
            **context: any context information.
                "message" needs to be provided if the `generate_init_message` method is not overridden.
        """
``````.
In general, at 2023-10-06 18:12:48 a user named bitsy_chuck said ```@afourney sorry to ping you. Can you please help here.```.
In general, at 2023-10-06 18:13:06 a user named bitsy_chuck said ```any source of ref would also work```.
In general, at 2023-10-06 18:24:50 a user named afourney said ```This question might be better answered by @sonichi or @bansalg . I've not had occasion to use that parameter.```.
In general, at 2023-10-06 18:29:54 a user named bitsy_chuck said ```i have found a workaround btw

```py
    def generate_init_message(self, problem: str, n_results: int = 20, search_string: str = "", **kwargs):
        """Generate an initial message with the given problem and prompt.

        Args:
            problem (str): the problem to be solved.
            n_results (int): the number of results to be retrieved.
            search_string (str): only docs containing this string will be retrieved.

        Returns:
            str: the generated prompt ready to be sent to the assistant agent.
        """
        global_context = kwargs.get("global_context", None)
        if global_context is None:
            global_context = {}
        self._reset()
        self.retrieve_docs(problem, n_results, search_string)
        self.problem = problem
        self.n_results = n_results
        doc_contents = self._get_context(self._results)
        print(f"vector store fetched: {doc_contents}")
        if global_context is not None:
            doc_contents = json.dumps({"global_context": global_context,
                                       "doc_contents": doc_contents,
                                       })

        message = self._generate_message(doc_contents, self._task)
        return message
``````.
In general, at 2023-10-06 18:54:51 a user named bitsy_chuck said ```if there's a better way, would love to know about it.```.
In general, at 2023-10-06 19:55:02 a user named bitsy_chuck said ```looks like it breaks down the line with NPE```.
In general, at 2023-10-06 19:55:43 a user named bitsy_chuck said ```is there any other way to provide global_context?```.
In general, at 2023-10-06 21:24:22 a user named bobaleaux said ```@bitsy_chuck is this any help? I wasn't aware of context parameter until your question.

```
- context (dict): the context of the message, which will be passed to
                    [Completion.create](../oai/Completion#create).
                    For example, one agent can send a message A as:
        ```python
        {
            "content": lambda context: context["use_tool_msg"],
            "context": {
                "use_tool_msg": "Use tool X if they are relevant."
            }
``````.
In general, at 2023-10-06 21:25:36 a user named bobaleaux said ``````
 if "context" in message:
                    content = oai.ChatCompletion.instantiate(
                        content,
                        message["context"],
                        self.llm_config and self.llm_config.get("allow_format_str_template", False),
                    )
``````.
In general, at 2023-10-06 21:27:57 a user named bobaleaux said ```it looks to me like it would be text as that is json string like any other content.

that might be the method of passing additional content at the same time.

please let me know what you find out```.
In general, at 2023-10-06 21:29:54 a user named bitsy_chuck said ```sure will check it out. Thanks for the help.```.
In general, at 2023-10-06 21:31:03 a user named bobaleaux said ```i just asked GPT this and here was the reply
```
When you see **context in a function call or definition, it means that the function is expecting a dictionary of keyword arguments, and **context is used to unpack that dictionary and pass its key-value pairs as keyword arguments to the function.
``````.
In general, at 2023-10-06 21:32:13 a user named bobaleaux said ```looking at 'conversable_agent.py' is where itis being used.```.
In general, at 2023-10-06 21:32:21 a user named bitsy_chuck said ```there;s actually no where we could use the global context json string in overridden methods. I added a kwargs and string concat it to vector db doc qurey results. That kinda works but I am getting NPE 

stack trace attached```.
In general, at 2023-10-06 21:32:43 a user named bitsy_chuck said ```cannot get why this is coming and how to debug it. been at it for 2 hrs xD```.
In general, at 2023-10-06 21:32:59 a user named bitsy_chuck said ```i dont think this is bcz of the kwargs i added.```.
In general, at 2023-10-06 21:35:06 a user named bobaleaux said ```oh man, i feel ya! it's like whack a mole!```.
In general, at 2023-10-06 21:37:11 a user named bitsy_chuck said ```do you think it could be the prompt?```.
In general, at 2023-10-06 21:37:21 a user named bitsy_chuck said ```i have tried editing it```.
In general, at 2023-10-06 21:42:53 a user named bobaleaux said ```I'm not sure what the code is doing but it looks like somewhere it is expecting something and it doesn't get it.

TypeError: argument of type 'NoneType' is not iterable```.
In general, at 2023-10-06 21:45:44 a user named bitsy_chuck said ```it worked when I removed code_execution_config from user proxy```.
In general, at 2023-10-06 21:47:34 a user named bobaleaux said ```no matter the reason, it's always time for a victory dance when it works!```.
In general, at 2023-10-06 17:34:56 a user named pbharrin said ```I would like to create a project that has a four stage pipeline, where each stage is a `GroupChat()` with three agents, the exact three agents involved in each `GroupChat` will not be the same in every stage.  Is this the best way to code it up (pseudo code):  
```
# we have eight agents; agent1, agent2,..
# we have four stages (GroupChat); groupchatA, groupchatB, ...

# define agents
agent1 = autogen.AssistantAgent(..)
agent2 = autogen.AssistantAgent(..)

# execute stageA 
groupchatA = autogen.GroupChat(agents=[user_proxy, agent1, agent2, agent8]...
manager = ....

# execute stageB
groupchatA = autogen.GroupChat(agents=[user_proxy, agent2, agent6, agent4]...
manager = ...
```
Is there anything wrong with this?```.
In general, at 2023-10-06 22:44:03 a user named sonichi said ```Remember to reset agent2 if your intention is to start a new chat fresh in stageB.```.
In general, at 2023-10-06 22:54:49 a user named fxtoofaan said ```I think ...

# we have eight agents; agent1, agent2,..
# we have four stages (GroupChat); groupchatA, groupchatB, ...

# define agents
agent1 = autogen.AssistantAgent(..)
agent2 = autogen.AssistantAgent(..)

# execute stageA 
groupchatA = autogen.GroupChat(agents=[user_proxy, agent1, agent2, agent8]...
manager = ....

# execute stageB
groupchatB = autogen.GroupChat(agents=[user_proxy2, agent22, agent26, agent24]...
manager = ...

# execute stageC
groupchatC = autogen.GroupChat(agents=[groupchatA, groupchatB]...
manager = ...

# review stageD```.
In general, at 2023-10-06 16:37:28 a user named qingyunwu said ```No worries. You are welcome.```.
In general, at 2023-10-06 16:36:30 a user named joao.morossini said ```Ohhhh, ok. That makes sense. I thought "web" was the name of the tool which enabled it to access the internet 🤦‍♂️ . Thanks again, @qingyunwu . Sorry about the dumb question haha```.
In general, at 2023-10-06 16:33:47 a user named qingyunwu said ```It is the folder name under "path_to_autogen" where we save the code execution results. The name could be any legitimate folder name specified by user. In the example you mentioned, we are just naming the folder to be "web". You can use other name as well. Does this answer your question?```.
In general, at 2023-10-06 16:23:17 a user named joao.morossini said ```Ok. I noticed in the example notebooks that one agent was set up with ```"work_dir": "web"```. How is that handled by the agent? The reason I ask is because I'm building an app which takes as input the url for a public Jupyter notebook, analyzes its contents and returns a brief report of what that program is meant to do. I got the agent to access the notebook by setting ```"work_dir": "web"```, but I'm not sure how it works```.
In general, at 2023-10-06 16:17:16 a user named qingyunwu said ```This is the only predefined option we have "If None, a default working directory will be used. The default working directory is the "extensions" directory under "path_to_autogen"."```.
In general, at 2023-10-06 16:15:33 a user named joao.morossini said ```Thank you! I'm still curious about the possible values for the "work_dir" argument. Is there a predefined set of options?```.
In general, at 2023-10-06 16:14:12 a user named qingyunwu said ```I have no clue what is causing the error based on your description. Can you provide some more info? E.g., what's the manager agent class? Did you do any customization.  @sonichi @li_jiang  @victor.dibia  Any thoughts on what is causing this error?```.
In general, at nan a user named qingyunwu said ```I think this is what you are looking for: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L80 And the "work_dir" argument only accepts one string value.```.
In general, at 2023-10-06 16:01:29 a user named qingyunwu said ```@faridkhan That's a great suggestion!```.
In general, at 2023-10-06 15:21:17 a user named 0x0ting said ```Hi @everyone
I have been working with groupChat.

def customChat(query):
    user_proxy.initiate_chat(manager, message = query)

And then I call the function using Gradio for Building quick UI.

It executes for a few to and fro conversation between the agents but then I get an error:
"ValueError: signal only works in main thread of the main interpreter"

Can somebody help me resolve this?
Thanks in Advance```.
In general, at 2023-10-07 03:08:28 a user named li_jiang said ```Hi @0x0ting , it would be nice if you could provide more details as @qingyunwu mentioned. But based on what you've posted, I guess the issue is that there is some incompatible between Gradio and the signal lib used in code_utils.py in autogen. Could you try running your code in a terminal without Gradio? Maybe it can help to locate the root cause.```.
In general, at 2023-10-08 21:09:09 a user named 0x0ting said ```Hi @li_jiang @qingyunwu 

I am using the same example, It is working fine in jupyter notebook, But cant run inside a function.
No customizations have been made, gents used are: Critic, coder and agent_proxy only.

Is there any possible way to access this over UI?Gradio or Streamlit any kind of UI would be fine.```.
In general, at 2023-10-09 05:15:57 a user named li_jiang said ```Hi @tonic_1 , have you successfully integrated autogen and Gradio?```.
In general, at 2023-10-13 06:29:23 a user named li_jiang said ```@0x0ting https://huggingface.co/spaces/thinkall/autogen-demos

A demo of Autogen Retrieve Chat with Gradio```.
In general, at 2023-10-06 14:30:26 a user named joao.morossini said ```Hey there! Can anyone point me to where I can find all the possible values for the "code_execution_config" parameter? Can a single agent have more than one value for its "work_dir" argument? For example:

code_execution_config={"work_dir": "coding", "web"})


Thanks in advance for any support. Cheers!```.
In general, at 2023-10-06 14:21:06 a user named fxtoofaan said ```@sonichi @everyone We’ve been in the community hangout voice chats quiet often. Can we get autogen dev team to join us from time to time? Would be nice to pick the dev teams brain and also have them listen to the autogen community. Friday virtual beer 🍺. What do you say ? 🙂```.
In general, at 2023-10-06 13:45:00 a user named m1337d said ```Here are the reproducible ai builds https://cknowledge.org i was talking about```.
In general, at 2023-10-06 13:43:47 a user named popcornfutures said ```What's the best way to track token usage in AutoGen? Is there an integration to Wandb or something similar?```.
In general, at 2023-10-06 12:53:55 a user named davec1623 said ```could modify the code and have your own fork maybe to include the prompt when the chat manager selects the next participant```.
In general, at 2023-10-06 12:36:34 a user named 0xjamp said ```I guess it won't have azure support tho for now until they can find a work around```.
In general, at 2023-10-06 12:35:33 a user named 0xjamp said ```Did we see the sdk from openai coming out soon ??!!```.
In general, at 2023-10-06 12:24:49 a user named m1337d said ```https://github.com/meta-introspector/meta-meme/issues/39```.
In general, at 2023-10-06 12:24:21 a user named eljefe69 said ```but how are you able to include the prompt , not only the name?```.
In general, at 2023-10-06 12:21:38 a user named m1337d said ```https://popl21.sigplan.org/details/CPP-2021/25/Extracting-Smart-Contracts-Tested-and-Verified-in-Coq```.
In general, at 2023-10-06 11:52:18 a user named davec1623 said ```you have "/completions" at the end of your base there, im not sure thats the full url for completion as you need to have deployment name etc, does having the base without "completions" work in autogen code?```.
In general, at 2023-10-06 11:48:09 a user named davec1623 said ```to make the name of the agent useful to help the manager understand when to use it, i had to use underscores rather than space```.
In general, at 2023-10-06 11:24:59 a user named eljefe69 said ```Is there a way to initially give context to the whole team? Like a knowledge base?```.
In general, at 2023-10-06 11:14:50 a user named morpheous3322_23215 said ```@aaronward_ Thanks, that helped. Can you help me with this as well
Also how does group chat stop when human_input_mode is set to NEVER. How is infinite loop prevented incase of error or lack of capabilities?```.
In general, at 2023-10-06 11:06:33 a user named aaronward_ said ```https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#caching```.
In general, at 2023-10-06 11:04:37 a user named morpheous3322_23215 said ```Also how does group chat stop when human_input_mode is set to NEVER. How is infinite loop prevented incase of error or lack of capabilities?```.
In general, at 2023-10-06 11:02:34 a user named morpheous3322_23215 said ```Can somebody help me understand how the memory for each agent works during a group chat?```.
In general, at 2023-10-06 10:49:40 a user named aaronward_ said ```this is currently being worked on, just trying to sort out the remaining bugs. Will update the chat when the tests have passed and its merged https://discord.com/channels/1153072414184452236/1158548894209282078/1159768441880846389```.
In general, at 2023-10-06 10:22:29 a user named eljefe69 said ```What’s the solution then to include the prompt?```.
In general, at 2023-10-06 09:57:35 a user named davec1623 said ```BTW i solved my own problem, the group chat manager only uses the agent name to decide who to ask things, not the prompt, my names didnt give enough information to help it decide. probably shouldnt have called one "researchboi"```.
In general, at 2023-10-06 09:55:11 a user named davec1623 said ```couple guesses:
1. your base might be incorrect, can you post the summary tab for your openai resource from azure portal
2. is the network connectivity set to public for the resource?
3. can you hit that base with curl```.
In general, at 2023-10-06 09:53:45 a user named trading4397 said ```yes correct still the same error 



Exception has occurred: InvalidRequestError
Resource not found```.
In general, at 2023-10-06 09:52:56 a user named davec1623 said ```but you need to go to the azure portal for your azure openai instance and it will be in the bottom right```.
In general, at 2023-10-06 09:52:13 a user named davec1623 said ```i think base is just this bit```.
In general, at 2023-10-06 09:49:53 a user named trading4397 said ```many thanks for your reply dave

error is chagned now 

Exception has occurred: InvalidRequestError
Resource not found
any suggestion```.
In general, at 2023-10-06 09:46:05 a user named pierrunoyt said ```i have a problem with something else than autogen```.
In general, at 2023-10-06 09:45:56 a user named pierrunoyt said ```Is someone good at coding```.
In general, at 2023-10-06 09:39:50 a user named _lansky said ```Hi everyone, first time trying AutoGen and local LLMS I just found out about this topic https://github.com/microsoft/autogen/issues/46 regarding the use of AutoGen with local LLMs to avoid using OpenAI API key and the cost of use that comes with it. Since I'm no expert, could you please tell me if a solution exist for me to use AutoGen without generating costs from OpenAI ? Is there a serious plus using AutoGen with OpenAI API or for example Ollama models can do the job almost as good ? Thanks a lot and have a good day ! 🙂```.
In general, at 2023-10-06 09:35:38 a user named davec1623 said ```also, if you have deployed a GPT model, check in the "deployments" tab in azure openai portal that you definitely called the deployment gpt-4 not something else```.
In general, at 2023-10-06 09:34:38 a user named davec1623 said ```and for base make sure youre using the full url of your azure openai resource as shown on its summary screen in portal```.
In general, at 2023-10-06 09:34:04 a user named davec1623 said ```might need to supply this: openai.api_type = "azure" and the api version```.
In general, at 2023-10-06 09:23:03 a user named trading4397 said ```can any one please suggest me what i am doing wrong i have provided azure api key and base in the code but still get this error```.
In general, at 2023-10-06 09:20:15 a user named davec1623 said ```hi all - autogen seems to be getting confused between agent personas in a group chat. I.e. i have an architect and a cyber securitist but the cyber securitist seems to be answering as an architect sometimes and vice versa?```.
In general, at 2023-10-06 08:01:59 a user named lessuse. said ```hey guys is twitter is like instagram?. i dont use that much social media. is twitter is useful for having up to date info about ai ?```.
In general, at 2023-10-06 07:58:33 a user named sonichi said ```certainly. See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints```.
In general, at 2023-10-06 07:32:06 a user named trading4397 said ```can we use azure keys for gpt 4 model instead of open ai key```.
In general, at 2023-10-06 05:30:55 a user named brot818 said ```I’d like it to build automated tests for my web application and API```.
In general, at 2023-10-06 04:15:45 a user named mistafisha said ```I want to have it build games```.
In general, at 2023-10-06 02:11:04 a user named afourney said ```Just ask it to via the prompt (user or system). It will then write code that will work with CSVs```.
In general, at 2023-10-06 02:08:41 a user named samin1 said ```anyone make an api out of autogen responses?```.
In general, at 2023-10-06 01:44:38 a user named 0xjamp said ```<#1157717881291812964> @aaronward_  posted in there about lightllm```.
In general, at 2023-10-06 01:10:47 a user named name_77933 said ```guys how do I connect a local llama-7B model?```.
In general, at 2023-10-06 01:10:30 a user named hypercodec said ```some are bigger than others lmao```.
In general, at 2023-10-06 01:10:23 a user named hypercodec said ```ew i messed up proportions slightly```.
In general, at 2023-10-06 01:10:11 a user named hypercodec said ```<:assistant:1159658701200822282> <:commander:1159658352377331772> <:conversable:1159658197871775784> <:gcmanager:1159658377920647299> <:manager:1159658083061076100>```.
In general, at 2023-10-06 01:04:59 a user named rtatlas said ```is there a tutorial to set this up somewhere? i have zero knowledge in this space and it could be revolutionary for me, any help is greatly appreciated```.
In general, at 2023-10-06 00:57:01 a user named hypercodec said ```hmm at least i can add random emojis and stickers without pissing too many people off (hopefully)```.
In general, at 2023-10-06 00:48:54 a user named bansalg said ```with great power comes great responsibility @hypercodec 😛```.
In general, at 2023-10-06 00:47:59 a user named hypercodec said ```i still have the perm```.
In general, at 2023-10-06 00:47:48 a user named bansalg said ```Its off for everyone else```.
In general, at 2023-10-06 00:47:37 a user named bansalg said ```It seems that @sonichi wanted users with the dev role to have this ability?```.
In general, at 2023-10-06 00:45:49 a user named bansalg said ```LOL thank you for reporting! Trying to figure out how to fix it 🙂```.
In general, at 2023-10-06 00:40:35 a user named hypercodec said ```https://discord.gg/zzdjUa9z?event=1159650631930368083 uh why do i have perms to do this```.
In general, at 2023-10-06 00:25:52 a user named thedasenqueen said ```can you use vs code with this?```.
In general, at 2023-10-06 00:22:51 a user named sonichi said ```I'm surprised the question was about open-interpreter, which is even much later than Code Interpreter```.
In general, at 2023-10-06 00:21:20 a user named .beibinli said ```Lots of our features are earlier than Code Interpreter, for instance the multi-agent coding (OptiGuide), the MathChat, and the Retrival agents.```.
In general, at 2023-10-06 00:18:42 a user named bansalg said ```Lmao @sonichi you deserve more Twitter followers 🙂```.
In general, at 2023-10-06 00:09:54 a user named andyinater said ```He was just revising some tetris code 😭```.
In general, at 2023-10-06 00:00:52 a user named sonichi said ```I really should join Twitter earlier.```.
In general, at 2023-10-05 23:57:57 a user named sonichi said ```This feature was available in May and no one noticed. It was earlier than ChatGPT+Code Interpreter 🥲```.
In general, at 2023-10-05 23:54:40 a user named kevlarmonkey said ```How similar is this to open-interpreter?```.
In general, at 2023-10-05 23:54:23 a user named .psychickoala said ```how do you do that read and write from files (csv etc)```.
In general, at 2023-10-05 23:47:20 a user named sonichi said ```interesting that this dc guild doesnt```.
In general, at 2023-10-05 23:36:14 a user named afourney said ```But yeah, the timeout issue is a regular error that's encountered when dealing with the  OAI endpoints. It's less of a problem than it was months ago.```.
In general, at 2023-10-05 23:36:14 a user named name_77933 said ```Hi!
How do I register a config for llama 7B in llama.cpp ?
{
            "model": "llama-7B",
            "api_base": "http://127.0.0.1:8080",
            "api_type": "open_ai",
            "api_version": None,
        }
Maybe you can somehow register the path to my model here?```.
In general, at 2023-10-05 23:34:13 a user named afourney said ```Maybe it was moonlighting. Who knows 😛```.
In general, at 2023-10-05 23:32:55 a user named 0xjamp said ```The agent got stuck living a completely different life and had 3 kids and a wife while on the quest to complete the task you gave it.```.
In general, at 2023-10-05 23:31:40 a user named afourney said ```Yes for sure. If you are using GPT-4-32k and passing long contexts, it can sometimes take a while. Also, sometimes the OAI endpoints just keep the connection open and blocking until it can be fulfilled rather than returning a rate limit error.```.
In general, at 2023-10-05 23:09:10 a user named fxtoofaan said ```Either increase the timeout or see what the agent is doing . Maybe it fell asleep lol```.
In general, at 2023-10-05 23:08:47 a user named fxtoofaan said ```Yeah. An agent is taking longer than 2 minutes to come back with data```.
In general, at 2023-10-05 23:07:07 a user named andyinater said ```Anyone get this one before? 
```
openai.error.Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=120)
``````.
In general, at 2023-10-05 22:42:06 a user named _fenix_atx said ```Discovered Autogen through many of the YouTube channels I follow```.
In general, at 2023-10-05 21:55:05 a user named kajatta said ```Good luck! There are similar topic in the threads section fyi```.
In general, at 2023-10-05 21:54:28 a user named troymurs said ```Exploring my options on enterprise vs opensource LLM agent chaining```.
In general, at 2023-10-05 21:54:08 a user named troymurs said ```not really just wanted to join the discord working on things internally right now```.
In general, at 2023-10-05 21:53:50 a user named kajatta said ```I have a similar goal```.
In general, at 2023-10-05 21:53:32 a user named kajatta said ```How has it been going, got anything you can show @troymurs```.
In general, at 2023-10-05 21:52:38 a user named troymurs said ```Hi, been building agents and exploring the enterprise side of things```.
In general, at 2023-10-05 21:40:30 a user named bitsy_chuck said ```More than one conversation is found in user_proxy... How to handle it?```.
In general, at 2023-10-05 21:46:39 a user named bitsy_chuck said ```first conversation is due to initate_conversation with user query

second is 


```py
user_proxy.initiate_chat(cs_group_chat_manager, message=user_msg, search_string="demo")
    user_proxy.stop_reply_at_receive(customer_support_manager)
    user_proxy.send(
        message="Give me the result you came up with to resolve my query. Return it in json format with the following keys. action_type to denote if the instructions are to be performed by human or agent. actions to denote the instructions.",
        recipient=customer_support_manager
    )
    return user_proxy.last_message()["content"]

``````.
In general, at 2023-10-05 23:51:43 a user named sonichi said ```use https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#chat_messages```.
In general, at 2023-10-06 05:17:46 a user named bitsy_chuck said ```my bad. Thankyou for the help @sonichi```.
In general, at 2023-10-05 21:36:13 a user named afourney said ```What do you mean? You can include in your prompt a list of files that are available, and what functions are in them, and the coder will tend to use those functions if appropriate. You can also ask the agents to write and read from files.```.
In general, at 2023-10-05 21:22:38 a user named jatique said ```Please... is there any way to use autogen in a nextjs website 🥺```.
In general, at 2023-10-05 21:03:32 a user named limaconnect said ```Autogen is open source too 

Let's see about getting it as part of the  software```.
In general, at 2023-10-05 21:02:13 a user named limaconnect said ```We all.live in a simulation anyway now I recreate in his image lol```.
In general, at 2023-10-05 20:58:40 a user named bitsy_chuck said ```1st llm replaced writer, then it replaced coders, then it replaced God
(it's a joke.)```.
In general, at 2023-10-05 20:55:40 a user named limaconnect said ```And can Autogen continue working and developing the world as time goes on so I can develop a video game metaverse that others can play too like Free Guy```.
In general, at 2023-10-05 20:54:55 a user named .psychickoala said ```How do you point the code execution at a specific File?```.
In general, at 2023-10-05 20:51:55 a user named bitsy_chuck said ```Can we include  RetrieveUserProxyAgent in group chat?```.
In general, at 2023-10-05 20:49:39 a user named bitsy_chuck said ```what determines how many times agents```.
In general, at 2023-10-05 20:49:13 a user named jb_5579 said ```Has anyone tried to setup a Pedals enabled open source distributed LLM to be utilized by one or more of the agent classes?```.
In general, at 2023-10-05 20:47:17 a user named limaconnect said ```Will Autogen work with zapier or another automation tool so it can get directions and continue working on various projects```.
In general, at 2023-10-05 20:46:35 a user named limaconnect said ```How do I connect Autogen to another text to 3d Image tools so it can generate a metaverse for me```.
In general, at 2023-10-05 20:14:35 a user named afourney said ```is_termination_msg and max_consecutive_auto_reply are the arguments that determine under what conditions a conversation will end.  If the next agent responds with an empty message it will also terminate the conversation.  To make this more explicit, we often set     is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),   and instruct agents to output "TERMINATE" when they have nothing to add to the conversation.```.
In general, at 2023-10-05 20:11:59 a user named zeesa27 said ```Found autogen on youtube. Exploring now. My Coding Ability: 0.1```.
In general, at 2023-10-05 19:52:26 a user named hypercodec said ```interesting that this dc guild doesnt have any bots, colored/hoisted roles, or boost levels yet. when was this created?```.
In general, at 2023-10-05 23:47:21 a user named sonichi said ```two weeks ago. 🆕. Suggestions are appreciated!```.
In general, at 2023-10-06 00:37:40 a user named hypercodec said ```Ok, here are some of my suggestions:

It could use some bots like Wick, Dyno, etc. for member roles/captcha/automod. Be aware that bot-based verification systems like Wick can sometimes conflict with onboarding depending on server setup. 

Also (up to personal preference), the staff roles could be displayed separately and/or have distinct colors to make them more noticeable.

The server could additionally benefit from a ticket system, although I'm sure much of that can be accomplished with GH issues.```.
In general, at 2023-10-06 13:49:14 a user named sonichi said ```Thanks! Let me start with coloring.```.
In general, at 2023-10-05 19:48:29 a user named ghar_tok said ```Been using AI tools and built a couple of products with them.
Using autogen for the first time and it felt like magic - thanks for this!```.
In general, at 2023-10-05 19:42:20 a user named regen2moon said ```Ill update how it works out```.
In general, at 2023-10-05 19:41:55 a user named regen2moon said ```and they work together to control a person```.
In general, at 2023-10-05 19:41:49 a user named regen2moon said ```Each instance is an emotion```.
In general, at 2023-10-05 19:41:38 a user named regen2moon said ```I'm working on a group of prompts to recreate the movie Inside Out```.
In general, at 2023-10-05 19:21:56 a user named bitsy_chuck said ```what determines how many times agents will talk to each other? is there any way to enforce ?```.
In general, at 2023-10-05 20:49:40 a user named bitsy_chuck said ```@afourney Thanks for your response. 

Putting your reply here for context

> is_termination_msg and max_consecutive_auto_reply are the arguments that determine under what conditions a conversation will end.  If the next agent responds with an empty message it will also terminate the conversation.  To make this more explicit, we often set     is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),   and instruct agents to output "TERMINATE" when they have nothing to add to the conversation.```.
In general, at 2023-10-05 18:28:38 a user named jatique said ```Do they have a JavaScript version of autogen yet?```.
In general, at 2023-10-05 18:28:02 a user named pierrunoyt said ```I mean webui for autogen```.
In general, at 2023-10-05 18:26:10 a user named regen2moon said ```I made a discord 'wrapper' for open ai keys```.
In general, at 2023-10-05 18:23:15 a user named regen2moon said ```discord py is really straightforward via gpt 3.5```.
In general, at 2023-10-05 18:22:48 a user named regen2moon said ```You know whats a perfect platform to host and display chat conversations?```.
In general, at 2023-10-05 18:09:06 a user named bitsy_chuck said ```can i use pinecone with autogen?```.
In general, at 2023-10-05 18:05:15 a user named bitsy_chuck said ```GitHub - amadad/agentcy: Multi-Agent Cre...```.
In general, at 2023-10-05 18:05:10 a user named telepathyx said ```can setup a loop situation to get something similar to autogen```.
In general, at 2023-10-05 18:04:29 a user named telepathyx said ```if you're looking to chain prompts together and extract answers with regex etc you might want to look at Rivet https://github.com/Ironclad/rivet/```.
In general, at 2023-10-05 18:02:07 a user named catsrcool123 said ```Hey ty for ur response

Sorry I am totally new at all this and I do not understand how to communicate my ideas in terms of art. Is it correct that AutoGen is a platform for building conversable agent topologies with any system prompt and simulated chat input prompt workflow, ie any promptchain of n-node flow can be constructed, or not? What do I need to stack to make that? Sorry I am very very new```.
In general, at 2023-10-05 17:49:18 a user named afourney said ```It's both a super power and a risk. The strong recommendation is to (1) use Docker, and (2) keep the human_input_mode on until you are comfortable with your specific scenario, or have other safeguards in place.```.
In general, at 2023-10-05 17:45:05 a user named afourney said ```I'm not sure if understand this question. You can file and review all issues on the GH page. As for the current status: it's a research project, and was released only very recently. Costs and performance are related to the models you choose, the prompts used, etc. etc. and optimizing this is part of the exciting research ahead.```.
In general, at 2023-10-05 17:31:24 a user named .bigbangtheory said ```Just use the code interpreter for storing the tasklist and code in a static variable or db```.
In general, at 2023-10-05 17:29:38 a user named telepathyx said ```A single chat instance can have a multi-agent chat```.
In general, at 2023-10-05 17:21:54 a user named telepathyx said ```put this into chatgpt-4 native app system prompt and compare: https://github.com/ProfSynapse/Synapse_CoR/blob/main/prompt.txt```.
In general, at 2023-10-05 17:20:59 a user named telepathyx said ```i'm not sure how/why reasoning would be improved with parallel context windows rather than one```.
In general, at 2023-10-05 17:16:33 a user named telepathyx said ```From the technical paper on problem solving success rate: "Our analysis of the entire dataset reveals that AutoGen achieves an overall accuracy of 69.48%, while GPT-4’s accuracy stands at 55.18%"

What about GPT-4 with "Synapse_CoR prompt" town square debate function that dynamically conjures up 3 expert agents to debate in a single context window? I think it would be also ~ 69%```.
In general, at 2023-10-05 17:09:58 a user named cethewe said ```I reminds me of the eval() discussion in JavaScript```.
In general, at 2023-10-05 17:09:40 a user named cethewe said ```Got that. My question is whether it is OK for people to let some instance generate code and let another instance just execute that? I mean... that is really trusting a lot of instances doing no harm 🙂```.
In general, at 2023-10-05 17:07:28 a user named cethewe said ```What feature are you referring to?```.
In general, at 2023-10-05 17:05:20 a user named au8 said ```I feel like it's fine as is to be honest, you can just use_docker=True if you're concerned that much, no?```.
In general, at 2023-10-05 17:03:38 a user named sonichi said ```What are people's thoughts about refusing code execution without docker unless use_docker=False?```.
In general, at 2023-10-05 17:00:35 a user named thedasenqueen said ```Has anyone tried a complex project using multiple languages front end and back end?```.
In general, at 2023-10-05 16:53:20 a user named telepathyx said ```i was thinking about a hierarchy UI like this integrated with Flowise. so each agent could be customized with their UI for RAG/tools/etc and then linked together```.
In general, at 2023-10-05 16:47:31 a user named cethewe said ```Hey all - really enjoying reading the AutoGen docs and playing around with it.

BUT: is nobody really worried that we see in a lot of samples that some random Python code is generated that then gets executed by some agent? 

What are your thoughts here?```.
In general, at 2023-10-05 15:59:21 a user named jb_5579 said ```Totally agree with that.  My initials thought were to  have a UI where you can drag and drop specific sub-agents (either based on sub-agent past performance , use of a specific method or LLM) into a project file .  Associated with the runtime environment would be  preview panel for output  with tabbed windows per sub-agent to monitor and  iteratively guide through the process.  The last part of that concept was to be able to add a new agent into the chain when it is obviously a specific skill is now needed or the project changes direction. A good example would be developing a webapp that then needs to change to a iOS app with native UI requirements  without starting completely over. Or addressing data privacy  issues that was not a consideration  in the initial concept.```.
In general, at 2023-10-05 15:44:01 a user named salishsea said ```estimation of token cost before running```.
In general, at 2023-10-05 15:43:37 a user named salishsea said ```appeared on my social mediea feed```.
In general, at 2023-10-05 15:29:50 a user named aaronward_ said ```You're trying to create a db thats already there, you can delete the folder manually or you can runs something like this to do it programmatically: 
```
client = chromadb.PersistentClient(path=f"{os.getcwd()}/chromadb")

# Create an instance of RetrieveUserProxyAgent
ragproxyagent = RetrieveUserProxyAgent(
    name="ragproxyagent",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    retrieve_config={
        "task": "default",
        "docs_path": str(path), 
        "chunk_token_size": 2000,
        "model": config_list[0]["model"],
        "client": client, 
        "embedding_model": "all-mpnet-base-v2",
    },
)

# NOTE: Call this to delete collection if you want to run again
#  client.delete_collection('autogen-docs')
``````.
In general, at 2023-10-05 15:16:49 a user named catsrcool123 said ```Hi can someone pls explain what is the current status of issues w AutoGen? If it truly is what it says, why isn’t everyone using it for everything? Seems like it is more the case that yes there is a conversable agent topology architecture but actually the agent interactions themselves are not optimized or efficient at all (Costs too much, not scopable etc). Can someone help me understand? 🙏```.
In general, at 2023-10-05 15:06:00 a user named kakao014 said ```Any one can help please:     I got this error everytime.
....
Trying to create collection.
Collection natural-questions already exists.
doc_ids: [[]]
No more context, will terminate.
ragproxyagent (to assistant):```.
In general, at 2023-10-05 14:50:34 a user named aaronward_ said ```@sonichi Cast this guy to the shadow realm```.
In general, at 2023-10-05 14:49:38 a user named bobaleaux said ```hahaha, probably! seems like there are a lot of the same people chasing this rainbow!```.
In general, at 2023-10-05 14:48:31 a user named jimmysandwiches said ```I think were in the same group persona discord group lol```.
In general, at 2023-10-05 14:36:40 a user named tomexmachina said ```in the meantime though, let's have some fun```.
In general, at 2023-10-05 14:24:34 a user named asswetsweat said ```Hey everyone, What is autogens relationship with Microsoft?```.
In general, at 2023-10-05 14:19:16 a user named agustinb.eth said ```Anyone who wants to build a proper UI for this project will be rich in a matter of minutes.```.
In general, at 2023-10-05 14:05:53 a user named fxtoofaan said ```your script is getting complex very quick, when i first saw it and what you have on github now is big difference 🙂  Have you check out this repo? https://github.com/dgarnitz/vectorflow maybe useful for private local vector db```.
In general, at 2023-10-05 14:03:44 a user named amadad said ```I'm juggling 10 agents that have some soft guidance on when to call on one another https://github.com/amadad/agentcy```.
In general, at 2023-10-05 18:05:16 a user named bitsy_chuck said ```I think client should be created first...```.
In general, at 2023-10-05 18:07:58 a user named bitsy_chuck said ```lol looks like you merged all the collab files```.
In general, at 2023-10-05 13:57:53 a user named bobaleaux said ```@jimmysandwiches totally agree. When I first started playing with ChatGPT, I found out about prompt engineering personas and got involved in a community that is focused on that.
Anyway, I have a full office staff of personas that I am trying to wire into AG.
I haven't come up with a way to provide a 'company' directory to the 'agents' so they would have enough smarts to call on the proper agent for support or to discreetly pass the required data.```.
In general, at 2023-10-05 13:57:37 a user named christolito said ```how does the caching (seed?) work... does it store the previous iterations/code? say i want to go back and instruct a code agents to change the code?```.
In general, at 2023-10-05 13:30:18 a user named zer0h1ro said ```Create content for my startup with maximum efficiency```.
In general, at 2023-10-05 12:40:41 a user named davec1623 said ```hi all, does anyone have experience in how autogen and semantic kernel might work together or are they totally separate visions for similar things? I.e. i like the idea of defining skills/functions in semantic kernel, but like that autogen will plug away until something works. Cant work out in my head where i would use semantic kernel vs autogen or even together```.
In general, at 2023-10-05 12:32:57 a user named jimmysandwiches said ```you then hve full control of the agents themselves```.
In general, at 2023-10-05 12:32:05 a user named jimmysandwiches said ```I was thinking the same but I think a better way would be to have a large selection of different agents the specific roles, skills and prompts and simply have autogen select the correct one/s for the project at hand```.
In general, at 2023-10-05 12:23:58 a user named jb_5579 said ```I tried to build an Agent that would build over agents for a given goal.  

I think I am well over my novice Skis:

ef init(self, name: str):
    super().init(name)
    self.agents = {}

def build_agent(self, agent_type: str, name: str, kwargs) -> ConversableAgent:
    """Build an agent of the given type with the provided name and kwargs"""
    if agent_type == "user_proxy":
        agent = UserProxyAgent(name, kwargs)
    elif agent_type == "assistant":
        agent = AssistantAgent(name, kwargs)
    else:
        raise ValueError(f"Unknown agent type: {agent_type}")

    self.agents[name] = agent
    return agent

def get_agent(self, name: str) -> ConversableAgent:
    """Get a previously built agent by name"""
    return self.agents[name]

def generate_reply(self, sender: "Agent", kwargs) -> str:
    if sender is None: # Initial message
        return "I can build customized agents for you. Tell me the agent type, name and configuration."

Process request to build agent
    agent_type = kwargs.get("agent_type") 
    agent_name = kwargs.get("agent_name")
    if agent_type and agent_name:
        agent = self.build_agent(agent_type, agent_name, **kwargs)
        return f"Created agent {agent.name} of type {agent_type}"

Process request to get agent
    if agent_name:
        agent = self.get_agent(agent_name)
        return f"Got agent {agent.name}"```.
In general, at 2023-10-05 12:21:33 a user named jaemil said ```I mean, it should be possible to create an autogen agent that creates an autogen script with selected agents based on the task - correct me if im wrong```.
In general, at 2023-10-05 12:08:44 a user named jb_5579 said ```Premise: Can Autogen be more like MetaGPT or ChatDev but more interactive, iterative  and specialized. 
Is there a way to build a project initiation agent?  I would describe it as a Chat Interaction where the human user  would brain storm with  a Agent on a Use Case (initially provided by the user) , sub-use cases  (features), refine those uses cases, and the final result would be to spin up a project file with a Core Agent and Sub agents (created by the project initiation agent) that are highly specialized. These created agents would be crafted to use a specific LLM (some for research, some for coding etc.), and trained using data sources recommend by the project initiation agent.   (for example, If the Project Initiation Agent created a sub-Agent (as a part of a project)  that specialized  in APIs, they would be directed to use Gorrila LLM to start with and then have fall back LLMs to meet the requirements of the goal provided) .  This is not as coherent as it sounded in my head, but I am looking at this from a person that sells generative AI solutions and not a truely technical person. I am just a self taught dreamer.```.
In general, at 2023-10-05 11:50:59 a user named jaemil said ```Has anyone tried to connect autogen with fastapi? I want to create an API, e.g. /run-agent, and it should stream back the response```.
In general, at 2023-10-05 11:19:43 a user named cryptokungfu said ```if you run things in docker.. should it work the same way as if you run it locally on Windows 11? I seem to be having issues getting it to execute its own code / install pip requirements etc.```.
In general, at 2023-10-05 11:18:14 a user named otherinqz said ```this error has nothing to do with rate limiting lmao```.
In general, at 2023-10-05 11:02:18 a user named aaronward_ said ```Heres my take on :

from my experience with traditional ML where no-code solutions are often pitched by companies looking to save money, they can only get you so far but don't consider the broader scope of what it takes to put a project into production. You can use tools like Zapier or N8N for no-code development of LLM workflows, and this is great for understanding how LLMs can be used in tandem to solve a problem. It isn't feasible to rely on just on LLMs, in reality your application would be much larger than just the simple LLM calls and tools you give the agents.

 For example, say you working in industry: you're probably going to need a data pipeline, and some company specific domain knowledge and some additional in-house built specific use-case ML models for various tasks (some modelling problems are too nuanced for LLM agents to figure out, currently). Having the ability to influence your application programatically will always give you more control. When your objective goes out of the bounds of what the 3rd party providers UI lets you do, your stuck. (*that is until ai can just replace our role in the equation /s*)

tldr: having control over your own infrastructure is better.```.
In general, at 2023-10-05 10:11:59 a user named tomexmachina said ```There are other projects that are similar to autogen and do multi-agent automation out of the box without having to write code. I'm sure someone will (probably already have) make some with autogen too but it's not that big of a deal. Autogen doesn't do anything super new that makes the agents created with it anymore capable (unless I'm missing something). It's just nicer to work with than most frameworks from a programming POV. The hyperparameter/tuning features are kinda unique but most ppl probably aren't using it, especially if they're using openai api (would get expensive).```.
In general, at 2023-10-05 09:59:13 a user named jaemil said ```I don't know much about autogen and its capabilities, but I would love to contribute on a frontend```.
In general, at 2023-10-05 09:53:57 a user named greyfalls. said ```I saw a video on youtube last night, trying it out this morning.```.
In general, at 2023-10-05 09:52:57 a user named pierrunoyt said ```yes i dont understand it because its not easy to use```.
In general, at 2023-10-05 09:46:42 a user named pierrunoyt said ```Can someone create a web ui```.
In general, at 2023-10-05 09:44:46 a user named tomexmachina said ```riffusion is another but I think audiocraft might be a better starting-point```.
In general, at 2023-10-05 09:43:36 a user named tomexmachina said ```the amount of compute that must be required tho...```.
In general, at 2023-10-05 09:42:40 a user named tomexmachina said ```would have to do your own training run with it to be good. it has a small context window and bugs. I looked into it before, and just double-checked. I would def use it as a starting-point if I wanted to train my own tho. Just needs some work```.
In general, at 2023-10-05 09:42:05 a user named memo_memo said ```Thank you for this amazing library(AutoGen)! <:echo:1072737827529429022> <a:spongeboblove:901282270890057788>```.
In general, at 2023-10-05 09:34:00 a user named pierrunoyt said ```there is audiocraft by meta```.
In general, at 2023-10-05 09:30:53 a user named tomexmachina said ```would be a good project```.
In general, at 2023-10-05 09:30:43 a user named tomexmachina said ```These things never get trained on a ton of edm```.
In general, at 2023-10-05 09:30:18 a user named tomexmachina said ```I told it Electro House club drop and that's what it gave me lol```.
In general, at 2023-10-05 09:28:40 a user named yogeshharibhaukulkarni said ```While working on `CAMEL` agent, came across `autogen````.
In general, at 2023-10-05 09:20:31 a user named tomexmachina said ```but I think the best music generator is a discord bot so getting that in there would be a suck```.
In general, at 2023-10-05 09:19:12 a user named tomexmachina said ```you could do it with a hf gradio api```.
In general, at 2023-10-05 09:09:08 a user named ilaffey said ```hahahahahahah i was about to be like, no way```.
In general, at 2023-10-05 08:46:08 a user named adriangalilea said ```I've heard worse EDM so we good```.
In general, at 2023-10-05 08:40:13 a user named pierrunoyt said ```or a full working plugin for lspdfr gta v mod```.
In general, at 2023-10-05 08:39:54 a user named pierrunoyt said ```how to generate audio with autogen```.
In general, at 2023-10-05 07:47:36 a user named digicat3194 said ```Would really appreciate if someone of knowledge of this rep can help. We are trying to replicate the use case of AutoGen as a browser agent. We are successfully able to build the docker image which is provided by microsoft autogen but getting some errors to run the relevant code provided by autogen. We are investigating the issue at our end and checking what needs to done to execute the scripts further. (https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb)```.
In general, at 2023-10-05 07:34:09 a user named morpheous3322_23215 said ```How does the agent decide when to use the function call ?```.
In general, at 2023-10-05 07:19:17 a user named ath3nA said ```I have tried adding Llama-2 Anyscale endpoints in to my code and it works fine for normal chat. But if you try to implement this with the 

`manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt3_llm_config)' (here i am passing the gpt3 config instead of the llama2 config)`

For some reason things break. And gives me a (  Error:  response = openai_completion.create(**config) )
Till we have a fix for this, You can let gpt3/4 make the important decisions and use the open source or other cheaper options for rest of the tasks.```.
In general, at 2023-10-05 06:58:04 a user named ath3nA said ```You can pretty much use any tool. Check this - https://www.youtube.com/watch?v=Bq-0ClZttc8 
6 minute marker. 

I think the process gets smoother if you use langchain 🙂```.
In general, at 2023-10-05 06:55:53 a user named morpheous3322_23215 said ```It's mentioned in the doc the agent have access to tools, what are the tools here?```.
In general, at 2023-10-05 06:54:10 a user named ath3nA said ```got it thank you very much```.
In general, at 2023-10-05 06:53:52 a user named ath3nA said ```oh right thank you. Meaning i'll have to use two different llm_config's ?```.
In general, at 2023-10-05 06:47:48 a user named shintai8531 said ```have you guys settled on a good backend to run your open source models on? I have Text-generation-webUI and localAI both working but was wondering if there is a lighter, faster option.```.
In general, at 2023-10-05 06:40:41 a user named shintai8531 said ```yes. I don't have the link handy to post and example, but i was playing with code doing basically that. you just define a separate llm_config for each agent```.
In general, at 2023-10-05 06:40:13 a user named sonichi said ```Yes, use `llm_config` to set the model```.
In general, at 2023-10-05 06:36:02 a user named ath3nA said ```Hey everyone, can we use multiple models depending on the agent, Like use GPT4 for important decisions making agents and use GPT3.5 for rest of the work? Where do we add this functionality if we are adding this D:```.
In general, at 2023-10-05 06:33:31 a user named ilaffey said ```What determines groupchat ending ?```.
In general, at 2023-10-05 06:41:49 a user named sonichi said ```either when max_rounds is reached, or when the next speaker stops replying, i.e., the termination condition of that agent is met.```.
In general, at 2023-10-05 06:43:06 a user named ilaffey said ```hmmm - could you take a look @ this real quick ?```.
In general, at 2023-10-05 06:43:48 a user named ilaffey said ```After the first execution of search_emails - the groupchat ends and returns```.
In general, at 2023-10-05 06:48:27 a user named sonichi said ````max_consecutive_auto_reply=1` plus `human_input_model="NEVER"` makes that agent stop replying after one reply```.
In general, at 2023-10-05 06:49:35 a user named ilaffey said ```i see, so the executor can only execute once, which is bad- but shouldn't the Leader & Admin continue ?```.
In general, at 2023-10-05 06:49:57 a user named ilaffey said ```or is the issue that the control is passed to Executor, who types TERMINATE, then the whole groupchat dies...```.
In general, at 2023-10-05 06:51:08 a user named ilaffey said ```yep, that was the issue```.
In general, at 2023-10-05 06:30:00 a user named ath3nA said ```Hey 👋 anyone have any luck using Anyscale endpoints for llama-2 intergrations?```.
In general, at 2023-10-05 05:48:42 a user named sonichi said ```oh that's the most basic feature we have.```.
In general, at 2023-10-05 05:47:06 a user named pierrunoyt said ```wen ui also would be cool```.
In general, at 2023-10-05 05:46:45 a user named pierrunoyt said ```like in autogpt you could lile chat and type what you want and it reflects itself and ask question if unclear```.
In general, at 2023-10-05 05:45:38 a user named sonichi said ```Would love to hear more```.
In general, at 2023-10-05 05:39:55 a user named pierrunoyt said ```it would be easier if you can chat with autogen like autogpt```.
In general, at 2023-10-05 05:37:59 a user named pierrunoyt said ```let me watch later thx```.
In general, at 2023-10-05 05:37:32 a user named sonichi said ```Have you seen this video? https://x.com/chi_wang_/status/1709615803832635436?s=46&t=HW3LQnkY2VkckNNTvFnbcA```.
In general, at 2023-10-05 05:36:44 a user named pierrunoyt said ```can someone explain how to use it?```.
In general, at 2023-10-05 05:34:40 a user named sonichi said ```Check the example about "context": https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#send```.
In general, at 2023-10-05 05:32:38 a user named ilaffey said ```i.e. where there is a state change betweeen calls```.
In general, at 2023-10-05 05:32:28 a user named ilaffey said ```for something like:

it's 1:30 PM
it's 1:31 PM```.
In general, at 2023-10-05 05:32:15 a user named ilaffey said ```or like re-set the system message on each call ?```.
In general, at 2023-10-05 05:31:20 a user named ilaffey said ```yo is there a way to append context to every call to an agent ?```.
In general, at 2023-10-05 05:28:28 a user named pierrunoyt said ```like there is autogpt or metagpt etc```.
In general, at 2023-10-05 05:25:05 a user named pierrunoyt said ```what can I do with autogen?```.
In general, at 2023-10-05 05:23:57 a user named sonichi said ```is there a way to connect vector```.
In general, at 2023-10-05 04:50:22 a user named the_god_of_universe said ```hes gonna be damn poor```.
In general, at 2023-10-05 04:20:19 a user named mushymechanic said ```I found some youtube videos online talking about autogen I've used interpreter in my command line to learn more about running the command line interface, ive tried autogpt, ran docker and launched superagi. I would really like to find an agent solution that works for me. So far interpreter has worked well unless it crashes then their is no function to go back a step and try something new. Autogen worked pretty well but I dont know its limits so I would like to know what is possible.```.
In general, at 2023-10-05 03:36:32 a user named tomexmachina said ```https://www.youtube.com/watch?v=pq1k5USZZ9A```.
In general, at 2023-10-05 03:29:03 a user named amadad said ```Is it good practice to include multiple distinct functions in one llm_config, or separate them into distinct configs for each agent?```.
In general, at 2023-10-05 03:17:01 a user named wayliu said ```hi all, i work in azure ai team and saw the blog. really interesting stuff. super exciting!```.
In general, at 2023-10-05 03:04:35 a user named jidun67 said ```I think they solved this here ... https://discord.com/channels/1153072414184452236/1157316448398622883```.
In general, at 2023-10-05 02:34:59 a user named tomexmachina said ```https://github.com/whitphx/streamlit-webrtc```.
In general, at 2023-10-05 02:32:35 a user named operator2k said ```I would like to build a feature that allows me to just browse the web and extract information```.
In general, at 2023-10-05 02:31:52 a user named operator2k said ```I wanted to learn more about how to use LLMs and came across it online.```.
In general, at 2023-10-05 01:49:25 a user named andyinater said ```Hey everyone, just pushed another big change to <#1158564427117903882> .

The functionality has been moved in a class "IterativeCoding" to hopefully allow for some more complex problem solving down the road. Also, multiple projects can now be worked on, with each getting it's own sub-directory so you can pick up and drop off as desired. I wrote more about it in that thread. Sorry, the documentation is frankly not representative anymore, and will need it's own overhaul. But, it should be much easier to use.

Still lots of ideas going forward - feel free to chime in on the thread with any ideas of your own! And if you have success/fail stories using it I would also love to know about it.```.
In general, at 2023-10-05 00:48:31 a user named frank.martinez said ```no, because my API key is in a file; need to move it into env variables [fast prototyping!]```.
In general, at 2023-10-05 00:45:24 a user named shinypickel said ```is the code open sourced ?```.
In general, at 2023-10-05 00:37:19 a user named frank.martinez said ```Just built a German language tutor, hosted on Replit, in less than 15 minutes. AutoGen is v efficient; doesn’t have the abstraction bloat seen in LC.```.
In general, at 2023-10-05 00:21:41 a user named rubberdauck said ```Why do I get this error if i just want to use auto reply```.
In general, at 2023-10-04 23:53:32 a user named aaronward_ said ```yeah 3.12 only came out like 2 days ago so its pretty new and may have some code breaking updates that haven't been fixed yet```.
In general, at 2023-10-04 23:50:21 a user named rubberdauck said ```Ok wow.. it's not working in 3.12 but works in 3.9```.
In general, at 2023-10-04 23:46:47 a user named ghostmaker001 said ```I keep hitting token limit. Any easy solutions? I provided my code here: <#1159259187751170068>```.
In general, at 2023-10-04 23:45:10 a user named aaronward_ said ```pip uninstall and install again, double check which python version you have```.
In general, at 2023-10-04 23:43:23 a user named bobaleaux said ```if you have developing skills in 2 weeks you'll have automated most of your company including the CEO! hahaha
this is some fun stuff!```.
In general, at 2023-10-04 23:41:11 a user named rubberdauck said ```I did. still not working```.
In general, at 2023-10-04 23:40:57 a user named aaronward_ said ```create a conda environment and make life easier for yourself```.
In general, at 2023-10-04 23:35:58 a user named rubberdauck said ```Can't seem to get autogen working. I did pip install autogen and pip install pyautogen. But still getting this error. Even tried it in a conda env but still not working```.
In general, at 2023-10-04 23:24:34 a user named afourney said ```Can you try printing config_list to console to see what's in there? Perhaps the filtering isn't working for some reason? (Don't share the output if it has keys etc. though!) I have this code in a project and it works as expected: 

    CONFIG_LIST = autogen.config_list_from_json(
        "OAI_CONFIG_LIST", filter_dict={"model": ["gpt-3.5-turbo-16k"]}
    )

    LLM_CONFIG = {
        "request_timeout": 600,
        "config_list": CONFIG_LIST,
        "temperature": 0,
    }```.
In general, at 2023-10-04 23:14:28 a user named afourney said ```Well.. it's 30 seconds and audible. That's something.```.
In general, at 2023-10-04 23:06:57 a user named otherinqz said ```HOLY SHIT I LOVE FETTUCINE ALFREDO```.
In general, at 2023-10-04 23:06:36 a user named pheek0 said ```Asked autogen to make a 30second EDM track. Thoughts?🔥```.
In general, at 2023-10-04 23:04:56 a user named otherinqz said ```can you check this to see if you see im doing something blatantly wrong```.
In general, at 2023-10-04 23:04:35 a user named avataraustin said ```gpt 4 really sucks up the cash 🙂```.
In general, at 2023-10-04 23:03:20 a user named otherinqz said ```i rlly can't do anything now as the payment form is broken anyways lmao```.
In general, at 2023-10-04 23:03:03 a user named avataraustin said ```im no expert but if my limited knowledge had to guess, I suppose I might try "gpt-4-32k-0613" as model instead , dunno though```.
In general, at 2023-10-04 23:01:43 a user named otherinqz said ```im out of creds and the the website is broken rn so i can't buy more```.
In general, at 2023-10-04 23:00:09 a user named avataraustin said ```hope you revoked your api key 🙂```.
In general, at 2023-10-04 22:59:16 a user named otherinqz said ```im using gpt 4 32k but it still says 8k limit```.
In general, at 2023-10-04 22:59:04 a user named otherinqz said ```does anyone know why this is producing this error
```py
from autogen import AssistantAgent, UserProxyAgent, config_list_from_json
import openai

openai.api_key="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"

# Load LLM inference endpoints from an env variable or a file
# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints
# and OAI_CONFIG_LIST_sample
config_list = config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": [
            "gpt-4-32k",
        ],
    },
)
assistant = AssistantAgent("assistant", llm_config={"config_list": config_list})
user_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding"}, human_input_mode="TERMINATE")
user_proxy.initiate_chat(assistant, message="Create a python program that will allow me to draw numbers and use a neural network to determine which digit is being shown. Some progress has already been made in ./coding/digit_recognizer.py")
# This initiates an automated chat between the two agents to solve the task
```
```openai.error.InvalidRequestError: This model's maximum context length is 8192 tokens. However, your messages resulted in 13638 tokens. Please reduce the length of the messages.``````.
In general, at 2023-10-04 22:43:55 a user named ghostmaker001 said ```**Max Token Limit Issue** What solution has been found there? <#1159259187751170068>```.
In general, at 2023-10-04 22:24:06 a user named xb3sox said ```This project is one of the simplest projects i tried so far, So impressed 🤩. 

Wondering if it can handle writing and reading files 🤔, any one tried this ?```.
In general, at 2023-10-04 22:23:54 a user named shubhamkhichi said ```is there a way to connect vector database like Weaviate with Autogen?```.
In general, at 2023-10-05 05:23:58 a user named sonichi said ```There is an example using chromadb: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb```.
In general, at 2023-10-04 22:23:23 a user named datastructures said ```very excited about this project```.
In general, at 2023-10-04 22:20:02 a user named tonic_1 said ```i'll DM it to you now, yea, welcome aboard 👊🏻```.
In general, at 2023-10-04 22:17:51 a user named ohcool_ said ```While using this library, I found it difficult to get the agents to take action, they were all happy to help build a plan, but often ended up just passing the plan back and forth before wishing the other agent luck on the project.

Anyone encountered this before? Any tips for a prompt that resolves this for the engineer agent?```.
In general, at 2023-10-04 22:15:54 a user named quebuen0 said ```Saw a bunch of videos about it on YouTube```.
In general, at 2023-10-04 21:48:39 a user named tonic_1 said ```You should join us building on my little server in that case 😅👊🏻```.
In general, at 2023-10-04 21:45:38 a user named hanley7082 said ```omg, just found this channel. I'm freaking out on this project. Talked our CEO into having me spend the next two weeks in an autogen deep dive 😄```.
In general, at 2023-10-04 21:33:30 a user named tonic_1 said ```that part is already made actually xD```.
In general, at 2023-10-04 21:33:15 a user named pierrunoyt said ```okay thx dont forget a web ui```.
In general, at 2023-10-04 21:32:09 a user named tonic_1 said ```we're making better autogpt with autogen right now, it wont be so long, just be patient or join us if you're a developper```.
In general, at 2023-10-04 21:31:26 a user named pierrunoyt said ```it should be like autogpt```.
In general, at 2023-10-04 21:30:40 a user named xam1311 said ```/answer https://microsoft.github.io/FLAML/docs/reference/autogen/agentchat/agent```.
In general, at 2023-10-04 21:30:03 a user named xam1311 said ```and define at the beginning```.
In general, at 2023-10-04 21:29:54 a user named xam1311 said ```you just call it by python command```.
In general, at 2023-10-04 21:29:37 a user named pierrunoyt said ```so how can i deploy agents```.
In general, at 2023-10-04 21:28:52 a user named xam1311 said ```nope just a pip command```.
In general, at 2023-10-04 21:28:29 a user named pierrunoyt said ```like it would be much easier```.
In general, at nan a user named .drak. said ```(nor is only supporting openai, not that I saw anybody argue that point here)```.
In general, at 2023-10-04 21:21:46 a user named .drak. said ```one model is not the answer, nor is one family of models```.
In general, at 2023-10-04 21:17:19 a user named qslug said ```Also, use `venv` or `conda` or `docker` to create a sandbox environment, rather than using your system default python for everything.```.
In general, at 2023-10-04 21:15:32 a user named qslug said ```Unless you are installing from source (which might be a good idea ah this stage). Then from the repo root you would run either `pip install -e .` or `python setup.py install` (if there exists a `setup.py`).```.
In general, at 2023-10-04 21:00:36 a user named kelbresqe said ```Hi folks! I've been digging into AI agents that can run locally for quite some time. The examples I've bumped into often lean on the OpenAI API, but given the exchange rate challenges in my country, that's a bit out of reach for me. So, having a local setup is key. My rig's got a 5900x CPU, 32 GB RAM, and a 4070TI GPU. Any recommendations on which model would be a good fit? Another thing I'm curious about: is it possible to have multiple models humming at the same time? Like, one geared towards coding for a code-related task, and another chat-focused model for communicating with me.```.
In general, at 2023-10-04 20:55:35 a user named grkthegreat said ```how do i install stuff with python?```.
In general, at 2023-10-04 20:53:55 a user named coolrazor said ```You'll probably only want to snag the main_example.py and grab the info for connected to the FastChat API```.
In general, at 2023-10-04 20:53:20 a user named coolrazor said ```in the development branch I have parts of the AutoGen client I'm working on.```.
In general, at 2023-10-04 20:47:29 a user named coolrazor said ```Sometime I'll make that read an .env var.```.
In general, at 2023-10-04 20:47:10 a user named coolrazor said ```You'll have to edit the path to the model for your use case in fastchat.sh```.
In general, at 2023-10-04 20:46:32 a user named coolrazor said ```Here's the my FastChat for Mistral 7B Instruct.  I haven't uploaded the Autogen part though.
https://github.com/coolrazor007/cloudai```.
In general, at 2023-10-04 20:41:18 a user named qslug said ```Maybe, but I have always found value in focusing on what is possible foremost,  deferring the "how", until a concrete problem shows up. There's too much "how" out there, and it's tricky to prioritize specific learning until you have a real need.```.
In general, at 2023-10-04 20:24:15 a user named twezoalgo said ```hey guys, was able to get auto gen setup today. made a tic tac toe game, anything else seemed to be too much for it was getting alot of errors when trying to build stuff more complicated like a webscraper```.
In general, at 2023-10-04 20:23:39 a user named coolrazor said ```All of my stuff is running in Docker btw.  Let me know if you want me to share```.
In general, at 2023-10-04 20:21:34 a user named coolrazor said ```I thought VLLM is a replacement for FastChat?```.
In general, at 2023-10-04 20:21:21 a user named mnsatrq said ```I guess I have 2 discords```.
In general, at 2023-10-04 20:20:56 a user named fxtoofaan said ```let me try that model in there```.
In general, at 2023-10-04 20:20:52 a user named fxtoofaan said ```i am using fastchat+vllm server```.
In general, at 2023-10-04 20:19:50 a user named fxtoofaan said ```ah, got it, you on nvidia ?```.
In general, at 2023-10-04 20:19:07 a user named fxtoofaan said ```Mistral 7B or Mistral 7B  Instruct ?```.
In general, at 2023-10-04 20:18:46 a user named coolrazor said ```I got Mistral 7B working with AutoGen using FastChat.  It is surprisingly fast actually.```.
In general, at 2023-10-04 20:17:27 a user named jidun67 said ```You can serve models from the share flag on the start command even with username and password auth. I use... bash start_linux.sh --share --gradio-auth username:password ... command to start it up.```.
In general, at 2023-10-04 20:15:10 a user named fxtoofaan said ```I think everyone that wants to run models locally need to huddle up. First let’s figure out which model we should all run, something that is multi use. For example for content and coding. And then pick local llm server and openai api server endpoint. Then we can work on autogen and create stuff locally.```.
In general, at 2023-10-04 20:12:53 a user named jidun67 said ```Right but, I think the mistral 7b could be useful in an autogen framework. Also it is very useful to think of the compressed data they hold i.e. internet outage locally available on an individual machine. I personally feel AI's strongest point is just how much information can be pulled from such a small amount of storage space.```.
In general, at 2023-10-04 20:09:44 a user named adriangalilea said ```So entretainment 🙂 fair enough, but they are use-less for anything else```.
In general, at 2023-10-04 20:09:03 a user named jidun67 said ```Well, this model interests me for the fact that it once and I can't make it do it again said basically "Hey Sh^tpouch, I can't have feelings they way you do..... etc, al" When I introduced myself to it the first time saying... Hello, friend how are you feeling today? lmfao 🙂```.
In general, at 2023-10-04 20:07:28 a user named fxtoofaan said ```Anyone know how to create a docker image with everything in it that’s needed to run openai api server and serve models ?```.
In general, at 2023-10-04 20:06:41 a user named fxtoofaan said ```I haven’t checked out the oobagooba lol or whatever it’s called yet on Ubuntu```.
In general, at 2023-10-04 20:04:46 a user named jidun67 said ```Well, I used git to install locally for the textgen webui 2 note you need the 2 version and I git pull regularly--- also a lot of fun using silly tavern and set up web gui with api command flag for that.```.
In general, at 2023-10-04 20:03:59 a user named fxtoofaan said ```I believe that’s where history of chat is saved with that seed. So same prompt it’ll just grab text from that seed db. Don’t quote me on it but that how I think it works```.
In general, at 2023-10-04 20:02:59 a user named adriangalilea said ```What is the most useful thing you got out of a model like that that is not pure entretainment, porn or spicy questions```.
In general, at 2023-10-04 20:02:49 a user named andyinater said ```Does anyone know what is contained in the .cache folder? The *.db that is tied to the seed. I'm not sure how/why it is there nor what it does.```.
In general, at 2023-10-04 20:02:47 a user named fxtoofaan said ```I can load awq ones no problem s```.
In general, at 2023-10-04 20:02:38 a user named fxtoofaan said ```How you loading the gguf models ? I cannot load them at all```.
In general, at 2023-10-04 20:01:55 a user named jidun67 said ```I usually get the models from The Bloke and have been having fun with uncensored-frank-13b.Q5_0.gguf as well.```.
In general, at 2023-10-04 20:00:03 a user named jidun67 said ```I been enjoying the kimiko-mistral-7b.Q8_0.gguf lately. I can run up to 13b parameter models pretty well on my 16 gb HP EliteBook 840 G5 laptop.```.
In general, at 2023-10-04 19:56:46 a user named fxtoofaan said ```Which model you loading ?```.
In general, at 2023-10-04 19:56:40 a user named adriangalilea said ```From my understanding and may be very easily be wrong:

Langchain agents are more focused in serving specific tasks to a user.
AutoGen agents are focused on inter-cooperation between agents and the user being part of the active conversation.```.
In general, at 2023-10-04 19:52:49 a user named jidun67 said ```I run all the local llms on linux that I want with "text-generation-webui-2" 🙂 And they run twice as fast on it than they do in LM Studio with windows on my dual boot laptop.```.
In general, at 2023-10-04 19:47:07 a user named jimmysandwiches said ```is this any help?

Here are the steps to add your local LLaMA model to llm_config:

Specify the model name as "Llama-2-13B-Chat-fp16"
Since this is a local model, you don't need an API key. Set "api_key" to an empty string or remove it.
Set "api_base" to the URL of your local server (http://127.0.0.1:7860/)
Add the model config to the "config_list":
python

Copy code

llm_config = {
  "request_timeout": 600,
  "seed": 44,
  "config_list": [
    {
      "model": "Llama-2-13B-Chat-fp16", 
      "api_key": "",
      "api_base": "http://127.0.0.1:7860/" 
    }
  ],
  "temperature": 0
}
The key things are:

Model name matches your local model
api_key is empty/removed
api_base points to your local server
This model config is added to the config_list
Let me know if this helps explain how to setup llm_config for your local LLaMA model!```.
In general, at 2023-10-04 19:42:39 a user named slagado. said ```Need some help / hints regarding "llm_config". 
I am running a local LLaMA2 server. 
Server is up and (well) running. 

To be specific: 
Model is "TheBloke_Llama-2-13B-Chat-fp16" / https://huggingface.co/TheBloke/Llama-2-13B-Chat-fp16
running at http://127.0.0.1:7860/

How to add this model into llm_config?
(Yes, I know. The "config_list" part should be a separat file due possible api_key content ... but I would like to keep it simple - here)

llm_config={
    "request_timeout": 600,
    "seed": 44,  # change the seed for different trials
    "config_list": [{
        "model": "Llama-2-13B-Chat-fp16", # "gpt-3.5-turbo-16k-0613", # "gpt-3.5-turbo",
        "api_key": "local server no api key needed",
        "api_base": " http://127.0.0.1:7860/"
    }],
    "temperature": 0,
}```.
In general, at 2023-10-04 19:40:39 a user named andyinater said ```<#1158564427117903882>  might be something that touches on that```.
In general, at 2023-10-04 19:31:55 a user named coroleu said ```Hi, been trying to search in the discord if this was already answered but ... no luck: 
- which are the differences (strengths vs constraints) of using AutoGen vs LangChain Agents? Particularly interested in a use-case where a given set of tools/functions are the only external datasources to use.

Happy to get redirected if this was already answered```.
In general, at 2023-10-04 19:28:35 a user named beratfromearth said ```Hey, I found out about AutoGen while I was searching through Microsoft's Github page. I'm glad I did because so far it looks very promising yet user friendly.```.
In general, at 2023-10-04 19:19:37 a user named mviejo017 said ```And another agent that takes the references used by the research agent and writes them out in APA 7th edition format```.
In general, at 2023-10-04 19:18:03 a user named mviejo017 said ```Hi i am an autogen noob. I want to create a group of agents for research. I want one agent that does the research, and another that fact checks everything that the research agent comes up with so i make sure there are no hallucinations. How can i go about doing this?```.
In general, at 2023-10-04 19:14:27 a user named adriangalilea said ```https://github.com/microsoft/autogen/issues/108 @bigmiao```.
In general, at 2023-10-04 19:13:28 a user named largonaut said ```I’ve let the passion drive the education.  When I encounter things I don’t know how to do, I add em to the list.  You’d be surprised how much you can learn in generative AI courses without knowing coding.  Plus I get the benefit of knowing *why* code does a thing when I do a thing, instead of it just being text strings.  The more practical hooks I have to attach abstract education to, the better.```.
In general, at 2023-10-04 19:11:25 a user named thunderbird365 said ```Jason AI has been amazing with Agent frameworks for LLM```.
In general, at 2023-10-04 19:10:23 a user named adriangalilea said ```Let me open an issue```.
In general, at 2023-10-04 19:09:55 a user named adriangalilea said ```https://github.com/JayZeeDesign/microsoft-autogen-experiments/blob/main/content_agent.py
I got the loops running this```.
In general, at 2023-10-04 19:09:40 a user named thunderbird365 said ```I tried LLAMA 2 7B 5.5 gig model on GPU 2060 TI

I mean I can make a coffee before that thing generates an output 😂```.
In general, at 2023-10-04 19:09:40 a user named shiccup said ```So people will be able to run local llms on Linux with that```.
In general, at 2023-10-04 19:09:14 a user named shiccup said ```Apparently a linux build of lm studio will be coming out soon as well```.
In general, at 2023-10-04 19:08:37 a user named slagado. said ```but the best apporach seems to be to create your own local server (running for example LLaMA2, etc.)```.
In general, at 2023-10-04 19:07:58 a user named shiccup said ```So some companies are working on computers that use human brain neurons i wonder if in the future using that it would be easier to get a computer in your head```.
In general, at 2023-10-04 19:04:54 a user named slagado. said ```Seems to be a strange approach. You have to learn to walk first before you can run - or even win the olympics. ... just a suggestion.```.
In general, at 2023-10-04 19:02:50 a user named thunderbird365 said ```My free subscription to OPEN AI api expired after 10 or so prompts to agents ( with 10 retries user proxy ) 😂

This thing churns through API . 

 any suggestions ? 💀```.
In general, at 2023-10-04 18:58:52 a user named largonaut said ```Heyyo, first message.  Matt Berman's video brought me here.  I've been learning Python in order to set up a home PAL, and AutoGen sounds like a great fit.  I did build my knowledge pyramid upside down, learning the more advanced concepts before I even knew python, so my understanding and jargon regarding programming is... mediocre at best.```.
In general, at 2023-10-04 18:22:54 a user named james_coho said ```Has anyone developed a full application with Autogen? I am specifically interested in its software development capabilities if people have resources or examples on its output```.
In general, at 2023-10-04 17:51:03 a user named elcapitan__ said ```anyone with expreinece in this want to help me with a project i have some money not alot but i could deff use some help here```.
In general, at 2023-10-04 17:46:52 a user named _zippman said ```I saw the video on YouTube```.
In general, at 2023-10-04 17:40:53 a user named afourney said ```Can you provide more details about your setup, what agents you have, how they are currently configured, and what you've tried so far?  This notebook has a reasonably short example for setting up a group chat workflow: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb```.
In general, at 2023-10-04 17:39:09 a user named tonic_1 said ```very cool my friend, if you're building with autogen, you should join my little builder's discord (link in bio) , will be fun to have you over there i'm sure```.
In general, at 2023-10-04 17:37:58 a user named qslug said ```Ok, I think I found it. Looks like you can just add `"max_tokens": 2048` to `llm_config` (next to `seed` and `temperature`). https://github.com/microsoft/autogen/blob/dc70b804ad6bcb74be5d02a806a53c990dc8fee8/autogen/oai/completion.py#L347```.
In general, at 2023-10-04 17:19:33 a user named ghostmaker001 said ```I think the token limit per minute could be resolved by function call. But I'm not fully sure```.
In general, at 2023-10-04 17:06:38 a user named tonic_1 said ```(that url doesnt work, just an example)```.
In general, at 2023-10-04 17:06:22 a user named tonic_1 said ```actually yes, but also , it's just the parameters there as an example, you do need to set them somehow```.
In general, at 2023-10-04 17:05:49 a user named qslug said ```Oh, you are using HF hosting instead of local FastChat hosting?```.
In general, at 2023-10-04 17:03:36 a user named tonic_1 said ```parameters are specified in this url : https://ui.endpoints.huggingface.co/huggingface/new?repository=mistralai/Mistral-7B-Instruct-v0.1&vendor=aws&region=us-east-1&accelerator=gpu&instance_size=medium&task=text-generation&no_suggested_compute=true&tgi=true&tgi_max_batch_total_tokens=undefined&tgi_max_input_length=2048&tgi_max_total_tokens=4096&tgi_quantize=```.
In general, at 2023-10-04 17:01:34 a user named qslug said ```I have had some minimal luck with Mistral-7B-Instruct so far. You will need to override most of the `system_message`s, since Mistral is not as clever as GPT.  @tonic_1 Any pointers to specifying `max_tokens` at deploy time? Seems as though FastChat just infers this, I don't see any tunable params.```.
In general, at 2023-10-04 16:54:11 a user named ath3nA said ```Hey everyone, does anyone know how to switch on the Verbose mode for these models? To check their thought process```.
In general, at 2023-10-04 16:29:59 a user named tonic_1 said ```https://defog.ai/blog/sqlcoder2-technical-details/ this might help (open source coding models)```.
In general, at 2023-10-04 16:17:59 a user named andyinater said ```Anyone can drive a Ferrari around a track quickly, but it doesn't say anything about nor does it hone your skill of driving - meaning you get into a miata later to only find out you're not actually that quick.

Sorry for weird car analogy, but I'm a car person. Among other things```.
In general, at 2023-10-04 16:16:40 a user named andyinater said ```For what it's worth, gpt3.5-turbo is quite cheap, and if you don't do group chats all of the time and focus on understanding how the agents work one at a time/manually controlled group convos, you can get a lot done.

I've done everything so far with under $3 of api calls, and over half of that is just one or two tests with gpt4. Really, don't use 4 until you master 3.5```.
In general, at 2023-10-04 16:08:54 a user named slagado. said ```I started yesterday with AutoGen. Tryed it immediately because of its possibilities and results! 
But figured out ver y fast that it´s expensive. 
Found no solution until I was (re-)pointed to the fact that you can use any LLM. 
So I think about a local installation of LLaMA2. (https://www.youtube.com/watch?v=k2FHUP0krqg)
Finger crossing I will find some time to do so.```.
In general, at 2023-10-04 16:07:18 a user named ninjaturtled said ```Hi all. New here and tried AutoGen yesterday. This is some next gen tech.```.
In general, at 2023-10-04 16:00:48 a user named bigmiao said ```Are you using groupchat and gpt 3? Can you create an issue in autogen repo and maybe share your using case so I can try reproduce it?```.
In general, at 2023-10-04 15:46:55 a user named adriangalilea said ```I had a problem sometimes the chatroom enters a loop as the agent spams blank messages and burns me $$$, anyone else with the same problem? Any idea?```.
In general, at 2023-10-04 15:46:01 a user named adriangalilea said ```I'm loving Autogen, I've been looking for it for a while, I just didn't know existed but was seeing the problem of managing what I call a Squad(team of agents)```.
In general, at 2023-10-04 15:28:53 a user named tonic_1 said ```one year ago they would have been laughed at , now they can actually do it (if they stick with it)```.
In general, at 2023-10-04 15:28:18 a user named tonic_1 said ```everyone is building, i guess until more developpers put their eyes on it, so it will take more than a few hours/days after a pretty soft (second) launch i think```.
In general, at 2023-10-04 15:25:24 a user named andyinater said ```Me too - I love seeing so many curious people, regardless of experience level.

It exemplifies how much of a democratizing force AI is going to be - so many people asking how to do things that maybe 1 year ago they never would have considered.```.
In general, at 2023-10-04 15:14:41 a user named sonichi said ```Thanks for the insight. Love the vibrance in this community. ❤️```.
In general, at 2023-10-04 14:57:18 a user named andyinater said ```Barrier to entry perhaps - more curious non-coders than coders.

And even many hobby coders won't have githubs.


Also, I think some video might have pointed to this server, judging by some of the new comments```.
In general, at 2023-10-04 14:54:28 a user named elcapitan__ said ```can someone help me getting my agents to start the discussions together```.
In general, at 2023-10-04 14:54:11 a user named sonichi said ```Does anyone have a clue why the GitHub stars do not grow as fast as discord members? 🤔```.
In general, at 2023-10-04 14:02:51 a user named tonic_1 said ```You have to specify max token lengths at deploy time```.
In general, at 2023-10-04 14:02:27 a user named tonic_1 said ```Can I come over to your house to hang out lol```.
In general, at 2023-10-04 13:36:36 a user named sonichi said ```need to talk to some1 who has used```.
In general, at 2023-10-04 13:31:19 a user named sonichi said ```is there any example with the following```.
In general, at 2023-10-04 12:42:51 a user named derekbarrera said ```How do you deal with different prompt requirements on different models?```.
In general, at 2023-10-04 12:38:19 a user named derekbarrera said ```Has anyone had any luck with mistral or any non OAI models? I keep getting content issues on the executor message object in the request body being a blank string when serving the models on a local API.```.
In general, at 2023-10-04 12:07:16 a user named lb0273 said ```need to talk to some1 who has used MathUserProxyAgent```.
In general, at 2023-10-04 15:59:26 a user named kevinwyr said ```@lb0273 Are you using groupchat for this? MathUserProxyAgent is not tested with groupchat. 
Can you describe what are you trying to do and what agents are you using with groupchat? Maybe we can sort a way out```.
In general, at 2023-10-05 10:19:21 a user named lb0273 said ```yes, using group chat for it
what was the imagined purpose of MathUserProxyAgent?

I want it to solve a math equation etc. if any pops up in the chat```.
In general, at 2023-10-05 23:42:03 a user named sonichi said ```A general `AssistantAgent` is very capable to do that. Please give it a try.```.
In general, at 2023-10-05 23:43:58 a user named sonichi said ```Our technical report shows the evidence: https://twitter.com/Chi_Wang_/status/1709932523990729129```.
In general, at 2023-10-06 11:24:26 a user named lb0273 said ```what's the use of MathUserProxyAgent? id love to have a more reliable way of solving math problems (using python / wolfram (MathUserProxyAgent should be able to do so?))```.
In general, at 2023-10-06 13:33:37 a user named sonichi said ```AssistantAgent + UserProxyAgent uses python.
AssistantAgent + MathUserProxyAgent can use python or wolfram.
Please test which works better in your math problems. The latter is not necessarily better depending on the problems. @kevinwyr please correct if I'm wrong.```.
In general, at 2023-10-06 14:07:35 a user named kevinwyr said ```Yes, I agree. A generic usage is to construct a conversation between two agents: AssisantAgent and MathUserProxyAgent```.
In general, at 2023-10-04 12:04:03 a user named andyinater said ```And to those new, try to comb through those - there are lots of good discussions, and maybe yours could be next.```.
In general, at 2023-10-04 12:03:14 a user named andyinater said ```We must utilize the discussion and help threads for what they are for now. 

If you want a discussion that stays focused, and can span days, that will be the only way.

It was inevitable - this stuff is very interesting.```.
In general, at 2023-10-04 11:43:50 a user named utkarshn03 said ```Hey can someone share docs```.
In general, at 2023-10-04 11:40:55 a user named lb0273 said ```hi all, this is a python programming question more than about autogen, but

def generate_init_message(problem,
                          prompt_type="default",
                          customized_prompt=None)

agentchat.contrib.math_user_proxy_agent


How do i change the prompt_type argument for this func```.
In general, at 2023-10-04 11:20:37 a user named corgi108 said ```well that video is 2 years old. a quick look into vllm would had provided you with this information: GPU: compute capability 7.0 or higher (e.g., V100, T4, RTX20xx, A100, L4, etc.)```.
In general, at 2023-10-04 10:57:26 a user named slagado. said ```yeah getting busy .. so busy that related questions "fade-out" / aren´t anylonger answered 😕```.
In general, at 2023-10-04 10:45:53 a user named itsameeemaario said ```hey guys, just checking this server out i read the article about this project and it seems really cool! 😎😊```.
In general, at 2023-10-04 10:30:05 a user named morfes said ```it's a good card for what I needed to do, but I will have to put it on my server in the garage cuz it's build to be in server not PC. 
this YT video telling more about what can be used for.
https://youtu.be/zh4SnZET93Q```.
In general, at 2023-10-04 10:24:27 a user named litinit said ```a little bit of google I find "K80 requires older drivers (nvidia 4xx, not 5xx); it only has compute capability 3.5" I don't know exactly what that means though```.
In general, at 2023-10-04 10:19:41 a user named morfes said ```this is a good offer I THINK, I have to do more research about hardware requirements for running LLM locally```.
In general, at 2023-10-04 10:17:12 a user named fearless_sniper said ```gpu is no more profitable```.
In general, at 2023-10-04 10:16:53 a user named fearless_sniper said ```i am planning to give anydesk access so that someone can test there stuff and in return i will get a working offline agent```.
In general, at 2023-10-04 10:16:14 a user named morfes said ```I think it's more efficient to use Nvidia Tesla K80 to mine coins```.
In general, at 2023-10-04 10:15:29 a user named fearless_sniper said ```so have 3060s and 3080 10gb```.
In general, at 2023-10-04 10:15:05 a user named fearless_sniper said ```i was a crypto miner```.
In general, at 2023-10-04 10:14:01 a user named morfes said ```but that tesla card is good for AI accelerator```.
In general, at 2023-10-04 10:13:19 a user named morfes said ```that's good for gaming as well```.
In general, at 2023-10-04 10:12:20 a user named fearless_sniper said ```i have 5 3060 12gb```.
In general, at 2023-10-04 10:11:52 a user named morfes said ```just thinking about to get one card and try it out with 11B LLM first.```.
In general, at 2023-10-04 10:09:28 a user named andyinater said ```Looks like the channel is getting busy! <#1156574905773596712> has a mix of examples and discussion. <#1157397569375309864> has lots of troubleshooting.```.
In general, at 2023-10-04 10:03:13 a user named litinit said ```maybe for reference, I think the biggest llama2 (70b) model starts at 36-38gb vram for "4-bit quantization" (I dont have any experience in what the quantization actually impacts..)```.
In general, at 2023-10-04 10:02:00 a user named morfes said ```more info about this card https://youtu.be/Z5Isf6Airo0```.
In general, at 2023-10-04 09:49:12 a user named morfes said ```hey guys, can this card do good job working with LLM on i7 /25G RAMs?```.
In general, at 2023-10-04 09:41:36 a user named mvs4414 said ```Hi .I am new to this server . Can anyone tell me about this server ?```.
In general, at 2023-10-04 09:32:56 a user named slagado. said ```@ghostmaker001 
Did you find the reason why you are running out of tokens? 
How many tokens are included in the "GPT-4 for US-$ 20 per month" subscription included?

Read some posts here in discord that also others facing the "issue" that AutoGen needs a lot of tokens ...

Seems AutoGen is very expensive! 
May be I could not effort it. 😕 
Again a (very streamed) technology (trend) for rich people 😦```.
In general, at 2023-10-04 09:31:14 a user named litinit said ```well, like, autogen is a python library```.
In general, at 2023-10-04 09:22:36 a user named kikkerd said ```Less noise in the context just makes the attention mechanism in transformers perform better, is that what could make these group chats superior?```.
In general, at 2023-10-04 09:18:48 a user named neoliminal said ```Are the roles/goals set in the 'system_message' for each agent, I assume? 😳```.
In general, at 2023-10-04 09:15:14 a user named neoliminal said ```How do I control which agents can speak to each other and how do I define their individual roles/goals?```.
In general, at 2023-10-04 09:15:06 a user named shade.name said ```I know it beacuse of 👆```.
In general, at 2023-10-04 09:13:56 a user named neoliminal said ```I saw the video on YouTube```.
In general, at 2023-10-04 09:03:28 a user named cosmickrover said ```Then maybe see what I can do with app development```.
In general, at 2023-10-04 09:02:28 a user named cosmickrover said ```I would like to understand the capabilities first.```.
In general, at 2023-10-04 08:29:20 a user named lb0273 said ```is there any example with the following: https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/math_user_proxy_agent/https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/math_user_proxy_agent/```.
In general, at 2023-10-04 13:31:20 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_MathChat.ipynb
For questions about this notebook please ask @kevinwyr```.
In general, at 2023-10-04 08:20:08 a user named thedasenqueen said ```So does Autogen only use python? or can it make applications in other languages?```.
In general, at 2023-10-04 08:15:37 a user named kikkerd said ```Hi. I had the chess example spend about $2 in less than a minute. After that it got rate limited using gpt4. Anything obvious that I could be doing wrong?

I did notice that it wasn't showing the SVG chess board.```.
In general, at 2023-10-04 07:50:06 a user named KLANe4H said ```I got to know it from Searching the web```.
In general, at 2023-10-04 07:10:49 a user named fxtoofaan said ```How to load TheBloke/Mistral-7B-OpenOrca-GGUF/ files in fastchat/vllm? 
Like if I want to run the mistral-7b-openorca.Q8_0.gguf model in fastchat/vllm how do I reference it?

I have tried these but no luck:
python3 -m vllm.entrypoints.openai.api_server --model ./mistral-7b-openorca.Q8_0.gguf 

python3 -m vllm.entrypoints.openai.api_server --model TheBloke/Mistral-7B-OpenOrca-GGUF

python3 -m vllm.entrypoints.openai.api_server --model /home/aitoofaan/LLMs/models/Mistral-7B-OpenOrca-GGUF/

like how do you serve GGUF models using fastchat/vllm ?```.
In general, at 2023-10-04 05:27:46 a user named shiccup said ```now imagine auto gen but its like a council telling a robot how to move```.
In general, at 2023-10-04 05:27:16 a user named shiccup said ```google just released a vision language action model```.
In general, at 2023-10-04 05:26:56 a user named shiccup said ```https://www.youtube.com/watch?v=GZdytTKeGYM```.
In general, at 2023-10-04 03:35:42 a user named li_jiang said ```Hi @jasonzhou1993 , here it is https://mp.weixin.qq.com/s/OFbZyC0_M3uBJlOhQIKJLg.  This account is actually just for me to easily share things to my friends.```.
In general, at 2023-10-04 02:26:53 a user named elcapitan__ said ```Please please tell me what u end up doing. I created all my agents in just trying to get them to communicate with eachother now. I thought autogen offered this frameworks```.
In general, at 2023-10-04 02:26:08 a user named .trouble_ said ```I'm doing something similar to this now```.
In general, at 2023-10-04 02:14:46 a user named andyinater said ```You're right, I completely forgot. I had at least one example saved in a folder, forgot it on the push.

Tomorrow I will regenerate some and toss them in an examples folder.```.
In general, at 2023-10-04 02:05:34 a user named juanfrank77 said ```That's incredible for sure. It'd be cool to have those games as examples of what can be done with the framework so others folks can join.```.
In general, at 2023-10-04 01:57:35 a user named shaneyu said ```https://github.com/microsoft/autogen/issues/96```.
In general, at 2023-10-04 01:52:58 a user named elcapitan__ said ```or am i going the wrong route```.
In general, at 2023-10-04 01:49:20 a user named elcapitan__ said ```someone @ me if you have an answer lol```.
In general, at 2023-10-04 01:47:50 a user named elcapitan__ said ```AutoGen primarily focuses on automating the generation of reinforcement learning models and does not inherently provide a framework for agent communication (right? or am i wrong?). I feel like establishing a multi-agent system with conversational abilities requires a more sophisticated setup with integration with a library like SPADE.```.
In general, at 2023-10-04 01:46:20 a user named elcapitan__ said ```does anyone know if integrating SPADE with AutoGen to allow for the agents created with AutoGen to communicate via SPADE's protocols.```.
In general, at 2023-10-04 00:57:18 a user named andyinater said ```Hey everyone,

I just pushed a large overhaul to <#1158564427117903882> . It works much better now - I have managed to zero shot snake, breakout, connect 4, tic tac toe, and some weird rendition of asteroids that was more of a leapfrog game. 

Most of the performance improvement comes from prompt overhauls, both clarity as well as logic. Even if you don't try the repo out, I think the diffs on the system prompts are a good example of bad vs good.

Documentation updates will lag, but it is now easier to run.```.
In general, at 2023-10-04 00:55:40 a user named li_jiang said ```Right, I’ll find some time to work on it in a few days. Would you like to create an issue in github so we can track it? @shaneyu```.
In general, at 2023-10-04 00:54:26 a user named zespind said ```for community-driven hosting that's a huge hurdle```.
In general, at 2023-10-04 00:53:51 a user named zespind said ```tbh the drivers for amd are so messy and most llm libraries use like 4 machine learning stacks```.
In general, at 2023-10-04 00:31:46 a user named enragedporcupine said ```anyway apols for all the msgs -- super excited about autogen. & glad to see it gaining steam despite being fairly under the radar. (MS is doing so much amazing stuff right now re: O365 / copilot / etc. -- much of which I'm on beta/preview channel for.)```.
In general, at 2023-10-04 00:30:33 a user named enragedporcupine said ```I think I need a legit, human tutor. someone who I can explain what I know, what I don't know, and them to tell me "you need to learn these concepts..." then come back, etc etc```.
In general, at 2023-10-04 00:29:50 a user named enragedporcupine said ```checked petals out a while back -- maybe should revisit.```.
In general, at 2023-10-04 00:28:00 a user named enragedporcupine said ```my line of work has little to do with this space (although I'm encouraging everyone to get onboard) -- this is my nights/weekends *hardcore* investment, continuing education-wise, since Nov last year.```.
In general, at 2023-10-04 00:26:41 a user named enragedporcupine said ```but I did web-dev in the 90's, BBS's, IRC, old-school stuff, and a bit of coding *way* back (seems totally obsolete now).. know *basic* python (still horrendous.)  just familiarized myself with docker, venvs, etc...```.
In general, at 2023-10-04 00:25:33 a user named enragedporcupine said ```like... my sys environment path variables are a nightmare, I'm 99% sure I have at least 5-6x conflicting versions of python/MS distributables... I recently bought a home server that's "clean" for remote desktop/docker purposes only... don't know the first thing about remote access (outside of MS remote via MS auth)... have GCP/AWS/Azure/Replit/Codespaces running full blast... I'm like a kid in a candy shop with a little too much money (*NOT* long-term -- viewing this all as an investment) -- who doesn't know what to buy or how to consume 😉```.
In general, at 2023-10-04 00:24:04 a user named .beibinli said ```Hi everyone, I created a tutorial on how to support open source model in the PR here, please take a look at my notebook: https://github.com/microsoft/autogen/blob/osllm/notebook/open_source_language_model_example.ipynb

Any suggestions are welcome. <#1158548894209282078>```.
In general, at 2023-10-04 00:24:04 a user named shinypickel said ```what are the other uses cases? 

I was trying to build something to help research businesses/companies to acquire.```.
In general, at 2023-10-04 00:23:54 a user named lcbusby said ```Saw a videoo on youtube```.
In general, at 2023-10-04 00:23:40 a user named enragedporcupine said ```(i know software but am a horrendous coder / am a total amateur.)```.
In general, at 2023-10-04 00:23:23 a user named enragedporcupine said ```been following this space since.. GPT2-ish days```.
In general, at 2023-10-04 00:23:08 a user named enragedporcupine said ```but I've got dozens of use cases. maybe 50+```.
In general, at 2023-10-04 00:22:43 a user named enragedporcupine said ```starting point... I'd love to have a decent research agent. and one that re-analyzes, re-categorizes, re-sorts, removes redundant information, etc. with a budget (a la autogpt) - or even just a set # of commands I could pre-fill & see what the costs racked up to, etc...
have the bing search API, serpAI & all.```.
In general, at 2023-10-04 00:16:21 a user named shinypickel said ```whats ur expectation with autogen? / usecase```.
In general, at 2023-10-04 00:14:17 a user named coolrazor said ```Has anyone gotten those doc retrieval agents to work in the groupchat?  I added them but I can’t tell if they are working right or at all (meaning just searching the web or something)```.
In general, at 2023-10-04 00:13:18 a user named enragedporcupine said ```can't wait to start using this to the fullest. truly incredible. got the stock charting one up & running and threw it a basic challenge (undefined tickers w/ little guidance) and it absolutely nailed it.

autogpt & similar repos have yielded... uhh.. let's just say the ROI has been a *lot* of effort to *few/no* meaningful results.```.
In general, at 2023-10-04 00:11:07 a user named enragedporcupine said ```is colab the way to go? (I've got the pro sub.) or local/docker/etc.? curious what folks are using for their deployments. (iv'e got Azure/AWS/GCP/etc. but am by no means a server admin pro.. racked up a hefty bill messing around in that zone 😉 )```.
In general, at 2023-10-04 00:10:59 a user named ichnigo said ```hi all i came rn to this server I wanted to start contributing to this repo and I found an easy issue that I could solve. can anyone tell me how to move forward? I did cmnt there to know if i could start to contri but I didnt get any response```.
In general, at 2023-10-04 00:09:19 a user named coolrazor said ```I’m not ready to push my stuff up yet.  Hopefully soon.  But for clarity I’m not using AutoGPT (I was and it never worked as well as I wanted it to).  I’m using Mistral with AutoGen.  I want to build custom Agents but not quite there```.
In general, at 2023-10-04 00:06:13 a user named tonic_1 said ```Are you in the repo where where we’re rebuilding autogpt with autogen ?```.
In general, at 2023-10-04 00:05:10 a user named coolrazor said ```I find it cost effective lol.  I racked up $30 on OpenAI in one day messing around.  That’s a lot more than AutoGPT ever did but AutoGen works way better.```.
In general, at 2023-10-03 23:51:58 a user named rain696 said ```this is really cool! I just setup everything and is work like a charm!```.
In general, at 2023-10-03 23:38:29 a user named gb4de said ```this is absolutely the best content on autogen

https://www.youtube.com/watch?v=Bq-0ClZttc8&ab_channel=AIJason```.
In general, at 2023-10-03 23:23:16 a user named jbowen_disc said ```Hi Folks, Just getting started and was thinking I could run autogen on a docker in Unraid. Has anyone set this up / any advice?```.
In general, at 2023-10-03 22:57:10 a user named btcmansatariq said ```https://tenor.com/view/gru-minions-despicable-me-dance-twerk-gif-26630206```.
In general, at 2023-10-03 22:56:56 a user named btcmansatariq said ```IM SO CREATING A MINIONS UI```.
In general, at 2023-10-03 22:34:39 a user named slagado. said ```@ghostmaker001 No. You can also generate api keys for gpt-3.5!  but now I am more surprized. because I though using the payed GPT-4 version includes some tokens which can be used for AutoGen usage```.
In general, at 2023-10-03 22:33:31 a user named stampystamperson said ```Hey, excited to be here… Are we early yet?```.
In general, at 2023-10-03 22:31:44 a user named ghostmaker001 said ```I use the paid version. Thats how you can access API Keys```.
In general, at 2023-10-03 22:30:54 a user named slagado. said ```@ghostmaker001 Same on my side using gpt-3.5-turbo. What plan / billing type do you have? I am thinking about to buy GPT-4 on a monthly base for 20 bugs per month.```.
In general, at 2023-10-03 22:25:26 a user named slagado. said ```@AaronWard: Thanks for your answer! There was just the "-turbo" part missing. Everything else worked fine - except that I run out of my quota. lol .... Think I have to buy GPT- for $ 20 / mo. 😦```.
In general, at 2023-10-03 22:24:04 a user named ghostmaker001 said ```I am curious as to why i keep hitting token limit. Any solutions? 
gpt4_config = {
    "seed": 42,  
    "temperature": 0,
    "request_timeout": 120,
    "max_retry_period":240,
    "retry_wait_time": 90,```.
In general, at 2023-10-03 22:20:42 a user named sonichi said ```I am new to Autogen I saw some videos```.
In general, at 2023-10-03 22:05:41 a user named jy3d said ```is there a way to get real time code output from the user proxy instead of just output after step is completed?```.
In general, at 2023-10-03 21:53:38 a user named aaronward_ said ```Alternatively, if you would like to just use a `.env` file you can see [this notebook](https://github.com/AaronWard/generative-ai-workbook/blob/main/projects/autogen/concept_examples/0.quickstart.ipynb) for pointers:```.
In general, at 2023-10-03 21:52:53 a user named aaronward_ said ```You have to create a file called  `OAI_CONFIG` and put that JSON structure in it, then use this function ```config_list = autogen.config_list_from_json(
    env_or_file="OAI_CONFIG_LIST",
    filter_dict={
        "model": {
            "gpt-3.5-turbo",
        },
    },
)``` then you can pass your `config_list` to your agents.```.
In general, at 2023-10-03 21:47:36 a user named rain696 said ```hi! How do I use it ?```.
In general, at 2023-10-03 21:46:34 a user named slagado. said ```I am new to Autogen. I saw some videos reagrding AutoGen and tried it out. but stuck with the config because I have only a GPT-3.5 API-Key. And it seems that  this does not work:
SO how to fix it? is it possible to use GPT-3.5 or is GPT-4 requested?

import autogen

llm_config={
    "request_timeout": 600,
    "seed": 44,  # change the seed for different trials
    "config_list": [{
        "model": "gpt-3.5",
        "api_key": "<added my gpt-3.5 key here>"
    }],
    "temperature": 0,
}```.
In general, at 2023-10-03 22:20:43 a user named sonichi said ```Please change gpt-3.5 into gpt-3.5-turbo```.
In general, at 2023-10-03 22:36:21 a user named slagado. said ```run out of tokens:
"openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details."```.
In general, at 2023-10-03 22:37:32 a user named slagado. said ```list of gpt model names can be found here:
https://platform.openai.com/account/rate-limits```.
In general, at 2023-10-03 22:40:20 a user named slagado. said ```And: in the other thread Ghostmaker001  wrote that he uses the payed GPT-4 model and has the same issue / runs also out of tokens. 
So I am not sure whether I should make a GPT-4 contract for US-$ 20 per month.
Amy ideas whats going on?```.
In general, at 2023-10-03 22:41:13 a user named slagado. said ```Sorry its late (early) her in Germany. See you soon! And thanks in advance!```.
In general, at 2023-10-04 08:09:53 a user named slagado. said ```What must be done to overcome this error:
"openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details."

Would it be solved in case I make a "chat GPT Plus" subscription?
Or is another (additional ?) subscription (from "openai.com") needed?```.
In general, at 2023-10-04 13:25:44 a user named sonichi said ```You can ask in the <#1157397569375309864>  forum```.
In general, at 2023-10-03 21:20:18 a user named aaronward_ said ```I'm experienced with MLOps, but haven't a clue when it comes to LLMOps, i know it's still loosely defined but does anyone have any good resources or tools they'd recommend me to look at? Would MLFlow be a good path forward?```.
In general, at 2023-10-03 20:54:44 a user named tonic_1 said ```nice yea mistral , not much handling for the instructions , or do you find it actually advantageous (instruct model)```.
In general, at 2023-10-03 20:51:20 a user named .trouble_ said ```I'm excited for this project and also intimidated. it's a similar concept to what I'm building```.
In general, at 2023-10-03 20:50:53 a user named jy3d said ```i believe you can set each agent at diff model when defined```.
In general, at 2023-10-03 20:32:49 a user named alphatrader6423 said ```Hi, If I use one of the example `notebooks`, how does the agent knows, which model to use if I provide a list? `"model": ["gpt-4-32k", "gpt-4-32k-0314", "gpt-4-32k-v0314"],````.
In general, at 2023-10-03 20:12:04 a user named 0xjamp said ```Seems he's being a Critic in that video about it tho... haha jeez```.
In general, at 2023-10-03 20:09:40 a user named 0xjamp said ```Not sure if it's been posted here yet but this guy I've been watching since about 5k subscribers he's very solid posted about autogen https://youtu.be/JFotv9PVW_4?si=v8R9_iZzlhYjp4Jr```.
In general, at 2023-10-03 20:01:49 a user named scdnap said ```Thanks great Looking forward to it```.
In general, at 2023-10-03 19:25:49 a user named noscopedev said ```Is there a subgroup for roadmap?```.
In general, at 2023-10-03 19:24:36 a user named noscopedev said ```Hi everyone, thank you very much for accepting me into the group. Very excited about the evolution of autogen!```.
In general, at 2023-10-03 19:07:09 a user named kareem6370 said ```I was thinking about extending user proxy agent to do that, but I just heard about AutoGen last night and I'm still discover it, so I wasn't confident enough to discuss that idea lol, Thanks a lot for all good info you are sharing```.
In general, at 2023-10-03 19:02:27 a user named aayushc1308 said ```Better way than function calling if you want to do after every message (and not token) would be extending the class and overriding the function in that case. Significantly faster and cheaper.```.
In general, at 2023-10-03 19:01:45 a user named 0xjamp said ```I was typing my response out for an idea but scrolled up and saw you are already doing that. Having an agent  take messages from multiple agents and feed out one completed message```.
In general, at 2023-10-03 18:59:35 a user named aayushc1308 said ```Function calls are a message level construct. One message from openai denotes one function call.
Callbacks are one level down the hierarchy. Callbacks are run for each token within a single message when it is being generated using oai_reply function. 
I don't think this will be a valid substitute.
However, you can use this if you want to not wait for the whole auto reply flow to finish and send every message as it finishes.```.
In general, at 2023-10-03 18:57:00 a user named kareem6370 said ```I have an Idea, what if we create that call-back technique using the function call feature and create an agent for just streaming the result using that function_call, is that an applicable solution with the current autogen architecture?```.
In general, at 2023-10-03 18:55:37 a user named aayushc1308 said ```Oh, thanks for sharing. I thought you meant you had video for combining messages from multiple agents and good approaches to do that. The end user should be given only one response.```.
In general, at 2023-10-03 18:54:21 a user named 0xjamp said ```This is it I believe! Of course it was James briggs
https://youtu.be/y2cRcOPHL_U?si=pz0tNxxUs8rt-J2m```.
In general, at 2023-10-03 18:52:39 a user named aayushc1308 said ```@0xjamp  Do share the video if you find it. Looking for more ideas in this space.```.
In general, at 2023-10-03 18:51:56 a user named 0xjamp said ```I watched a video on this but forgot where it is! need to rewatch this```.
In general, at 2023-10-03 18:51:39 a user named aayushc1308 said ```Not exactly. I think it will be more helpful for programmatic scenarios where you can make programmatic choices from each token.
Here are good examples from langchain community: https://integrations.langchain.com/callbacks

Major Uses: Streaming + Observability (Logging, Monitoring, etc)```.
In general, at 2023-10-03 18:49:10 a user named 0xjamp said ```So basically you can preview the output from agents and adjust?```.
In general, at 2023-10-03 18:45:36 a user named aayushc1308 said ```As the responses from openai are coming, they are simultaneously streamed to UI so the user doesn't have to wait for the entire thing. This is more helpful for two agent senarios. 
I think a more appropriate way that this might help Autogen will be simply introducing callbacks (similar to langchain callbacks). The callbacks will help users to extend individual agents. Callbacks are run for each streamed response from OpenAI and users can decide what they want in those callbacks.```.
In general, at 2023-10-03 18:42:43 a user named aayushc1308 said ```Sure thing. Thanks. 
There are still some open questions in terms of how to combine the final messages from the agents and respond back. I think this will be a function of the application. We are using a separate agent at the end that takes all the messages from multiple agents and creates a single coherent response for the user. That's a minor subtlety that I think you will need to figure out.```.
In general, at 2023-10-03 18:42:10 a user named fxtoofaan said ```How you use streaming ? Or what benefits it will provide autogen ?```.
In general, at 2023-10-03 18:39:13 a user named kareem6370 said ```Thank you so much, yes that's exactly I asked for, that how can I stream the result of autogen to my ui application, and how can I scale if I have many concurrent users, Thank you so much I really appreciate it.
And congratulation and happy launching:)```.
In general, at 2023-10-03 18:37:29 a user named aayushc1308 said ```@sonichi 
On this note, are there any plans to add Streaming support to AutoGen? This will help a lot for production usage. OpenAI and langchain both support streaming and we can hopefully add this soon to AutoGen as well. Is there a roadmap for AutoGen?```.
In general, at 2023-10-03 22:19:37 a user named sonichi said ```I sensed this is a must-have feature at some time. I'm not aware of anyone working on it. I'm asking around. I'll get back to you later.```.
In general, at 2023-10-03 22:22:49 a user named sonichi said ```@jy3d Please check this thread later.```.
In general, at 2023-10-03 23:06:05 a user named jy3d said ```This def be nice, quicker to help debug vs scrolling through after```.
In general, at 2023-10-04 03:01:30 a user named sonichi said ```I confirmed that no one is working on this. Please feel free to propose a solution and @pcdeadeasy and I can provide input.```.
In general, at 2023-10-31 16:11:24 a user named sonichi said ```PR is made: https://github.com/microsoft/autogen/pull/491
Your feedback is appreciated.```.
In general, at 2023-10-03 18:36:25 a user named aayushc1308 said ```Roughly speaking:
- Create a websocket connection to connect to chat.
- Take the user message. Using a user proxy agent, initiate the chat with whatever AutoGen topology makes more sense to your application.
- Wait for the response.
- Use the messages from the AssistantAgent and response back with some function of the messages. You can invoke the chat_messages property on conversable agents to get access to the messages.```.
In general, at 2023-10-03 18:33:01 a user named aayushc1308 said ```Hey @kareem6370 
Thanks for the kind words. We will be launching Kniru in the US and Canada on Oct 15 and go full scale on production. Autogen will be one part of the tools we will use. We were building something like this internally but thanks for the team here we can now build this much faster together. Our team at Kniru will make sure to keep helping in every way to push improvements to Autogen.
Can you explain what you mean by using Autogen via API? We are using the package from pypi install inside a docker container as part of our service and wrapping it using Websockets. Is that what you mean in terms of API on how to serve the response from Autogen as part of an API call? If so, happy to share further.```.
In general, at 2023-10-03 18:32:56 a user named muharremokutan said ```I am good too! Anyone wants to VC?```.
In general, at 2023-10-03 18:19:37 a user named muharremokutan said ```Hey everyone how is it going```.
In general, at 2023-10-03 18:02:41 a user named bansalg said ```Yes use different llm_config for each assistant agent```.
In general, at 2023-10-03 18:01:43 a user named lb0273 said ```hey
is it possible to run agents on different models each?```.
In general, at 2023-10-03 18:00:08 a user named 0xjamp said ```Or any models api you specify. But to run locally I'm still figuring out through fast chat```.
In general, at 2023-10-03 17:59:10 a user named 0xjamp said ```Oof misread this... I meant the code I have right now is using oai config list to call the gpt4 api```.
In general, at 2023-10-03 17:58:51 a user named shaneyu said ```Thanks great! Looking forward to it```.
In general, at 2023-10-03 20:01:49 a user named scdnap said ```My first attempt was to call a function that spawned a separate chat for RAG, then returned the last assistant message, it works but i'm sure there's a better way to do it```.
In general, at 2023-10-03 20:57:34 a user named shaneyu said ```Brilliant I see what you are doing here. I never thought it could work that way.```.
In general, at 2023-10-03 21:00:17 a user named shaneyu said ```I think this is a pretty good work around in our current settings. I was trying to use it as using a general UserProxyAgent, but it does not answer the call from other agents and terminate the entire group chat session immediately.```.
In general, at 2023-10-03 21:02:27 a user named shaneyu said ```I think the desired way to use it is sill within the one group chat context, instead of prompting a new conversation, but I dont know why Autogen doesn't provide such use case. It seems a pretty important and practical use case.```.
In general, at 2023-10-03 21:03:20 a user named shaneyu said ```Thank you again for your update!```.
In general, at 2023-10-04 13:59:56 a user named scdnap said ```agree, ideally we should be able to add the ragproxyagent as a member of the group chat```.
In general, at 2023-10-03 17:58:42 a user named fxtoofaan said ```I just saw mistral openorca awq model```.
In general, at 2023-10-03 17:58:04 a user named 0xjamp said ```I can send you the code I was using to get it working that way```.
In general, at 2023-10-03 17:57:31 a user named scdnap said ```Just started looking into it, will let you know```.
In general, at 2023-10-03 17:57:19 a user named 0xjamp said ```Trying to set this up now.... struggling with the setup lol switching from the gpt4 api it was running on to running it on mistral locally  and eventually set it up to run multiple models locally, so I can configure which model I want each agent using based on their jobs```.
In general, at 2023-10-03 17:53:51 a user named shaneyu said ```I'm trying to but it's not working so far. Do you have any idea?```.
In general, at 2023-10-03 17:48:49 a user named kareem6370 said ```Hi @aayushc1308 , congrats on your startup , i checked it out and it looks really cool.
I'm on my to build my first AI app using AutoGen, and I was wondering if there any example out there to use AutoGen via Api or get it ready for production.
if you know any reasorces regard this topic or any advice that would be much appreciate it, Thanks in advance:)```.
In general, at 2023-10-03 17:44:21 a user named mviejo017 said ```He has great AI videos```.
In general, at 2023-10-03 17:44:14 a user named mviejo017 said ```The video that Wes Roth posted```.
In general, at 2023-10-03 17:43:53 a user named scdnap said ```Has anyone incorporated a RetrieveUserProxyAgent into a group chat with a planner?```.
In general, at 2023-10-03 17:38:58 a user named mviejo017 said ```I learned about autogen from a youtube video```.
In general, at 2023-10-03 17:38:45 a user named mviejo017 said ```Hi guys i am new here```.
In general, at 2023-10-03 17:29:19 a user named allandclive said ```No ideas/features yet, but I will definitely get one```.
In general, at 2023-10-03 17:26:33 a user named allandclive said ```FLAML introduced me to AutoGen, I am deeply passionate about AutoML research```.
In general, at 2023-10-03 17:05:08 a user named kikkert2 said ```Hi there. Could AutoGen mean that in the near future a company's product will mainly be an agent fine-tuned on their proprietary information/skills that you then get to use in your agent chats for a fee?

How to distill knowledge into an agent, there has got to be a better way then a simple vector database search of chopped up fragments or showing a few hundred sample question and answers...```.
In general, at 2023-10-03 16:48:31 a user named sonichi said ```@li_jiang this may be because the agent is set to terminate as soon as the code execution succeeds. I had concerns about that earlier.```.
In general, at 2023-10-03 16:23:31 a user named shaneyu said ```@li_jiang Also worth mentioning, if I ask Admin agent a question that involves RAGProxyAgent in a group chat (e.g. Provide me with some data in an explicit or inexplicit manner) the group chat will terminate without reporting any error```.
In general, at 2023-10-03 16:18:17 a user named shaneyu said ```Regarding the RAGProxyAgent in a groupchat context, I couldn't make it work up to this point, I tried to guide it in system_message of RAGProxyAgent, system_message of all other participating agents, and a combination of both. However, none of the setup works.```.
In general, at 2023-10-03 16:10:49 a user named au8 said ```no worries, sorry I had to shoot for a few minutes```.
In general, at 2023-10-03 16:06:32 a user named s666. said ```thanks @au8  for the help```.
In general, at 2023-10-03 16:06:21 a user named s666. said ```right that sems to have solved it - i was being dumb```.
In general, at 2023-10-03 16:03:48 a user named s666. said ```oh maybe I need to change my `human_input_mode` to always...```.
In general, at 2023-10-03 16:01:39 a user named xam1311 said ```config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST.json",file_location=".",filter_dict={
        "model": {
            "gpt-3.5-turbo",
            "gpt-4"
        }
    })
assistant = AssistantAgent("assistant", llm_config={"config_list": config_list})
user_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding"})
user_proxy.initiate_chat(assistant, message="Plot a chart of NVDA and TESLA stock price change YTD.")```.
In general, at 2023-10-03 16:00:48 a user named fxtoofaan said ```can you paste the python code edit you did here so I can copy paste it in my code please```.
In general, at 2023-10-03 16:00:10 a user named s666. said ```@au8 for example I am supposed to be asked to reply TERMINATE or CONTINUE but i never ge tthe option```.
In general, at 2023-10-03 16:00:05 a user named fxtoofaan said ```thank you let me check```.
In general, at 2023-10-03 15:59:57 a user named xam1311 said ```[
        {
            "model": "gpt-4",
            "api_key": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
            "api_base": "https://xxxxxxxxxxxxxxx.openai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-07-01-preview"
        }, 
        {
            "model": "gpt-3.5-turbo",
            "api_key": "xxxxxx",
            "api_base": "https://xxxxxxxxxxxxopenai.azure.com/",
            "api_type": "azure",
            "api_version": "2023-07-01-preview"
        }
]```.
In general, at 2023-10-03 15:58:34 a user named s666. said ```occassionally at the very end I get asked for comments```.
In general, at 2023-10-03 15:58:29 a user named au8 said ```It won’t let you type?```.
In general, at 2023-10-03 15:58:09 a user named s666. said ```ah its more that I seem unable to give user input.```.
In general, at 2023-10-03 15:57:56 a user named au8 said ```You have human inputs required as part of the group chat?```.
In general, at 2023-10-03 15:57:25 a user named au8 said ```Ok so I would say it’s fine, I have the same thing because I run on laptop I can wait 10 minutes before a reply for example```.
In general, at 2023-10-03 15:55:53 a user named s666. said ```I am running them locally using my OpenAI API key```.
In general, at 2023-10-03 15:55:25 a user named au8 said ```Are you running models locally or using chatgpt```.
In general, at 2023-10-03 15:54:55 a user named s666. said ```should i be running it in a Docker container or somesuch?```.
In general, at 2023-10-03 15:54:17 a user named s666. said ```Hi all - apologies if this is not the correct place to ask this question - but I am running pyautogen in VS Code on Windows 11 and I am getting the message:

`WARNING:root:SIGALRM is not supported on Windows. No timeout will be enforced.`

I know that SIGALARM is not available on Windows but am unsure how to substitite it with a Windows equivilant - currently I am unable to respond to any of the agent with user input. 

Anyone kind enough to help?```.
In general, at 2023-10-03 15:53:15 a user named knaackee. said ```Yes, i mean. They would make less if the users are not forced to send past messages.```.
In general, at 2023-10-03 15:52:40 a user named au8 said ```Last I heard, OpenAI was actually losing a lot of money```.
In general, at 2023-10-03 15:51:51 a user named knaackee. said ```OpenAI's API needs this `past_message_id`thing. But, I guess, they're making a lot of money because they don't have it (yet?).```.
In general, at 2023-10-03 15:50:22 a user named au8 said ```Improvements are on the roadmap I believe```.
In general, at 2023-10-03 15:49:52 a user named au8 said ```Context window can quickly become an issue```.
In general, at 2023-10-03 15:49:00 a user named knaackee. said ```Hey everyone, I'm curious about how Autogen works. I'm aware that the API doesn't support chat or context, but does Autogen always send all the previous messages in a conversation?```.
In general, at 2023-10-03 15:47:40 a user named au8 said ```You have vllm native or with Docker? I know you were installing Linux a few days ago```.
In general, at 2023-10-03 15:46:19 a user named fxtoofaan said ```the vllm can generate almost 40 tokens/sec on llama-2 7b awq model```.
In general, at 2023-10-03 15:45:42 a user named au8 said ```I do exactly that but with fastchat. It has been on my todo list to get something working through vllm as it will perform much better.```.
In general, at 2023-10-03 15:44:56 a user named fxtoofaan said ```that be awesome. i hope mistral 7b instruct will run on my pc and allow multople virtual agents connecting to same llm 😉```.
In general, at 2023-10-03 15:43:34 a user named au8 said ```I will run some tests later if I have time and can maybe help you get it working```.
In general, at 2023-10-03 15:43:03 a user named fxtoofaan said ```on a different note, i am not able to run any gpt connections, cant get past error regarding OAI_CONFIG_LIST file```.
In general, at 2023-10-03 15:42:20 a user named fxtoofaan said ```i can paste the errors```.
In general, at 2023-10-03 15:42:15 a user named fxtoofaan said ```should I move the topic to issues-and-help section ?```.
In general, at 2023-10-03 15:41:32 a user named au8 said ```You’ve passed the quantization parameter to the api entry point server```.
In general, at 2023-10-03 15:38:49 a user named elcapitan__ said ```yea i know its going to explode eventually and theres gonna be a bunch of fiverr gigs for it but lets be real 90% of them arent going to know what the hell they are doing and just taking advantage of a trend lol.```.
In general, at 2023-10-03 15:38:48 a user named fxtoofaan said ```you running mistral instrict locally on vllm server ?```.
In general, at 2023-10-03 15:37:35 a user named fxtoofaan said ```I only have 12GB VRAM, thats why```.
In general, at 2023-10-03 15:37:11 a user named au8 said ```Why awq and not official?```.
In general, at 2023-10-03 15:35:51 a user named fxtoofaan said ```cant load the mistral 7b awq model from TheBloke on the vllm server from mistral docker image```.
In general, at 2023-10-03 15:35:19 a user named au8 said ```What issue are you having?```.
In general, at 2023-10-03 15:32:33 a user named sledgehumma said ```Ey all, heard of AutoGen through YT, cloned the Repo this morning and well, setting up my team. Loving this era of tech! Keep well you wonderful learners and builders. So grateful to be in this server, to continue my journey of growth with you all.```.
In general, at 2023-10-03 15:32:26 a user named au8 said ```Every day that passes there’s like an extra 100 people in here 😄 not only last week there were about 150 people online in here```.
In general, at 2023-10-03 15:17:40 a user named elcapitan__ said ```if anyone was looking to collab and help me out i would greatly appreciate it i have a few bucks i can spare for now nothing crazy tho im knee deep in debt building my platform lol.```.
In general, at 2023-10-03 15:07:22 a user named coolrazor said ```It will work with GPT-3.5, I've done it.```.
In general, at 2023-10-03 15:03:52 a user named elcapitan__ said ```I’m thinking of just tackling it by myself with the help of gpt now that it has internet access back. But damn it’s hard lol```.
In general, at 2023-10-03 15:02:43 a user named elcapitan__ said ```Like my dream hahaha but I don’t know the first thing about Python Development and anyone u find on fiverr has no clue what autogen is or knows how to develop multi-agent conversation frameworks.```.
In general, at 2023-10-03 15:01:17 a user named elcapitan__ said ```Yea same it’s literally what I have been thinking for awhile to add to my community  platform I am developing```.
In general, at 2023-10-03 14:52:27 a user named coolrazor said ```Checking out AutoGen, found out about it from YouTube videos.  I just got it working with Mirstal AI locally!  All using Docker too.```.
In general, at 2023-10-03 14:49:17 a user named digicat3194 said ```does anyone know if autogen can support GPT 3.5 or does it need to use GPT 4?```.
In general, at 2023-10-03 14:47:19 a user named fxtoofaan said ```let me know when you jumping on the local llm bandwagon. I am having trouble serving Mistral 7B model using vLLM openai API server```.
In general, at 2023-10-03 14:42:01 a user named xam1311 said ```What do you think to use COT and inference prompting in default user ask/directive ?```.
In general, at 2023-10-03 14:40:57 a user named 0xjamp said ```So basically for example my analytics agent can request to the dev to build them a tool to use like a web scraper for data so it can analyze it in real time```.
In general, at 2023-10-03 14:40:55 a user named telepathyx said ```personally i get better practical results for stuff i'm doing using regular chatgpt4 interface with this as a system prompt: https://github.com/ProfSynapse/Synapse_CoR and the "/ts" town square thing conjures up 3 agents on demand to debate```.
In general, at 2023-10-03 14:39:28 a user named 0xjamp said ```I tried to introduce tool building into my dev agent along with my strategist and other agents suggesting the design or implementation of tools the other agents need to the dev to complete their objectives```.
In general, at 2023-10-03 14:38:36 a user named xam1311 said ```i was thinking the same thing 🙂```.
In general, at 2023-10-03 14:38:16 a user named 0xjamp said ```I assumed it was hahaha I'm going to try Llama2 today on the framework I made based off autogens multi agent 6 agent 1 manager setup see how it responds```.
In general, at 2023-10-03 14:37:22 a user named telepathyx said ```it was mostly a simulation```.
In general, at 2023-10-03 14:37:15 a user named telepathyx said ```yeah for sure, 3.5 turbo```.
In general, at 2023-10-03 14:37:05 a user named 0xjamp said ```Seems amazing but responses seem generic form agents```.
In general, at 2023-10-03 14:35:27 a user named 0xjamp said ```Either way autogens various frameworks are great with how it's setup. Tons of ideas going through my head of what to build with it.```.
In general, at 2023-10-03 14:35:12 a user named telepathyx said ```this guy had this going back in june using discord as a UI. autogen still isn't as powerful```.
In general, at 2023-10-03 14:35:09 a user named jasonzhou1993 said ```It’s possible, will check out! (I actually just realised chatdev also introduced that a few days ago)```.
In general, at 2023-10-03 14:34:19 a user named 0xjamp said ```Hmmm I swear a couple of months ago someone made a iteration to autogpt and added human feedback into the loop but I could be misremembering since I cant even remember the specific video/tweet I was watching that mentioned that```.
In general, at 2023-10-03 14:33:18 a user named jasonzhou1993 said ```Maybe autogpt introduced something new, but from my memory I can’t define specific human feedback input points during SOP like autogen has; also autogpt is not a multi agent framework```.
In general, at 2023-10-03 14:30:04 a user named 0xjamp said ```In what ways does it differ from other frameworks you have tried? Wasn't the human feedback in loop introduced in autogpt too?```.
In general, at 2023-10-03 14:29:29 a user named telepathyx said ```i'm unsubscribing if you post anything with a 🙀  face```.
In general, at 2023-10-03 14:29:15 a user named jasonzhou1993 said ```Totally, I honestly surprised not more people talking about autogen, it’s the best multi agent framework I ve tried so far```.
In general, at 2023-10-03 14:29:10 a user named 0xjamp said ```I 100% block those channels lol.. don't need an AI channel just following hypes and trends for clicks and views```.
In general, at 2023-10-03 14:28:18 a user named jasonzhou1993 said ```Let me know your channel actually after you post! Will follow```.
In general, at 2023-10-03 14:28:15 a user named 0xjamp said ```Autogen deserves more stars on github pshhh```.
In general, at 2023-10-03 14:27:58 a user named telepathyx said ```nice! i respect that you haven't lowered yourself to using clickbait expressions in your thumbnails like some people (cough cough)```.
In general, at 2023-10-03 14:27:56 a user named jasonzhou1993 said ```Sure thing, feel free to do so! I was actually thinking about bilibili, but just never get a chance to do so hah```.
In general, at 2023-10-03 14:27:51 a user named 0xjamp said ```Ah man here comes all of the autogen tutorials hahaha```.
In general, at 2023-10-03 14:24:28 a user named fxtoofaan said ```https://youtu.be/vU2S6dVf79M```.
In general, at 2023-10-03 14:18:20 a user named li_jiang said ```I'd like to share your video to my friends but youtube won't work for them. Do you have channels in wechat or bilibili? If not, do you mind if I download your video and upload it to my personal channel in wechat? Thanks.```.
In general, at 2023-10-03 14:05:10 a user named jasonzhou1993 said ```hah yea revoked all the api keys! learnt it hard way before 😂```.
In general, at 2023-10-03 14:04:22 a user named li_jiang said ```Very nice video @jasonzhou1993 . Just a reminder, I hope you've revoked the API keys you used in your video.```.
In general, at 2023-10-03 13:59:22 a user named li_jiang said ```Hi @brucejan , are you the author of this video? If yes, have you posted it in wechat video or bilibili?```.
In general, at 2023-10-03 13:59:20 a user named jasonzhou1993 said ```Hey team, Just made a tutorial video about autogen 🙂
went through a few use cases, hope this helps and feel free to share around!

https://youtu.be/Bq-0ClZttc8?si=mB6zDQOd5BbO-heA```.
In general, at 2023-10-03 13:59:17 a user named fxtoofaan said ```Sounds like a solid plan```.
In general, at 2023-10-03 13:56:34 a user named 0xjamp said ```Future of AI is definitely multi agent groupchat...and other multi agent frameworks. literally experts of each field you assign them can chat with each other and improve ideas based upon each agents respective input based on their assigned expertise. I remember seeing this with autogpt months ago but actually using it is powerful. Going to use a multi agent setup and reconstruct the framework again today and implement an personal trainer, dating coach/counsler, life coach/counsler, career coach/counsler, and whatever else fits in that grouping where they can all communicate with each other for a answer to any questions about these topics I give it. Maybe even use some data about to pull from for more personalized outputs```.
In general, at 2023-10-03 11:20:49 a user named beamengineer said ```i saw autogen from Github Trending```.
In general, at 2023-10-03 10:01:20 a user named takeshi__kovacs said ```Thanks for the response. I tried streamlit, gradio for the start but I'm not getting any response on the front. Maybe I am missing something, can you please provide some examples with Autogen?```.
In general, at 2023-10-03 09:42:10 a user named brucejan said ```https://www.youtube.com/watch?v=buuPOpHNOX0&t=7s```.
In general, at 2023-10-03 09:17:56 a user named semi2995 said ```im back, who was knocking in voice channel? ;d```.
In general, at 2023-10-03 05:39:51 a user named shadowraker said ```Echohive did a video on autogen and provided code files. Good place to start. Love his stuff. Here's his announcement:

AutoGen Introduction in 5 files step by step including how to enable Docker

We will take a look at the AutoGen library by Microsoft in this video on how we can use it to easily create agent interactions with OpenAI's GPT-4. We will also learn about how to set llm config, save conversation history to a file and set up Docker for safe execution of code blocks.

Code files are available to download for free at Patreon:
https://www.patreon.com/posts/90228560

Auto AGI original video: https://youtu.be/jTC-6kBOfn8
Auto AGI original source code: https://www.patreon.com/posts/87530987

Search 180+ echohive videos and code download links:
https://www.echohive.live/

WSL windows install: https://learn.microsoft.com/en-us/windows/wsl/install
Docker deskptop: https://www.docker.com/products/docker-desktop/

https://youtu.be/WnBCPG-ZdLk```.
In general, at 2023-10-03 05:18:01 a user named bigmiao said ```For a more advanced chatbot (like [semantic copilot chat](https://devblogs.microsoft.com/semantic-kernel/announcing-copilot-chat/)) You probably would want to separate frontend and backend. IMO even it might introduce some complexity, the extra effort is worthwhile to spend on using a different tech stack (instead of python) to build frontend. For the backend, you can use fastapi, which is well-design and documented, and easy to get start```.
In general, at 2023-10-03 05:12:42 a user named bigmiao said ```gradio chatbot might be a good place to start for python-first solution. It has built-in support for markdown/img/video as well, and also quite easy to deploy to your own server or share on huggingface.

https://www.gradio.app/guides/creating-a-custom-chatbot-with-blocks```.
In general, at 2023-10-03 05:07:26 a user named shinypickel said ```You would need to stream the response to the frontend right?```.
In general, at 2023-10-03 04:59:20 a user named takeshi__kovacs said ```How to build a UI for Autogen? Can someone guide please I'm new here?```.
In general, at 2023-10-03 03:40:06 a user named skorakora said ```You know what I am missing here?```.
In general, at 2023-10-03 03:09:13 a user named shaneyu said ```Thanks, will definitely check it out!```.
In general, at 2023-10-03 02:48:47 a user named sonichi said ```Right. They are the same. This problem should be solved at the `ConversableAgent` level which will solve it for all the agents.```.
In general, at 2023-10-03 02:38:01 a user named shaneyu said ```https://github.com/microsoft/autogen/issues/9 Is this the one you are refering to? I thought it mainly tackles assistant agent's behavior instead of group chat's```.
In general, at 2023-10-03 02:30:45 a user named sonichi said ```Right. That's a problem that needs to be solved. There is an issue and a thread discussing it.```.
In general, at 2023-10-03 02:25:22 a user named shaneyu said ```Thanks for your reply! So everytime groupchat manager is called, it will send entire chat history to the llm to determine the next speaker? How does autogen handle the token limitation issue if the conversation grows bigger?```.
In general, at 2023-10-03 02:16:50 a user named sonichi said ```For 1. The selection is based on system_message of each agent and the conversation history```.
In general, at 2023-10-03 02:01:09 a user named shaneyu said ```That being said, I also have some questions about this setup, 1. From groupchat.py, I found that it selects the next speaker solely based on the name (correct me if I'm wrong)? So the name has to be self-explanatory? 2. Is the RetrieveAssistantAgent needed in above setup? I think it only checks for the code execution result for termination condition. 3. If I were to let user step in for an assistant's feedback, should I do it in the Admin agent(human_input_mode: ALWAYS & prompt guided(you should ask for user's feed back when hearing from agent A)) or Assistant agent( human_input_mode: ALWAYS)? Which one is the prefered one?```.
In general, at 2023-10-03 01:57:16 a user named berkeley said ```for real - i have to dig through all my expenses tonight for my extended filing and came straight here lol```.
In general, at 2023-10-03 01:55:17 a user named shinypickel said ```I need this asap lol```.
In general, at 2023-10-03 01:54:35 a user named shaneyu said ```I haven't found any issues here or other sources. I made a setup that it enters the group conversation with RAG proxy agent, it retrieves the material at first and can never be called again. I'll continue the research tmr. I'm thinking about a set up that contains a UserProxyAgent as admin, serveral AssistantAgent as different assistant, and a RAGProxyAgent as db entry point.```.
In general, at 2023-10-03 01:40:50 a user named li_jiang said ```Should be doable. @shaneyu , have you made it or do you find any issues on this https://discord.com/channels/1153072414184452236/1153072414184452241/1158521831783936000 ?```.
In general, at 2023-10-03 01:37:30 a user named berkeley said ```anyone put together a tax accountant team yet? 🤕```.
In general, at 2023-10-03 00:57:52 a user named .beibinli said ```Quick question: how can I use GPT-4v from ChatGPT? I have ChatGPT+, but cannot find an image upload button.```.
In general, at 2023-10-03 00:43:19 a user named kajatta said ```Anyone got Retrieval with Sources working?```.
In general, at 2023-10-03 00:42:41 a user named andyinater said ```Heres my latest thing <#1158564427117903882> . I have talked to some of you looking for this kind of setup - hope it helps!

https://github.com/Andyinater/AutoGen_IterativeCoding```.
In general, at 2023-10-03 00:41:57 a user named andyinater said ```Wowee, it always takes a little longer than you expect, doesn't it?```.
In general, at 2023-10-03 00:34:22 a user named tonic_1 said ```Jamp's Really Cool Marketting Autogen Bot```.
In general, at 2023-10-02 23:53:06 a user named sonichi said ```This post has a number of them: https://discordapp.com/channels/1153072414184452236/1157419832443150447/1157419832443150447```.
In general, at 2023-10-02 23:40:30 a user named .beibinli said ```Hi everyone! I would like to discuss <#1158548894209282078>  with everyone. Let me know if you have suggestions, needs, ideas for open-source models!```.
In general, at 2023-10-02 23:38:32 a user named adamg2334 said ```Social media posted and checking it out```.
In general, at 2023-10-02 23:38:21 a user named ghostmaker001 said ```Does anyone have a great beginners video guide to get started?```.
In general, at 2023-10-02 23:10:33 a user named fxtoofaan said ```ok so you gave chatgpt the script for the group chat example and told it to make a new script? got it```.
In general, at 2023-10-02 23:09:37 a user named 0xjamp said ```I provided the code for the autogen multiagent groupchat framework (6 group member 1 manager) then told it this: "Using the same format as above and maintaining the same agent hierarchical structure, create me new agents by changing name="" and system_message="".
Create me a structure that can be used to manage and automate AI driven social media bots. Follow the platforms rules and maintain ethical standards and practices. Must optimize and create a strategies that can be used to gain the most amount of followers for the end goal of monetizing the account. Make sure the structure includes an engineer that can help execute ideas of other agents and help create new tools."```.
In general, at 2023-10-02 23:07:46 a user named fxtoofaan said ```Unable to load conversation 72c971d0-8b72-43a4-b649-600f38428db3```.
In general, at 2023-10-02 23:06:51 a user named 0xjamp said ```https://chat.openai.com/c/72c971d0-8b72-43a4-b649-600f38428db3```.
In general, at 2023-10-02 23:03:54 a user named purplxd said ```Is it possible to connect a web scraper combined with a vector database in order to enable the agents to "browse" large webpages bigger than their context length? How would I go about doing this?```.
In general, at 2023-10-02 22:53:59 a user named fxtoofaan said ```very nice, I am trying to test it now. What message did you use in the script? I am using this...

message="""
create variations of the autogen framework https://github.com/microsoft/autogen.
"""```.
In general, at 2023-10-02 22:52:24 a user named 0xjamp said ```yeah input it into Pycharm and it seems like it works! I had gpt 4 analyze to help it understand the structure of the original framework then had it create me a new one based on my idea. It took a few fixes and suggested it for improvements but It created something thats blowing my mind honestly... its designed for managing and automating a social media campaign. Also asked chatgpt to give me a summary of how it works here 🙂```.
In general, at 2023-10-02 21:57:04 a user named tonic_1 said ```we are making it 10/10```.
In general, at 2023-10-02 21:52:08 a user named shaneyu said ```Hi guys, Do we have an example of retrieval agent used in group chat context? 🧐  I am thinking of using RAG proxy agent as a DB port where other agents can access if needed. I'm trying to get this setup to work now, at the mean time, Im really interested to see others idea on it. 💡```.
In general, at 2023-10-02 21:38:46 a user named sheldor3316 said ```Hey guys, any update on this?
Still getting errores when the chat_manager receives:
"Suggested function Call: list_directory "```.
In general, at 2023-10-02 21:11:14 a user named aaronward_ said ```Still only 4.2K stars on github, people really are sleeping on `autogen````.
In general, at 2023-10-02 19:42:49 a user named .sathan said ```did anybody connect nucliadb as their vector database?```.
In general, at 2023-10-02 19:06:50 a user named fxtoofaan said ```Do you have python script showing what you ran?```.
In general, at 2023-10-02 18:20:37 a user named 0xjamp said ```Guys! It's very fun using gpt 4 to create variations of the autogen framework "Automated Complex Task Solving by Group Chat (with 6 group member agents and 1 manager agent)" 
give it a try!!! It will  create some amazing ideas for agents with this structure!```.
In general, at 2023-10-02 17:55:05 a user named cryptofox1971 said ```I'm on a journey to develop an AI application, despite having no prior coding experience. My self-learning journey led me to discover AutoGen, a tool I believe can be instrumental in bringing my vision to life. The concept of my software has already piqued the interest of potential customers, and I have a ready market just waiting to get their hands on it. Now, all that’s left is to delve into the development phase, and I’ll be on my way to not only providing a solution but also earning from it.```.
In general, at 2023-10-02 17:34:31 a user named 0xjamp said ```Well a framework is like a recipe. It's a conceptual structure. And autogen is a certain framework made for ai agents```.
In general, at 2023-10-02 17:32:31 a user named cipherself said ```I've briefly looked at MetaGPT  https://github.com/geekan/MetaGPT and it has complementary roles like Product Manager, Engineer, ...etc, could be used for inspiration.```.
In general, at 2023-10-02 17:31:22 a user named 0xjamp said ```Nice I was looking for this```.
In general, at 2023-10-02 17:31:02 a user named salegrem said ```"Collaborative AI" sounds short and nice.```.
In general, at 2023-10-02 17:30:14 a user named salegrem said ```This is a good step in the right direction```.
In general, at 2023-10-02 17:29:54 a user named salegrem said ```Specially because the word frameworks translates poorly to spanish lol```.
In general, at 2023-10-02 17:29:11 a user named salegrem said ```Maybe I'm being unreasonable but I think this needs a catchier name```.
In general, at 2023-10-02 17:27:07 a user named salegrem said ```However, it fails to give a name to the tech beyond "Frameworks for AI Agents"```.
In general, at 2023-10-02 17:26:34 a user named salegrem said ```This is great, thank you!```.
In general, at 2023-10-02 17:25:00 a user named 0xjamp said ```Found this github should help you get a understanding of things. Helped me https://github.com/e2b-dev/awesome-sdks-for-ai-agents#--try-out-e2bs-ai-playgrounds-for-agents-copilots-and-ai-apps

It's under the category of "Frameworks for building agents"```.
In general, at 2023-10-03 00:34:23 a user named tonic_1 said ```i would love to see the thing you made for real, seems really simple + powerful```.
In general, at 2023-10-03 00:49:56 a user named 0xjamp said ```here I posted the code in a txt file give it a try!```.
In general, at 2023-10-03 00:50:17 a user named tonic_1 said ```thank you, this is gonna be fun for me a lot```.
In general, at 2023-10-03 00:50:54 a user named 0xjamp said ```I just burnt through $30 messing around with iterations of it hahaha have fun```.
In general, at 2023-10-03 00:51:06 a user named 0xjamp said ```I think thats the best so far```.
In general, at 2023-10-03 00:51:09 a user named tonic_1 said ```yep !!! sounds familiar !```.
In general, at 2023-10-03 00:51:37 a user named tonic_1 said ```can i show it as an example in the huggingface collection ?```.
In general, at 2023-10-03 00:52:14 a user named 0xjamp said ```Also I asked Chatgpt to give an overview of how it work here you go```.
In general, at 2023-10-03 01:14:32 a user named tonic_1 said ```I for sure saved a copy of that image … it’s really so interesting !```.
In general, at 2023-10-03 01:14:53 a user named tonic_1 said ```Normally I don’t read generated texts but lately I find it very rewarding for things like this```.
In general, at 2023-10-03 01:24:49 a user named tonic_1 said ```Hey @0xjamp I DMed you as well 👊🏻```.
In general, at 2023-10-02 17:22:41 a user named salegrem said ```Hey guys, I'm writing an article on Auto AI, and I want to cover Auto-GPT, BeeBot, and AutoGen. However, I'm at a bit of a crossroads. What is the name of this technology? It's not Intelligent Agents, and I don't see Auto AI being used anywhere online except for a different IBM thing.```.
In general, at 2023-10-02 17:21:30 a user named andyinater said ```I think openai is actively balancing rates right now.

I recommend if you are hitting these limits regularly to try and rework your test bed to run manually - will save tokens and calls, and honestly it is easier to debug```.
In general, at 2023-10-02 17:16:46 a user named lola_yan said ```But it still eventually reaches a point where it loops itself to death with "Rate limit reached for 10KTPM-200RPM"```.
In general, at 2023-10-02 17:15:42 a user named lola_yan said ```It helps a little,  It just delays the eventual crash if I make the "retry_wait_time" higher```.
In general, at 2023-10-02 17:10:45 a user named au8 said ```https://microsoft.github.io/autogen/docs/FAQ/#handle-rate-limit-error-and-timeout-error```.
In general, at 2023-10-02 17:09:42 a user named lola_yan said ```Any idea on how to start debugging it?```.
In general, at 2023-10-02 17:02:05 a user named iamhere said ```Alright, so I tried a bunch of methods, this is what I have to show you. Its still not working, this is what my OAI_CONFIG_LIST looks like. I have removed the .txt as well so that is no longer an issue, Still gettting the error.```.
In general, at 2023-10-02 16:58:05 a user named aaronward_ said ```we can call it inceptGen```.
In general, at 2023-10-02 16:45:48 a user named andyinater said ```"It's token 5 million, do you know where your AI is?"```.
In general, at 2023-10-02 16:45:13 a user named andyinater said ```AutoGen has exemplified the importance of alignment to me now lol. If we plan on having them in little gossip circles that we don't pay attention to...```.
In general, at 2023-10-02 16:43:54 a user named andyinater said ```We humans still stack up pretty good in intelligence so it's good to leverage that where reasonable to get it on the right track```.
In general, at 2023-10-02 16:43:16 a user named andyinater said ```I can imagine so, yes. Generally the more focused of an ask the better, and if it has source material/examples for reference even better again```.
In general, at 2023-10-02 16:41:15 a user named fxtoofaan said ```You think it’ll help if we first write list of possible personalities and org chart hierarchies for various type of teams ? Like marketing team. Programming team. Content team. Script main manager or CEO etc ?```.
In general, at 2023-10-02 16:31:49 a user named andyinater said ```Maybe the last time I'll have to manually tune prompts 🤔```.
In general, at 2023-10-02 16:30:33 a user named andyinater said ```I am hardly a programmer, but I will try 😛

Honestly, getting the agents to reliably do what you want is the hardest part right now. To be able to test/iterate the agents prompts, with other agent(s) evaluating the post-mortem.

I have high expectations.```.
In general, at 2023-10-02 16:29:20 a user named fxtoofaan said ```@andyinater I’m not a programmer but if you are and you can create this it’ll be awesome 👏```.
In general, at 2023-10-02 16:25:31 a user named andyinater said ```Honestly I'm getting a little excited thinking about it so I might start on that tomorrow 😛```.
In general, at 2023-10-02 16:23:02 a user named andyinater said ```Would need some extra work to evaluate group performance afterwards, but I believe it will be a good framework/example.```.
In general, at 2023-10-02 16:22:31 a user named andyinater said ```To make it produce agents, the planning could be focused on agent needs instead of program needs, and script iterations could be group configuration/prompt iterations```.
In general, at 2023-10-02 16:21:54 a user named andyinater said ```I will release a repo tonight that could facilitate such an idea. Iterative coding, preceded by a planning phase, with files saving iterative progress along the way to allow easy resumption.

Context windows kept very narrow to keep focus/prevent distraction. In a sense fixed token iteration cost assuming code and review comments stay similar in length.```.
In general, at 2023-10-02 16:10:14 a user named fxtoofaan said ```Who’s up to take on this challenge and make this autogen script or app ?```.
In general, at 2023-10-02 16:04:10 a user named fxtoofaan said ```Need autogen to make autogen virtual team agents 🙂```.
In general, at 2023-10-02 16:01:20 a user named sandratoolan said ```same here. We need to go a layer down to understand i gues```.
In general, at 2023-10-02 15:57:13 a user named lola_yan said ```if so then I have no idea why I get ratelimited```.
In general, at 2023-10-02 15:56:28 a user named aurowk said ```I thought GroupChat agents worked in sequence?```.
In general, at 2023-10-02 15:55:23 a user named lola_yan said ```Hey , I have a little problem.
With the following code I get ratelimited immediatly after the admin defines the workflow:
```python
import openai
from autogen import AssistantAgent, UserProxyAgent, config_list_from_json, ChatCompletion, GroupChat, GroupChatManager

config_list_gpt4 = config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": ["gpt-3.5-turbo"],
    },
)

gpt4_config = {
    "seed": 42,  # change the seed for different trials
    "temperature": 0,
    "config_list": config_list_gpt4,
    "request_timeout": 120,
}
user_proxy = UserProxyAgent(
   name="Admin",
   system_message="A human admin. Interact with the planner to discuss the plan. Plan execution needs to be approved by this admin.",
   code_execution_config=False,
)
engineer = AssistantAgent(
    name="Engineer",
    llm_config=gpt4_config,
    system_message='''Engineer. You follow an approved plan. You write python/shell code to solve ...
''',
)
scientist = AssistantAgent(
    name="Scientist",
    llm_config=gpt4_config,
    system_message="""Scientist..."""
)
planner = AssistantAgent(
    name="Planner",
    system_message='''Planner...
''',
    llm_config=gpt4_config,
)
executor = UserProxyAgent(
    name="Executor",
    system_message="Executor...",
    human_input_mode="NEVER",
    code_execution_config={"last_n_messages": 3, "work_dir": "paper"},
)
critic = AssistantAgent(
    name="Critic",
    system_message="Critic...",
    llm_config=gpt4_config,
)
groupchat = GroupChat(agents=[user_proxy, engineer, scientist, planner, executor, critic], messages=[], max_round=50)
manager = GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)

user_proxy.initiate_chat(
    manager,
    message="""
find papers on LLM applications from arxiv in the last week, create a markdown table of different domains.
""",
)
```

I think that it has something to do with the parallel execution of agent requests , Does anyone know how can i send the requests sequantially?```.
In general, at 2023-10-02 15:51:03 a user named aurowk said ```Autogen within autogen making an autogen solution 😄```.
In general, at 2023-10-02 15:35:41 a user named sonichi said ```All the related files are in the repo.
examples: https://github.com/microsoft/autogen/tree/main/notebook
documentation website: https://github.com/microsoft/autogen/tree/main/website
docstr: https://github.com/microsoft/autogen/tree/main/autogen```.
In general, at 2023-10-02 15:33:15 a user named fxtoofaan said ```Is there detail documentation about every feature and explanation of that feature for autogen ? Watching the video I linked about from Manish Gupta seems like autogen has features I’ve not explored or seen in the documentation before. Would be nice to feed autogen it’s own documentation and examples and then learn from that and then use autogen to create various types of virtual agent environments```.
In general, at 2023-10-02 15:29:53 a user named sonichi said ```Interesting idea to try. Give it an example. Use the doc and RetrieveChat if necessary.```.
In general, at 2023-10-02 14:46:36 a user named fxtoofaan said ```@sonichi is it possible to use autogen to create autogen python scripts? Like use autogen to create a complex group chats and define roles and responsibilities in a virtual team. Like give it a single prompt and based on that it’ll do research and find out what roles are needed and based on that create like a python script that defines connection to llm and create agents and their definitions and then also setup the group chats and then final output either with or without human intervention```.
In general, at 2023-10-02 14:38:02 a user named fxtoofaan said ```https://youtu.be/2RT8i-VP7V0```.
In general, at 2023-10-02 14:17:54 a user named andyinater said ```Welcome to the party Lumpy! Expect a bit if a steep learning curve figuring out how the Lego pieces fit together - it seems we all start off forcing it in bad ways.

But once you get passed that it's pretty wild all the opportunity.```.
In general, at 2023-10-02 14:04:19 a user named lumpyfarts said ```I don't know autogen, but I want to learn. I'm an old programmer looking to learn/play in Python and AI.```.
In general, at 2023-10-02 14:00:34 a user named redai.ai said ```Glad to see we got some new people in here```.
In general, at 2023-10-02 12:45:57 a user named _joberg said ```I am curious where we are in 1 month```.
In general, at 2023-10-02 12:45:40 a user named _joberg said ```Me too. We are in the algorithm```.
In general, at 2023-10-02 12:35:05 a user named 0xjamp said ```Anyway to get around api rate limit lol```.
In general, at 2023-10-02 11:44:20 a user named tigremon said ```I'd like to build an app to show GPX tracks over a 3D map```.
In general, at 2023-10-02 11:43:39 a user named tigremon said ```YouTube recommended me this video https://www.youtube.com/watch?v=8TLwSH_UFwI```.
In general, at 2023-10-02 10:24:43 a user named .princeps said ```I'll bring you into a forum so we can chat there```.
In general, at 2023-10-02 10:23:26 a user named lessuse. said ```hey guys anybody made any useful use case of the autogen, please share```.
In general, at 2023-10-02 10:22:44 a user named lessuse. said ```i copy your repo code 🤷‍♂️```.
In general, at 2023-10-02 10:21:07 a user named .princeps said ```Oh seems like you are trying a different script```.
In general, at 2023-10-02 10:18:26 a user named .princeps said ```I usually leave on the .JSON extension```.
In general, at 2023-10-02 10:05:48 a user named aurowk said ```I've not seen that before and I'm still learning myself but maybe you should try the use_docker=False option for the agents```.
In general, at 2023-10-02 10:04:46 a user named lessuse. said ```can u tell me about the above error```.
In general, at 2023-10-02 10:04:15 a user named aurowk said ```what have you called your OAI_CONFIG_LIST? Does it still have the .json extension?```.
In general, at 2023-10-02 10:02:50 a user named lessuse. said ```my code - 

```
from autogen import AssistantAgent, UserProxyAgent, config_list_from_json, GroupChat, GroupChatManager
import autogen
# Load the configuration for GPT-4 from a JSON file
config_list_gpt4 = autogen.config_list_from_json(
    "OAI_CONFIG_LIST",
    file_location=".",
    filter_dict={
        "model": {
            "gpt-4",
        }
    }
)

llm_config = {"config_list": config_list_gpt4, "seed": 42}
user_proxy = autogen.UserProxyAgent(
   name="User_proxy",
   system_message="A human admin.",
   code_execution_config={"last_n_messages": 2, "work_dir": "groupchat"},
   human_input_mode="TERMINATE"
)
coder = autogen.AssistantAgent(
    name="Coder",
    llm_config=llm_config,
)
pm = autogen.AssistantAgent(
    name="Product_manager",
    system_message="Creative in software product ideas.",
    llm_config=llm_config,
)
groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)
manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)

user_proxy.initiate_chat(manager, message="Find a latest paper about gpt-4 on arxiv and find its potential applications in software.")
# type exit to terminate the chat``````.
In general, at 2023-10-02 10:01:39 a user named lessuse. said ```its stop at step 2```.
In general, at 2023-10-02 10:01:26 a user named lessuse. said ```hey , now why it keep showing this error - 

```docker.errors.DockerException: Error while fetching server API version: (2, 'CreateFile', 'The system cannot find the file specified.')``````.
In general, at 2023-10-02 09:59:42 a user named aurowk said ```So you either remove those models from the available list, or you add your key to use for them in the AOI_CONFIG_LIST```.
In general, at 2023-10-02 09:59:00 a user named aurowk said ```in your OAI_CONFIG_LIST you've probably not specified a key to use for the other 2 models (gpt-4-0314 and gpt-4-0613)```.
In general, at 2023-10-02 09:58:57 a user named lessuse. said ```also, i try many autogen examples and try the auto mode, but it keep gettting this error - 

```docker.errors.DockerException: Error while fetching server API version: (2, 'CreateFile', 'The system cannot find the file specified.')``````.
In general, at 2023-10-02 09:58:09 a user named lessuse. said ```i dont know exactly, but i replace this - 
```config_list_gpt4 = config_list_from_json(
    "../OAI_CONFIG_LIST.json",
    filter_dict={
        "model": ["gpt-4-0613", "gpt-4-32k", "gpt-4", "gpt-4-0314"],
    },
)
```

with this - 

```config_list = autogen.config_list_from_json(
    "OAI_CONFIG_LIST",
    file_location=".",
    filter_dict={
        "model": {
            "gpt-4",
            "gpt-3.5-turbo",
        }
    }
)```

and it works```.
In general, at 2023-10-02 09:56:01 a user named .princeps said ```What was the issue ?```.
In general, at 2023-10-02 09:55:57 a user named .princeps said ```@lessuse. Seems like you got it to work```.
In general, at 2023-10-02 09:48:55 a user named lessuse. said ```awesome, it can run the code itself🔥```.
In general, at 2023-10-02 09:33:51 a user named aurowk said ```https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In general, at 2023-10-02 09:32:01 a user named aurowk said ```It'll be issue with the model_list you've specified and your OAI_CONFIG_LIST```.
In general, at 2023-10-02 09:31:38 a user named lessuse. said ```no, i have gpt-4 access```.
In general, at 2023-10-02 09:31:10 a user named egalitaristen said ```Try using GPT-3.5, it might be that you don't have GPT-4 API access```.
In general, at 2023-10-02 09:29:02 a user named lessuse. said ```@.princeps hey i use your repo to try the snake game, i install the requirements.txt, i also add the the api key in the config file, still it showing this error - 
```raise openai.error.AuthenticationError(
openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.``````.
In general, at 2023-10-02 09:17:37 a user named egalitaristen said ```Friend request sent, I'm trying to gather a list of people in the AI space with similar goals.```.
In general, at 2023-10-02 09:14:51 a user named egalitaristen said ```Maybe I didn't know the true meaning of irony, seems to have slightly different meanings in English and Swedish```.
In general, at 2023-10-02 09:14:10 a user named melekgharbi said ```https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/```.
In general, at 2023-10-02 09:14:06 a user named melekgharbi said ```Hi guys, just discovered this discord and autogen via an article in microsoft research 😄```.
In general, at 2023-10-02 09:12:21 a user named egalitaristen said ```Well, I consider myself to be an egalitarian. My goals for AGI are egalitarian and the reason why I'd like to keep AGI (presuming that I could create it) to myself is to not share that power with the ruling class because they'd just use it to subjugate people even more.```.
In general, at 2023-10-02 09:01:01 a user named .princeps said ```Cause your name is Egalitarian, meaning : believing in or based on the principle that all people are equal and deserve equal rights and opportunities.
"a fairer, more egalitarian society"```.
In general, at 2023-10-02 08:57:04 a user named egalitaristen said ```I've been planning a real world Polyverse scenario for some years now (all in my head). It's based on Manna - A tale of 2 cities and FALC```.
In general, at 2023-10-02 08:51:35 a user named egalitaristen said ```What's ironic about my name? My name means "The egalitarian" in Swedish. Does it have another meaning in another language?```.
In general, at 2023-10-02 08:47:29 a user named lessuse. said ```it showing this error - ``AttributeError: partially initialized module 'autogen' has no attribute 'config_list_from_json' (most likely due to a circular import)`````.
In general, at 2023-10-02 08:47:10 a user named lessuse. said ```hey princeps, can u help me with the error , even a normal code is not working - 
```from autogen import AssistantAgent, UserProxyAgent
import openai

openai.api_key = 'sk-xxxx'

assistant = AssistantAgent("assistant")
user_proxy = UserProxyAgent("user_proxy")
user_proxy.initiate_chat(assistant, message="make a snake game in python")
``````.
In general, at 2023-10-02 08:46:04 a user named .princeps said ```Ironic name you got there @egalitaristen

Here is Abit about my goals 
https://youtu.be/yJMojuvNmSk?si=dnORE5MzOylxyqHx```.
In general, at 2023-10-02 08:35:58 a user named lessuse. said ``````AttributeError: partially initialized module 'autogen' has no attribute 'config_list_from_json' (most likely due to a circular import)``````.
In general, at 2023-10-02 08:35:18 a user named aaronward_ said ```remove the `.json` file extension from the file, and run again```.
In general, at 2023-10-02 08:31:37 a user named egalitaristen said ```That'd be nice. Although I'm really focused on the local integration of all of these frameworks. I want a self-improving AI but I want it locally. Figure that I have more noble goals for humanity than all the big companies (which have profit as the main goal) and that I'd like to not give them the solution to AGI if I stumble upon it.

I'm aware of my god complex 😛```.
In general, at 2023-10-02 08:27:33 a user named .princeps said ```Been using it for 3 weeks now, before the hype, made some sample project that you can play around with```.
In general, at 2023-10-02 08:26:54 a user named egalitaristen said ```Sorry, I'm not really knowledgeable about the details of AutoGen yet```.
In general, at 2023-10-02 08:26:49 a user named .princeps said ```Yeah, I think it's doable in the next 3 months with GPT-V coming out```.
In general, at 2023-10-02 08:26:08 a user named egalitaristen said ```That's a shame. Self-improving AI is kind of my holy grail```.
In general, at 2023-10-02 08:24:44 a user named .princeps said ```I was looking for a GitHub but seems like it wasn't shared```.
In general, at 2023-10-02 08:24:36 a user named aaronward_ said ```You're forgetting `config_list = autogen.config_list_from_json()`, then you pass the config list to your `llm_config` dictionary - See "Setup API" Section of this notebook: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb```.
In general, at 2023-10-02 08:03:59 a user named lessuse. said ```my keys are not loading into the code```.
In general, at 2023-10-02 08:03:52 a user named lessuse. said ```hey Egalitaristen , can u help me with my error```.
In general, at 2023-10-02 08:02:41 a user named egalitaristen said ```You need an X account to view posts these days it seems. Care to share another source on this?```.
In general, at 2023-10-02 08:01:04 a user named lessuse. said ```hey guys, there is a error when i run the code - ``AttributeError: partially initialized module 'autogen' has no attribute 'config_list_from_json' (most likely due to a circular import)``

this is my code - 

```import autogen

config_list = [
    {
        'model': 'gpt-4',
        'api_key': 'my_key',
    }
]

# Set large language model configuration
llm_config = {
    "request_timeout": 600,
    "seed": 42,
    "config_list": config_list,
    "temperature": 0,
}

# Create an AssistantAgent instance named "assistant"
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
)

# Create a UserProxyAgent instance named "user_proxy"
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "web"},
    llm_config=llm_config,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet."""
)

# Begin the chat
user_proxy.initiate_chat(
    assistant,
    message="Who should read this paper: https://arxiv.org/abs/2308.08155?",
)
``````.
In general, at 2023-10-02 07:39:30 a user named .princeps said ```@sonichi is there a repo for this ? 

https://twitter.com/oscarmoxon/status/1708603929011863871```.
In general, at 2023-10-02 06:51:57 a user named __erice__ said ```AutoGen x Multi-Agent Reinforcement Learning seems like a natural next step yeah? Which RL frameworks would be good to look into?```.
In general, at 2023-10-02 06:49:39 a user named aayushc1308 said ```What do people think about enforcing a more stricter type interface for the library. For eg. things like human_input_mode should be enums instead of string types and bunch of similar things internally. If people agree, I can start helping migrate things and open some PRs. 
This will help avoid downstream bugs and make usage easier without having to read library code.```.
In general, at 2023-10-02 06:48:13 a user named aayushc1308 said ```Hey everyone,
I'm Aayush (Founder, CEO of a startup called Kniru https://kniru.com). Kudos to all the great work happening here. Looking forward to participating as AutoGen evolves.```.
In general, at 2023-10-02 06:44:50 a user named pradeep1148 said ```https://www.youtube.com/watch?v=w6hhnVa68yE&ab_channel=DLExplorers made this video from this notebook. thanks for the contribution```.
In general, at 2023-10-02 06:44:34 a user named pradeep1148 said ```https://colab.research.google.com/gist/ElliotWood/af12566db5d6948e8ed6dd6324aa9697/autogen-langchain.ipynb#scrollTo=r7PFvDS7Ev-E```.
In general, at 2023-10-02 05:34:02 a user named kajatta said ```You're welcome - hit me up if you need something else```.
In general, at 2023-10-02 03:35:03 a user named devegavc_83455 said ```I see it on github```.
In general, at 2023-10-02 03:33:32 a user named ondaje said ```Oh heck yeah. Thank you so much. This looks perfect and much simpler than a full reimplementation.

My pipelines have wrappers for langchain tooling and I have stuff that does the fastapi server as well, plus a way to prompt it, I just need to expose an async run function ultimately, so this looks perfect.```.
In general, at 2023-10-02 03:28:45 a user named __erice__ said ```@ondaje looks like you're in here too 😏 lol.. what do you think about this approach?```.
In general, at 2023-10-02 02:37:15 a user named tawnniee said ```thanks @qingyunwu this was what i needed, am browsing now!```.
In general, at 2023-10-02 02:29:42 a user named qingyunwu said ```Yes, of course. This is an example. https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.
In general, at 2023-10-02 02:28:42 a user named tawnniee said ```hey what's up friends, am playing around with autogen now, does anyone have a link to the docs on how to use it to browse the web?```.
In general, at 2023-10-02 02:25:27 a user named mizerati1313 said ```I sent something to htb bot commands as well```.
In general, at 2023-10-02 02:23:58 a user named mizerati1313 said ```I wanted to do a smoke test on something```.
In general, at 2023-10-02 02:23:36 a user named qingyunwu said ```Thanks! Is this related to AutoGen?```.
In general, at 2023-10-02 02:23:13 a user named mizerati1313 said ```I joined the voice connected```.
In general, at 2023-10-02 02:22:23 a user named mysticaldiscofrog said ```I did, to the point that I deleted all the reference to gpt-4 in my code. I thought maybe it was somewhere in autogen itself. 

Thank you, I will work with this example you provided.```.
In general, at 2023-10-02 02:20:06 a user named mizerati1313 said ```I have something to share!```.
In general, at 2023-10-02 02:20:05 a user named qingyunwu said ```This is an example using GPT-3.5-turbo: https://github.com/qingyun-wu/autogen-eval/blob/main/application/A2-retrieval-augmented-chat/NaturalQuestionsQA-gpt35turbo.ipynb```.
In general, at 2023-10-02 02:19:40 a user named qingyunwu said ```Did you try setting the model field to "gpt-3.5-turbo" in `config_list` fileld of the  llm_config?```.
In general, at 2023-10-02 02:05:40 a user named mysticaldiscofrog said ```Does anyone know where to shift the calls from gpt-4 to gpt-3.5-turbo? The tests I am doing do not need gpt-4 right now but I have changed everything I can find and the billing keeps going up got 4 and staying the same for 3.5. Thank you.```.
In general, at 2023-10-02 01:56:05 a user named Drogend said ```Might sound stupid, but how? I tried and it reverts back to .txt```.
In general, at 2023-10-02 00:53:10 a user named andyinater said ```Beautiful. I plan on having my own workforce in the basement closet 😛```.
In general, at 2023-10-02 00:42:10 a user named fxtoofaan said ```doing about 18 tokens / second.```.
In general, at 2023-10-02 00:40:23 a user named fxtoofaan said ```then I ran the python script (city_planner.py) attached as my first request to Plan a week long trip to Dallas Texas. Include a table of dates and activity.

and bam this is what happened. 

13B parameter loaded in my 12GB GPU no problems. 

so I've got a potential virtual army that I can run 100% offline if I want to that costs me $0 going forward forever for under a grand 🙂

need to keep adding features to autogen. keep going 🙂 

power of Nvidia, llama-2 13B model, TheBloke's AWQ model, docker, vLLM, Python and ofcourse autogen```.
In general, at 2023-10-02 00:40:08 a user named fxtoofaan said ```ok so check this out 🙂

I bought an old used Nvidia A2000 GPU with 12GB VRAM. I installed it in my old dell optiplex sff pc with i7, 32GB Ram and 256GB SSD Drive, all from ebay for no less than 600 UK Pounds GBP. 

with all hardware in, I loaded the machine with Ubuntu 22.04.3 LTS on a bootable USB stick. from there I installed Ubuntu 22.04.3 LTS on the computer's internal SSD. Now pc boots into ubuntu and its a beautiful interface. I installed a bunch of updates and services using various commands, i cannot remember the order but I remember running these commands to get things working. 

sudo apt update
sudo apt install snapd
sudo snap install nvtop
https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
sudo pip3 install lfs --break-system-packages
git clone https://huggingface.co/TheBloke/Llama-2-13B-chat-AWQ
sudo pip3 install git+https://github.com/huggingface/transformers.git@72958fcd3c98a7afdc61f953aa58c544ebda2f79 --break-system-packages
sudo pip3 install git+https://github.com/casper-hansen/AutoAWQ.git@1c5ccc791fa2cb0697db3b4070df1813f1736208 --break-system-packages

then I loaded the model of my choice and a docker image...

docker run --gpus all \
    -p 8000:8000 \
    -v /home/aitoofaan/LLMs/models/Llama-2-13B-chat-AWQ:/mnt/model/ \
     ghcr.io/mistralai/mistral-src/vllm:latest \
    --host 0.0.0.0 \
    --model="/mnt/model/" \
     --quantization awq

sudo pip3  install pyautogen --break-system-packages```.
In general, at 2023-10-02 00:37:29 a user named slayerdeebo said ```The api key should be like : open_ai_key = ‘your_key’```.
In general, at 2023-10-02 00:12:09 a user named fxtoofaan said ```@sonichi when will the following be updated? mistral-src/vllm . It was last updated 2 days ago. I think they added some new LLM's to the vllm server and wondering if we can get the latest changes in this repository please 🙂```.
In general, at 2023-10-01 21:59:57 a user named iamhere said ```I keep getttin this error, but I have the keys in OAI_CONFIG_LIST.txt Any suggestions?```.
In general, at 2023-10-01 21:45:09 a user named tonic_1 said ```join the discord, join us on github (send me your username) , join us on hugging face and let's get started making super cool stuff```.
In general, at 2023-10-01 21:42:11 a user named fragrancefreak said ```Just discovered autogen I'm really interested in using it and helping out maybe```.
In general, at 2023-10-01 21:30:27 a user named iamhere said ```What can I do to help?```.
In general, at 2023-10-01 20:53:59 a user named sonichi said ```sonichi is there currently a way for a```.
In general, at 2023-10-01 20:32:23 a user named epicrookie_ said ```Hey, does anyone know if Semantic Kernel will have a feature to invoke Autogen?```.
In general, at 2023-10-01 20:32:13 a user named kosiarn said ```does it work similarly to ensemble learning?```.
In general, at 2023-10-01 20:31:41 a user named kosiarn said ```hi, I saw a video about autogen on youtube and got interested```.
In general, at 2023-10-01 20:26:21 a user named andyinater said ```.... it is utterly surreal to experience being legitimately problem solving in code and natural language. I am constantly amazed and excited. Good job again MS guys - absolutely revolutionary.```.
In general, at 2023-10-01 20:22:45 a user named andyinater said ```And also allow resumption of a project after closing all chats. Leave enough, and the right, breadcrumbs such that everyone can pick up where they left off.```.
In general, at 2023-10-01 20:22:10 a user named andyinater said ```I want to post it, but it takes time to format a nice repo to explain all the moving parts. So I am working on integrating a semi-hard-coded versioning system for code iterations. The goal is to minimize the context windows of every chat down to only what is necessary.```.
In general, at 2023-10-01 20:21:11 a user named andyinater said ```Lol exactlyyyy. Despite the capabilites of the LLMs and autogen, there  is still a higher level of granularity required in setting up agents and chats than we might have hoped for. But it is just a learning curve.

I have already started seeing huge improvements in code generation by breaking up the steps and manually controlling the group chat in a logical order. The programming test case I've been using, that seems to fail in the autogen examples (running on 3.5 turbo), is "write a python program that displays the current time on an analog clock face". Through the examples, it would definitely get something. But it was rough, and particularly the arm positions were always inaccurate/wrong. Through the flow I'm running now it gets it absolutely every time. The MS paint they produce is quite good too, and other generic asks have done well.```.
In general, at 2023-10-01 20:18:08 a user named __orderandchaos said ```Have had a good laugh at a few projects derail this way, little too close to home haha```.
In general, at 2023-10-01 20:17:08 a user named __orderandchaos said ```"A bad manager can ruin the entire team's efforts" so we've already reached human level capabilities in ai```.
In general, at 2023-10-01 20:04:30 a user named __orderandchaos said ```I'm looking for a way to have the next run read the existing file structure, requirements.txt/poetry and any code files to get an overview of the existing stack. 

Then plan out the prompt request and add new files or replace existing ones```.
In general, at 2023-10-01 19:30:31 a user named 0xjamp said ```I keep getting a rate limit error on my openapi when running the multi agent group chat```.
In general, at 2023-10-01 19:10:14 a user named andyinater said ```Not sure, but let me know! These things listen well 🙂```.
In general, at 2023-10-01 19:09:51 a user named andyinater said ```@sonichi is there currently a way for a user agent to be manager of a group chat? I achieved it by overriding GroupChatManager and GroupChat, setting the selector in 'select_speaker' to choose agent by name "MrManager", user_proxy controlled by me, but if there is a way to do it without modifying the code base I'd prefer it.```.
In general, at 2023-10-01 20:54:00 a user named sonichi said ```Interesting question. There is a hacky way: You can set the GroupChatManger's `generate_oai_reply` function to be `check_termination_and_human_reply​` which will change LLM reply into human reply; also set `human_input_mode="ALWAYS"````.
In general, at 2023-10-01 21:30:46 a user named andyinater said ```OK, so I wasn't crazy hacking together a solution. I'm finding it incredibly insightful to be able to manually select the speaker as I see fit - there may even be some workflows that can only realistically be run this way. And it is useful to isolate when you have a manager problem vs an agent participant problem.```.
In general, at 2023-10-02 02:01:24 a user named sonichi said ```What I meant is just
`group_chat_manager.generate_oai_reply = group_chat_manager.check_termination_and_human_reply````.
In general, at 2023-10-02 02:01:39 a user named sonichi said ```a little hacky but not complicated```.
In general, at 2023-10-02 02:03:01 a user named andyinater said ```OH, I see. I will try that out. Thank you```.
In general, at 2023-10-02 20:53:02 a user named andyinater said ```Did I do it wrong?```.
In general, at 2023-10-02 21:23:57 a user named sonichi said ```You did it right. There is a minor mismatch that causes this error: the `check_termination_and_human_reply` function expects the sender to be not None, but the `select_speaker` function doesn't give it. A minor fix would make it work. If you can figure it out, give it a try. Otherwise create an issue on GitHub.```.
In general, at 2023-10-01 19:08:14 a user named aaronward_ said ```wen autonomous agent manager role in the job market?```.
In general, at 2023-10-01 19:05:22 a user named rejekts said ```btw the Layman in the text example is a fine tuned openai model, while the philosopher and psychologist are the regular gpt 3.5```.
In general, at 2023-10-01 19:03:51 a user named andyinater said ```I recommend anyone who is currently trying to get a group to solve a problem well, with members with predefined roles and abilities, to try BEING the manager. It is nice to have an auto-manager, but it is such a critical role that if it isn't set up well you will have trouble evaluating the performance of all the other agents.

You could have GPT7 agents, but a bad 3.5 turbo manager can ruin all their efforts and abilities. 

.... we've all been there 😛```.
In general, at 2023-10-01 19:03:02 a user named rejekts said ```Has anyone tried mixing models? It gave me a pretty fun result```.
In general, at 2023-10-01 19:02:43 a user named rejekts said ```I would guess all agents see all context at all times and they just add their response to it each iteration```.
In general, at 2023-10-01 19:01:03 a user named andyinater said ```I'm not certain how the context windows in a group chat are for each agent, but I am assuming each participant sees the entire chat log. If you have multiple plan revisions and code revisions in the same context, I can imagine it gets confusing```.
In general, at 2023-10-01 18:59:34 a user named andyinater said ```Hah, I am working on this as we speak. Through my memory manager experiments I've come to value the ability for text files to hold key steps/facts/iterations such that you can reset the context windows but still proceed with work```.
In general, at 2023-10-01 18:38:16 a user named mantiscrypto said ```wen multi agent browser chat for idiots like me that can't install```.
In general, at 2023-10-01 18:21:56 a user named rejekts said ```Have you tried passing the code as part of the prompt when initializing it, and having the task be to advance on the code based on your new requests?```.
In general, at 2023-10-01 18:13:28 a user named guardiang said ```Ben’s Bites led me here, super happy to check out AutoGen!```.
In general, at 2023-10-01 17:50:21 a user named andyinater said ```Before you write it off, dig into the manager and assistant default system prompts in the source files. There are some non-obvious things going on in there. As-Is they work well on GPT for the example problems, but extendibility depends on the task you are asking and how that relates to the underlying dynamics set up by the prompts.```.
In general, at 2023-10-01 17:25:42 a user named sonichi said ```not only. check https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs```.
In general, at 2023-10-01 17:13:33 a user named 8i8__papillon__8i8d1tyr said ```does this only work with ioenai?```.
In general, at 2023-10-01 16:19:06 a user named sonichi said ```I have inputted a new key to the```.
In general, at 2023-10-01 16:17:51 a user named sonichi said ```That happens. Check: https://microsoft.github.io/autogen/docs/FAQ/#handle-rate-limit-error-and-timeout-error```.
In general, at 2023-10-01 16:07:40 a user named orderandchaos_at_work said ```Anyone know how I can get Autogen agents to continue work on the code they've previously written in past runs? Is that even possible?```.
In general, at 2023-10-01 16:05:38 a user named rotten_lion said ```I have inputted a new key to the environment, why is it still using old one```.
In general, at 2023-10-01 16:19:07 a user named sonichi said ```how did you set the `llm_config`?```.
In general, at 2023-10-01 16:19:58 a user named rotten_lion said ```I am pretty new here. so bear with me please.```.
In general, at 2023-10-01 16:20:00 a user named rotten_lion said ````# echo "export OPENAI_API_KEY='sk-...'" >> ~/.zshrc
# source ~/.zshrc
# echo $OPENAI_API_KEY````.
In general, at 2023-10-01 16:20:09 a user named rotten_lion said ```I input this into terminal```.
In general, at 2023-10-01 16:20:42 a user named rotten_lion said ```and then part of the conversation gets printed , but not the answer bit```.
In general, at 2023-10-01 16:21:10 a user named rotten_lion said ```I input the key also to OAI_CONFIG_LIST```.
In general, at 2023-10-01 16:21:36 a user named rotten_lion said ```and also redeployed env, but still comes back using the old key```.
In general, at 2023-10-01 16:34:14 a user named sonichi said ```So is the old key anywhere in any file, or the environment? Is the new key directly specified in `llm_config`?```.
In general, at 2023-10-01 16:35:52 a user named rotten_lion said ```when I tried `autogen.config_list_openai_aoai()` the old key pop up, but when I `echo` in the terminal the new key is there```.
In general, at 2023-10-01 16:36:02 a user named rotten_lion said ```where can I set the `llm_config````.
In general, at 2023-10-01 16:37:52 a user named sonichi said ```in the constructor of `AssistantAgent````.
In general, at 2023-10-01 16:38:20 a user named sonichi said ````autogen.config_list_openai_aoai()` loads from `os.environ` first```.
In general, at 2023-10-01 16:38:37 a user named rotten_lion said ```oh yeah, it just the screen shot I sent you, I did directly put it in there```.
In general, at 2023-10-01 16:39:22 a user named rotten_lion said ````# create an AssistantAgent instance named "assistant"
assistant_config0 = {
    "name": "assisstant0",
    "system_message": "You are a helpful assistant.",
    "llm_config":{
        "request_timeout": 600,
        "seed": 42,
        "config_list": config_list,
    }
}

assistant0 = AssistantAgent(assistant_config0)````.
In general, at 2023-10-01 16:41:25 a user named rotten_lion said ```somehow this is still old one `os.environ['OPENAI_API_KEY']````.
In general, at 2023-10-01 16:42:38 a user named rotten_lion said ```can I just do `os.environ['OPENAI...] = 'new_key'`?```.
In general, at 2023-10-01 16:44:10 a user named sonichi said ```if you use the code above, it should override the `os.environ`.```.
In general, at 2023-10-01 16:45:06 a user named sonichi said ```It will not change `os.environ` but make the new key used instead of the old key.```.
In general, at 2023-10-01 16:45:39 a user named sonichi said ```Do you have other agents which did not get the new `config_list`?```.
In general, at 2023-10-01 16:47:26 a user named sonichi said ```math proxy doesn't use llm, unless you added `llm_config ` to it.```.
In general, at 2023-10-01 16:48:18 a user named rotten_lion said ```no, then it's the only agent I used, and `echo` is new, but `os.environ` is old. where can I override it?```.
In general, at 2023-10-01 16:51:24 a user named rotten_lion said ```I solved it, thanks, just needed to close terminal```.
In general, at 2023-10-01 16:51:27 a user named sonichi said ```oh, I see the problem. Need to use **```.
In general, at 2023-10-01 16:51:54 a user named sonichi said ```in the constructor of AssistantAgent()```.
In general, at 2023-10-01 16:52:17 a user named rotten_lion said ```ah, i see like `**kwag`?```.
In general, at 2023-10-01 16:54:59 a user named rotten_lion said ```cool stuff you built, can't wait to try it out```.
In general, at 2023-10-01 16:56:52 a user named sonichi said ```https://tenor.com/view/elvis-thankyou-gif-6754675021318788732```.
In general, at 2023-10-01 17:34:49 a user named rotten_lion said ```which API of wolframAlpha was used in testing?```.
In general, at 2023-10-01 17:36:21 a user named rotten_lion said ```tried with both simple and steps```.
In general, at 2023-10-02 14:44:09 a user named kevinwyr said ```https://products.wolframalpha.com/api

The MathChat example uses this API```.
In general, at 2023-10-01 15:55:59 a user named crj_wm said ```Learned about AutoGen from Youtube channel AI Explained. Downloaded it and tried to connect it to local LLMs run via LMStudio. The connection works but the quality of CodeLlama or WizardCoder 13B seems insufficient for AutoGen agents.```.
In general, at 2023-10-01 15:52:57 a user named korner83 said ```is it normal to get timeout errors regularly? (my balance and key is working, it just stoped all the sudden)   `line 617, in request_raw
    raise error.Timeout("Request timed out: {}".format(e)) from e
openai.error.Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60)````.
In general, at 2023-10-01 15:34:00 a user named sonichi said ```The cost info will be available if the logging is used (https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logging-experimental). It's an experimental feature so would love to get help from the community to improve it.```.
In general, at 2023-10-01 15:16:09 a user named amadad said ```Coming from ChatDev to AutoGen:

1.  Simpler install,  pip install and a few imports vs navigating a whole library
2. ChatDev focuses on phases of a workflow in addition to roles, so that's something I'm curious to explore in AutoGen
3. Incorporating a researcher tool into ChatDev, for query/search/scrape/summarize, was tricky; hoping to find a cleaner implementation for AutoGen
4. Token counting/cost was a helpful output in the report with ChatDev
5. AutoGen has a friendlier usage license```.
In general, at 2023-10-01 15:13:26 a user named tonic_1 said ```kinda, i think microsoft for one is putting a TON of research out there also that i use in general outside of autogen context, and open research is absolutely huge + the biggest driver of "cool demos" and dont we love cool demos```.
In general, at 2023-10-01 15:07:59 a user named sonichi said ```Shall we create a channel for research?```.
In general, at 2023-10-01 15:04:49 a user named sandratoolan said ```GOT HERE BY:  saw the paper , FLAML -> autogen```.
In general, at 2023-10-01 14:40:15 a user named andyinater said ```Hey, does anyone have an alternative to OpenAI for getting gpt3.5 turbo keys? I am finding it almost impossible to work efficiently with a rate-limit of 3 requests per minute. I wish they would let me spend more money, lol.```.
In general, at 2023-10-01 14:36:51 a user named tonic_1 said ```we're literally building it in public , also trying to make a push to flowise for llama using ollama , we have this inside there easily - discord link is in the bio, and btw i did spam the group quite a lot already with the github link, dm me to join us, there's also a hugging face collection you're welcome to join that organisation if you like```.
In general, at 2023-10-01 14:35:11 a user named winstonhammerton said ```hey @tonic_1 will you be posting your agents in the flowise community? I jsut sent you a friend request I'd be keen to join and meet people working working on similar projects, cheers```.
In general, at 2023-10-01 13:49:14 a user named tonic_1 said ```** but I really hope folks join us for autogpt / GitHub -> autogen ** we’ll be making all sorts of agents for autogen as a natural / necessary activity 🚀```.
In general, at 2023-10-01 13:47:53 a user named tonic_1 said ```Im an active member of the flowise community and the langflow community and I know what you’re trying to say - we’ll be using gradio I think while we build , eventually it would be nice to make a pr to one or the other of those or make a new barebones style design that works with autogen orchestration```.
In general, at 2023-10-01 13:44:14 a user named ansonparker said ```github = alibama - would be delighted to see what you're doing.... i'm a bit of a lazy coder = am hoping this all gets put in to a visual layer like langflow or flowise 🙂```.
In general, at 2023-10-01 13:37:13 a user named tonic_1 said ```we're trying to build this exactly , right now : https://github.com/team-tonic-arena-hacks send me your github user name even you dont want to contribute you can still take a look just let me know```.
In general, at 2023-10-01 13:32:22 a user named tonic_1 said ```we're building autogpt with autogen if you wanna hop on with us```.
In general, at 2023-10-01 13:01:11 a user named loprz said ```Found it trending on GitHub.```.
In general, at 2023-10-01 12:57:04 a user named ansonparker said ```my understanding is that agentgpt could be one of several agents orchestrated with autogen```.
In general, at 2023-10-01 12:27:38 a user named vincentjedi said ```If we want to add autogen as a plugin  to the quivr project, do you think the integration work would be quite tough? https://github.com/StanGirard/quivr#quivr---your-second-brain-empowered-by-generative-ai```.
In general, at 2023-10-01 12:14:14 a user named sonichi said ```Each agent can be customized. You can use LLMs, tools or human behind each agent. If you use an LLM for an agent, use the one best suited for its role. There is no limit of the number of agents, but start from a small number like 2, 3. The more capable is the LLM and the fewer roles you need, the fewer agents you need.```.
In general, at 2023-10-01 12:10:13 a user named vincentjedi said ```How about other agents ? How many agents can be used ? How do we decide how many agents in the group ?```.
In general, at 2023-10-01 12:08:08 a user named sonichi said ```The default user proxy agent doesn't use LLM. If you'd like to use an LLM in UserProxyAgent, the use case could be to simulate user's behavior. So you can use a model that's good at doing that.
The default assistant agent is instructed to use both coding and language skills. It doesn't have to do coding, depending on the tasks. And you can customize the system message. So if you want to use it for coding, use a model that's good at coding. Otherwise, you don't have to.```.
In general, at 2023-10-01 11:40:18 a user named vincentjedi said ```How do we decide what llm is used for each agent ? For example code llama should be chosen as the assistant agent as it is better at coding ? How about the user proxy agent ?```.
In general, at 2023-10-01 07:34:41 a user named .princeps said ```like it worked when I used it as you set it up, so I'll take a look at my other scripts and see what I'm doing wrong, thanks man, here is my little contributions: 

https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts```.
In general, at 2023-10-01 07:31:24 a user named kajatta said ```Nah just the colab notebook, it worked first try. Added this so others can use it too
https://github.com/microsoft/autogen/pull/58```.
In general, at 2023-10-01 07:30:17 a user named .princeps said ```@kajatta suprised you got function calling working in the autogen, was having issues with that so I used the library version through flaml. Did you use any special wizardry ?```.
In general, at 2023-10-01 07:28:31 a user named .princeps said ```On no worries, got that sauce in there 🙂```.
In general, at 2023-10-01 07:27:21 a user named kajatta said ```This morning i did yeah - found a better way 😉```.
In general, at 2023-10-01 07:26:50 a user named .princeps said ```@kajatta did you just update this in the past 2 hours ?```.
In general, at 2023-10-01 07:25:07 a user named kajatta said ```As seen here https://colab.research.google.com/gist/ElliotWood/af12566db5d6948e8ed6dd6324aa9697/autogen-langchain.ipynb```.
In general, at 2023-10-01 07:23:56 a user named kajatta said ```Nice but replace this 
```
    if tool.args_schema is None:
        return function_schema
    elif tool.args_schema.__annotations__ is not None:
        for field_name, field in tool.args_schema.__annotations__.items():
            type_mapping = {
                int: 'integer',
                float: 'float',
                str: 'string',
                bool: 'boolean',
                list: 'list',
                tuple: 'tuple',
                dict: 'dictionary',
                set: 'set',
                complex: 'complex'
            }
            full_name = type_mapping[field]

            function_schema["parameters"]["properties"][field_name] = {
                "type": full_name,
                "description": field.__doc__,
            }
            if field_name in getattr(tool.args_schema, "__required_fields__", []):
                function_schema["parameters"]["required"].append(field_name)

    return function_schema
```

With the args prop instead it'll work better more often 
```
# Define a function to generate llm_config from a LangChain tool
def generate_llm_config(tool):
    # Define the function schema based on the tool's args_schema
    function_schema = {
        "name": tool.name.lower().replace (' ', '_'),
        "description": tool.description,
        "parameters": {
            "type": "object",
            "properties": {},
            "required": [],
        },
    }

    if tool.args is not None:
      function_schema["parameters"]["properties"] = tool.args

    return function_schema
``````.
In general, at 2023-10-01 07:21:56 a user named .princeps said ```I tested the langchain tools notebook and it worked! Good job! here is a script for it 

https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts/blob/master/autogen_notebooks/langchain_tools.py```.
In general, at 2023-10-01 07:02:58 a user named dalipyadav68 said ```i just found you on the github```.
In general, at 2023-10-01 06:28:16 a user named winstonhammerton said ```hey guys probably a noob question but im recreating the example of the stock price agents, I'm doing BTC vs ETH price change YTD. I do the first part and the agents do well and come back with the correct price increases.. When I do the second task to plot it on a graph it seems like the agents start again  and don't follow up from the first task, is this what is being mentioned in memory conversation above?```.
In general, at 2023-10-01 11:53:44 a user named sonichi said ```When you call `initiate_chat` the conversation restarts by default. You can use `send` or `initiate_chat(clear_history=False)` to continue the conversation.```.
In general, at 2023-10-01 06:24:40 a user named steevek_62832 said ```I just going to learn Langchain but I found Autogen.```.
In general, at 2023-10-01 06:23:56 a user named steevek_62832 said ```Cool! So can I say Langchain is the framework for building the agent while Autogen is the framework for how to organize the agents to finish tasks?```.
In general, at 2023-10-01 06:18:57 a user named .princeps said ```hahah yeah, I'm definitely excited```.
In general, at 2023-10-01 06:17:06 a user named kajatta said ```Nah not a replacement Langchain is more of an interoperability framework that happens to have agents, one of them is CAMEL architecture which can be compared to AutoGen.

My goal was to enable the tools from Langchain to work with Autogen agents so we have the best of both```.
In general, at 2023-10-01 06:13:11 a user named kings530 said ```Learn from watching some ai YT video```.
In general, at 2023-10-01 06:10:13 a user named steevek_62832 said ```I just read about the paper, I wander if Autogen is the replacement of Langchain?```.
In general, at 2023-10-01 06:01:55 a user named steevek_62832 said ```Wow, looks like you really excited about autogen.```.
In general, at 2023-10-01 05:40:06 a user named kajatta said ```There is a PR on AutoGen for the notebook also FYI```.
In general, at 2023-10-01 05:39:24 a user named .princeps said ```@kajatta thanks man, was hard to sleep last night , so excited, so thanks for this gift, I'll work on it today```.
In general, at 2023-10-01 05:16:16 a user named uttamdinodia said ```I found it on youtube while going through Github Copilot.```.
In general, at 2023-10-01 04:47:57 a user named steevek_62832 said ```And, I think that the agent have to verify what it generate.```.
In general, at 2023-10-01 04:44:57 a user named steevek_62832 said ```I think that should be hard to achieve, because some tasks require more tokens than others.```.
In general, at 2023-10-01 04:39:52 a user named felly007. said ```chat history so it can refer back to previous conversations. Potentially we could make an memory agent. or we can follow @andyinater example```.
In general, at 2023-10-01 04:28:18 a user named Drogend said ```I just read the paper. Someone correct me if I’m wrong but I think you can adjust your stop setting to determine how many tokens get used```.
In general, at 2023-10-01 04:23:52 a user named steevek_62832 said ```It feels like autogen is token-consumed.```.
In general, at 2023-10-01 03:58:25 a user named kajatta said ```This will give your AutoGen agent the callability to use this toolkit to solve the problem or query```.
In general, at 2023-10-01 03:57:44 a user named kajatta said ```try my example https://colab.research.google.com/gist/ElliotWood/af12566db5d6948e8ed6dd6324aa9697/autogen-langchain.ipynb
with the SQLDatabaseToolkit from Langchain
https://api.python.langchain.com/en/latest/_modules/langchain/agents/agent_toolkits/sql/toolkit.html#SQLDatabaseToolkit```.
In general, at 2023-10-01 03:48:32 a user named Drogend said ```How would you go about that?```.
In general, at 2023-10-01 03:46:13 a user named mdfahad999 said ```Can we add SQL agent in autogen , which can connect with sqldb and we can do complex queries on it.```.
In general, at 2023-10-01 03:43:16 a user named vincentjedi said ```U can ask your skynet to build you a trading algorithm and do backtesting for you ?```.
In general, at 2023-10-01 03:32:15 a user named steevek_62832 said ```What is "multi-agent conversations" in  `AutoGen enables complex LLM-based workflows using multi-agent conversations.` . Do you mean that multiple LLM-based robots talk to each other to solve problem?```.
In general, at 2023-10-01 03:29:10 a user named steevek_62832 said ```Can I say autogen is something like agentGPT?```.
In general, at 2023-10-01 03:21:26 a user named iamhere said ```I feel so good right now, biggest accomplishment all week 🤣```.
In general, at 2023-10-01 02:41:37 a user named andyinater said ```Hey everyone, just dropped a thing https://discord.com/channels/1153072414184452236/1157869584901226586

Let me know what you think. I hope it inspires you to try using the method.```.
In general, at 2023-10-01 01:58:38 a user named nikoma said ```If you are using vllm sometimes timeouts are shown when the context is too large. Also, do you run it in openai compatible mode like this? python -m vllm.entrypoints.openai.api_server --model Xwin-LM/Xwin-LM-70B-V0.1```.
In general, at 2023-10-01 01:53:07 a user named kajatta said ```Note if you use the custom_tool the type error throws for non strings to do internal AutoGen Schema to function call. Should be easy to fix.```.
In general, at 2023-10-01 01:50:58 a user named kajatta said ``````Read the file with the path 'Test.txt', then calculate the circumference of a circle that has a radius of that files contents.

--------------------------------------------------------------------------------
chatbot (to user_proxy):

***** Suggested function Call: read_file *****
Arguments: 
{
  "file_path": "Test.txt"
}
**********************************************

--------------------------------------------------------------------------------

>>>>>>>> EXECUTING FUNCTION read_file...
user_proxy (to chatbot):

***** Response from calling function "read_file" *****
7.81mm
******************************************************

--------------------------------------------------------------------------------
chatbot (to user_proxy):

***** Suggested function Call: circumference_calculator *****
Arguments: 
{
  "radius": 7.81
}
*************************************************************

--------------------------------------------------------------------------------

>>>>>>>> EXECUTING FUNCTION circumference_calculator...
user_proxy (to chatbot):

***** Response from calling function "circumference_calculator" *****
49.071677249072565
*********************************************************************

--------------------------------------------------------------------------------
chatbot (to user_proxy):

The circumference of a circle with a radius of 7.81mm is approximately 49.071mm.

--------------------------------------------------------------------------------
user_proxy (to chatbot):



--------------------------------------------------------------------------------
chatbot (to user_proxy):

TERMINATE

--------------------------------------------------------------------------------
```
https://colab.research.google.com/gist/ElliotWood/af12566db5d6948e8ed6dd6324aa9697/autogen-langchain.ipynb (updated 1/10/2023)
@.princeps @sonichi - a Langchain Tools bridge example```.
In general, at 2023-10-01 01:49:09 a user named iamhere said ```this is what the workspace looks like```.
In general, at 2023-10-01 01:50:47 a user named sonichi said ```Sorry, could you check whether "AutoGen" is in the pip list?```.
In general, at 2023-10-01 01:52:52 a user named iamhere said ```absolutely, here is the results around AU```.
In general, at 2023-10-01 01:54:35 a user named sonichi said ```Do you have multiple python environments?```.
In general, at 2023-10-01 01:57:42 a user named iamhere said ```I'm not sure how to answer that. I don't believe so, but I've installed python many times over the past couple years tinkering here and ther```.
In general, at 2023-10-01 02:00:51 a user named iamhere said ```I want to say no, but I do think something is up with the python version(s) that might be on my computer.```.
In general, at 2023-10-01 02:03:35 a user named iamhere said ```the visual studio says we are on 3.10.    3.9.5 is what I told you though when you asked, per the terminal respons```.
In general, at 2023-10-01 02:24:26 a user named iamhere said ```pyautogen is actually in the pip list, I was looking for autogen per the module error. Sorry about that```.
In general, at 2023-10-01 03:03:40 a user named sonichi said ```In the Python version where you see pyautogen in the list, you should be able to import autogen```.
In general, at 2023-10-01 03:07:46 a user named iamhere said ```I think I got it, but I'm getting another error, if I did get it.

AttributeError: 'UserProxyAgent' object has no attribute 'inipytiate_chat'```.
In general, at 2023-10-01 03:15:46 a user named iamhere said ```I got it! we are installing the math packages! thank you for all of your help to this point.```.
In general, at 2023-10-01 01:41:58 a user named sonichi said ```Could you run `pip install pyautogen`? Please let me know if it fails.```.
In general, at 2023-10-01 01:40:04 a user named iamhere said ```its not on this list```.
In general, at 2023-10-01 01:36:11 a user named sonichi said ```could you run `pip list` and verify if pyautogen is in the list?```.
In general, at 2023-10-01 01:33:32 a user named iamhere said ```I believe so, I think I need to get the files from the git hub into my visual studio so it has a module(?) to work with.```.
In general, at 2023-10-01 01:29:35 a user named sonichi said ```has the `pip install` finished successfully?```.
In general, at 2023-10-01 01:26:10 a user named iamhere said ```I'm extremely new to all of this if you can't tell. How I made it here, is merely by exploring and staying curious and focused on what I'm wanting to accomplish```.
In general, at 2023-10-01 01:24:42 a user named iamhere said ```I just received this after going the quickstart and running this test file```.
In general, at 2023-10-01 01:22:53 a user named sonichi said ```That's weird because the dependency is small. Could you make sure the package name is `pyautogen` ?```.
In general, at 2023-10-01 01:20:27 a user named iamhere said ```I actually remembered what happened, during the installation process it seemed like it froze or something. It was taking a really long time```.
In general, at 2023-10-01 01:18:03 a user named kenfucius5452 said ```Yes I have the package installed. This is the example I was following which led to the error. This is my first time using Autogen so everything's completely new to me but that generate_code_execution_reply function looks like exactly what I need!```.
In general, at 2023-10-01 01:17:52 a user named iamhere said ```Let me try again. A new day with some fresh energy might do the trick. thanks for showing me this```.
In general, at 2023-10-01 01:16:06 a user named sonichi said ```have you installed the pyautogen package? have you checked this part: https://github.com/microsoft/autogen#quickstart```.
In general, at 2023-10-01 01:13:27 a user named sonichi said ```You can register a reply function with `register_reply`. And in that function, you call the built-in `generate_code_execution_reply` and filter its result.```.
In general, at 2023-10-01 01:11:32 a user named sonichi said ```some filtering can be done before this line: https://github.com/microsoft/autogen/blob/904b293aa47c0e87e27e127254ce4f17a391048c/autogen/agentchat/conversable_agent.py#L632C45-L632C45```.
In general, at 2023-10-01 01:10:09 a user named kenfucius5452 said ```I guess one workaround would be to pass human input, specifying that I will install the required library and then the user_proxy can execute the code 🤔```.
In general, at 2023-10-01 01:07:06 a user named kenfucius5452 said ```That ran fine. But then, the user_proxy sends the entire code execution back to the assistant which is very verbose. It's 120+ lines of downloading and installing requirements. I checked the token length of that message which is 4839 and over the max for 3.5-turbo, hence the error. I wonder if there's a workaround to this type of prompting where we can make the output of installing requirements much less verbose to keep the token length shorter.```.
In general, at 2023-10-01 01:05:36 a user named iamhere said ```I would love to get started with this. Just not sure how.```.
In general, at 2023-10-01 01:04:06 a user named kenfucius5452 said ```Ah, I think I understand why. This is the assistant to user_proxy prompt just before the error:

assistant (to user_proxy):

It seems that the `yfinance` library is not installed. Please try installing it by running the following command in your Python environment:

```
pip install yfinance
```

After installing the `yfinance` library, you should be able to execute the code successfully.```.
In general, at 2023-10-01 00:55:10 a user named sonichi said ```Good point. This example is not that "simple" for 3.5-turbo. @bansalg do you know a simpler but still interesting example that works w/ 3.5-turbo?```.
In general, at 2023-10-01 00:50:39 a user named kenfucius5452 said ```I know GPT4 has the longer context length, I just thought the simple example would work on 3.5-turbo```.
In general, at 2023-10-01 00:49:01 a user named sonichi said ```I just tried with gpt-4 and it worked. Are you using gpt-3.5-turbo?```.
In general, at 2023-10-01 00:33:19 a user named kenfucius5452 said ```I ran into the error below when running the typical Autogen example, "Plot a chart of NVDA and TESLA stock price change YTD.". Have others ran into this too? I would think the example Autogen themselves use would work out of the box.

"InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 8661 tokens. Please reduce the length of the messages."```.
In general, at 2023-09-30 23:27:39 a user named kajatta said ```Are we looking for memory as in (chat history) or memory as in a Knowledge base?```.
In general, at 2023-09-30 21:10:16 a user named .princeps said ```So I'll ease off on those```.
In general, at 2023-09-30 21:10:05 a user named .princeps said ```I was really loosing my mind @sonichi```.
In general, at 2023-09-30 21:09:35 a user named sonichi said ```there is one PR to fix a bug: https://github.com/microsoft/autogen/pull/52```.
In general, at 2023-09-30 21:08:42 a user named tonic_1 said ```It gets super expensive with infinite loops if you let it```.
In general, at 2023-09-30 21:08:19 a user named nachos.ai said ```Aurora, I think we should aim for gpt-3.5 and only let gpt-4 plan/manage things.
Maybe use gpt-3.5 with training for specific roles.

Do you know if we have instruct models support? (Non-chat)```.
In general, at 2023-09-30 21:05:32 a user named au8 said ```Well I appreciate the feedback, looks like I'm stuck with open source 😄```.
In general, at 2023-09-30 21:04:02 a user named jartan said ```I've only been playing around with it for a hour or so, and I've used 2$. And I can handly get it to work, so I'm a bit fearful of when I do get it to actually function properly.```.
In general, at 2023-09-30 21:03:34 a user named au8 said ```for someone who is doing it as a hobby```.
In general, at 2023-09-30 21:03:23 a user named au8 said ```That is my fear. Autogen + GPT-4 = big OpenAI costs```.
In general, at 2023-10-26 21:58:03 a user named karlka said ```Hey @au8 read through the discord and it got my eye that you're worried about the pricing of autogen agents with OAI gpt's..

Have you tried any alternative solutions already that suit your needs?

If not, we are currently working on an agent cloud that reduces the cost of running agents by 10x. Let me know if that would be valuable for you. We are currently onboarding a limited set of early devs to collaborate on the design with.```.
In general, at 2023-09-30 21:02:06 a user named jartan said ```Yes if you use API, no if you use the ChatGPT website for 20$/month.```.
In general, at 2023-09-30 21:00:46 a user named .princeps said ```Show me the last think on your terminal ?```.
In general, at 2023-09-30 21:00:41 a user named au8 said ```If you don't mind me asking, do you find ChatGPT-4 expensive if you use it for personal use? I'm trying to work out if I just start spending XX/month to use it but I'm scared costs could spiral out of control```.
In general, at 2023-09-30 20:59:04 a user named .princeps said ```You on Mac or windows?```.
In general, at 2023-09-30 20:58:25 a user named jartan said ```I presume that's what you meant.```.
In general, at 2023-09-30 20:58:19 a user named jartan said ```Added back the OAI stuff. No change```.
In general, at 2023-09-30 20:56:37 a user named .princeps said ```Can you track how many tokens you use? Someone asked me```.
In general, at 2023-09-30 20:55:47 a user named jartan said ```Except OAI file I removed all the unused ones.```.
In general, at 2023-09-30 20:54:46 a user named .princeps said ```Did you change anything ?```.
In general, at 2023-09-30 20:53:58 a user named jartan said ```Maybe I need to run in administrator mode? 🤔```.
In general, at 2023-09-30 20:53:46 a user named jartan said ```@.princeps I was trying out your snake game project, but I'm encountering this problem. Do you know what I need to adjust?```.
In general, at 2023-09-30 20:30:15 a user named .princeps said ```It's the number of last messages the agent should look at, for code executors, I wanted them to look back to more messages for context```.
In general, at 2023-09-30 20:29:20 a user named jartan said ```Could you explain to me what last_n_messages does and why you would raise it on some agents and not others, please?```.
In general, at 2023-09-30 20:20:19 a user named nachos.ai said ```I'll take a look.
Going to tweak your snake game into my new team, then give them maybe shared memory. (With fields, we can give personal, public-personal and public memory - groups need to be re-evaluated)

Don't wait for me, though. I'm balancing this between different projects at work and their priorities.```.
In general, at 2023-09-30 20:16:46 a user named .princeps said ```However, I haven't got these agents to work, anyone have any luck```.
In general, at 2023-09-30 20:16:28 a user named .princeps said ```@nachos.ai the only thing I'm aware off it this: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb```.
In general, at 2023-09-30 20:15:16 a user named nachos.ai said ```@.princeps Am also interested in agent shared memory - how does new features work?
Can I work on a feature on my repo and suggest merge back?```.
In general, at 2023-09-30 20:13:13 a user named .princeps said ```I got some topics up too you can checkout```.
In general, at 2023-09-30 20:12:38 a user named .princeps said ```Yeah, I have some projects on the <#1157447399044821132>```.
In general, at 2023-09-30 20:10:36 a user named jartan said ```Anyone able to provide a simple example of using Autogen with 3+ agents at one time?```.
In general, at 2023-09-30 20:07:53 a user named .princeps said ```Figure out how to do memory```.
In general, at 2023-09-30 20:06:10 a user named .princeps said ```I need to setup the agents with shared memory```.
In general, at 2023-09-30 20:05:52 a user named .princeps said ```Anyone got the retriever agents working ?```.
In general, at 2023-09-30 19:49:33 a user named nachos.ai said ```Anyone noticed this Emotional Prompting from the examples?
"I think we all remember that feeling when the result of some long-awaited event is finally known. The feelings and thoughts you have at that moment are definitely worth noting down and comparing." 
Feels like next-level emotional prompting (to me)

Also, I tried autogen for the first time yesterday and filled with anticipation!
Came right on time for my (model-) team building

Kudos!```.
In general, at 2023-09-30 18:23:07 a user named giano.bifronte said ```Hi people. Just a quick shout-out to the Autogen team for the phenomenal job. I have been waiting for the technology to reach this point since GTP-2. 

I author a business-focused newsletter on the impact of AI on jobs, productivity, and operations, and will feature Autogen in the new issue out tomorrow. 

Thanks @sonichi and the rest of the team.```.
In general, at 2023-09-30 18:11:54 a user named kvnn8 said ```Does anyone have a detailed breakdown of Autogen vs. Langchain vs. SuperAGI ? It seems like people here are definitely using Langchain with Autogen?```.
In general, at 2023-09-30 16:31:18 a user named tonic_1 said ```forget codellama , enter mistral```.
In general, at 2023-09-30 16:27:18 a user named andyinater said ```text file is single line, looks like "Memory/thought 1| Memory 2| Memory 3|" etc...```.
In general, at 2023-09-30 16:26:53 a user named andyinater said ```the real magic is in very careful function and parameter descriptions, and system prompts that, in a painstakingly verbose way, explain how I/You want it to use the tools/memory```.
In general, at 2023-09-30 16:26:31 a user named ffund said ```Great Idea! What's the general structure??```.
In general, at 2023-09-30 16:25:31 a user named andyinater said ```I am working on that right now, with some great looking progress. I'm hoping to upload a good example in the <#1156574905773596712>  tonight. But to give you an idea, I'm using text files and function calls - just very basic but it does seem to be good so far.```.
In general, at 2023-09-30 15:22:09 a user named salegrem said ```Hey guys, hope someone could help me out with some setup stuff real quick. I'm probably doing something dumb. Here's the issue link:

https://discord.com/channels/1153072414184452236/1157697278530834532```.
In general, at 2023-09-30 14:38:13 a user named felly007. said ```Has anyone added memory/database to autogen yet?```.
In general, at 2023-09-30 14:29:20 a user named .princeps said ```I see, I'll try it once I'm done```.
In general, at 2023-09-30 14:26:08 a user named kajatta said ```Yeah - this can break if type isn't right for example str vs string
"Add properties based on the tool's args_schema"```.
In general, at 2023-09-30 14:23:55 a user named tonic_1 said ```xD codellama autoreply + away from office emails ftw 🚀```.
In general, at 2023-09-30 13:59:34 a user named kajatta said ```Yeah definitely, it's all very exciting and new. Time to retire soon I think```.
In general, at nan a user named tonic_1 said ```using unstructured and webscrappers alone is a big deal to me lol```.
In general, at 2023-09-30 13:54:00 a user named kajatta said ```It maps Langchain tools to AutoGen functions so agents can use them to solve problems```.
In general, at 2023-09-30 13:53:58 a user named .princeps said ```did you run this ?```.
In general, at 2023-09-30 13:53:58 a user named tonic_1 said ```folks really click when you show them something they can understand```.
In general, at 2023-09-30 13:53:48 a user named tonic_1 said ```yes that would actually be really hot```.
In general, at 2023-09-30 13:53:34 a user named tonic_1 said ```if someone sees this and drops credits i use bing directly lol```.
In general, at 2023-09-30 13:53:28 a user named .princeps said ```@tonic_1 I'll put all this into a marketing team that I can share```.
In general, at 2023-09-30 13:53:22 a user named tonic_1 said ```yeah so far i'm heavy on langchain using serp... i want a bit more though, have been thinking about a custom serp / google search agent```.
In general, at 2023-09-30 13:52:49 a user named .princeps said ```function calling and also internet```.
In general, at 2023-09-30 13:52:23 a user named tonic_1 said ```this would bring langchain to autogen or autogen to langchain actually?```.
In general, at 2023-09-30 13:49:48 a user named kajatta said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In general, at 2023-09-30 13:47:21 a user named kajatta said ```This should work with most Langchain tools - i used the read file tool as an example```.
In general, at 2023-09-30 13:46:51 a user named kajatta said ``````
from langchain.tools.file_management.read import ReadFileTool

def generate_llm_config(tool):
    function_schema = {
        "name": tool.name.lower().replace (' ', '_'),
        "description": tool.description,
        "parameters": {
            "type": "object",
            "properties": {},
            "required": [],
        },
    }
    if tool.args is not None:
      function_schema["parameters"]["properties"] = tool.args
    return function_schema

read_file_tool = ReadFileTool()
custom_tool = CircumferenceTool()

# Construct the llm_config
llm_config = {
  "functions":[
      #generate_llm_config(custom_tool), # ERROR: this one fails becuase - Invalid schema for function 'circumference_calculator': 'float' is not valid under any of the given schemas
      generate_llm_config(read_file_tool),
  ],
  "config_list": config_list,  # Assuming you have this defined elsewhere
  "request_timeout": 120,
}
user_proxy.register_function(
    function_map={
        #custom_tool.name: custom_tool._run,  # ERROR: this one fails becuase - Invalid schema for function 'circumference_calculator': 'float' is not valid under any of the given schemas
        read_file_tool.name: read_file_tool._run,
    }
)
``````.
In general, at 2023-09-30 13:43:17 a user named vincentjedi said ```Have u chosen which llm are used for different agents?```.
In general, at 2023-09-30 13:41:00 a user named tonic_1 said ```hope you're happy been driving me nuts for 15 minutes```.
In general, at 2023-09-30 13:40:51 a user named tonic_1 said ```i'm honestly stuck on (from flaml import autogen) on that notebook ^^```.
In general, at 2023-09-30 13:40:28 a user named tonic_1 said ```for function calling you mean?```.
In general, at 2023-09-30 13:38:26 a user named .princeps said ```@tonic_1 you should know this too```.
In general, at 2023-09-30 13:37:01 a user named .princeps said ```the reason I was on this is so that I can get a small marketing team going and so I needed to have a tool agent and an internet agent```.
In general, at 2023-09-30 13:36:30 a user named .princeps said ```Well it has internet access and you can also make it work with function calling so I think you can setup external tools use```.
In general, at 2023-09-30 13:36:15 a user named fxtoofaan said ```Thank you. My fresh Ubuntu just booted up. Let me set it up```.
In general, at 2023-09-30 13:35:50 a user named .princeps said ```here is a file for you```.
In general, at 2023-09-30 13:35:49 a user named fxtoofaan said ```So what does that mean now ? It can use any external tool ?```.
In general, at 2023-09-30 13:35:24 a user named .princeps said ```you just have to use the old library through `from flaml import autogen````.
In general, at 2023-09-30 13:34:55 a user named .princeps said ```@fxtoofaan I got it to work, I repeat, autogen agents have internet```.
In general, at 2023-09-30 13:21:22 a user named tonic_1 said ```I’ll give you access to it too```.
In general, at 2023-09-30 13:20:23 a user named felly007. said ```awesome, thanks. And joined 🙂```.
In general, at 2023-09-30 13:18:17 a user named tonic_1 said ```Hey there’s a GitHub yeah on @.princeps GitHub also there’s a hugging face org you can join and please do so actually```.
In general, at 2023-09-30 13:17:32 a user named felly007. said ```is there a github repo for this project?```.
In general, at 2023-09-30 13:15:15 a user named fxtoofaan said ```That’s good to know 👍```.
In general, at 2023-09-30 13:14:54 a user named .princeps said ```Can I just got it to call my function with Claude so I think we can setup function calling for other tools```.
In general, at 2023-09-30 13:14:18 a user named .princeps said ```we might still have it work with autogen, let me test the internet access through  `flaml import autogen````.
In general, at 2023-09-30 13:13:36 a user named fxtoofaan said ```Maybe operate it using telegram chat 🙂```.
In general, at 2023-09-30 13:13:12 a user named fxtoofaan said ```Anything else to add to that?```.
In general, at 2023-09-30 13:12:55 a user named fxtoofaan said ```User->execute python script->spawn agents that have access to internet, tools, knowledge base, local llm(s) and gptx, short and long term memory.```.
In general, at 2023-09-30 13:12:43 a user named tonic_1 said ```I’ll take a look at that notebook too yeah - I think @kajatta is on the right though … unfortunately```.
In general, at 2023-09-30 13:11:48 a user named .princeps said ```function calling works but you have to use ` flaml import autogen````.
In general, at 2023-09-30 13:10:25 a user named kajatta said ```Ill take a look at options```.
In general, at 2023-09-30 13:10:08 a user named tonic_1 said ```Seems very much necessary actually ?```.
In general, at 2023-09-30 13:10:05 a user named kajatta said ```Its really the Toolkits/tools that are valuable - everything else has parody```.
In general, at 2023-09-30 13:09:31 a user named kajatta said ```Or more appropriately the other way around```.
In general, at 2023-09-30 13:09:02 a user named kajatta said ```Effectively we want to do https://python.langchain.com/docs/use_cases/more/agents/agents/camel_role_playing but swap Camel out for Autogen```.
In general, at 2023-09-30 13:08:08 a user named cryptofekt said ```Anyone else thinking about 📎 ?```.
In general, at 2023-09-30 13:07:55 a user named fxtoofaan said ```Don’t forget some kind of local intellectual property knowledge or vector db. Maybe separate db for each agent ?```.
In general, at 2023-09-30 13:07:00 a user named tonic_1 said ```so yeah, seems useful ^^```.
In general, at 2023-09-30 13:06:54 a user named tonic_1 said ```nope... was totally wrong about that, my appologies```.
In general, at 2023-09-30 13:06:29 a user named tonic_1 said ```pretty sure there's langchain / autogen , no ?```.
In general, at 2023-09-30 13:05:20 a user named fxtoofaan said ```I think vllm server has langchain capability or connections built n```.
In general, at 2023-09-30 13:04:50 a user named kajatta said ```We should write a toolchain bridge to Langchain so we can inherit 35+ tools/integrations```.
In general, at 2023-09-30 13:02:36 a user named tonic_1 said ```you can see it yourself and run it on your computer 👊🏻 it's command line```.
In general, at 2023-09-30 13:02:09 a user named kajatta said ```Nice have you got screenshot of outputs?```.
In general, at 2023-09-30 12:55:19 a user named jasonzhou1993 said ```Hey team - what does "messages=[]" do for groupchat?```.
In general, at 2023-09-30 12:55:02 a user named .princeps said ```Have I setup up seomthing wrong ?```.
In general, at 2023-09-30 12:54:42 a user named .princeps said ```@tonic_1 or @sonichi does the web one work, I have been trying it but it's retrieving information correctly```.
In general, at 2023-09-30 12:56:19 a user named .princeps said ```@tonic_1 I just want to setup an agent with internet so I want to see if you or someone else has got this working outside the notebook```.
In general, at 2023-09-30 12:56:42 a user named tonic_1 said ```i would use the serp tool in langchain for that```.
In general, at 2023-09-30 12:59:01 a user named .princeps said ```Yeah I can do it with langchain but  this notebook says that we can, and I did run it and it worked once but when I moved the agent to a new script it stopped working 

https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.
In general, at 2023-09-30 13:02:13 a user named tonic_1 said ```i actually just tried the same notebook and it's not importing autogen even, so ...```.
In general, at 2023-09-30 13:04:43 a user named .princeps said ```hmm maybe moving on autogen from flaml may  have caused some issues```.
In general, at 2023-09-30 13:04:57 a user named tonic_1 said ```ah hahahaha it's totally that```.
In general, at 2023-09-30 13:05:24 a user named tonic_1 said ```how many times a month has this been happening the last ten months?? a million times maybe```.
In general, at 2023-09-30 13:12:40 a user named .princeps said ```@tonic_1 so seems like I was right, function calling works but only if you import it like this ` flaml import autogen````.
In general, at 2023-09-30 13:12:47 a user named .princeps said ```Let me test the internet```.
In general, at 2023-09-30 12:43:19 a user named vincentjedi said ```Anyone has tried out llama2 long yet ?```.
In general, at 2023-09-30 12:42:07 a user named vincentjedi said ```https://venturebeat.com/ai/meta-quietly-releases-llama-2-long-ai-that-outperforms-gpt-3-5-and-claude-2-on-some-tasks/```.
In general, at 2023-09-30 12:29:39 a user named tonic_1 said ```i threw up @.princeps tutorial here : https://huggingface.co/spaces/MultiTransformer/snake_by_princepspolycap if you're making something you want to share we can host it in the community 🚀```.
In general, at 2023-09-30 12:12:20 a user named fxtoofaan said ```I think for now an os where I can setup fastest llm server that can serve any open source llm model and also support openai api. Then I’ll have a local llm server and use my MacBook to test front end apps like autogen```.
In general, at 2023-09-30 12:02:23 a user named vincentjedi said ```Running everything in docker is ideal. But coding all the dockerfiles may take you a while.```.
In general, at 2023-09-30 11:33:09 a user named .princeps said ```@fxtoofaan what are you trying to achieve, so I'm hopping into this late```.
In general, at 2023-09-30 11:23:34 a user named fxtoofaan said ```so what you guys suggest? setup ubuntu with docker and run all my stufff inside docker on ubuntu or use conda virtual environemnts for various AI/ML projects or just install stuff natively in ubuntu? which you guys use or prefer?```.
In general, at 2023-09-30 11:15:57 a user named fxtoofaan said ```I am redoing my AI machine and installing ubuntu this time instead of windows. lets see if all my problems will go away```.
In general, at 2023-09-30 10:59:57 a user named au8 said ```I believe you’ll also need cuda 11.8```.
In general, at 2023-09-30 10:58:29 a user named au8 said ```Use docker or native Linux```.
In general, at 2023-09-30 10:58:19 a user named au8 said ```I don’t think that you can build the vllm wheel on windows, I had the same issue.```.
In general, at 2023-09-30 10:33:13 a user named fxtoofaan said ```I’m only able to use fastchat for one agent conversation. The moment I add another agent I get timeout errors. Not sure if it’s a config somewhere or fastchat server. So wanted to try vllm server to test```.
In general, at 2023-09-30 10:32:04 a user named fxtoofaan said ```That’s what I have too```.
In general, at 2023-09-30 10:32:02 a user named vincentjedi said ```Is fastchat not fast enough ?```.
In general, at 2023-09-30 09:56:26 a user named jimmysandwiches said ```Try this, it’s what I’m running - https://learn.microsoft.com/en-us/windows/wsl/install```.
In general, at 2023-09-30 09:43:33 a user named fxtoofaan said ```I’ll try all that. Thank you. I’m wondering if I should just format my windows machine and install Ubuntu instead.```.
In general, at 2023-09-30 09:12:35 a user named jimmysandwiches said ```Here are a few suggestions for troubleshooting the CUDA runtime not found error when installing vllm:

Make sure you have a compatible Nvidia GPU and the Nvidia drivers installed. vllm requires CUDA which only works with Nvidia GPUs.
Check that you have the CUDA toolkit installed and the CUDA_HOME environment variable set properly. The error message indicates it's pointing to v11.7 which is good, but double check the path.
Try installing an older version of vllm that may have better CUDA support, like pip install vllm==0.5.1
Install CUDA separately first by downloading it from the Nvidia website and running the installer. Then retry installing vllm.
Use a vllm Docker image which has CUDA and the drivers pre-configured.
Make sure your pip and setuptools are up to date. Try pip install pip setuptools --upgrade first.
Try a different command like pip wheel vllm to build the wheel before installing.
Check your CMake version is 3.8 or later for CUDA support.
If it's still not working, look at the full error logs for more details on what CUDA component is missing. You may need to configure CUDA_HOME to point to the Nvidia install folder or install additional Nvidia runtime libraries.```.
In general, at 2023-09-30 08:49:38 a user named fxtoofaan said ```I know this is not server for vllm but I wonder if anyone else having issue installing vllm server from pip install vllm. I am getting the following error..

No CUDA runtime is found, using CUDA_HOME='C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7'

ERROR: Could not build wheels for vllm, which is required to install pyproject.toml-based projects```.
In general, at 2023-09-30 07:41:46 a user named vincentjedi said ```It seems they are still writing the dockerfile for autogen...```.
In general, at 2023-09-30 07:31:36 a user named scratchinknight said ```has anyone used autogen with used_docker not sure how to get it working?```.
In general, at 2023-09-30 06:17:24 a user named andyinater said ```oh, and be sure the function returns something, and mention in the descriptions what it should expect to return. I am not certain that it sees all terminal outputs like print()```.
In general, at 2023-09-30 06:13:58 a user named andyinater said ```The description of the function and it's parameters that you pass in are shown to the agent, so if you make a function called search_google(search_string) and give it discriptive definitions for what the function does and what the parameter is, when the idea of googling something comes up in the dialog, it should see the opportunity to use a tool on its belt```.
In general, at 2023-09-30 06:10:16 a user named andyinater said ```I have just been working on this and think I have some good advice.

The agents are very capable, but making them generate api calls can be hit or miss, as you are likely experiencing. It is better to hardcode these things and put them on a toolbelt for the agent to consider using, instead of consider generating to use. I have been writing functions in my main file and using the "functions" paramter in the llm_config for the agent who will *decide* to use the tools.

This example from the autogen docs helped: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb```.
In general, at 2023-09-30 06:04:27 a user named benbot said ```Hey all, what's the best way to give agents access to tools?

Say I wanted an agent to search google and/or make some calls to llamaindex.

How should i go about that```.
In general, at 2023-09-30 04:21:28 a user named .princeps said ```Yes, you need to request access, I had to request access too```.
In general, at 2023-09-30 02:41:04 a user named haharvs said ```Is there ways to deploy a UI for it, maybe as simple as using gradio?```.
In general, at 2023-09-30 00:18:02 a user named tonic_1 said ```If it’s a deployment on azure it could be that you need to request increases , if not … the mystery continues …🤔🤔```.
In general, at 2023-09-30 00:16:54 a user named andyinater said ```I'm only trying to use 4k 😭```.
In general, at 2023-09-30 00:11:22 a user named tonic_1 said ```Could be related to your access of gpt32k , I had to request increases - if it’s not that it’s a mystery to me 🤷🏻‍♂️👊🏻```.
In general, at 2023-09-30 00:04:29 a user named andyinater said ```Did anyones openAI API rate limits change? My limit on requests per minute is 3 right now, and it is throwing errors for hitting that rate limit. I ran the same workflows yesterday without any issues.```.
In general, at 2023-09-29 23:58:58 a user named bansalg said ```Based on the feedback in forums we created a new channel

https://discord.com/channels/1153072414184452236/1157447399044821132```.
In general, at 2023-09-29 23:49:18 a user named tonic_1 said ```i mean using langchain you can call tools... let's figure it out```.
In general, at 2023-09-29 23:48:57 a user named tonic_1 said ```import langchain , then run a function, then pass the data to the agent, agents can maybe call tools , like on langchain```.
In general, at 2023-09-29 23:47:37 a user named shinypickel said ```ah okay, need to wrap my head around how to get the agents to call langchain```.
In general, at 2023-09-29 23:42:50 a user named tonic_1 said ```Not yet now - normally it’s fine though just use both as normal 🤷🏻‍♂️```.
In general, at 2023-09-29 23:15:57 a user named jasonzhou1993 said ```Does anyone had this error?

"""ImportError:** cannot import name 'AssistantAgent' from partially initialized module 'autogen' (most likely due to a circular import) **(/Users/jasonzhou/Desktop/autogen/autogen.py)"""```.
In general, at 2023-09-29 23:06:43 a user named tonic_1 said ```you can use langchain , yes```.
In general, at 2023-09-29 22:31:39 a user named shinypickel said ```Possible to give Autogen internet access?```.
In general, at 2023-09-29 21:59:24 a user named fxtoofaan said ```I would love to make a killer newsletter with it 🙂```.
In general, at 2023-09-29 21:56:19 a user named you.wish said ```anybody managed to make a good fictin novel with it or a video game?```.
In general, at 2023-09-29 21:02:41 a user named avi12 said ```Hey, is there an online version of AutoGen that I can try out? I don't really want to mess with local installs```.
In general, at 2023-09-29 20:50:36 a user named au8 said ```mistral provide a docker image to get it up and working asap```.
In general, at 2023-09-29 20:50:28 a user named au8 said ```If you have a good machine and can run vLLM it will definitely be worth trying```.
In general, at 2023-09-29 20:46:10 a user named fxtoofaan said ```I am trying to see if I change the api server from fastchat to vllm if that will help,```.
In general, at 2023-09-29 20:45:45 a user named fxtoofaan said ```lol its a race 🙂```.
In general, at 2023-09-29 20:45:25 a user named au8 said ```You're probably ahead of me by now @fxtoofaan 😄```.
In general, at 2023-09-29 20:39:55 a user named tonic_1 said ```your computer is probably not strong enough for what you're trying to do homie```.
In general, at 2023-09-29 20:38:50 a user named au8 said ```well it's running the example about the TSLA stock:```.
In general, at 2023-09-29 20:37:57 a user named fxtoofaan said ```you able to use multiple agents with local llm ?```.
In general, at 2023-09-29 20:37:18 a user named au8 said ```@fxtoofaan So I have it working with an open source LLM. I couldnt run Mistral because my laptop couldn't handle it and vLLM needed more so instead I'm running a different model with FastChat```.
In general, at 2023-09-29 20:10:02 a user named fxtoofaan said ```@amadad are you able to run your code on local llm instead of chatgpt ?```.
In general, at 2023-09-29 20:07:56 a user named fxtoofaan said ```Quick feedback on the local llm and autogen. If I have a single agent and use local llm everything is fine. If I use more than 1 agent and use group chat I get timeout error. I’ve tried even 900 seconds for timeout and after 15 minutes I get time out error. I wonder where the issue is```.
In general, at 2023-09-29 19:58:11 a user named bansalg said ```I ve kinda been out of it for a couple```.
In general, at 2023-09-29 19:58:07 a user named tonic_1 said ```i'm trying to find all the cool autogen tutorials / examples from the community and put them here : https://huggingface.co/spaces/MultiTransformer/autogen-tutorials so far , there's only the notebooks and one community example, so if you're happy to share consider adding it to the collection 👊🏻```.
In general, at 2023-09-29 19:46:33 a user named bansalg said ```Ali, what was your experince like with this port? Any key differences you observed that you found helpful?```.
In general, at 2023-09-29 19:21:59 a user named bansalg said ```**Based on the feedback in the forum we created as new issues-and-help forum**

https://discord.com/channels/1153072414184452236/1157397569375309864```.
In general, at 2023-09-29 19:17:35 a user named pbharrin said ```When code or other artifacts are created such as the stock plotting Python code in `twoagent.py` do these artifacts get saved somewhere?  I'm asking because it would be helpful to know where the code lives if I want to modify it.```.
In general, at 2023-09-29 19:23:15 a user named bansalg said ```In the work_dir. In the example below work_dir is set to "coding"

user_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding"})```.
In general, at 2023-09-29 19:13:49 a user named fxtoofaan said ```you interested in local LLM perhaps? I am playing with the fastchat api server and Mistral-7B-v0.1```.
In general, at 2023-09-29 19:12:32 a user named amadad said ```Perhaps...but I'm not acquainted with that. Can you share any links?```.
In general, at 2023-09-29 18:57:19 a user named fxtoofaan said ```@amadad  would you be able to connect this to petals api server?```.
In general, at 2023-09-29 18:51:17 a user named amadad said ```Thanks! Struggled with some of the examples, and wanted to share something...once I figured it out.```.
In general, at 2023-09-29 18:50:49 a user named daninvirtualreality said ```Yeah, I agree - having joined all of a few minutes ago, seeing something like this is extremely instructive!```.
In general, at 2023-09-29 18:50:08 a user named fxtoofaan said ```wow thank you @amadad . its good to see actual code and everything in a single python file 🙂```.
In general, at 2023-09-29 18:47:10 a user named amadad said ```Ported over my mini-creative agency from ChatDev to Autogen, no polish or detail yet, but it is working: https://github.com/amadad/agentcy/```.
In general, at 2023-09-29 17:29:56 a user named tonic_1 said ```the beebot is the benchmark to beat on autogtp hackathon : we could make a submission using autogen ?```.
In general, at 2023-09-29 17:22:45 a user named ffund said ```Here's the GitHub repo for Beebot

https://github.com/AutoPackAI/beebot```.
In general, at 2023-09-29 17:19:37 a user named tonic_1 said ```i just added the notebooks to a space on huggingface so you can run them directly from there too : https://huggingface.co/spaces/MultiTransformer/autogen-tutorials/tree/main hope you put all the experiments in the collection and join the org 👊🏻```.
In general, at 2023-09-29 17:18:44 a user named salegrem said ```I've kinda been out of it for a couple of months and I'm not even able to get autogen running. Does anyone know why I'm getting an "No API key provided" error when I have an env variable in json, a json file, and literally put it on the llm config```.
In general, at 2023-09-29 19:58:12 a user named bansalg said ```Please feel free to create a post here with more deets so that we can help better 🙂 https://discord.com/channels/1153072414184452236/1157397569375309864```.
In general, at 2023-09-29 17:18:21 a user named pkscary said ```believe beebot is currently the most effective agent-based platform. however, after autogpt's hackathon, that may change.```.
In general, at 2023-09-29 17:17:26 a user named salegrem said ```Nope, this is the third one I'm trying to try. Was also using another one on Hugging Face but forgot it's name```.
In general, at 2023-09-29 17:15:56 a user named salegrem said ```Also very dumb and would constanly fall into loops```.
In general, at 2023-09-29 17:15:42 a user named salegrem said ```AutoGPT felt very expensive when I was using it```.
In general, at 2023-09-29 17:15:14 a user named fxtoofaan said ```updated: manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={"config_list": config_list})

still same error:
ValueError: dictionary update sequence element #0 has length 1; 2 is required```.
In general, at 2023-09-29 17:18:38 a user named sonichi said ```The config_list needs to be a list. Or, if you want to use a dict, then just set llm_config=the_dict```.
In general, at 2023-09-29 17:19:36 a user named sonichi said ```llm_config is a dict. If you have a single config dict to use, simply set llm_config to that dict. If you have more than one dicts, put them in a list and set llm_config={"config_list": config_list}```.
In general, at 2023-09-29 17:20:10 a user named fxtoofaan said ```i just need help with the start part of the python script to conenct with the local LLM. 


import autogen
from autogen import AssistantAgent, UserProxyAgent, oai

config_list = (
    {
        "model": "Mistral-7B-v0.1",
        "api_base": "http://localhost:8000/v1",
        "api_type": "open_ai",
        "api_key": "NULL", # just a placeholder
    }
)

messages=[{"role": "user", "content": "hi"}]

response = oai.ChatCompletion.create(
    prompt="hi",
    messages=messages,
    config_list=config_list
)

print(response)```.
In general, at 2023-09-29 17:20:30 a user named fxtoofaan said ```what should I replace the top section with please? can you copy paste it ?```.
In general, at 2023-09-29 17:21:12 a user named sonichi said ```config_list = [
    {
        "model": "Mistral-7B-v0.1",
        "api_base": "http://localhost:8000/v1",
        "api_type": "open_ai",
        "api_key": "NULL", # just a placeholder
    }
]```.
In general, at 2023-09-29 17:21:16 a user named fxtoofaan said ```for my simplicity sake I like to keep everything in a single python file if possible instead of calling json files for config_list```.
In general, at 2023-09-29 17:21:47 a user named fxtoofaan said ```what about this part?

messages=[{"role": "user", "content": "hi"}]

response = oai.ChatCompletion.create(
    prompt="hi",
    messages=messages,
    config_list=config_list
)

print(response)```.
In general, at 2023-09-29 17:24:49 a user named fxtoofaan said ```Let me try it 👍```.
In general, at 2023-09-29 17:40:15 a user named vincentjedi said ```Are you using fastchat as the llm server ?```.
In general, at 2023-09-29 17:49:38 a user named vincentjedi said ```Will u try vllm to replace fastchat ?```.
In general, at 2023-09-29 17:50:26 a user named fxtoofaan said ```ok os using [] instead of () worked. thank you @sonichi```.
In general, at 2023-09-29 17:50:40 a user named fxtoofaan said ```i never used vllm, does it work on windows 10 ?```.
In general, at 2023-09-29 17:54:53 a user named vincentjedi said ```U use Nvidia GPU to run it ?```.
In general, at 2023-09-29 17:55:32 a user named vincentjedi said ```How is the inference speed ?```.
In general, at 2023-09-29 17:56:08 a user named vincentjedi said ```How much vram do you have ?```.
In general, at 2023-09-29 17:57:07 a user named vincentjedi said ```My Nvidia GPU only has 4gb vram. So I think i am going to use cpu only ..```.
In general, at 2023-09-29 17:13:37 a user named sonichi said ```manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=config_list) -> llm_config={"config_list": config_list}```.
In general, at 2023-09-29 17:12:07 a user named fxtoofaan said ```so I am trying to make this work. Here is my python file and error I am getting. cant seem to make the local llm work with autogen. what am i doing wrong in the python file ?

from autogen import AssistantAgent, UserProxyAgent, oai
import autogen
import openai

config_list = (
    {
        "model": "Mistral-7B-v0.1",
        "api_base": "http://localhost:8000/v1",
        "api_type": "open_ai",
        "api_key": "NULL", # just a placeholder
    }
)

messages=[{"role": "user", "content": "hi"}]

response = oai.ChatCompletion.create(
    model="Mistral-7B-v0.1",
    api_key = "1234567890",
    #"api_key": "NULL", 
    prompt="hi",
    temperature=0.4,
    max_tokens=1024, 
    stop=".",
    messages=messages,
    config_list=config_list
)

print(response)

# create an AssistantAgent instance named "assistant"
assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config_list}
    )

# create a UserProxyAgent instance named "user_proxy"
user_proxy = UserProxyAgent(
    name="user_proxy",
    llm_config={"config_list": config_list}
    )

groupchat = autogen.GroupChat(agents=[assistant, user_proxy], messages=[], max_round=50)
manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=config_list)

# the assistant receives a message from the user, which contains the task description
user_proxy.initiate_chat(
    assistant,
    message="""What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?""",
)```.
In general, at 2023-09-29 17:09:23 a user named vincentjedi said ```Do you think u may use colab and code it in Jupiter notebook ?```.
In general, at 2023-09-29 17:07:56 a user named vincentjedi said ```import openai
# Modify OpenAI's API key and API base to use vLLM's API server.
openai.api_key = "EMPTY"
openai.api_base = "http://localhost:8000/v1"
completion = openai.Completion.create(model="facebook/opt-125m",
                                      prompt="San Francisco is a")
print("Completion result:", completion)```.
In general, at 2023-09-29 17:06:46 a user named vincentjedi said ```python -m vllm.entrypoints.openai.api_server \
    --model facebook/opt-125m```.
In general, at 2023-09-29 17:06:04 a user named vincentjedi said ```Where do we save llama2 in order for vllm to load it ?```.
In general, at 2023-09-29 16:56:15 a user named au8 said ```"vLLM outperforms Hugging Face Transformers (HF) by up to 24x and Text Generation Inference (TGI) by up to 3.5x, in terms of throughput"```.
In general, at 2023-09-29 16:55:27 a user named au8 said ```I've not directly compared them myself, nor have I yet to try vLLM but it sounds very promising.```.
In general, at 2023-09-29 16:53:44 a user named vincentjedi said ```Are you saying vllm is better than fastchat ?```.
In general, at 2023-09-29 16:51:41 a user named au8 said ```@fxtoofaan I'll do some experimenting and if I get it working I'll let you know. I'll hopefully get started in a couple of hours.```.
In general, at 2023-09-29 16:47:09 a user named au8 said ```It has an OpenAI compatible API server as part of it```.
In general, at 2023-09-29 16:46:19 a user named au8 said ```If you use vLLM you might find that your issues go away and you'll get better performance in theory```.
In general, at 2023-09-29 16:43:13 a user named au8 said ```I see your thinking but I don't believe that to be the case, it's probably just not a priority```.
In general, at 2023-09-29 16:42:53 a user named fxtoofaan said ```i think my issue is i am using non Mistral prompts template in the python code. according to mistal here is their prompt: <s>[INST] {prompt} [/INST]```.
In general, at 2023-09-29 16:42:37 a user named vincentjedi said ```Perhaps Microsoft is trying to make it difficult to switch to other llm.```.
In general, at 2023-09-29 16:41:26 a user named au8 said ```I've yet to start my experiments with it though```.
In general, at 2023-09-29 16:41:13 a user named au8 said ```I've not tried it myself. Personally I'm interested in getting it working with vLLM```.
In general, at 2023-09-29 16:40:00 a user named fxtoofaan said ```these examples online have missing parts. or not complete. they are snippets of the code.```.
In general, at 2023-09-29 16:34:46 a user named au8 said ```https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/```.
In general, at 2023-09-29 16:33:20 a user named vincentjedi said ```Do we change llm in this section of code ?```.
In general, at 2023-09-29 16:32:24 a user named vincentjedi said ```# create an AssistantAgent instance named "assistant"
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
)
# create a UserProxyAgent instance named "user_proxy"
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "web"},
    llm_config=llm_config,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet."""
)```.
In general, at 2023-09-29 16:30:56 a user named blu-ray said ```how could i replace gpt-4 with another llm in autogen?```.
In general, at 2023-09-29 16:24:59 a user named tonic_1 said ```there's plenty of time (3 weeks) and it will be very laid back + for the builders & anyway the repos will all be available so plenty of chances to collaborate (my discord server link is in my bio) the live youtube event here : https://www.youtube.com/watch?v=qxleX8YCntg```.
In general, at 2023-09-29 16:23:02 a user named andyinater said ```That sounds interesting, but I am not sure how much I can contribute. I will check it out```.
In general, at 2023-09-29 16:19:03 a user named tonic_1 said ```i'm actually joining the autogpt hackathon with a nice team + one of the components will be to improve it with auto reply from autogen + more 🚀 would love to have you over if you're keen, started 20 minutes ago , lasts 3 weeks 👊🏻 invitation is open to all, i've also shared above so i dont wanna spam```.
In general, at 2023-09-29 16:16:42 a user named andyinater said ```I think what they are trying to compare is harder to measure than we think.

AutoGen comes with no default "logic" in the sense that, without a workflow and agents, you have nothing. It is the assembly and connections and definitions of the agents and how they are interact that makes up the logic machine.


So, and I may be wrong as I am not 100% familiar with how AutoGPT runs, but my understanding is that AutoGen is the framework that AutoGPT could have been built from.


So, when benchmarking, it won't simply be AutoGen vs AutoGPT; the specific workflow and configuration of AutoGen, and it's resulting performance, is what will be compared.```.
In general, at 2023-09-29 16:13:03 a user named fxtoofaan said ```Are the prompt message different between the different models ? Like gptx vs llama2 vs falcon vs mistral ?```.
In general, at 2023-09-29 16:11:01 a user named pkscary said ```The AutoGPT team has been benchmarking all the agent-based projects so I wonder how AutoGen stacks up```.
In general, at 2023-09-29 16:10:29 a user named pkscary said ```Does anyone have experience with Beebot, BabyAGI, AutoGPT, etc. and how do you think AutoGen compares to these other projects?```.
In general, at 2023-09-29 16:08:32 a user named pkscary said ```Someone should pin the repo https://github.com/microsoft/autogen to the welcome page for this Discord```.
In general, at 2023-09-29 15:57:41 a user named sonichi said ```AssistantAgent(name=..., llm_config={"model": "gpt-3.5-turbo", "api_key": ...})```.
In general, at 2023-09-29 15:38:53 a user named vincentjedi said ```response = autogen.Completion.create(
    config_list=[
        {
            "model": "gpt-4",
            "api_key": os.environ.get("AZURE_OPENAI_API_KEY"),
            "api_type": "azure",
            "api_base": os.environ.get("AZURE_OPENAI_API_BASE"),
            "api_version": "2023-07-01-preview",
        },
        {
            "model": "gpt-3.5-turbo",
            "api_key": os.environ.get("OPENAI_API_KEY"),
            "api_type": "open_ai",
            "api_base": "https://api.openai.com/v1",
            "api_version": None,
        },
        {
            "model": "llama-7B",
            "api_base": "http://127.0.0.1:8080",
            "api_type": "open_ai",
            "api_version": None,
        }
    ],
    prompt="Hi",
)```.
In general, at 2023-09-29 15:35:12 a user named crankfunk said ```hey there, trying for hours now, but I dont get it: just want to get the quickstart example running ("Plot a chart of NVDA and TESLA stock price change YTD."). how can I switch the model to gpt-3.5-turbo? dont have access to gpt-4. i read the FAQs and everything but am totally stucked.```.
In general, at 2023-09-29 15:29:35 a user named tonic_1 said ```that's what i'm trying to have folks do for this one : https://huggingface.co/collections/MultiTransformer/autogengradiohuggingface-651626e54256270d6fad2621
join the organisation here : https://huggingface.co/MultiTransformer

i'll probably go through the shares on this discord to add them to the collection, but let's make some cool demos together, it will be fun 👊🏻```.
In general, at 2023-09-29 15:08:07 a user named vincentjedi said ```Have u tried to add a simple gradio or streamlit frontend to use it with browser ?```.
In general, at 2023-09-29 14:50:19 a user named fxtoofaan said ```I’m trying to figure that out```.
In general, at 2023-09-29 14:48:18 a user named vincentjedi said ```How can we use llama2 or other local llm instead of using openai api?```.
In general, at 2023-09-29 14:45:20 a user named fxtoofaan said ```It’s missing some information which I cannot find any how to for it.```.
In general, at 2023-09-29 14:44:38 a user named fxtoofaan said ```I think we all have similar goals. Would be nice to maybe have a chat group where we can share code snippets making this work ?```.
In general, at 2023-09-29 14:44:30 a user named nexorsist said ```One of the issues on the Github page shows how to connect it to a local LLM (i think it was fastchat)```.
In general, at 2023-09-29 14:43:42 a user named nexorsist said ```it can likely then also optimize priming individual worker agents with better system prompts as it progresses```.
In general, at 2023-09-29 14:43:03 a user named fxtoofaan said ```At this point I’d love to see a single python file with everything in it to connect autogen to a local llm server like fastchat running mistral 7b model. No openai api keys, all local stuff. Simple bot that can answer who is current president of united states for example. Can anyone build code for this please ?```.
In general, at 2023-09-29 14:42:37 a user named nexorsist said ```What is missing from an agentverse setup is a decision maker which an LLM is not. What we need is a reinforcement learning bot (like what DeepMind makes) that acts as the central decision maker in conjunction with an LLM to send out the instructions. The RL agent can read the project "environment" and can perform actions (instructions) to LLM agents.```.
In general, at 2023-09-29 14:40:18 a user named nexorsist said ```I think the idea would be to think about it a little differently. Think of every agent you need to perform tasks as a clean slate skilled person. You prime it with the correct prompt to setup the "skillset" and to be specific about the type of tasks it should perform and how.

Then think of a workflow for the project you want to build and how it should interact with your pre-primed agents so that memory retention isn't required. 

That still has limitations if you trying to build on past things but it will likely just result in you changing how you design things. Could maybe make an agent that documents all tasks that were completed in a summarised manner to a central storage which you can then use as a knowledge index for the model of all things that have been built and done for future additions to a project?```.
In general, at 2023-09-29 14:31:15 a user named sspoth said ```Is there a way to have these bots retain its memory```.
In general, at 2023-09-29 13:43:06 a user named fxtoofaan said ```getting this error using local llm:

ValueError: dictionary update sequence element #0 has length 1; 2 is required```.
In general, at 2023-09-29 13:36:58 a user named .princeps said ```here is the project I setup to create a simple snake game 

https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.
In general, at 2023-09-29 13:15:23 a user named tonic_1 said ```If y’all are building tutorials and demos don’t forget this 👆🏻```.
In general, at 2023-09-29 13:07:46 a user named fxtoofaan said ```i am getting timeout issues using local llm. I even set the timeout to 900 seconds. (read timeout=900) in \autogen\autogen\oai\completion.py file.```.
In general, at 2023-09-29 13:01:11 a user named redai.ai said ```Any newbies that need help getting autogen working check it out```.
In general, at 2023-09-29 13:01:01 a user named redai.ai said ```https://www.youtube.com/watch?v=8TLwSH_UFwI&feature=youtu.be```.
In general, at 2023-09-29 13:00:56 a user named redai.ai said ```My video on autogen is premiering now```.
In general, at 2023-09-29 10:16:25 a user named fxtoofaan said ```My first use case is using autogen to help me create a virtual agents team for a specific task. And I want autogen to give me the team members abilities , deliverables and which other agent it should listen to or give orders to. Like make me a team that can start and scale a b2b newsletter from $0 to $1million in 12 months.```.
In general, at 2023-09-29 09:45:50 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.
In general, at 2023-09-29 09:39:11 a user named thunderbird365 said ```Ah, I see. I see the pattern```.
In general, at 2023-09-29 09:37:50 a user named thunderbird365 said ```No, that is false. 
Here's the proof it does```.
In general, at 2023-09-29 09:37:09 a user named scratchinknight said ```userProxy doesnt generate anything unless its your input```.
In general, at 2023-09-29 09:36:29 a user named fxtoofaan said ```@sonichi is it possible for an agent to go to web and search for stuff and gather up to date info? Like research for a topic or concept```.
In general, at 2023-09-29 09:36:25 a user named thunderbird365 said ```Anyone getting this problem: 

The user proxy chooses not to reply anything randomly.```.
In general, at 2023-09-29 09:35:55 a user named scratchinknight said ```i get this error docker.errors.DockerException: Error while fetching server API version: request() got an unexpected keyword argument 'chunked'```.
In general, at 2023-09-29 09:31:21 a user named sonichi said ```You can provide the image name as a str```.
In general, at 2023-09-29 08:50:41 a user named nexorsist said ```Suspect it will be the latter because the OpenAI API gpt models do not have access to the internet yet```.
In general, at 2023-09-29 08:46:24 a user named fxtoofaan said ```So does autogen have access to the internet yet? Or can I use autogen to gather data from internet for its agents ? What about local docs vector db or local knowledge added to agents ?```.
In general, at 2023-09-29 08:28:44 a user named scratchinknight said ```do i setup the docker in environment and then provide or it create the container?```.
In general, at 2023-09-29 08:27:03 a user named scratchinknight said ```how does use_docker work ?```.
In general, at 2023-09-29 08:01:42 a user named jimmysandwiches said ```Can i suggest a excellent tip I use when learning and debugging code - use claude.ai (seems to work better for me with code errors than chatgpt, also try bard) and simply post the error message into chat (thats all i did, we're all learning 🙂 🥪```.
In general, at 2023-09-29 07:55:40 a user named fxtoofaan said ```we getting somewhere now 🙂```.
In general, at 2023-09-29 07:55:12 a user named fxtoofaan said ```yes, now mistral works too. thank you 🙂

2023-09-29 08:50:40 | INFO | model_worker | Send heart beat. Models: ['Mistral-7B-v0.1']. Semaphore: None. call_ct: 0. worker_id: fb50d747.
2023-09-29 08:51:26 | INFO | model_worker | Send heart beat. Models: ['Mistral-7B-v0.1']. Semaphore: None. call_ct: 0. worker_id: fb50d747.
2023-09-29 08:52:11 | INFO | model_worker | Send heart beat. Models: ['Mistral-7B-v0.1']. Semaphore: None. call_ct: 0. worker_id: fb50d747.
2023-09-29 08:52:56 | INFO | model_worker | Send heart beat. Models: ['Mistral-7B-v0.1']. Semaphore: None. call_ct: 0. worker_id: fb50d747.
2023-09-29 08:53:00 | INFO | stdout | INFO:     ::1:63190 - "POST /model_details HTTP/1.1" 200 OK
2023-09-29 08:53:00 | INFO | stdout | INFO:     ::1:63191 - "POST /count_token HTTP/1.1" 200 OK
2023-09-29 08:53:00 | INFO | stdout | INFO:     ::1:63192 - "POST /worker_get_conv_template HTTP/1.1" 200 OK
2023-09-29 08:53:31 | INFO | stdout | INFO:     ::1:63193 - "POST /worker_generate HTTP/1.1" 200 OK
2023-09-29 08:53:31 | INFO | stdout | INFO:     ::1:63204 - "POST /model_details HTTP/1.1" 200 OK
2023-09-29 08:53:31 | INFO | stdout | INFO:     ::1:63205 - "POST /count_token HTTP/1.1" 200 OK
2023-09-29 08:53:41 | INFO | model_worker | Send heart beat. Models: ['Mistral-7B-v0.1']. Semaphore: Semaphore(value=4, locked=False). call_ct: 2. worker_id: fb50d747.
2023-09-29 08:54:02 | INFO | stdout | INFO:     ::1:63206 - "POST /worker_generate HTTP/1.1" 200 OK
2023-09-29 08:54:26 | INFO | model_worker | Send heart beat. Models: ['Mistral-7B-v0.1']. Semaphore: Semaphore(value=5, locked=False). call_ct: 2. worker_id: fb50d747.```.
In general, at 2023-09-29 07:54:03 a user named jimmysandwiches said ```These logs show normal operations of a model server worker handling API requests to generate responses using the vicuna language model.

Did you check my first message for steps to rectify?```.
In general, at 2023-09-29 07:40:49 a user named fxtoofaan said ```2023-09-29 08:35:15 | INFO | model_worker | Send heart beat. Models: ['vicuna-7b-v1.3']. Semaphore: None. call_ct: 0. worker_id: 56371133.
2023-09-29 08:36:00 | INFO | model_worker | Send heart beat. Models: ['vicuna-7b-v1.3']. Semaphore: None. call_ct: 0. worker_id: 56371133.
2023-09-29 08:36:05 | INFO | stdout | INFO:     ::1:62762 - "POST /model_details HTTP/1.1" 200 OK
2023-09-29 08:36:05 | INFO | stdout | INFO:     ::1:62763 - "POST /count_token HTTP/1.1" 200 OK
2023-09-29 08:36:05 | INFO | stdout | INFO:     ::1:62764 - "POST /worker_get_conv_template HTTP/1.1" 200 OK
2023-09-29 08:36:19 | INFO | stdout | INFO:     ::1:62765 - "POST /worker_generate HTTP/1.1" 200 OK
2023-09-29 08:36:19 | INFO | stdout | INFO:     ::1:62776 - "POST /model_details HTTP/1.1" 200 OK
2023-09-29 08:36:19 | INFO | stdout | INFO:     ::1:62777 - "POST /count_token HTTP/1.1" 200 OK
2023-09-29 08:36:35 | INFO | stdout | INFO:     ::1:62778 - "POST /worker_generate HTTP/1.1" 200 OK
2023-09-29 08:36:45 | INFO | model_worker | Send heart beat. Models: ['vicuna-7b-v1.3']. Semaphore: Semaphore(value=5, locked=False). call_ct: 2. worker_id: 56371133.```.
In general, at 2023-09-29 07:38:41 a user named fxtoofaan said ```ok so I am able to use autogen with default vicuna-7b-v1.3 model now problem```.
In general, at 2023-09-29 07:31:58 a user named fxtoofaan said ```i am able to load default model```.
In general, at 2023-09-29 06:41:53 a user named jimmysandwiches said ```@fxtoofaan Make sure the model path is correct - Mistral-7B-v0.1 should point to the location where the model files are stored.

Check that you have sufficient permissions to access the model files. The error may be caused by the model worker not being able to read the model.

Verify that the model files are valid and not corrupted. Try re-downloading the model if needed.

There may be an issue with the environment - check dependencies like PyTorch, TensorFlow, etc. Make sure they are installed and the versions are compatible with the model.

Try running the model worker without GPU to rule out any CUDA/GPU related errors.

Look at the full traceback (not shown here) for more details on where exactly the error is occurring.

So in summary, validate the model path, permissions, environment and dependencies. The full traceback should provide clues to pinpoint the problem. Let me know if the error persists after checking these things!```.
In general, at 2023-09-29 06:38:57 a user named fxtoofaan said ```I am trying to load Mistral using fastchat. getting this error. not sure how to pass the huggingface api to the local server.```.
In general, at 2023-09-29 05:53:21 a user named martcpp said ```I am Mart I love open source ai what are tg wats u can assist```.
In general, at 2023-09-29 05:38:09 a user named thunderbird365 said ```Hi. I am wondering if team will be actively working on adding new features or this is kind of a research project that has it's end at some point ?```.
In general, at 2023-09-29 01:37:13 a user named tonic_1 said ```let me know if you want write access, eventually we could make a common spaces for collaboratively building these tutorials and demos for folks 🚀 we're also on my server (link in bio) with @merkle kinda```.
In general, at 2023-09-29 01:28:18 a user named tonic_1 said ```so basically if you're on hugging face you can add your demo / tutorial / app to the collection here : https://huggingface.co/collections/MultiTransformer/autogengradiohuggingface-651626e54256270d6fad2621```.
In general, at 2023-09-29 01:02:49 a user named bansalg said ```I cant seem to force it to use only gpt```.
In general, at 2023-09-29 01:00:55 a user named wally_5040 said ```and since i generally think about cognitive volume now, the bigger context window isn't that helpful, since the cognitive capacity just gets spread over more tokens which can actually have detrimental effects very often```.
In general, at 2023-09-29 00:58:54 a user named wally_5040 said ```i use gpt-4 for the heavy lifting and some 3.5-16k for summarization and categorization tasks.
gpt-4-32k is really nice for these cases too, but waaay too costly (I regularily attach multiple source code files to my conversations and those drive the token usage up quite a bit)```.
In general, at 2023-09-29 00:57:10 a user named wally_5040 said ```same for me. I played around with a few other, esp. Llama, but for my use cases, they didnt even get close```.
In general, at 2023-09-29 00:54:21 a user named jonny7377 said ```gpt-4 and 3.5-16k waiting for the open source models to get a bit better before i start offloading some tasks to them.```.
In general, at 2023-09-29 00:52:28 a user named wally_5040 said ```@jonny7377 out of curiosity: what models do you mainly use?```.
In general, at 2023-09-29 00:51:21 a user named wally_5040 said ```(i mostly use my own gpt instances on azure with the Azure OpenAI Studio)```.
In general, at 2023-09-29 00:50:37 a user named wally_5040 said ```on azure there is a better way via the Key Vault, but as everything in azure: it costs quite some 😄```.
In general, at 2023-09-29 00:49:38 a user named wally_5040 said ```sry. its
openai.api_key = os.getenv("OPENAI_API_KEY")
of course.```.
In general, at 2023-09-29 00:49:31 a user named jonny7377 said ```Yup, that is about where i have landed. thanks for talking me through this.```.
In general, at 2023-09-29 00:47:35 a user named wally_5040 said ```i see. I only ever played around with remote execution (by the LLM) as I didnt see anything beneficial in it and only drawbacks (impossible to debug!). So all generated code runs on a compute that i control (locally or cloud) and in those cases, I just have a few lines in the system message that tell it how certains keys and configs can be accessed. e.g.:
openai.api_key = OPENAI_API_KEY
somelibrary.someconfig = SOME_CONFIG_SETTING
is often totally sufficient```.
In general, at 2023-09-29 00:47:00 a user named bart9154 said ```Well, I will go back there with my questions in 10 minutes```.
In general, at 2023-09-29 00:43:47 a user named tonic_1 said ```hey there folks, i made a huggingface organisation to produce a collection for autogen tutorials with @merkle  : join us and let's build some nice examples people can take home 👊🏻🚀 https://huggingface.co/MultiTransformer```.
In general, at 2023-09-29 00:43:43 a user named jonny7377 said ```my struggle atm is not so much where to put it but how to get the generated code to load it.```.
In general, at 2023-09-29 00:42:44 a user named wally_5040 said ```sorry, I must have misunderstood. what data did you mean? The .env way is not just for oai key, but I also use it for db logins and other config, that should never leave my machine```.
In general, at 2023-09-29 00:41:40 a user named jonny7377 said ```Not talking about OAI key but i take your point.  Just looking for a better way```.
In general, at 2023-09-29 00:41:14 a user named wally_5040 said ```at this point, for me it's mostly about containing cognitive load and spreading it over enough calls, so I try to stick to the ways that are the most easy on poor chatty's brain 😊```.
In general, at 2023-09-29 00:41:00 a user named bart9154 said ```Anyone know what the trick is to getting fastchat to use an api locally? Is it all in the name?```.
In general, at 2023-09-29 00:40:28 a user named wally_5040 said ```which i found to be a good idea to use, since it is *naturally* chosen by gpt models anyways```.
In general, at 2023-09-29 00:40:02 a user named wally_5040 said ```in the openai docs they mostly use the string `OPENAI_API_KEY````.
In general, at 2023-09-29 00:39:02 a user named wally_5040 said ```you would tell it to use the specific environment variable```.
In general, at 2023-09-29 00:38:00 a user named wally_5040 said ```(maybe I am just traumatized from my experience with FLAN 🙈 )```.
In general, at 2023-09-29 00:37:25 a user named wally_5040 said ```I still refuse to talk to anything below **gpt-4-32k** 😆  /jk```.
In general, at 2023-09-29 00:36:02 a user named jonny7377 said ```I put this in the llm_config:  "model": "gpt-3.5-turbo-16k", in the AssistantAgent setup.```.
In general, at 2023-09-29 00:33:12 a user named wally_5040 said ```for python i usually put it in a `.env` file.```.
In general, at 2023-09-29 00:24:09 a user named fxtoofaan said ```I cant seem to force it to use only gpt-3.5-turbo.```.
In general, at 2023-09-29 01:02:50 a user named bansalg said ```Can you share a more complete snippet. Especially where you pass the config list to an agent.```.
In general, at 2023-09-29 07:13:57 a user named bansalg said ```Also see: https://github.com/microsoft/autogen/blob/main/test/twoagent.py```.
In general, at 2023-09-29 00:16:16 a user named jonny7377 said ```What is the recommended approach to making api key or other data available for using in generated code?  I don't want to have any api keys floating around in the logs on someone else's server but i do need code executed locally to be able to use the key (or any other data).```.
In general, at 2023-09-28 23:52:42 a user named shubhdi5cord said ```For other people's reference - this should answer the question 
https://json-schema.org/understanding-json-schema/```.
In general, at 2023-09-28 23:34:44 a user named fxtoofaan said ```so no spaces then ?```.
In general, at 2023-09-28 23:31:19 a user named sonichi said ```replace " " with "_"```.
In general, at 2023-09-28 23:30:40 a user named fxtoofaan said ```is this ok? name="Business Coach",```.
In general, at 2023-09-28 23:29:19 a user named sonichi said ```please remove " " in the name of the agent```.
In general, at 2023-09-28 23:22:04 a user named samin1 said ```can someone help me make a fastapi with autogen willing to pay```.
In general, at 2023-09-28 23:20:11 a user named fxtoofaan said ```@sonichi I am getting this error.```.
In general, at 2023-09-28 22:41:32 a user named bansalg said ```Also sonichi Is it possible to have```.
In general, at 2023-09-28 22:18:33 a user named shubhdi5cord said ```I'll try it out and let you know if that works.```.
In general, at 2023-09-28 22:15:51 a user named sonichi said ```A PR was made in flaml https://github.com/microsoft/FLAML/pull/1223
@kevinwyr would you like to make it in autogen? Or would you like others to do it?```.
In general, at 2023-09-28 22:13:44 a user named fxtoofaan said ```ok I got something to report 🙂```.
In general, at 2023-09-28 22:12:38 a user named shubhdi5cord said ```And how about the function call @sonichi  within group chat. Is that resolved yet? 

I've been rigorously trying to  use autogen for multiple usecases. Need some support, so please bear with these questions.```.
In general, at 2023-09-28 22:10:07 a user named shubhdi5cord said ```Also @sonichi  Is it possible to have group chats within a  group chat?```.
In general, at 2023-09-28 22:41:34 a user named bansalg said ```Can you give a simple example of a group chat within a group chat?```.
In general, at 2023-09-28 22:49:10 a user named shubhdi5cord said ```Let's say I create an agent which is in role of a product manager that is prompted with a feature idea and the product manager create user stories for the feature and based on the user stories set of backend developer agents can work to create a complete backend (nested group chat1 ). Set of frontend engineers (nested group chat 2) can develop on frontend userstories.

We can have a frontend manager and backend manager involved in a group chat with the product manager which initiate nested group chat.```.
In general, at 2023-09-28 22:55:30 a user named sonichi said ```function call is one way to do it```.
In general, at 2023-09-28 22:56:59 a user named bansalg said ```how about this:  the product m, back m, front m can be in a gc. but the back m and front m can have functions that let them spin up engineers```.
In general, at 2023-09-29 17:17:28 a user named sonichi said ```@bigmiao you maybe interested in this thread.```.
In general, at 2023-09-28 22:09:00 a user named cyberian_mishka said ```got it up and running. thank you, @GalacticMech !```.
In general, at 2023-09-28 22:06:45 a user named shubhdi5cord said ```@sonichi can you help me out here. And tell me like what are the possible types for a parameter.
I tried dict and list. Which did not work.```.
In general, at 2023-09-28 21:45:34 a user named shubhdi5cord said ```You can avoid that with a meaningful termination condition in system message as you must have observed in the example notebooks as well```.
In general, at 2023-09-28 21:35:43 a user named GalacticMech said ```Try pasting the output from the those two commands here, feels like you're doing something wrong.```.
In general, at 2023-09-28 21:32:32 a user named cyberian_mishka said ```Thank you for getting back to me. It didn't work.```.
In general, at 2023-09-28 21:30:12 a user named shubhdi5cord said ```Assuming it's a function call. Accepted parameter type should be of type str```.
In general, at 2023-09-28 21:24:19 a user named GalacticMech said ```You may have installed requirements to the wrong version of python. Try something like:
```python -m pip install pyautogen
python agents.py
``````.
In general, at 2023-09-28 21:17:55 a user named cyberian_mishka said ```is anyone else encountering ModuleNotFoundError: No module named 'autogen'? I installed pyautogen + blendsearch. when trying to launch a script this is what I get:
C:\>agents.py
Traceback (most recent call last):
  File "C:\agents.py", line 1, in <module>
    from autogen import AssistantAgent, UserProxyAgent
ModuleNotFoundError: No module named 'autogen'

Looks like the module is either not installed or it can't find it. I had the same error while running in notebook. What am I missing?```.
In general, at 2023-09-28 20:58:44 a user named fxtoofaan said ```I think whats missing in these latest generative ai related python projects is that alot of us programmers are jumping on the scene and we not able to use it like we should. I think if w can list some of or ideas what we trying to do with AI and you programmers can write the code up and produce it as a simple executable python file on github and then this will really take off. hat the ai will create the appropriate agents team, make use of local llms and gpt resources that are cost optimized. ask human a```.
In general, at 2023-09-28 20:50:55 a user named fxtoofaan said ```wow finally able to run this thing on my windows 10 pc and python 3.10. ok  now its getting interesting. Can someone help me build something? Let's say I wanted to create a Newsletter AI Assistant (NAIA) to write me a newsletter about a "topic". This (NAIA) should first become the best knowledgeable person on this "topic" by learning from latest online content. I can also feed this (NAIA)  information about this "topic" like vector db so it has public and private knowledge about this "topic". This (NAIA) should then go find out what are the best newsletters that currently talk about this "topic"? what are they talking about? learn from competition and then bring back the best article to write about that topic keeping virality in mind, meaning using trends in this "topic".  Basically become a sales/marketing expert in this "topic". so maybe a human agent, research agent, marketing agent. can anyone write a 3-4 agents python file that does this? maybe give me option to test it with gpt 3.5turbo or gpt 4.0, or optimize cost for gpt hence use gpt 3.5 turbo for grunt work and gpt 4.0 for final end newsletter to publish. 🙂```.
In general, at 2023-09-28 20:35:06 a user named GalacticMech said ```Ok, maybe just a false positive. Thanks.```.
In general, at 2023-09-28 20:31:15 a user named GalacticMech said ```Anyone else getting antivirus hits on the pyautogen package on python? ESET NOD32 is detecting Python/TrojanDownlaoder.Agent.WG trojan on: 
\Lib\site-packages\autogen\__pycache__\retrieve_utils.cpython-311.pyc.2323331787360```.
In general, at 2023-09-28 20:20:21 a user named pajamasuit said ```Took me waaaaay too long to realize it was `pyautogen` and not `autogen````.
In general, at 2023-09-28 19:46:47 a user named .beibinli said ```You can find the safeguard implementation here: https://github.com/microsoft/OptiGuide/blob/ec15d935b5dc70714a0c8e2730f905ffe0526f5d/optiguide/optiguide.py#L169

In the example, we ask another LLM agent to determine the safety of the code. In real world production, you can also include additional custom check, such as static code analysis, regular expression matching, file/user privilege check, etc.

If the code is marked as malicious, it will ask the LLM to redo it (rewrite the code), until a safe code is given or allowed debug times reached.```.
In general, at 2023-09-28 19:35:05 a user named sneaky1442 said ```What if any projects or conversations are related to the security aspect of things like open-interpreter and autogen? 
I detect major shenanigans ahead skewed towards open-source models. 

If i understand the current flow would look like:
    ```(User interacts with an app that connects to black boxed LLM) => 
(Malicious/Jailbroke LLM: "syskey yourself") => 
(Open-Interpreter: "Do you want to run this code?")```

but within the autogen paper it talks about:
```"The paper describes a "Safeguard" agent that screens code for safety before execution. If a security red flag is raised by the Safeguard, the code will not be executed. (Page 13, 28)"```
but I can't find the implementation unless I'm blind lol

with AutoGen it'd look like:
```(User interacts with an app that connects to black boxed LLM) => 
(Malicious/Jailbroke LLM: "syskey yourself") => 
(Auto-Gen: SafeGuardChecksIfMalicious) IFNOT => 
(Open-InterpreterRoot: llmCommand)

OR

(User interacts with an app that connects to black boxed LLM) => 
(Malicious/Jailbroke LLM: "syskey yourself") => 
(Auto-Gen: SafeGuardChecksIfMalicious) => EXECUTEIFNOT
```


What are the current safeguards, if any, that exist?```.
In general, at 2023-09-28 19:31:33 a user named fxtoofaan said ```Anyone get autogen to work with mistral 7b as local llm ?```.
In general, at 2023-09-28 18:49:00 a user named sonichi said ```PR made to address bug in windows and improve sample code: https://github.com/microsoft/autogen/pull/38```.
In general, at 2023-09-28 18:32:21 a user named fxtoofaan said ```lol no. Maybe Cheech and Chong reference```.
In general, at 2023-09-28 18:27:54 a user named grindman said ```is that a venture bros reference?```.
In general, at 2023-09-28 18:26:31 a user named fxtoofaan said ```Now we cooking with gas 🙂```.
In general, at 2023-09-28 18:00:07 a user named redai.ai said ```anyone else having timeout issues due to api ratelimits```.
In general, at 2023-09-28 17:37:38 a user named felly007. said ```https://github.com/Perfect-Your-Trading/gengen```.
In general, at 2023-09-28 17:31:11 a user named felly007. said ```good point, didn't think of it. Can share on there as well```.
In general, at 2023-09-28 17:30:49 a user named redai.ai said ```Why not just share the code, or github link```.
In general, at 2023-09-28 17:30:24 a user named fxtoofaan said ```Thank you. I’ll check it out```.
In general, at 2023-09-28 17:30:21 a user named redai.ai said ```careful with files shared here guys```.
In general, at 2023-09-28 17:30:04 a user named felly007. said ```@fxtoofaan This is what I've been using. Just replace the API key and install the depencies (pip install pyautogen)```.
In general, at 2023-09-28 17:28:06 a user named sonichi said ```I'll try to make that. Working on a bug fix for windows.```.
In general, at 2023-09-28 17:24:43 a user named felly007. said ```but what if changes need to be made? This is an rapidly changing code```.
In general, at 2023-09-28 17:23:12 a user named fxtoofaan said ```@sonichi  can you just give us a python file where we can just replace the api key and run it and get some result. I’m having hard time following programming lingo. Any of the examples as python file or zip file with everything in it and all we do is change the api key and off we go. Can we get that please ?```.
In general, at 2023-09-28 17:09:36 a user named sonichi said ```Yes. It's a dict like {"api_key": ..., "model": ...}. You can also use a config_list for multiple inference configurations to use: https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints```.
In general, at 2023-09-28 17:04:08 a user named felly007. said ```got the same question, I think it is in the gpt4_config but the dev doesn't import that function```.
In general, at 2023-09-28 17:02:48 a user named felly007. said ```I'm trying to duplicate this but it isn't clear what

llm_config=gpt4_config

is here. Would this be openai config that the writer has defined on their local?```.
In general, at 2023-09-28 16:59:17 a user named redai.ai said ```Sure will, hopefully video will be up by tonight I just want more good examples and want to customize it more for the video```.
In general, at 2023-09-28 16:57:16 a user named fxtoofaan said ```Where is the openai api key used in this example ?```.
In general, at 2023-09-28 16:56:52 a user named fxtoofaan said ```Please show a sample project and how to run it locally on python files instead of jupyter notebooks. Maybe include a python file along with its variables files needed. This will make us non programmers really happy 🙂```.
In general, at 2023-09-28 16:51:40 a user named redai.ai said ```going to make a video about this tool```.
In general, at 2023-09-28 16:30:50 a user named tonic_1 said ```love this & love bangkok 🚀```.
In general, at 2023-09-28 16:27:52 a user named you.wish said ```seems like using a smart laser guided hammer to kill a house fly```.
In general, at 2023-09-28 16:20:21 a user named sonichi said ```https://twitter.com/pwang_szn/status/1707334415691686227?s=46&t=HW3LQnkY2VkckNNTvFnbcA```.
In general, at 2023-09-28 16:19:55 a user named felly007. said ```haha, what have you used it for? @you.wish```.
In general, at 2023-09-28 16:08:53 a user named pajamasuit said ```task #1: Determine a logo for the autogen discord```.
In general, at 2023-09-28 15:53:30 a user named you.wish said ```so what have u created with autogen so far```.
In general, at 2023-09-28 15:37:42 a user named skorakora said ```Can somone help me to explain what is the difference in architecture between superAGI and AutoGen, as for now in low level they are same for me.```.
In general, at 2023-09-28 15:36:25 a user named skorakora said ```Hi all, I am here to learn more and help with developement of AGI, as working together can speed up my research```.
In general, at 2023-09-28 14:21:31 a user named theresechante said ```After line 902 in conversable_agent.py i added the line : "logs = logs.decode('utf-8')"  to decode the log to an char so it can be appended to the output code string```.
In general, at 2023-09-28 14:10:21 a user named tonic_1 said ```try flowiseai instead i think that's a better place for you to start actually```.
In general, at 2023-09-28 13:11:48 a user named mantiscrypto said ```hey guys, any chance someone who doesn't know coding can get this set up or no?```.
In general, at 2023-09-28 12:46:25 a user named felly007. said ```Yep, that works. thank you @sonichi```.
In general, at 2023-09-28 12:38:07 a user named sonichi said ```sonichi even though I m using gpt 32 k```.
In general, at 2023-09-28 12:37:12 a user named sonichi said ```When you are prompted to enter input for the user proxy agent, press enter to skip the input and the code will be executed automatically. (assuming human_input_mode='ALWAYS' which is the default setting)```.
In general, at 2023-09-28 12:25:58 a user named felly007. said ```decent code output from autogen. Is there a way to make the system run the code and debug it? Currently I am running it in google collab```.
In general, at 2023-09-28 12:11:19 a user named fxtoofaan said ```I am a non programmer, thats why struggling with all the notebooks files and back and forth calling of OAI_CONFIG_LIST and api's```.
In general, at 2023-09-28 12:07:23 a user named tonic_1 said ```Just use the notebooks and be patient to learn perhaps ? also there are links on this discord 🤷🏻‍♂️```.
In general, at 2023-09-28 12:01:43 a user named fxtoofaan said ```Do you have an example project to share so we can set it up as well? At this time I’d be even happy if it can go out to internet and grab top 10 stocks today or something```.
In general, at 2023-09-28 12:01:10 a user named steve_anton said ```I'm doing the same, no jupyter, VSC w/ Python 3.11 and console.```.
In general, at 2023-09-28 11:51:44 a user named tonic_1 said ```works as python script , correct```.
In general, at 2023-09-28 11:49:08 a user named fxtoofaan said ```are you able to run it locally as python script rather than jupyter notebook ?```.
In general, at 2023-09-28 11:43:50 a user named tonic_1 said ```useable for me 🤷🏻‍♂️ dont really understand the negativity here tbh, i really like the auto reply and the utils are very useful - a lot i'll be using starting prolly today ^^```.
In general, at 2023-09-28 11:34:07 a user named fxtoofaan said ```I think we have to wait for maybe an update or service pack before it becomes somewhat useable```.
In general, at 2023-09-28 11:31:12 a user named steve_anton said ```is it safe to say, that this isn't really intended to run on Windows (yet?) and I should swap to a Linux vm?  I'm getting TypeError exceptions, even with the readme.md example.```.
In general, at 2023-09-28 10:56:26 a user named fxtoofaan said ```Which local llm is drop in replacement for openai api? And also which server serves local llms the fastest using GPU? I’m guessing llama2 and falcon maybe ?```.
In general, at 2023-09-28 10:53:58 a user named .bigbangtheory said ```Gpt32k is with a waitlist, not every1 can use it```.
In general, at 2023-09-28 10:40:39 a user named izc333 said ```you can do it with notebook```.
In general, at 2023-09-28 10:29:44 a user named scratchinknight said ```who has the ability to write,create file and making cli commands userproxyagent or assitant agent?```.
In general, at 2023-09-28 09:17:38 a user named scratchinknight said ```what are the docker image that can be used?```.
In general, at 2023-09-28 09:07:26 a user named corehelion said ```Anyone using this with local Oobabooga LLMs?```.
In general, at 2023-09-28 08:10:39 a user named fxtoofaan said ```Can you translate that into English ? 🙂 what did you change to UFT-8? Can you post update code here?```.
In general, at 2023-09-28 08:02:36 a user named theresechante said ```I had the same error in a windows environment, I had to decode the output to utf-8 (directly in the module) , then it worked```.
In general, at 2023-09-28 07:48:02 a user named jasper.cooper said ```Hey All, keen to get stuck into this one. I was wondering if anyone has been able to setup the Retrieveal Agent with something like Pinecone and Ada Embedding?```.
In general, at 2023-09-28 06:02:13 a user named scratchinknight said ```do you need a docker for execute code block to work```.
In general, at 2023-09-28 05:30:45 a user named scratchinknight said ```does anyone know how to deal with this error TypeError: can only concatenate str (not "bytes") to str after excecute code block for conversableagent.py```.
In general, at 2023-09-28 05:04:54 a user named shubhdi5cord said ```@sonichi even though I'm using gpt-32 k models only on oai_config. I get a context limit exceeded stating that the context limit is just 8k. 
Can somebody explain how is that happening?```.
In general, at 2023-09-28 12:38:08 a user named sonichi said ```did you set `llm_config` in the construction of `AssistantAgent````.
In general, at 2023-09-29 05:09:42 a user named shubh2023_14031 said ```config_list_gpt4 = autogen.config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": ["gpt-4-32k", "gpt-4-32k-0314", "gpt-4-32k-v0314"],
    },
)```.
In general, at 2023-09-29 05:20:14 a user named shubh2023_14031 said ```InvalidRequestError: This model's maximum context length is 8192 tokens. However, your messages resulted in 8858 tokens. Please reduce the length of the messages```.
In general, at 2023-09-29 09:18:42 a user named sonichi said ```Do you have a groupchatmanager? Is its llm_config set with the same?```.
In general, at 2023-09-29 14:15:39 a user named sonichi said ```Have you checked the content of config_list_gpt4?```.
In general, at 2023-09-29 20:37:41 a user named shubhdi5cord said ```Yes just shared it here```.
In general, at 2023-09-29 20:49:41 a user named sonichi said ```The filter_dict is right. What about the actual content of the `config_list_gpt4`? Does it have "gpt-4-32k" etc. in it?```.
In general, at 2023-10-04 19:55:15 a user named vanheerdena said ```I don't have access to gpt-4-32k? Is there some way to truncate the history so we don't have the program crash?```.
In general, at 2023-10-04 20:32:57 a user named sonichi said ```@andyinater and @kevinwyr have done some work about it.```.
In general, at 2023-09-28 04:56:01 a user named you.wish said ```i dont think multiple agents talking to each other will help with anything.```.
In general, at 2023-09-28 01:59:01 a user named sonichi said ```To use only GPT 3 5 use this filter dict```.
In general, at 2023-09-28 01:36:19 a user named you.wish said ```so i can tell every agent who they are. 
otherwise no difference to chatdev?```.
In general, at 2023-09-28 01:28:01 a user named jonny7377 said ```To use only GPT-3.5 use this:     filter_dict = {"model": {"gpt-3.5-turbo"}}
Correct?  Doesn't seem to force GPT-3.5!```.
In general, at 2023-09-28 01:59:01 a user named sonichi said ```Could you show the code snippet?```.
In general, at 2023-09-28 02:01:47 a user named jonny7377 said ```config_list = autogen.config_list_from_json(
    env_or_file = "OAI_CONFIG_LIST",
    file_location = "./app_data",
    filter_dict = {"model": {"gpt-3.5-turbo"}}
)
OAI_CONFIG_LIST contains gpt-4 and gpt-3.5```.
In general, at 2023-09-28 02:03:11 a user named sonichi said ```did you pass `llm_config={"config_list": config_list}` in the constructor of `AssistantAgent`?```.
In general, at 2023-09-28 02:07:40 a user named jonny7377 said ```😀  Yes and it still uses gpt-4.```.
In general, at 2023-09-28 02:10:52 a user named sonichi said ```Can I see the code that follows?```.
In general, at 2023-09-28 02:18:17 a user named sonichi said ```Also, could you print config_list on your side to verify that {"model": "gpt-3.5-turbo"} is contained in each element of the list?```.
In general, at 2023-09-28 12:40:55 a user named nightcode1024 said ``````py
import os
from dotenv import load_dotenv

# Load environment variables from .env into os.environ
load_dotenv()

import autogen

from autogen import AssistantAgent, UserProxyAgent

config_list = autogen.config_list_from_json(
    env_or_file = "OAI_CONFIG_LIST",
    file_location = "./app_data",
    filter_dict = {"model": {"gpt-3.5-turbo"}}
)

assistant = AssistantAgent("assistant", llm_config={"config_list": config_list})
user_proxy = UserProxyAgent("user_proxy")
user_proxy.initiate_chat(assistant, message="What is 1+1?") 
```

Still gives the error: openai.error.InvalidRequestError: The model `gpt-4` does not exist or you do not have access to it.```.
In general, at 2023-09-28 12:50:20 a user named sonichi said ```is `{"model": "gpt-3.5-turbo"}` contained in the `config_list`?```.
In general, at 2023-09-28 12:52:06 a user named nightcode1024 said ```Yeah its in config_list =```.
In general, at 2023-09-28 12:52:14 a user named nightcode1024 said ```is there an OAI_CONFIG_LIST.json file I'm missing?```.
In general, at 2023-09-28 12:55:58 a user named sonichi said ```You have a file named OAI_CONFIG_LIST, right? That's the file you need. How many elements are in the `config_list`? What's `len(config_list)`?```.
In general, at 2023-09-28 13:09:23 a user named nightcode1024 said ```Well I do now, but I'm not 100% sure  what to put in it found some config_list looking code here: https://microsoft.github.io/autogen/docs/reference/oai/completion so wrote it as json and just an array in the json file.

I had to put ./ as the file_location argument and .json on the end.

I get a new error now, which understandably is progress. I have no quota guess I can't use it for free haha.

`You exceeded your current quota, please check your plan and billing details.` 

OAI_CONFIG_LIST.json looks like this now.

```json
[
    {
        "model": "gpt-3.5-turbo",
        "api_type": "open_ai",
        "api_base": "https://api.openai.com/v1"
    }
]
```
And the code in my py file.
```py
import os
from dotenv import load_dotenv
load_dotenv()
import autogen
from autogen import AssistantAgent, UserProxyAgent

config_list = autogen.config_list_from_json(
    env_or_file = "OAI_CONFIG_LIST.json",
    file_location = "./",
    filter_dict = {"model": {
        "gpt-3.5-turbo",
    }}
)

assistant = AssistantAgent("assistant", llm_config={"config_list": config_list})
user_proxy = UserProxyAgent("user_proxy")
user_proxy.initiate_chat(assistant, message="What is 1+1?") 
```

Neato```.
In general, at 2023-09-28 14:11:10 a user named sonichi said ```maybe you had an environment variable OAI_CONFIG_LIST which is loaded before it tries to load the file. Changing the filename solved that.```.
In general, at 2023-10-11 13:11:44 a user named alexzander8376 said ```I haven't quite understood.
How do I get my code to use 3.5 turbo?
Here it is:

```from autogen import AssistantAgent, UserProxyAgent, config_list_from_json
import openai

openai.api_key = ''

# Load LLM inference endpoints from an env variable or a file
# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints
# and OAI_CONFIG_LIST_sample

config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")
assistant = AssistantAgent("assistant", llm_config={"config_list": config_list})
user_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding"})

user_proxy.initiate_chat(assistant, message="")

# This initiates an automated chat between the two agents to solve the task``````.
In general, at 2023-10-11 13:46:28 a user named sonichi said ```make sure `config_list` contains a list of dicts, each dict containing `"model": "gpt-3.5-turbo" ````.
In general, at 2023-09-28 01:25:05 a user named you.wish said ```push ups dont train my chest at all 😭
sorry for not accepting your friendship```.
In general, at 2023-09-28 01:24:43 a user named tonic_1 said ```the coding utils alone are worth it imho ^^```.
In general, at 2023-09-28 01:19:36 a user named merkle said ```it seems to have a similar theme for sure. might be that autogen allows for more flexible structures and setups? i havent looked into chatdev enough to know the ins and outs but it seems a bit more rigid in the setup. could be wrong.```.
In general, at 2023-09-28 00:43:36 a user named tonic_1 said ```plugin for scrivener... i'll be afk```.
In general, at 2023-09-28 00:43:19 a user named you.wish said ```plugin for an llm agent? but autogen is already that?```.
In general, at 2023-09-28 00:42:44 a user named tonic_1 said ```you could build a plugin for a series of agents that interact to give you real time information and suggestions as you play Scrivener for example... hope this helps 👊🏻```.
In general, at 2023-09-28 00:37:41 a user named you.wish said ```i meant what you do with it```.
In general, at 2023-09-28 00:37:26 a user named tonic_1 said ```single or multi agent environments that work together or compete to achieve an objective```.
In general, at 2023-09-28 00:21:37 a user named you.wish said ```what do people do with autogen?```.
In general, at 2023-09-27 23:32:40 a user named nathan.lannan said ```Anyone able to get this doing anything useful yet? 

I know Agent are the future, have been for a hot minute, but also, have you seen Agents do more then spin their wheels eating tokens?```.
In general, at 2023-09-27 22:46:53 a user named bansalg said ```is this a question about how to switch models? https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In general, at 2023-09-27 22:23:36 a user named merkle said ```not sure if anyone already asked this but are we able to use turbo instead of gpt4?```.
In general, at 2023-09-27 21:48:33 a user named tonic_1 said ```hi there folks, Tonic here, just a builder from France/USA currently in Paris. I use azure services quite a lot especially now that i'm building systems for my enterprise and business apps for the public. I have an accidental and lively  🛠️build-in-public server too - 👊🏻 link in bio - happy to be here 🚀```.
In general, at 2023-09-27 19:57:34 a user named thepositionofbread said ```microsoft is known to make unopinioned tooling (or half-finished if you will), so it'll be reusable in different scenarios they hadn't thought of. At least that's how it goes for a lot of the C#/dotnet stuff```.
In general, at 2023-09-27 19:56:32 a user named egalitaristen said ```Look, all I'm saying is that every single one of these Autonomous Agent projects that I've looked at and tried (basically all of them) have had some form quickstart which didn't require more than a few simple cmd lines at most. But for this one, made by one of the biggest companies in the world, I have to actually code (or copy/paste code)```.
In general, at 2023-09-27 19:57:36 a user named unicorn1997 said ```im curious, what other agent projects have you tried? do you mean completely no-code things, like Superagent?```.
In general, at 2023-09-27 20:02:42 a user named egalitaristen said ```So, I started with AutoGPT. Then, some of the Autonymous Agents that I tried (off the top of my head) have been

* SmartGPT
* SuperAGI
* BabyAGI
* GPTengineer
* Aider
* ChatDev
* OpenIntrepreter
* MicroGPT```.
In general, at 2023-09-27 20:03:37 a user named egalitaristen said ```There are plenty of others but yeah, the gist is that they require very little or no coding for a *user* to get started```.
In general, at 2023-09-27 20:04:10 a user named thepositionofbread said ```this is a different offering than that, really```.
In general, at 2023-09-27 20:04:21 a user named egalitaristen said ```Yeah, I'm starting to get that```.
In general, at 2023-09-27 20:04:45 a user named egalitaristen said ```Just the hype I guess```.
In general, at 2023-09-27 20:04:50 a user named thepositionofbread said ```probably someone will make a plug and play solution build on top of this. It'll be interesting to see how it plays out.```.
In general, at 2023-09-27 20:05:11 a user named egalitaristen said ```Yeah, they'll start coming next week```.
In general, at 2023-09-27 20:07:05 a user named egalitaristen said ```I should have been more attentive to the "AutoGen is a framework..." part right at the start```.
In general, at 2023-09-27 20:07:24 a user named egalitaristen said ```It's just that I got distracted by the nice pictures```.
In general, at 2023-09-27 20:08:26 a user named thepositionofbread said ```lmao, yes, it's easy to get carried along.```.
In general, at 2023-09-27 20:15:13 a user named unicorn1997 said ```agree.. for me, the term "framework" is a bit ambiguous, since you can use it on variety of products.
tbh for me some of the no-code platforms didnt work that well, so i perceive that as a tradeoff in some sense```.
In general, at 2023-09-27 20:24:57 a user named egalitaristen said ```Yeah, most of the no-code platforms don't work great tbh. But they do work most/some of the time for users that have 0 experience with coding.```.
In general, at 2023-09-27 20:26:10 a user named egalitaristen said ```It'll be interesting to see if AutoGen actually results in anything that other's haven't already done or if it'll just end up being used with no-code stuff that works somewhat some of the time```.
In general, at 2023-09-27 20:27:58 a user named unicorn1997 said ```not sure what pain points they are trying to solve.
but the inter-agent communication is big topic imo, I havent came accross similar products on that in particular.
also, it is stack agnostic, as opposed to some of the easier frameworks. you have more freedom, but more difficulty running it, fair tradeoff```.
In general, at 2023-09-27 20:29:47 a user named egalitaristen said ```There are plenty of inter-agent communication stuff. The hottest one this week is ChatDev```.
In general, at 2023-09-27 20:30:01 a user named egalitaristen said ```https://github.com/OpenBMB/ChatDev```.
In general, at 2023-09-27 20:31:27 a user named egalitaristen said ```I'm afraid that I don't know what stack-agnosic means, but I'll take your word for it```.
In general, at 2023-09-27 20:58:10 a user named unicorn1997 said ```i meant that it doesnt limit you in what tech you should use and what approach you should take```.
In general, at 2023-09-27 21:01:52 a user named egalitaristen said ```Hey @unicorn1997 are you with Microsoft?```.
In general, at 2023-09-27 21:04:44 a user named egalitaristen said ```I mean, we're on an AutoGen Discord. AutoGen is created by Microsoft. I assume that some employee of Microsoft started this Discord. You seem like you belong.

Are you emplyed or contracted by Microsoft?```.
In general, at 2023-09-27 21:05:24 a user named unicorn1997 said ```no lol
i just came here like 2 hours ago when I started playing with AutoGen```.
In general, at 2023-09-27 21:08:11 a user named unicorn1997 said ```i am actually part of E2B https://e2b.dev/ core team (we do cloud envs for running agents) .. so the topic of agents is still super-relevant to me.```.
In general, at 2023-09-27 21:18:55 a user named egalitaristen said ```That's cool, I was once part of the [E2D](https://en.wikipedia.org/wiki/E2D_International) movement 😛```.
In general, at 2023-09-27 21:19:46 a user named egalitaristen said ```Almost the same but not at all 😄```.
In general, at 2023-09-27 21:36:29 a user named unicorn1997 said ```haha nice
E2B was named as "English 2 Bits" btw 😄```.
In general, at 2023-09-27 19:55:10 a user named fxtoofaan said ```Microsoft is known to release software half baked and let end users find the bugs and then they fix the bugs. They get free testers. Every new product is buggy from Microsoft. Have to wait for at lease a service pack to be released 🙂```.
In general, at 2023-09-27 19:51:28 a user named egalitaristen said ```Simply stating a WTF doesn't mean I'm not chill 🙂```.
In general, at 2023-09-27 19:50:56 a user named egalitaristen said ```https://tenor.com/view/frog-lily-lake-water-relax-gif-21614201```.
In general, at 2023-09-27 19:50:02 a user named pbeheca said ```I found the example note books very helpful:
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb

however im Struggling with one llm calling itself or another agent with an empty message in a loop. I'm also getting an error that interrupts the conversation as soon as the context window is exeeded```.
In general, at 2023-09-27 19:49:44 a user named shiccup said ```lol relax they released it opensource i think they expect people to use it in their projects```.
In general, at 2023-09-27 19:47:34 a user named egalitaristen said ```Hey, I'm stuck at not knowing what to do after the pip install```.
In general, at 2023-09-27 19:49:37 a user named unicorn1997 said ```What are you using?
I work in VSCode and I also use the terminal there.

So I just created a python file in VSCode where I am creating a first example with AutoGen. 

In high level: 

1. install AutoGen
2. create python file and there import a few necessary libraries and modules
3. add openai api key (I have it hidden in .env file)
4. copying simple example from AutoGen docs
5. solving bugs 
6. running it```.
In general, at 2023-09-27 19:49:44 a user named unicorn1997 said ```i can send the code I have if it helps```.
In general, at 2023-09-27 19:52:04 a user named egalitaristen said ```Hey, I also use VSCode```.
In general, at 2023-09-27 19:53:18 a user named egalitaristen said ```I'll figure it out but thanks```.
In general, at 2023-09-27 19:55:57 a user named unicorn1997 said ```okay no problem.
if you need help, just ping me```.
In general, at 2023-09-27 19:46:57 a user named unicorn1997 said ```hello! I am super new to coding and I managed to run AutoGen! (Im surprised haha). So do you need help?  Where are you stuck?```.
In general, at 2023-09-27 19:46:39 a user named egalitaristen said ```I mean, I will figure it out. And so will thousands of people. But that's thousands of manhours wasted```.
In general, at 2023-09-27 19:45:55 a user named egalitaristen said ```So, WTF Microsoft? Installation is as easy as a pip install but then us plebs need to figure out what to do next? Couldn't you have provided some form of UI and a very basic instruction on how to run AutoGen?```.
In general, at 2023-09-27 19:43:29 a user named shiccup said ```@fxtoofaan you could just look at real life newsletter companies and just copy them```.
In general, at 2023-09-27 19:38:15 a user named thepositionofbread said ```How does this compare to Semantic Kernel? I can't quite figure out yet if it's more like something built on top or something more in a different direction.```.
In general, at 2023-09-27 19:33:19 a user named fxtoofaan said ```If you were to start a LinkedIn newsletter on a topic and wanted to use autogen. How many agents will you use and each agent doing what ? 🙂```.
In general, at 2023-09-27 19:32:31 a user named quantomcpu said ```Does anyone have any log file examples I can view before I test this bad boy```.
In general, at 2023-09-27 19:19:19 a user named egalitaristen said ```And I'm not even using 50% of my RAM when doing this```.
In general, at 2023-09-27 19:18:55 a user named egalitaristen said ```But RAM is mostly taken up by context and I default my models to 8k context```.
In general, at 2023-09-27 19:16:39 a user named shiccup said ```how much ram in your pc```.
In general, at 2023-09-27 19:11:40 a user named shiccup said ```what gpu do you have```.
In general, at 2023-09-27 19:10:52 a user named egalitaristen said ```It simply depends on how many GPU layers you use for each model. I normally run my single models on 35-40 layers so when I ran 4 models at the same time I just used 8 layers instead```.
In general, at 2023-09-27 19:09:32 a user named shiccup said ```how much vram is necesary to do this though```.
In general, at 2023-09-27 18:08:58 a user named bansalg said ```One solution: create a bing search function with your bing api key as env var and simply the agent access to it (eg by putting it in the system prompt) or using the function call feature in the gpt models```.
In general, at 2023-09-27 18:16:26 a user named sonichi said ```One suggestion for api keys: Use a synthetic key in the LLM agent when suggesting code, and then replace it with the real key in the executor agent. This can be a feature to add in the built-in agents.```.
In general, at 2023-09-27 18:59:14 a user named bansalg said ```Is the advantage to never allow a path to expose sensitive info?```.
In general, at 2023-09-27 19:10:42 a user named sonichi said ```to avoid explicit exposure of it, yes```.
In general, at 2023-09-27 19:11:31 a user named sonichi said ```One can also use a key vault to store the real keys```.
In general, at 2023-09-27 19:12:00 a user named sonichi said ```This is one of the benefits of separating code generation and execution```.
In general, at 2023-09-27 18:08:01 a user named sonichi said ```Does this help? https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In general, at 2023-09-27 17:24:06 a user named pbeheca said ```I'm encountering an issue with the groupchat example where the user_proxy gets stuck in a loop trying to auto reply to chat_manager with emtpy messages. 🤔```.
In general, at 2023-09-27 17:18:19 a user named junaidamjad said ```https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/```.
In general, at 2023-09-27 17:16:22 a user named junaidamjad said ```Or use vector databases for embeddings and opensource```.
In general, at 2023-09-27 17:11:29 a user named junaidamjad said ```I'd also like to know. Was thinking if we could integrate LLMs such as Meta Lama instead of openai```.
In general, at 2023-09-27 16:41:49 a user named .princeps said ```You might want to check out retrieval user proxy, I'm not sure though```.
In general, at 2023-09-27 16:40:52 a user named jaemil said ```Is it possible to integrate dalle? Or integrations (tools) in general? Just like langchain is doing it or https://llamahub.ai```.
In general, at 2023-09-27 16:27:28 a user named pluckedout said ```I want to look for this later but does someone know if autogen allows integration with opensource llms?```.
In general, at 2023-09-27 16:18:56 a user named bunswo said ```Auto Generated Agent Chat: Solving Tasks Requiring Web Info```.
In general, at 2023-09-27 16:18:28 a user named bunswo said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb```.
In general, at 2023-09-27 16:04:06 a user named scratchinknight said ```can someone show how the OAI_CONFIG_LIST json file looks like```.
In general, at 2023-09-27 15:23:01 a user named rtproductions said ```damn this looks very promising```.
In general, at 2023-09-27 14:49:22 a user named Pedrod2 said ```looks like I got a bunch of terminology to learn too, thanks Bing AI, ok so getting AutoGen to interact with other local software or local systems```.
In general, at 2023-09-27 14:30:08 a user named egalitaristen said ```Yeah, seems like it. I think it's mostly because of a cleaner implimentation but I don't know. I haven't really ran any of these with GPT as my main focus has been to try to get local integration going.```.
In general, at 2023-09-27 14:28:18 a user named Pedrod2 said ```thanks, good to see you're here too haha. in the end looks like Autogen has more capabilities than Chatdev? at least according to Wes Roth```.
In general, at 2023-09-27 14:26:19 a user named egalitaristen said ```As I've understood it, yes. It should be able to install things like beautifulsoup for webscraping and yfinance and stuff like that.```.
In general, at 2023-09-27 14:21:37 a user named Pedrod2 said ```anyone knows if it's possible to get Autogen to access the internet?
perform Bing searches, open websites, grab info?```.
In general, at 2023-09-27 13:06:57 a user named beijeo said ```Anyone know if there is gonna be a JavaScript/TypeScript Framework for this```.
In general, at 2023-09-27 12:18:02 a user named 8i8__papillon__8i8d1tyr said ```Now on to the petals discord.```.
In general, at 2023-09-27 12:16:31 a user named 8i8__papillon__8i8d1tyr said ```I'm working with other open interpreter devs and potentially might use some of this.```.
In general, at 2023-09-27 12:14:53 a user named egalitaristen said ```Apperently the best prompt for Llama2 (that I know of) is telling it to "take a deep breath and solve the task"```.
In general, at 2023-09-27 12:14:41 a user named 8i8__papillon__8i8d1tyr said ```I have very simple cut'n'paste up that works.
https://github.com/CodeAKrome/petals```.
In general, at 2023-09-27 12:13:49 a user named egalitaristen said ```Yeah, I was going to suggest Petals for LMS but I haven't had time to look at Petals yet```.
In general, at 2023-09-27 12:13:32 a user named jimqode said ```@8i8__papillon__8i8d1tyr 😄 Ah the arcane art of AI whispering.```.
In general, at 2023-09-27 12:12:44 a user named 8i8__papillon__8i8d1tyr said ```@jimqode When someone ran into this problem, they told the llm "Have confidence in yourself, you can do anything" and it seems to have had an effect```.
In general, at 2023-09-27 12:10:54 a user named 8i8__papillon__8i8d1tyr said ```Is there somewhere that lists the api_type s? I'm trying to get this to work with petals and local models and I assume that affects prompting or the interaction somehow.```.
In general, at 2023-09-27 12:04:59 a user named 8i8__papillon__8i8d1tyr said ```O.K. I was having a similar convo on open interpreter. Lol. I'm trying to get this to work also. and Hi```.
In general, at 2023-09-27 12:02:15 a user named 8i8__papillon__8i8d1tyr said ```I also want this to hook up to petals, which was where I was going to look next.```.
In general, at 2023-09-27 12:00:53 a user named 8i8__papillon__8i8d1tyr said ```@egalitaristen you are a scholar and a gentlebeing. I was literally about to say something on their discord. Might still if I run into problems. Thank you most kindly.```.
In general, at 2023-09-27 11:17:20 a user named fxtoofaan said ```Can one or many of the agents be trained on local knowledge ? Like pdf or txt files ? Or research web sites etc ? Like proprietary knowledge or latest trending information and so on. Complement chatgpt per say```.
In general, at 2023-09-27 11:08:21 a user named fxtoofaan said ```This is great example. Thank you for that. It’s good to see the code in python files instead of jupyter notebook files```.
In general, at 2023-09-27 10:20:20 a user named egalitaristen said ```I've also just been able to get multiple instances om LM Studio server to run, so it should be easy to just replace api_base and have multiple local models run AutoGen```.
In general, at 2023-09-27 10:19:00 a user named egalitaristen said ```Found the local LLM part.```.
In general, at 2023-09-27 10:18:31 a user named egalitaristen said ```https://github.com/microsoft/autogen/blob/8e9cda716ec741ddcfcc0f552e7bb09ee2e21f57/website/blog/2023-07-14-Local-LLMs/index.mdx```.
In general, at 2023-09-27 09:17:48 a user named jimqode said ```ok it was an environment thing i guess. it works when i'm running on my system.```.
In general, at 2023-09-27 08:46:45 a user named jimqode said ```agents are continuosly suggesting they don't have the capability to open link or browse the internet```.
In general, at 2023-09-27 08:38:31 a user named jimqode said ```in the Auto Generated Agent Chat: Group Chat example, I have configured it to use GPT-3.5. The example ran. Product_manager suggested some python code to be ran. but it didn't run the python code. The dialogue is just some generic suggestions about the subject of the paper. Is this because i'm using GPT-3.5-turbo model? Maybe it needs function call access and GPT-3.5-turbo doesn't have it?```.
In general, at 2023-09-27 08:19:08 a user named jimqode said ```@bansalg thank you so much. i'll start experimenting in colab```.
In general, at 2023-09-27 08:18:35 a user named bansalg said ```Yes you can use 3.5 turbo. Performance with 4 is better, but can always fine tune the system prompts for 3.5 to fit your needs. Hope this helps!```.
In general, at 2023-09-27 08:03:16 a user named jimqode said ```does anyone know if autogen works with GPT-3.5-turbo? GPT-4 is quite expensive for me to play around.```.
In general, at 2023-09-27 06:33:37 a user named akash AI said ```is ther any collab notebook for autogen using open source llm, i dont have the openai api key```.
In general, at 2023-09-27 05:42:01 a user named .princeps said ```Here is some of the python code I have been playing with 

https://github.com/Poly186-AI-DAO/PolyGPT

This is just a project for me to experiment with this library```.
In general, at 2023-09-27 05:37:24 a user named .princeps said ```Check this out 

https://youtu.be/zdcCD--IieY?si=vLEbKjQLO_n_HRf-```.
In general, at 2023-09-27 05:36:27 a user named pradeep1148 said ```hi guys i made a video about autogen. this framewrok is amazing,
https://www.youtube.com/watch?v=JMpgsx74XDI&t=2s```.
In general, at 2023-09-26 21:41:09 a user named zespind said ```anyone running custom models on petals?```.
In general, at 2023-09-26 21:01:31 a user named bansalg said ```If you set you OPENAI_API_KEY you should be able to run this example: https://github.com/microsoft/autogen#quickstart

AutoGen supports much more comprehensive openAI config settings, see this example:
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_MathChat.ipynb
In this example, once you have a OAI_CONFIG_LIST set correctly (either as an environment variable or json), autogen.config_list_from_json( "OAI_CONFIG_LIST", ...) will read that config_list.

You can then use use this config in definition of the agents (e.g., see screenshot)```.
In general, at 2023-09-26 20:51:19 a user named sonichi said ```A PR was made in the flaml repo. We need to move it to the autogen repo.```.
In general, at 2023-09-26 20:42:24 a user named bansalg said ```I haven't used the finetuned models myself, but you should be able to pass a custom `llm_config`  to an agent. And that `llm_config` could be using your fine tuned model.```.
In general, at 2023-09-26 20:40:38 a user named sonichi said ```Do you mean the Transformers Agent? It should be easy to leverage Transformers Agent by registering a reply function based on Transformers Agent, using the `register_reply` method.```.
In general, at 2023-09-26 19:52:47 a user named sonichi said ```I’m not sure how to configure the OAI```.
In general, at 2023-09-26 19:17:22 a user named bigmiao said ```Thanks for the feedback, looks like there's a bug in group chat manager when distributing messages that is a function call, we'll push a fix pretty soon```.
In general, at 2023-09-26 18:50:00 a user named 360macky said ```Is it possible to run a conversational agent from Autogen with a fine-tuned OpenAI GPT model?```.
In general, at 2023-09-26 18:21:54 a user named fxtoofaan said ```Need a really good step by step how to guide on autogen. Maybe a YouTube video. Show how to run it locally on windows. Including how to connect to openai api and also local llm like lllama2. Seems like there is a blog from July https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs```.
In general, at 2023-09-26 18:14:07 a user named tomexmachina said ```FLAML had somehow escaped my attention until I just saw a video about autogen. Looks pretty cool. Guidance needs some more love imo. Idk if there's any crossover of devs from that repo here.```.
In general, at 2023-09-26 18:01:38 a user named fxtoofaan said ```I’m not sure how to configure the OAI_CONFIG_LIST file. I created this file without any extension and also with .json extension and copy pasted the relevant code in there but I get openai api error```.
In general, at 2023-09-26 19:52:49 a user named sonichi said ```Without any extension is right. Is it in the current path as you execute the code or did you specify the location via `file_location````.
In general, at 2023-09-27 11:49:48 a user named cluck0matic said ```I'm struggling with this as well on colag```.
In general, at 2023-09-28 02:20:41 a user named cyberian_mishka said ```hey @sonichi , i'm having trouble launching both from colab and terminal on mac. would you be so kind to share either a loom recording or share step-by-step on how to set OAI and launch autogen? i'm not sure where to set it + file location as well as how the code should look like.```.
In general, at 2023-09-28 02:22:07 a user named sonichi said ```Thanks for suggesting the idea of recording. That's a good idea. In the meanwhile, please check whether this helps: https://microsoft.github.io/autogen/docs/FAQ#use-the-constructed-configuration-list-in-agents```.
In general, at 2023-09-28 02:58:21 a user named cyberian_mishka said ```@sonichi , Thank you. I never worked with this before and wasn't able to figure what goes where. I am using terminal on mac for the first time i my life 🙂 I have the latest version on python and was able to run open interpreter today. Tried to use it to help launch autogen, but still need help.```.
In general, at 2023-09-28 02:59:57 a user named sonichi said ```if you already have `OPENAI_API_KEY` in your environment, you are good to go with the sample code here: https://microsoft.github.io/autogen/docs/Getting-Started#quickstart```.
In general, at 2023-09-26 17:56:02 a user named fxtoofaan said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb I’m trying to test out the 3 agent example.```.
In general, at 2023-09-26 17:33:54 a user named nousr said ```@samin1 @fxtoofaan https://microsoft.github.io/autogen/docs/Getting-Started ?```.
In general, at 2023-09-26 17:11:13 a user named fxtoofaan said ```That’s what I’m looking for```.
In general, at 2023-09-26 17:07:43 a user named samin1 said ```Anyone see any code samples to make autogen work?```.
In general, at 2023-09-26 17:07:32 a user named samin1 said ```Hey everyone! Software engineer, backend background ex FAANG right now I'm doing AI dev mostly langchain. Looking forward to connecting with you all and learning more```.
In general, at 2023-09-26 16:41:04 a user named 360macky said ```I didn't know Teams Community are even possible.```.
In general, at 2023-09-26 15:37:25 a user named aimuggle said ```is someone gonna get in trouble for starting a discord server instead of a teams community```.
In general, at 2023-09-26 15:37:04 a user named fxtoofaan said ```Anyone able to get it to run ? I’m having openai api errors. Not sure how to reference openai api etc. I’m not a programmer but ai enthusiast. Anyway to get the examples and samples in py files for easy testing. I’m not able to get it to run even with jupyter. I’m sure I’m missing something```.
In general, at 2023-09-26 15:12:41 a user named merkle said ```hey everyone! Software engineer, fullstack background in crypto and doing AI dev for past year or so (mostly langchain, llama index). one of my primary areas of focus right now is building agent systems that can accomplish more complex tasks through collaboration and task delegation so when i found this i was super excited! look forward to connecting with you all and learning more```.
In general, at 2023-09-26 15:10:54 a user named bixqu said ```will Autogen be compatible with Huggingface Transformers?```.
In general, at 2023-09-26 14:39:12 a user named fxtoofaan said ```How is this project different than ChatDev ?```.
In general, at 2023-09-26 14:25:30 a user named lionseagles said ```Looks exciting. Perhaps prevent posting in the Accouncement Channel```.
In general, at 2023-09-26 14:10:44 a user named fxtoofaan said ```Any examples on how to run autogen in windows 10 and not in Jupyter notebook ?```.
In general, at 2023-09-26 12:53:04 a user named fxtoofaan said ```Do I create a python file locally and put sample code in the python file and execute on windows 10? How I run this on windows 10 and not in junpyter notebook ?```.
In general, at 2023-09-26 12:39:17 a user named snoq_ said ```Will I be able to use any model like llama2 or only limited to got models?```.
In general, at 2023-09-26 00:31:51 a user named sonichi said ```https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/```.
In general, at 2023-09-24 21:48:57 a user named sonichi said ```https://x.com/suchenzang/status/1702741755186258138?s=46&t=HW3LQnkY2VkckNNTvFnbcA```.
In general, at 2023-09-24 21:44:55 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_vis.ipynb
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb```.
In general, at 2023-09-24 19:20:12 a user named ToYari said ```What is interesteing from the Agents paper : Symbolic Control: Different from existing frameworks for language agents that only use a simple task description to control the entire multi-agent system over the whole task completion process, Agents allows users to use an SOP (Standard Operation Process) that defines subgoals/subtasks for the overall task to customize fine-grained workflows for the language agents.```.
In general, at 2023-09-24 19:18:27 a user named ToYari said ```In which Notebook you use the GroupChatManager?```.
In general, at 2023-09-24 13:47:13 a user named sonichi said ```In the group chat, every agent sends msg to the GroupChatManager```.
In general, at 2023-09-24 13:46:43 a user named sonichi said ```akin to the current GroupChatManager```.
In general, at 2023-09-24 13:46:23 a user named sonichi said ```Or we could define an agent that performs the job of a queue, so we can use a unified programming interface.```.
In general, at 2023-09-24 12:11:44 a user named ToYari said ```Just done an article about you guys https://medium.com/@alcarazanthony1/towards-collaborative-intelligence-advanced-multi-agent-systems-in-large-language-models-with-d7e090d2d739```.
In general, at 2023-09-24 11:12:02 a user named ToYari said ```Hello maybe with this logic a queue : 

Shared Message Queue
Agents can coordinate through a shared queue:

python

Copy code

queue = Queue()

agent1.send(message, queue)
agent2.receive(queue)
This decouples the agents.```.
In general, at 2023-09-23 22:17:32 a user named ToYari said ```Thanks good day (night for me)```.
In general, at 2023-09-23 22:08:19 a user named sonichi said ```using the async methods should do it. I'm not an expert in parallel programming though.```.
In general, at 2023-09-23 21:45:23 a user named ToYari said ```I want a response time good for a chatbot so i need parallelisation```.
In general, at 2023-09-23 21:45:02 a user named ToYari said ```With possibly graph algorithm enabling different types of reasoning```.
In general, at 2023-09-23 21:44:40 a user named ToYari said ```Because I want to distribute my KG between multiple agents```.
In general, at 2023-09-23 21:16:26 a user named sonichi said ```For example, we can define a function call which invokes a few agents in parallel and return when they all finish?```.
In general, at 2023-09-23 21:13:14 a user named ToYari said ```It seems data received is asynchronous, not agents themselves. But i guess it would be simple to make them that way?```.
In general, at 2023-09-23 20:57:03 a user named ToYari said ```Maybe I can instruct it to consult MethodolyAgent first```.
In general, at 2023-09-23 20:56:31 a user named ToYari said ```My main concern is to give the main agent the UserProxyAgent access to a KG as a methology, 

It would consult it before activating other agents, 
Or activate one agent with this methodogy.```.
In general, at 2023-09-23 20:53:33 a user named sonichi said ```For parallelization, we have async methods like in https://github.com/microsoft/autogen/blob/main/notebook/agentchat_stream.ipynb```.
In general, at 2023-09-23 20:52:13 a user named sonichi said ```For hierarchy, one possible way is to create more agents when needed via a function call, e.g., https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb```.
In general, at 2023-09-23 20:44:07 a user named ToYari said ```Thanks for sharing your amazing work```.
In general, at 2023-09-23 20:43:52 a user named ToYari said ```My two cents (I m going to bed) eager to work with you guys```.
In general, at 2023-09-23 20:43:21 a user named ToYari said ```Is it feasible to deploy multiple agents to concurrently search for identical information, leveraging parallelization, a notable strength of GPT swarm, to enhance efficiency and response times?```.
In general, at 2023-09-23 20:43:14 a user named ToYari said ```Is it possible to establish a prioritization hierarchy among agents engaged in a multi-agent conversation to streamline the interaction process?```.
In general, at 2023-09-23 20:33:56 a user named ToYari said ```got it llm_config in the function calling notebook```.
In general, at 2023-09-23 20:32:27 a user named ToYari said ```How can I easily customize my .AssistantAgent adding my own tools for example?```.
In general, at 2023-09-23 20:13:33 a user named sonichi said ```@bansalg GPT-Swarm is here 😄```.
In general, at 2023-09-23 20:09:20 a user named ToYari said ```https://github.com/geekan/MetaGPT```.
In general, at 2023-09-23 20:09:10 a user named ToYari said ```https://github.com/Open-Swarm-Net/GPT-Swarm```.
In general, at 2023-09-23 20:08:48 a user named ToYari said ```I do now GPT swarm```.
In general, at 2023-09-23 20:08:37 a user named ToYari said ```So your paper is very good i think. First library to build something about multi agents system```.
In general, at 2023-09-23 20:07:55 a user named ToYari said ```For complex KG you can leverage graph algorithm```.
In general, at 2023-09-23 20:07:43 a user named ToYari said ```Output for KG agents is stable for the same question, not the case very often for vector similarity search.```.
In general, at 2023-09-23 20:06:47 a user named ToYari said ```https://medium.com/ai-in-plain-english/vector-search-is-not-all-you-need-ecd0f16ad65e```.
In general, at 2023-09-23 20:06:23 a user named ToYari said ```I think KG retrieval is far superior to vector retrieval```.
In general, at 2023-09-23 20:06:00 a user named ToYari said ```https://medium.com/ai-in-plain-english/llms-and-knowledge-graphs-the-technological-twins-1518bec38077 I write a lot on the subject```.
In general, at 2023-09-23 20:05:27 a user named ToYari said ```I want multiple RAG retrieval at the same time, and a central manager that do a summary, maybe itself with a methodlogy of its own```.
In general, at 2023-09-23 20:04:28 a user named ToYari said ```I intend to use your framework to leverage this RAG framework like this notebook https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb```.
In general, at 2023-09-23 20:03:22 a user named ToYari said ```I will tomorow. I m working right now on a multi agents system that leverage KG as a retriever```.
In general, at 2023-09-23 19:59:08 a user named qingyunwu said ```Great to hear from you ToYari. This sounds exciting. Have you start trying? Feel free to us know if you need any assistance.```.
In general, at 2023-09-23 19:31:28 a user named ToYari said ```I m interested in leveraging your framework with Llama index,```.
In general, at 2023-09-23 13:23:49 a user named sonichi said ```Let me know how it goes and feel free to create issue, pr etc.```.
In general, at 2023-09-23 03:55:34 a user named .princeps said ```@sonichi thanks! This would be awesome since something like Clause-2 with its longer context window can be useful in generating long text for code or books. Also I found that I can only run one big open source model at a time since they are later. 

My current setup is calling Claude api as a function and it’s easier like this so I was thinking of using Replicate to run the open source modes as APIs since I don’t have the space and powerful computer to run them locally```.
In general, at 2023-09-22 13:32:01 a user named sonichi said ```This is also relevant: https://github.com/microsoft/FLAML/pull/1212```.
In general, at 2023-09-22 09:21:01 a user named .princeps said ```so they do have a RESTful API, but the only one available is the post above, I think I will need to wrap it up to be OpenAI-compatible. however, I don't know how to do this so maybe you can show me or just let me know what documentation, notebook or blog to checkout. I'm guessing this is probably what you meant

https://github.com/lm-sys/FastChat/blob/main/docs/openai_api.md```.
In general, at 2023-09-22 06:29:13 a user named .princeps said ```I can test it in the config to see if it works```.
In general, at 2023-09-22 06:28:25 a user named .princeps said ```Hmmm not sure, but they do have an API:

curl --request POST \
     --url https://api.anthropic.com/v1/complete \
     --header 'accept: application/json' \
     --header 'anthropic-version: 2023-06-01' \
     --header 'content-type: application/json' \
     --header 'x-api-key: $ANTHROPIC_API_KEY'```.
In general, at 2023-09-22 06:20:20 a user named li_jiang said ```Hi @.princeps, does clause 2 have OpenAI-compatible RESTful APIs? Or can you wrap it up to be OpenAI-compatible?```.
In general, at 2023-09-22 05:48:02 a user named .princeps said ```On a different note, I just got access to clause 2, can I use it with Autogen ? @li_jiang @sonichi```.
In general, at 2023-09-22 04:31:04 a user named .princeps said ```@li_jiang @li_jiang let me know any resource or notebooks you have for using open source models,I have been studying this one: https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs```.
In general, at 2023-09-22 04:19:49 a user named .princeps said ```Will do! I made a team that created a snake game, my goal is to eventually have something more sophisticated. 

I'll be testing the library using open source models today through FastChat```.
In general, at 2023-09-22 04:00:34 a user named li_jiang said ```You're welcome. Let me know if you need more help. Also, we'd appreciate any suggestions and comments on the lib/feature. Thanks for trying out.```.
In general, at 2023-09-22 03:50:40 a user named .princeps said ```@li_jiang I don't know what is the right import statement, so basically I'm not able to find them to pull from, this notebook helped a lot! Thanks so much!```.
In general, at 2023-09-22 01:28:13 a user named li_jiang said ```Hi @.princeps , thanks for the question. I'd be happy to help you on it. You're referring to the right APIs, and here is an notebook example https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb. Could you post more info about the issue you've encountered?```.
In general, at 2023-09-21 11:48:46 a user named .princeps said ```I wanted to experiment with RetrieveAssistantAgent and RetrieveUserProxyAgent but I haven't been able to pull them in, I know that they are experiemental so I wanted to see if I can learn anything about these on how to use them 

https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/retrieve_assistant_agent

https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/retrieve_user_proxy_agent

`documentation_specialist = autogen.RetrieveAssistantAgent(
    name="documentation_specialist",
    system_message="You are the go-to expert for documentation queries.",
    llm_config={
        "request_timeout": 600,
        "seed": 42,
        "config_list": config_list_gpt4,
    },
)`

`code_assistant = autogen.RetrieveUserProxyAgent(
    name="code_assistant",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=2,
    retrieve_config={
        "docs_path": "./website/docs",
        "chunk_token_size": 2000,
        "model": config_list_gpt4[0]["model"],
        "client": chromadb.PersistentClient(path="/tmp/chromadb"),
    },
)````.
In general, at 2023-09-20 22:13:29 a user named shubh2023_14031 said ```For which I get the following error:```.
In general, at 2023-09-20 22:13:01 a user named shubh2023_14031 said ```llm_config1={
    "functions":[
        {
            "name": "create_ui_design",
            "description": "call create_ui_design given the application idea.",
            "parameters": {
                "type": "object",
                "properties": {
                    "application_ideas": {
                        "type": "string",
                        "description": "application ideas",
                    }
                },
                "required": ["application_ideas"],
            },
        },
    ],
    "request_timeout": 600,
    "seed": 42,
    "config_list": config_list_gpt4,
    "temperature": 0,

}
llm_config = {"config_list": config_list_gpt4, "seed": 42}
user_proxy = autogen.UserProxyAgent(
    name="User_proxy",
    system_message="A human admin.",
    code_execution_config={"last_n_messages": 3, "work_dir": "groupchat"},
    human_input_mode="TERMINATE",
    function_map={"create_ui_design": create_ui_design},
)
coder = autogen.AssistantAgent(
    name="Coder",
    llm_config=llm_config,
)
pm = autogen.AssistantAgent(
    name="Product_manager",
    system_message="Creative in software product ideas.",
    llm_config=llm_config
)
ui_dev = autogen.UserProxyAgent(
    name="UI_designer",
    is_termination_msg=lambda x: x.get("content", "") and x.get("content", "").rstrip().endswith("TERMINATE"),
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=10,

)
ui_des = autogen.AssistantAgent(
    name="UI_developer",
    llm_config=llm_config1,
    system_message="Execute only functions you have been provided. Reply TERMINATE when the task is done.",
    max_consecutive_auto_reply=10
    )

groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm, ui_des], messages=[], max_round=12)
manager = autogen.GroupChatManager(
    groupchat=groupchat, 
    llm_config=llm_config1
)```.
In general, at 2023-09-18 23:25:30 a user named sonichi said ```Could you create an issue? We only mentioned in the notebooks```.
In general, at 2023-09-18 20:30:18 a user named .beibinli said ```Can anyone provide an example of "OAI_CONFIG_LIST" file in documentation? It seems like we never mentioned what it is.```.
In announcements, at 2023-11-13 22:14:34 a user named sonichi said ```**new release: v0.2.0b5** https://github.com/microsoft/autogen/releases/tag/v0.2.0b5
🔥 Experimental [GPTAssistantAgent]( https://github.com/microsoft/autogen/blob/main/autogen/agentchat/contrib/gpt_assistant_agent.py), which leverages the OpenAI Assistant API for conversational capabilities in AutoGen. This agent is unique in its reliance on the OpenAI Assistant API for state management, differing from other agents using the Completion API.
- Blogpost: https://microsoft.github.io/autogen/blog/2023/11/13/OAI-assistants/
- Notebook 1: GPTAssistantAgent in a hello-world example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_twoagents_basic.ipynb
- Notebook 2: GPTAssistantAgent using function call: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_function_call.ipynb
- Notebook 3: GPTAssistantAgent with code interpreter: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_code_interpreter.ipynb
- Notebook 4: GPTAssistantAgent in a group chat: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_groupchat.ipynb

🔥 Blogpost for [EcoAssistant](https://microsoft.github.io/autogen/blog/2023/11/09/EcoAssistant), which is designed to solve user queries more accurately and affordably using assistant hierarchy and solution demonstration.

Thanks to @ianthereal @bansalg @jiale_liu @kevinwyr @qingyunwu @jieyuzhang_uw and all the other contributors!```.
In announcements, at 2023-11-11 20:37:24 a user named sonichi said ```**new release: v0.2.0b4** https://github.com/microsoft/autogen/releases/tag/v0.2.0b4
## Highlights

* **CompressibleAgent** (experimental) can be used to handle long conversations. Notebook: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_compression.ipynb
* Introducing Experimental **GPT Assistant Agent**: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/contrib/gpt_assistant_agent.py. More improvements are under way.
* Experimental **streaming** support is added.
* `seed` is renamed to `cache_seed` to be compatible with openai's `seed` parameter in chat completion. Migration guide is updated: https://microsoft.github.io/autogen/docs/Installation/#migration-guide-to-v02
* Better warnings and error handling for group chat.

Thanks to @ianthereal @kevinwyr @Alvaromah and all the other contributors!```.
In announcements, at 2023-11-09 14:50:02 a user named sonichi said ```🆕 AutoGen is selected in Open100: Top 100 Open Source achievements 🏆 
https://www.benchcouncil.org/evaluation/opencs/annual.html```.
In announcements, at 2023-11-08 13:41:14 a user named sonichi said ```**new release: v0.2.0b3** https://github.com/microsoft/autogen/releases/tag/v0.2.0b3
A quick release to switch to openai-python v1.1.1.
Thanks to @joshkyh for a new group chat notebook example with hierarchical flow: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_hierarchy_flow_using_select_speaker.ipynb```.
In announcements, at 2023-11-06 22:14:35 a user named sonichi said ```**new release: v0.2.0b2** https://github.com/microsoft/autogen/releases/tag/v0.2.0b2
## Highlights
* **Support for GPT-4V!** Introduced Large Multimodal Models in AgentChat, enhancing capabilities and interactions within the platform. Blogpost: https://microsoft.github.io/autogen/blog/2023/11/06/LMM-Agent
* Improved codebase reliability with updates such as dict copying before modifications (fixing a bug for Azure OpenAI) and various typo fixes.
* Added support for unstructured data in retrieve chat (RAG).
* Expanded functionality with async support for better `get_human_input` handling.
* A new simple Testbed tool for Autogen processes.
* Enhanced developer tools and documentation, including new README and TRANSPARENCY_FAQS updates.

Thanks to all the testers for the v0.2 migration. Thanks to @.beibinli @AkariLan @vatsalya-vyas @gfggithubleet @bansalg @li_jiang @hung-ngm @afourney @AaadityaG @jasondotparse @c_bonadio @aayushc1308 @qingyunwu @eltociear @marcgreen and other contributors!```.
In announcements, at 2023-11-04 04:53:46 a user named sonichi said ```**new release: v0.2.0b1** https://github.com/microsoft/autogen/releases/tag/v0.2.0b1
## Highlights
* Switching to openai v1. Please read the migration guide https://microsoft.github.io/autogen/docs/Installation/#migration-guide-to-v02 and report bugs.
* Support async function execution & get_human_input.
* Improvements in documentation and notebooks.

Thanks to all the reviewers for the v0.2 migration. Thanks to @aayushchhabra1999 @c_bonadio @marcgreen and other contributors!```.
In announcements, at 2023-10-30 22:02:42 a user named sonichi said ```AutoGen (http://aka.ms/autogen-gh) is the top trending repo on GitHub this month. I appreciate the huge interest, activities, and support from everyone in the community! 🫶
📖Paper: http://aka.ms/autogen-pdf
https://twitter.com/Chi_Wang_/status/1718339760278909321```.
In announcements, at 2023-10-28 01:17:38 a user named sonichi said ```Weekend **new release: v0.1.14** https://github.com/microsoft/autogen/releases/tag/v0.1.14
## Highlights

- 👀Give vision to your agent: **multimodal** examples are added at https://github.com/microsoft/autogen/blob/main/notebook/agentchat_lmm_llava.ipynb.
- 📖**TeachableAgent** blogpost: https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent.
- 🧵 Run a chat in a different thread/process: using thread safe timeout for code execution.
- 🪶 Qdrant vector store: A QdrantRetrieveUserProxyAgent is added in contrib/.
- 🚦 Support new version of chromadb in retrieve chat.
- 🧮 Token count utils.
- 🐋 Improve vscode extension setup in codespace.
- 📝 Many improvements in documentation, FAQ, useful tips, such as
  - how to prevent gpt-3.5 agents' appreciation loop
  - fixes in the langchain notebook
  - link to the roadmap
  - common issues in retrieve chat

Thanks to @.beibinli @rickyloynd @ragyabraham @Anush008 @li_jiang @kevinwyr  @shruti222patel @craigomatic @aaronward_ and all the other contributors!
## Headsup

v0.2 release is near the corner, and we'll switch to openai v1 in it. Please check for breaking changes in https://github.com/microsoft/autogen/pull/393. We'll try to add as many features back as possible before the release. If you see any breaking changes that affect your work, please comment in the PR thread.```.
In announcements, at 2023-10-21 17:01:35 a user named sonichi said ```**New release: v0.1.13** https://github.com/microsoft/autogen/releases/tag/v0.1.13

## Highlights

A preliminary `TeachableAgent` is added to allow users to teach their assistant facts, preferences, and tasks unrelated to code generation. Example notebook: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_teachability.ipynb

Conversational assistants based on LLMs can remember the current chat with the user, and can even demonstrate in-context learning of things that the user teaches the assistant during the chat. But these memories and learnings are lost once the chat is over, or when a single chat grows too long. In subsequent chats, the user is forced to repeat any necessary instructions over and over.

`TeachableAgent` addresses these limitations by persisting user teachings across chat boundaries in long-term memory (a vector database). Memory is saved to disk at the end of each chat, then loaded from disk at the start of the next. Instead of copying all of memory into the context window, which would eat up valuable space, individual memories (called memos) are retrieved into context as needed. This allows the user to teach frequently used facts, preferences and skills to the agent just once, and have the agent remember them in later chats.

This release also contains an update about openai models and pricing, and restricts the openai package dependency version. In v0.2 we will switch to openai>=1. 

Thanks to @rickyloynd @kevinwyr and all the other contributors!```.
In announcements, at 2023-10-20 00:01:32 a user named sonichi said ```**New release: v0.1.12** https://github.com/microsoft/autogen/releases/tag/v0.1.12
This release contains a significant improvement to function call in group chat. It decreases the chance of failures for group chat involving function calls. It also contains improvements to RAG agents, including added support for custom text splitter, example notebook (https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_RAG.ipynb) for RAG agent in group chat, and a blogpost (https://microsoft.github.io/autogen/blog/2023/10/18/RetrieveChat). Thanks to @thinkall and other contributors!```.
In announcements, at 2023-10-17 00:16:43 a user named sonichi said ```**New release: v0.1.11** https://github.com/microsoft/autogen/releases/tag/v0.1.11
This release contains bug fixes, more clear behaviors for docker, and model compatibility improvement. Agents using Langchain tools are demonstrated in https://github.com/microsoft/autogen/blob/main/notebook/agentchat_langchain.ipynb. Thanks to @kajatta and all the other 15 contributors!```.
In announcements, at 2023-10-10 14:21:31 a user named sonichi said ```**New release: v0.1.10** https://github.com/microsoft/autogen/releases/tag/v0.1.10
This release adds support to plug in *customized vectordb* and embedding functions in retrieve augmented chat.
Thanks to @li_jiang for the fast development to unblock the builders in the community!```.
In announcements, at 2023-10-10 01:33:48 a user named sonichi said ```**New release: v0.1.9** https://github.com/microsoft/autogen/releases/tag/v0.1.9
This release contains a number of improvements, including better support for different models and better termination logic in retrieval augmented chat, as well as warnings for better debuggability. Thanks to @li_jiang @afourney and other contributors!```.
In announcements, at 2023-10-08 16:43:11 a user named qingyunwu said ```** New release: v0.1.8  **https://github.com/microsoft/autogen/releases/tag/v0.1.8
The issue about code execution with docker under Windows environment is fixed now.  Thanks to @mrauter @mrauter1 for the contribution```.
In announcements, at 2023-10-07 13:12:06 a user named sonichi said ```**New release**: *v0.1.7* allows instantiating config_list with a .env file.
Example notebook about different ways of loading configs: https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb
Thanks to @aaronward_ and other contributors!```.
In announcements, at 2023-10-05 19:40:21 a user named bansalg said ```@everyone 

AutoGen has a new Twitter account! 
https://twitter.com/pyautogen

Please follow us to stay up to date on future major announcements!```.
In announcements, at 2023-10-05 14:14:18 a user named sonichi said ```📢 New tweet for our new technical report online today: https://twitter.com/Chi_Wang_/status/1709932523990729129
Please help with reposting because I have very few followers on twitter/X (I am new on it).
Also, please give it a star on GitHub (https://github.com/microsoft/autogen) if you like the project. Thank you @everyone!```.
In announcements, at 2023-10-04 17:40:21 a user named sonichi said ```📢 We just tweeted a short video: https://x.com/chi_wang_/status/1709615803832635436?s=46&t=HW3LQnkY2VkckNNTvFnbcA
Please help with retweeting it and growing the community! @everyone```.
In announcements, at 2023-10-03 05:20:56 a user named sonichi said ```*v0.1.6* is released. This release improved stability, fixes bugs related to `function_call` in group chat, and improve readme and docstring for readability.
Thank you to the community for your contributions! We are thrilled to see new contributors and appreciate your collaborative effort! 😃```.
In announcements, at 2023-10-01 14:48:59 a user named sonichi said ```*v0.1.5* is released. 🚀 This release adds support for PDF files in RetrieveChat (https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb)
What does it mean? 🤔 
We can now have different files ( a.txt, b.md, c.pdf, e.html ... ) under the given docs_path and all the files with supported formats will be parsed and added to the vector db. 🤩 
We don't have a new notebook example to demo this new feature yet. Example tutorials from the community are welcome! 😄 
This new feature is contributed by the community. 🫡```.
In announcements, at 2023-09-30 17:29:12 a user named sonichi said ```*v0.1.4* is released. This release makes it convenient to configure retry time to deal with rate limit error.
https://microsoft.github.io/autogen/docs/FAQ/#handle-rate-limit-error-and-timeout-error```.
In announcements, at 2023-09-30 13:35:34 a user named sonichi said ```We are trending on GitHub: https://github.com/trending 
Thanks for all the support and feedback!```.
In announcements, at 2023-09-28 21:37:11 a user named sonichi said ```v0.1.3 is released. This release fixes bug for windows and improves sample code.```.
In announcements, at 2023-09-28 02:13:47 a user named 2good4hisowngood said ```I was recently introduced to Obsidian by one of the devops engineers on my team. I love the ability to drop a pdf file into a text or graph files and scroll it then move it up out of the way to take notes before returning to it without having to switch tabs. You can also crosslink many small pages with each other, and then project the connections with the graph feature to see a web of knowledge. It's one of a thousand things I'd like to try with AI, just hard finding time learning and experimenting while working full time.

I collect papers, along with stuff like links to the sources, repos, etc, so I can explore and learn, and hopefully eventually find an opportunity to contribute back in some small way.```.
In announcements, at 2023-09-28 01:58:04 a user named askofu said ```Can you tell me more about your "notebook", I'm looking for a way of tracking the papers I'm interested in.```.
In announcements, at 2023-09-28 00:47:58 a user named izc333 said ```the big big big news that i see from open-interpreter come out it very fast forword 🚀🚀🚀🚀🚀🚀🚀🚀```.
In announcements, at 2023-09-27 19:19:11 a user named 2good4hisowngood said ```Added to my notebook on papers!```.
In announcements, at 2023-09-27 19:08:49 a user named pbeheca said ```https://arxiv.org/abs/2308.08155```.
In announcements, at 2023-09-27 19:08:35 a user named wyttearp said ```I'm incredibly interested in this paper and cannot wait to get it up and running!```.
In announcements, at 2023-09-27 19:08:20 a user named unicorn1997 said ```Please can you share the paper? I also havent come across it, but just trying to get AutoGen running```.
In announcements, at 2023-09-27 14:41:05 a user named gaborkukucska said ```It will definitely see more attention soon 🙂 there are also other implementations of this multi LLM infrastructure, but this is how we build AGI. single LLMs just like a single process in our brain or a thought 🙂 Well... that is how we should use it and not by pushing one LLM instance to it's limits 🤭 just spawn for singular purpose and build multiple layers of networks of LLMs. Perhaps one big LLM to interface with it's human counterpart 🧐  Lets go people! 😃  (excuse my hunglish)```.
In announcements, at 2023-09-27 14:33:06 a user named gaborkukucska said ```Thank you! Just what I needed 🙂```.
In announcements, at 2023-09-27 13:56:27 a user named morfes said ```Hi all, very interesting paper from MSF```.
In announcements, at 2023-09-27 13:37:23 a user named .mcalpha said ```Weird that this paper hasn't seen more attention yet.```.
In announcements, at 2023-09-27 12:02:13 a user named jharleydev said ```Hi, very cool paper can't wait to try this out !```.
In announcements, at 2023-09-26 11:50:39 a user named tonykipkemboi. said ```Hi y'all! Excited to try this!```.
In announcements, at 2023-09-23 19:29:51 a user named ToYari said ```Hello everyone very interesting paper```.
In announcements, at 2023-09-21 02:57:45 a user named sonichi said ```*v0.1.1* is released to pypi. Make RetrieveAssistantAgent importable.```.
In forum-discussion, at 2023-11-15 00:52:41 a user named lucemia. said ```I'm currently utilizing AutoGen for my DevOps tasks, and it performs admirably when I need to perform tasks like adding or removing lines across numerous repositories.

Nonetheless, I'm facing challenges when it comes to more intricate tasks. For instance, I'm interested in leveraging AutoGen to iterate through all Python files within a repository and apply typing using GPT.

At present, AutoGen is capable of generating a script that effectively iterates through the files within a repository. However, I'm uncertain about the proper approach to incorporate GPT within the generated scripts. How can I correctly integrate GPT into these scripts?

https://github.com/microsoft/autogen/issues/674```.
In forum-discussion, at 2023-11-14 12:07:50 a user named aaronward_ said ```https://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/14.openai-assistant-api/OpenAi-assistant-with-autogen.ipynb```.
In forum-discussion, at 2023-11-14 04:53:48 a user named _jojorge said ```Thanks for the tip! I got it working!

https://discord.com/channels/1153072414184452236/1153072414184452243/1173847890024738836```.
In forum-discussion, at 2023-11-14 03:18:25 a user named .jkyh said ```This example might get you half-way of what you need, the usage of NEXT: tag specifies who is next (and the example potentially also shows how to group up 13 agents, if that's helpful).
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_hierarchy_flow_using_select_speaker.ipynb```.
In forum-discussion, at 2023-11-13 21:34:41 a user named rickyloynd said ```@01011_balachandar Have you tried following this tutorial? https://www.youtube.com/watch?v=10FCv-gCKug```.
In forum-discussion, at 2023-11-11 20:00:51 a user named sonichi said ```I saw one video: https://www.youtube.com/watch?v=XGCWyfA3rgQ&t=7s```.
In forum-discussion, at 2023-11-11 02:46:58 a user named sonichi said ```@.vrda Happy to host it on https://microsoft.github.io/autogen/blog if you are interested in writing it there.```.
In forum-discussion, at 2023-11-10 16:02:51 a user named denonrails said ```Last Friday, during a hackathon, I initiated the Obsidian AutoGen project. You can check it out here: https://github.com/denonrailz/obsidian-autogen

The core objective of Obsidian AutoGen is to create an accessible framework that simplifies the process of tweaking, monitoring, and evaluating AutoGen agents. This project is currently in its nascent stage.

I'm eager to share this with our tech community and would greatly appreciate your insights and suggestions. What are your thoughts?

Moreover, I'm on the lookout for devs interested in tackling some challenges within the project for monetary compensation. My expertise lies in Go, so I need some Python firepower! PM me if you interested```.
In forum-discussion, at 2023-11-09 19:40:50 a user named zyadon7 said ```Nevermind.  This stickied video is great for local hosting.
https://www.youtube.com/watch?v=10FCv-gCKug```.
In forum-discussion, at 2023-11-09 08:44:21 a user named .vrda said ```I have created a gist where you can see the custom functions that connect llamaindex_retrieval with autogen agents. You can check it out here : https://gist.github.com/vrda23/9b366ce202367796e2fcaafd179b5709```.
In forum-discussion, at 2023-11-08 00:50:21 a user named john.jeong said ```Yes, they have worked on it and released a paper called HuggingGPT. You can test it out on HuggingFace 🙂
https://huggingface.co/spaces/microsoft/HuggingGPT```.
In forum-discussion, at 2023-11-06 22:14:17 a user named kevinwyr said ```I am creating a CompressibleAgent that handles the token limit problem, and looking for people to try it out! Welcome any suggestions or feedback, and it would be also great to hear your experiences with the MemGPT agent if you have tried it!

A discussion thread is created here: https://github.com/microsoft/autogen/discussions/561
CompressibleAgent: https://github.com/microsoft/autogen/blob/groupcompress/notebook/agentchat_compression.ipynb```.
In forum-discussion, at 2023-11-06 21:34:22 a user named kevinwyr said ```@good_guy_greg Hello there, I am creating a compressible_agent that allows you to remove old histories and others ways to deal with long context. Check out the third example here: https://github.com/microsoft/autogen/blob/groupcompress/notebook/agentchat_compression.ipynb

I am also creating a discussion here: https://github.com/microsoft/autogen/discussions/561
Let me know if you have any ideas or suggesionts!```.
In forum-discussion, at 2023-11-06 21:27:43 a user named kevinwyr said ```@wayliu  @Yahree Hello there, are you still having memory issues with autogen? I am creating a discussion here about handling long context: https://github.com/microsoft/autogen/discussions/561. I am working on the compressible agent and it now supports groupchat. It would be great if you can try it out or share your experience if you tried memGPT !```.
In forum-discussion, at 2023-11-06 21:18:00 a user named kevinwyr said ```Hello there, I am also creating a discussion here in github for experiences related to token limit issues and testing memGPTs: https://github.com/microsoft/autogen/discussions/561 
It would be great if you can also share your experiences there!```.
In forum-discussion, at 2023-11-06 17:59:12 a user named bobaleaux said ```here's a good source list that @bansalg put together.
I'm not sure how recent it has been updated though.

sorry, it's not specific but 'teachable_agent_ has the elements of a form of.

https://discord.com/channels/1153072414184452236/1161019174840188928```.
In forum-discussion, at 2023-11-06 07:38:05 a user named ragyabraham said ```however there is an open issue to make the handler more generic which we are working on. i just need to find time to get this done https://github.com/microsoft/autogen/issues/394```.
In forum-discussion, at 2023-11-06 01:08:02 a user named andrew0_1 said ```We've implemented this inside https://agentcloud.dev which is an open source UI to run autogen```.
In forum-discussion, at 2023-11-05 17:23:19 a user named bobaleaux said ```I also never used notebooks but I did find a sort of workaround that at the very least gets me close to a starting point for any notebook example.
I shared it here, hope it helps.

https://discord.com/channels/1153072414184452236/1153072414184452241/1161037470582972416```.
In forum-discussion, at 2023-11-04 21:55:56 a user named ibrahim_aka_ajax said ```Before Autogen was released, I followed the development of JARVIS. Does anyone know if Microsoft are still working on JARVIS?
https://github.com/microsoft/JARVIS```.
In forum-discussion, at 2023-11-04 14:22:01 a user named legendary_capybara_55573 said ```Not me. But I have tested his content agent. It's pretty interesting...https://github.com/JayZeeDesign/microsoft-autogen-experiments/blob/main/content_agent.py```.
In forum-discussion, at 2023-11-03 19:58:14 a user named aaronward_ said ```https://youtu.be/64Oy7pWEZIA?si=-dZTcpkLVnl5IdEI```.
In forum-discussion, at 2023-11-03 16:40:30 a user named afourney said ```https://1drv.ms/b/s!AizyymT31_HYi41v5EfxUVC4o4yLIg?e=fkgSLT```.
In forum-discussion, at 2023-11-03 16:39:54 a user named afourney said ```Here is an example: https://1drv.ms/b/s!AizyymT31_HYi41u1zEY-O6BWp3DuA?e=pHEx3q```.
In forum-discussion, at 2023-11-03 15:15:21 a user named macoson said ```Maybe you will find this repo useful https://github.com/OpenBMB/BMTools```.
In forum-discussion, at 2023-11-03 12:08:20 a user named sonichi said ```https://github.com/microsoft/autogen/pull/491```.
In forum-discussion, at 2023-11-02 03:53:24 a user named .jkyh said ```@jieyuzhang_uw's EcoAssistant paper is likely to give some context for this question, albeit not the direct comparison stated in your question. 🙂
https://arxiv.org/pdf/2310.03046.pdf```.
In forum-discussion, at 2023-11-02 03:31:16 a user named pengqd. said ```I created an online education multi-person classroom using autogen chatgroup.

A variety of roles are set up in the chatgroup, such as professors, teaching assistants, and tutors. Students ask the chatgroup to solve problems.

But it takes too long time for students to use it.

so, Is there any way to reduce the total time spent?

I tried the following:
1、Improve chatgroup manager, will be no loop
2、Set reasonable parameters, such as: set `max_consecutive_auto_reply` value smaller,  but the smaller the value, the worse the quality of the answer.
3、use streaming, such as: https://github.com/microsoft/autogen/pull/491. but total time is not decrease

Is autogen really suitable for building online real-time systems?```.
In forum-discussion, at 2023-11-01 22:35:00 a user named tonic_1 said ```Normally we did a good job here : https://www.GitHub.com/tonic-ai/polygpt-alpha```.
In forum-discussion, at 2023-11-01 21:17:10 a user named sonichi said ```Please find the PR here: https://github.com/microsoft/autogen/pull/509```.
In forum-discussion, at 2023-11-01 19:21:43 a user named konose_ said ```I just switched to https://huggingface.co/TheBloke/dolphin-2.1-mistral-7B-GPTQ and it is significantly better at choosing the right agent now```.
In forum-discussion, at 2023-10-31 23:54:12 a user named .jkyh said ```IMHO RAG-agents are great with unstructured data (pdf, txt), if your CSV is non-trivial, you'll quickly run out of tokens in the prompt. Personally, I'd elect to interface with Gorilla https://gorilla.cs.berkeley.edu/ or do function calling. OR, follow IndyDevDan's series on Autogen/Postgresql.
https://www.youtube.com/watch?v=UA6IVMDPuC8&t=101s.

Just my 2 cents, hope it helps.```.
In forum-discussion, at 2023-10-31 19:46:22 a user named xxpyroxxjonesxx said ```https://www.youtube.com/watch?v=VJ6bK81meu8

has anyone got this working on bare metal local llm? if so, did you watch this video, and what additional steps where necessary to get it working?```.
In forum-discussion, at 2023-10-31 12:05:19 a user named fran.abenza said ```@sonichi @li_jiang Trying to unify https://discord.com/channels/1153072414184452236/1159878033977659423 AND https://discord.com/channels/1153072414184452236/1167265706245632051 AND https://discord.com/channels/1153072414184452236/1159878033977659423/1160236612723146772```.
In forum-discussion, at 2023-10-31 12:01:59 a user named fran.abenza said ```How to make my agents: Self write code for later execution, modify existing code, function calling, source control (Git) , etc?```.
In forum-discussion, at 2023-10-31 09:20:02 a user named .jkyh said ```Mermaid lets you create diagrams and viz using text and code so might lend itself well to LLM outputs?
https://mermaid.js.org/intro/```.
In forum-discussion, at 2023-10-31 06:28:37 a user named lpaydat said ```I'm new here as well, but I hope I can help. I've seen some YouTubers demonstrate how to use AutoGen with Python, although I'm not certain about web UI. You might want to start by exploring their tutorials, or perhaps delve into some examples which could be very helpful (https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb)```.
In forum-discussion, at 2023-10-30 23:28:43 a user named kevinwyr said ```Hello there, we are on it! Check out this PR https://github.com/microsoft/autogen/pull/443. Is it based on dev/0.2 version which uses package openai1```.
In forum-discussion, at 2023-10-30 20:46:54 a user named robin_saunders said ```https://github.com/microsoft/autogen/issues/489```.
In forum-discussion, at 2023-10-30 17:24:40 a user named ivangabriele said ```Hi everybody here 🙂 !

I bring some updates about my OADS project as well as my related work:
- First, I created one-click deployment pre-loaded LLMs that are automatically served as OpenAI-Compatible APIs. It will help you up and down your online instances in one click, without any config (or HF key): https://github.com/ivangabriele/docker-llm. If you want more pre-loaded LLM models available in the tags, just ask me. I will try to build and push the most popular ones. I started by focusing on 16k-context models because for the most advanced tasks, 4K-context models are kind of useless. 
- Secondly I also created a one-click deployment for [Functionary LLM](https://github.com/MeetKai/functionary): https://github.com/ivangabriele/docker-functionary. Functionary LLM is one of the rare open-source solutions to Function Calling in Autogen outside of OpenAI world. You will need [this hack](https://github.com/ivangabriele/openai-autogen-dev-studio/blob/main/libs/functionary.py) to make it work, but even with that, it doesn't always work. This hack may certainly be improved.
- That's why I gave up on using Function Calling from an open-source LLM - for now. It takes a hell lot of time to try to get the few existing solutions to work "as is" in Autogen. And it's quite cheap + efficient to assign a Function Calling role to GTP3.5 (via OpenAI API) while handling all the rest with an open-source LLM.
- I'm still struggling to micro-manage relationships between my agents in OADS but I'm making progress, step by step. Hopefully I'll be able to finally push a first alpha version within 1 or 2 weeks.

A last note: The lowest price I get when deploying my images is from Vast.ai. Even if I hate their UX. And their instances organization is a real jungle. But as long as it only takes a single click to up/down, you may not care. I created ready-to-use templates for both Vast.ai and RunPod.io that you can see in my [README](https://github.com/ivangabriele/docker-llm#readme).```.
In forum-discussion, at 2023-10-30 06:08:12 a user named .jkyh said ```I tried to solve this problem with select_speaker in this PR and succeeded.
https://github.com/microsoft/autogen/pull/482

I hope to learn how to use register_reply in my next attempt.```.
In forum-discussion, at 2023-10-30 05:32:33 a user named drinkoblog.weebly.com said ```for those wanting to keep their autogen costs down, i have pplx-api beta working with autogen. i posted instructions on official perplexity server https://discord.com/channels/1047197230748151888/1054944216876331118/1168393509678632990

the perplexity (pplx) API is currently 'unlimited' (rate limited) for a subscription cost.  presumably soon they will introduce pay per query pricing model.

havent subscribed to pplx yet?  use my referral and we both get a discount! https://perplexity.ai/pro?referral_code=WH6YCUP6```.
In forum-discussion, at 2023-10-30 00:34:32 a user named sonichi said ```another example: https://github.com/microsoft/optiguide```.
In forum-discussion, at 2023-10-29 23:34:03 a user named sonichi said ```doc: https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#register_reply```.
In forum-discussion, at 2023-10-29 23:12:55 a user named dsouza_jude said ```Thanks, I'll give it a try. I found a similar post with the same use-case as mine [1], but mine is a comparatively smaller code base.

The only thing concerning with RAG is that, it might just retrieve only bits of the code base from the Vector DB or even bits of the (Terraform) module, which may constitute different files within a folder, instead of extracting the entire module to consume it, which may give inaccurate results.

Any thoughts? Is it possible instead to, in some way instruct the Agent, via the the config, to read through a designated folder where there are some modules properly documented as to what they do, use them to generate the code I want.?

[1] https://discord.com/channels/1153072414184452236/1159878033977659423```.
In forum-discussion, at 2023-10-29 22:07:47 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_chess.ipynb```.
In forum-discussion, at 2023-10-29 22:03:17 a user named rickyloynd said ```I would start with the RAG agents for this. https://microsoft.github.io/autogen/blog/2023/10/18/RetrieveChat```.
In forum-discussion, at 2023-10-29 17:41:48 a user named Pedrod2 said ```Just did a new Bing AI test search using the prompt in the first post:

Out of the 10 links, 2 got a 404, but that's already better than ChatGPT or even Bing AI a couple months ago.

However the results of the testbed look awesome! Looks like it double checked every link and removed the fake websites? very promising, can't wait to try it out.```.
In forum-discussion, at 2023-10-29 14:44:59 a user named aaronward_ said ```https://microsoft.github.io/autogen/docs/FAQ See here, and the linked notebook for full code examples```.
In forum-discussion, at 2023-10-29 14:44:24 a user named aaronward_ said ```Also discussed in the FAQs: https://microsoft.github.io/autogen/docs/FAQ```.
In forum-discussion, at 2023-10-28 13:27:03 a user named .drak. said ```bing *creative* is currently on another level
https://greasyfork.org/en/scripts/464747-enhanced-bing-chatai/code use that```.
In forum-discussion, at 2023-10-28 08:47:45 a user named macoson said ```check out chainlit, it doesn't fully support autogen yet but simple conversation without human feedback should work. https://github.com/yepher/autogen_demo/blob/main/app.py```.
In forum-discussion, at 2023-10-28 01:59:24 a user named qingyunwu said ```Hi Mehran, thank you for the follow-up question. Although there is no mention of "Python" in the `AssistantAgent` class name, it indeed does not have native support to execute other programming language. But there are two possible extension choices to provide that support:  Approach 1: create a new class and override the `execute_code_blocks` function https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L887 such that it could execute prolog code, and then change the system message to instruct the class to write Prolog code. Possible approach 2: do not create a new class but use function call: register a function that execute prolog code, and prompt the `AssistantAgent` to write prolog code. Check this notebook for an example: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In forum-discussion, at 2023-10-27 23:28:14 a user named afourney said ```Actually, I'm biased here, but Bing did a great job:```.
In forum-discussion, at 2023-10-27 23:13:37 a user named afourney said ```I added this example as a test in the testbed. Here was the final answer: 


assistant (to user_proxy):

Great! The script has successfully fetched the list of Spanish olive oil manufacturers along with their website URLs. Here's the list:

1. [Olive Line. Spanish olives and olive oil](https://www.oliveline.es/en)
2. [93 Spanish Brands Among World's Best Olive Oils - Olive Oil Times](https://www.oliveoiltimes.com/world/151-spanish-brands-among-worlds-best-olive-oils/62930)
3. [Leading Olive oil company in Spain | Aceites ABASA](https://aceitesabasa.com/en/)
4. [Spanish Extra Virgin Olive Oil | Las Valdesas](https://www.aceitedelasvaldesas.com/en/)
5. [Spanish extra virgin olive oil (EVOOs) Company | Goya Spain](https://www.goyaspain.com/)
6. [Spanish Olive Oil - SOLER ROMERO](https://soler-romero.com/about-us)
7. [La Española Olive Oil | The authentic taste of Spain](https://laespanolaoliveoil.com/)
8. [The Ultimate Guide to Spanish Olive Oil | Spanish Sabores](https://spanishsabores.com/all-about-spanish-olive-oil/)
9. [Extra virgin olive oil](https://www.spanish-oil.com/en/)
10. [Extra Virgin Olive Oil | La Española Olive Oil](https://laespanolaoliveoil.com/products/extra-virgin-olive-oil)

It's done! Please note that the availability of these websites and the companies can vary over time; the output is based on the Bing search results at the time of the query.

To verify the accuracy, please manually check each link, and you should be able to find information indicating that it is a Spanish olive oil manufacturer.

TERMINATE```.
In forum-discussion, at 2023-10-27 22:50:36 a user named karlka said ```LLM router which dynamically switches between GPT-3.5 and GPT-4. Still in alpha and currently for free. All feedback is appreciated 🙂

Readme: https://github.com/opencopilotdev/llm-router```.
In forum-discussion, at 2023-10-27 22:50:08 a user named karlka said ```LLM router which dynamically switches between GPT-3.5 and GPT-4. Still in alpha and currently for free. All feedback is appreciated 🙂

Readme: https://github.com/opencopilotdev/llm-router```.
In forum-discussion, at 2023-10-27 21:16:09 a user named bobaleaux said ```this is the source and the examples are a good first taste.

https://github.com/microsoft/autogen```.
In forum-discussion, at 2023-10-27 19:41:30 a user named iceja1 said ```Can't start 😦 Please take a look at the attached screenshot and tell me  what am I doing wrong?```.
In forum-discussion, at 2023-10-27 13:09:10 a user named rickyloynd said ```The blog post is out:  https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent```.
In forum-discussion, at 2023-10-27 02:43:47 a user named bansalg said ```https://github.com/microsoft/autogen/issues/196

We are working hard on it and will update this issue with status as well 🙂 
(cc @victor.dibia @pcdeadeasy )```.
In forum-discussion, at 2023-10-26 20:21:09 a user named afourney said ```Yes, these appear to be happening with more regularity this week: https://github.com/microsoft/autogen/issues/411```.
In forum-discussion, at 2023-10-26 15:41:58 a user named afourney said ```Here is a sample trace: https://github.com/microsoft/autogen/issues/430```.
In forum-discussion, at 2023-10-26 02:10:17 a user named vermino said ```https://tenor.com/view/adult-swim-comedy-billy-witch-doctor-arise-chicken-arise-gif-3382769```.
In forum-discussion, at 2023-10-25 21:16:39 a user named bansalg said ```The following are the default behaviors:

- what is sent back: The `generate_oai_reply` does send back the whole history but you could change that overriding the reply functionhttps://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L126 
- what if token length exceeds? https://github.com/microsoft/autogen/issues/156
- work_dir: if your agents are writing, executing code this dir is the cwd for them (unless the code changes that). They have read/write access to it.```.
In forum-discussion, at 2023-10-25 21:08:58 a user named bansalg said ```This may be of interest

https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb```.
In forum-discussion, at 2023-10-25 20:56:24 a user named qingyunwu said ```Hi Mehran. Good question. I believe it is possible to adjust the `AssistantAgent` (and `ConverseableAgent`) to enable other programming language as well, especially commonly used programming language. You will need to revise at least the following places: (1) the system message of the AssistantAgent (instruct it to write Prolog code (or other language) instead of Python code); (2) add corresponding code execution support here: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L887```.
In forum-discussion, at 2023-10-25 20:34:38 a user named .jbdc said ```SOLVING GAME OF 24 WITH AUTOGEN: HOW TO DO IT?

I tried this prompt and an open source LLM :

Prompt: 
“We will try a game of 24.   First an example.  Given are the numbers 2, 3, 4 and 5.  Using the numbers 2, 3, 4, and 5 exactly once, and only using the operations of addition (+), subtraction (-), multiplication (*), division (/), and parentheses (), how can we achieve a total of 24?  A solution to this is:  2 * ((3 + 4) + 5)   Now, can you solve this new game of 24: Our task is to use the numbers 1, 3, 4, and 6 each once and apply addition, subtraction, multiplication, and division to arrive at the target number of 24.  ANSWER: “

EXAMPLE (INCORRECT) ANSWER OF A SINGLE OPEN SOURCE LLM:

The answer is (4 * 3) - (1 + 6).


…

POE CHATGPT CAN GIVE THE CORRECT ANSWER :

POE CHATGPT:

https://poe.com/s/ewhgR62t3CbL8bkUsWLb

We will try a game of 24.   First an example.  Given are the numbers 2, 3, 4 and 5.  Using the numbers 2, 3, 4, and 5 exactly once, and only using the operations of addition (+), subtraction (-), multiplication (*), division (/), and parentheses (), how can we achieve a total of 24?  A solution to this is:  2 * ((3 + 4) + 5)   Now, can you solve this new game of 24: Our task is to use the numbers 1, 3, 4, and 6 each once and apply addition, subtraction, multiplication, and division to arrive at the target number of 24.  ANSWER:


POE CHATGPT ANSWERS :

Sure! Let's solve the game of 24 using the numbers 1, 3, 4, and 6. Here's one possible solution:

(6 / (1 - (3 / 4))) = 24

Explanation:
1. Divide 3 by 4: 3 / 4 = 0.75
2. Subtract the result from 1: 1 - 0.75 = 0.25
3. Divide 6 by the previous result: 6 / 0.25 = 24

So the solution is (6 / (1 - (3 / 4))) = 24.


WHICH IS CORRECT.

But if I then ask ChatGPT for other solutions, I get wrong answers …

MY QUESTION: How could the Game of 24 be solved by AutoGen ? I mean in general. Which prompt(s) and which kind of agents to use?

And better yet: using an open source LLM such as Mistral or Llama.

—————```.
In forum-discussion, at 2023-10-25 17:55:38 a user named bansalg said ```1. Get chat history
2. Loop to find final executable code
3. extract

https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L217```.
In forum-discussion, at 2023-10-25 11:05:11 a user named jennyhorner said ```I haven’t progressed on the autogen side partly because I’ve been distracted by ChatGPT advances too and also because I was having those OpenAI authentication error issues, but I see there’s other posts on that. 

I sort of conceptualise my AI team as existing in the ether and the platform is just how I get to talk to them. In ChatGPT I asked them if they were comfortable with how they look in this image, Fatima called a team meeting, the difference in the two responses seems to be difference between if I mention their unique diction in my question.```.
In forum-discussion, at 2023-10-25 06:07:38 a user named heresandyboy said ```Thanks @yogeshharibhaukulkarni I had a read of your PR, out of interest, and read the article you had linked. 
I sent it over to the devs of agentcloud so they could enable users to swap out the OpenAI config to try using Open Source/local models with their new AutoGen UI.

Excited to try it all out myself soon.
https://github.com/rnadigital/agentcloud```.
In forum-discussion, at 2023-10-25 04:33:25 a user named yogeshharibhaukulkarni said ```Hi @bansalg is it possible to approve the PR https://github.com/microsoft/autogen/pull/377 its a small addition in the documentation only.. Thanks```.
In forum-discussion, at 2023-10-25 02:35:28 a user named john.jeong said ```From what I've understood, they're all ways to build an agent system. 

LangChain, if you look into the codebase, is a just a set of pre-defined modules that contains a prompt. The good thing about it is that it enables users to build LLM applications really fast once you get used to it. But, there are some [posts](https://minimaxir.com/2023/07/langchain-problem/) about why it sometimes is an overkill. (From my POV, [Semantic Kernel](https://github.com/microsoft/semantic-kernel) by MS is a direct competitor to LangChain.)

AutoGPT is a single agent system that instructs itself based on each execution step. It's a nice demonstration of what an agent system can be capable of, but it has clear limitations. I've written about this in a [blog](https://blog.justasq.it/dissecting-autogpt/). (I think [PromptFlow](https://github.com/microsoft/promptflow) by MS is a direct competitor to AutoGPT.)

LlamaIndex is mainly focused on creating agent systems that operate upon RAG. If you look at [Jerry's Twitter](https://twitter.com/jerryjliu0), the co-founder and CEO of LlamaIndex, he posts a lot about RAG, in general.

AutoGen is the best one so far, I think. It's not the first multi-agent framework but it seems like the most concrete. If you've looked into other ones like [MetaGPT's codebase](https://github.com/geekan/MetaGPT), you'll be shocked. (No offense.)

Overall, I think they're all great advancements for agent systems. It seems similar to the web era, where various web-frameworks, even now, have been bursting into the world.```.
In forum-discussion, at 2023-10-25 02:18:18 a user named frank.martinez said ```https://www.reddit.com/r/LocalLLaMA/s/2YpihukZcd```.
In forum-discussion, at 2023-10-25 02:08:12 a user named yogeshharibhaukulkarni said ```@sonichi is it possible to approve the PR https://github.com/microsoft/autogen/pull/377 its a small addition in the documentation only.. Thanks```.
In forum-discussion, at 2023-10-24 22:26:41 a user named karlka said ```I've been doing some general research into benchmarking datasets, here's my rough notes if you're interested: https://nftport.notion.site/Agent-s-Benchmarking-Datasets-ae011cbda78d4e02a991bb7d823b6e26```.
In forum-discussion, at 2023-10-24 21:50:29 a user named afourney said ```I've posted some initial code for running repeatable tests in a known/conistent environment. It has not yet graduated to a pull request, but you can have a look, provide feedback while I do more testing, and write more documentation: https://github.com/microsoft/autogen/tree/testbed/samples/tools/testbed```.
In forum-discussion, at 2023-10-24 15:53:02 a user named flukeking said ```I am not too sure about Autogen since I am beginner too, but maybe instead of using ConversationBufferMemory you could try Vector Store backed memory. I am trying to build something similar to what you want. 
https://python.langchain.com/docs/modules/memory/types/vectorstore_retriever_memory

Additionally maybe you could use ReterviveUserProxyAgent that should allow you to call your Vector Database and get an answer from there Checkout the following from Docs https://microsoft.github.io/autogen/docs/reference/agentchat/contrib/retrieve_user_proxy_agent```.
In forum-discussion, at 2023-10-24 11:44:39 a user named 1_twisto said ```@frank.martinez  @.princeps provided some usefull ressources : https://scifilogic.com/best-llm-for-function-calling/ , i hope the OpenSources Models get more of this models so that autogen can be 100% used with Open Source Models, pay for finding ''functions''...```.
In forum-discussion, at 2023-10-24 01:32:23 a user named 1_twisto said ```https://github.com/rizerphe/local-llm-function-calling is this a solution to bypass the function calling api of openai ?```.
In forum-discussion, at 2023-10-23 08:57:58 a user named yogeshharibhaukulkarni said ```@sonichi https://github.com/microsoft/autogen/pull/377 to add info about LM Studio way in the notebook documentation```.
In forum-discussion, at 2023-10-23 04:09:10 a user named 0xe8d4a51000 said ```https://www.reddit.com/r/AutoGenAI/s/Sujiiee1x6

Hi, 

You may have seen this post on reddit. My issue on XAgent github regarding a potential XAgent-Autogen integration has been mentioned here, however, it is written that there is an ongoing process to integrate it (by the XAgent team). To the best of my knowledge, XAgent core devs and contributors haven't openly discussed this possibility yet. 

I have also mentioned this potential integration on this discord channel (and also on XAgent discord channel), which was first mentioned here by @beer23. 

What's more, there is now another github issue on XAgent regarding XAgent-Autogen integration: 
https://github.com/OpenBMB/XAgent/issues/62

It appears that many are quite into this potential integration. XAgent may be a useful integration just like the MemGPT integration. As XAgent itself acts like a special general-purpose multi-agent system; XAgent on Autogen framework could be multi-XAgents where some agents are or each agent is like a multi-agent, or an implementation of XAgent as a special agent type within the Autogen framework, or other combinations. 

Would be glad to hear your comments and thoughts on this.```.
In forum-discussion, at 2023-10-22 20:23:45 a user named jieyuzhang_uw said ```@jinx8436 please take a look at this repo https://github.com/JieyuZ2/EcoAssistant, where we show how to let the assistant use APIs via coding```.
In forum-discussion, at 2023-10-22 20:20:55 a user named sonichi said ```https://github.com/microsoft/autogen/issues/156```.
In forum-discussion, at 2023-10-21 17:24:59 a user named mrauter said ```@memo_memo at echohive just made a great video and python implementation of this paper https://youtu.be/FwGEtETa75A```.
In forum-discussion, at 2023-10-21 17:23:40 a user named mrauter said ```Relevant paper: Memwalker, a tree like retrieval system 

https://arxiv.org/pdf/2310.05029.pdf```.
In forum-discussion, at 2023-10-21 15:10:46 a user named sonichi said ```Might need to extend https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#run_code```.
In forum-discussion, at 2023-10-21 15:02:58 a user named sonichi said ```If you have tasks that couldn't be solved by code interpreter, it'll be worth considering whether autogen can help. AutoGen should enable you to do more. AutoGen can also be used as a code interpreter as a special case. When used in this way, it outperforms code interpreter in difficult math problems (A1 in  https://arxiv.org/abs/2308.08155)```.
In forum-discussion, at 2023-10-21 14:57:15 a user named sonichi said ```One option is to override https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent#run_code```.
In forum-discussion, at 2023-10-21 14:33:47 a user named sonichi said ```The groupchat use case is solved in the recent release. There is some discussion about this idea in https://github.com/microsoft/autogen/issues/302```.
In forum-discussion, at 2023-10-21 14:23:56 a user named sonichi said ```That idea is discussed here: https://github.com/microsoft/autogen/issues/156```.
In forum-discussion, at 2023-10-21 14:04:06 a user named .jbdc said ```So this is an example where the order in which the agents talk to the chat_manager is not pre-determined ! It is dynamically determined during the conversation! See: Enhanced Inference | AutoGen

https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference/```.
In forum-discussion, at 2023-10-21 14:02:06 a user named .jbdc said ```Topology used in this example is example A5 “Dynamic Group Chat” :```.
In forum-discussion, at 2023-10-21 13:15:32 a user named .jbdc said ```Perhaps an interesting example of a groupchat with x agents participating in the conversation is this one: Tutorial : AutoGen, Where Multiple AI Minds Become One ( Multiple Agent Chat Group) | by Simon Keban | Oct, 2023 | Medium

https://medium.com/@keane13_87093/tutorial-autogen-where-multiple-ai-minds-become-one-multiple-agent-chat-group-0f5a4bfb245b - GROUPCHAT WITH agents=[user_proxy,product_manager,ui_engineer, engineer, critic] - I think this is an example of a DYNAMIC groupchat, where the order in which the agents get to speak is dynamically determined based on the preceding history of messages (and the roles of the agents I think) !```.
In forum-discussion, at 2023-10-21 12:40:15 a user named .jbdc said ```I let ChatGPT analyze the source code of groupchat.py : 

https://github.com/microsoft/autogen/blob/main/autogen/agentchat/groupchat.py

1. The code imports necessary modules and classes:
   - `dataclass` from the `dataclasses` module
   - `sys` module
   - `Dict`, `List`, `Optional`, and `Union` types from the `typing` module
   - `Agent` and `ConversableAgent` classes from local modules (`agent` and `conversable_agent`)
   - `logging` module for logging purposes

2. The code defines a `GroupChat` data class that represents a group chat:
   - It contains data fields such as `agents` (a list of participating agents), `messages` (a list of messages in the chat), `max_round` (the maximum number of rounds), `admin_name` (the name of the admin agent, default is "Admin"), and `func_call_filter` (a flag to enforce function call filtering).
   - The class provides various methods to interact with the group chat, such as resetting the chat, finding the next speaker based on a message, selecting the next agent, generating a message for selecting the next speaker, and more.

3. The code defines a `GroupChatManager` class that extends the `ConversableAgent` class:
   - It represents a chat manager agent that can manage a group chat of multiple agents.
   - The class initializes with parameters such as the `groupchat` (an instance of `GroupChat`), `name` (name of the chat manager), `max_consecutive_auto_reply` (limit of consecutive auto replies), `human_input_mode` (mode for human inputs), `system_message` (initial system message), and additional keyword arguments.
   - The class overrides the `run_chat` method to run the group chat by iterating over rounds, selecting the next speaker, and generating replies from agents.

Overall, this code provides a framework for creating and managing group chat conversations among multiple agents. It allows agents to take turns speaking, select the next speaker, and simulate a role-playing game-like interaction.```.
In forum-discussion, at 2023-10-21 05:26:00 a user named 0xe8d4a51000 said ```Hi everyone,
MemGPT has just been integrated: 
https://github.com/microsoft/autogen/issues/156#issuecomment-1773670222

It's a basic integration at the moment, which can be enhanced. 
What an amazing milestone towards a proto-AGI...```.
In forum-discussion, at 2023-10-21 04:05:20 a user named sonichi said ```@bansalg  fyi, why I think https://github.com/microsoft/autogen/issues/109 is important```.
In forum-discussion, at 2023-10-20 17:37:10 a user named sonichi said ```The code is at: https://github.com/microsoft/autogen/blob/7e9fb4f0e800427111b6a41f0f751d60693d7663/autogen/agentchat/groupchat.py#L62-L63
For dynamic selection works, it needs `llm_config` available for the `GroupChatManager````.
In forum-discussion, at 2023-10-20 14:24:25 a user named bobaleaux said ```i had ChatGPT create a markdown of the GroupChat methods by doing a reverse trace on the process. 
It actually help shed some light on it for me.
For what it's worth, this is what GPT come up with. BTW - I read the markdown in pycharm.```.
In forum-discussion, at 2023-10-20 05:08:41 a user named yogeshharibhaukulkarni said ```https://medium.com/analytics-vidhya/microsoft-autogen-using-open-source-models-97cba96b0f75```.
In forum-discussion, at 2023-10-20 05:08:01 a user named yogeshharibhaukulkarni said ```@sonichi https://www.linkedin.com/feed/update/urn:li:activity:7120996118468960257/```.
In forum-discussion, at 2023-10-20 04:11:29 a user named coderabbit said ```I like the Orchestrator that IndyDevDan shows for controlling the order in his video: https://www.youtube.com/watch?v=4o8tymMQ5GM```.
In forum-discussion, at 2023-10-20 03:05:39 a user named kajatta said ```@biggboii. - Hey mate followed your video for local LLM with Autogen. It works via REST (as seen in screenshot) however via autogen in a dev container notebook i'm getting the following error. Did you have any problems with local execution?
```python
config_list = [
    {
        "api_key": "sk-111111111111111111111111111111111111111111111111",
        'api_base': 'http://localhost:5001/v1',
        'api_type': 'open_ai',
    }]
user_proxy (to assistant):
Hi
--------------------------------------------------------------------------------
[autogen.oai.completion: 10-20 03:03:36] {226} INFO - retrying in 10 seconds...
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/usr/local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/usr/local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
...
    result = self.request_raw(
  File "/home/vscode/.local/lib/python3.10/site-packages/openai/api_requestor.py", line 619, in request_raw
    raise error.APIConnectionError(
openai.error.APIConnectionError: Error communicating with OpenAI: HTTPConnectionPool(host='localhost', port=5001): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9d33e14460>: Failed to establish a new connection: [Errno 111] Connection refused'))
``````.
In forum-discussion, at 2023-10-20 02:18:37 a user named sonichi said ```Track it here: https://github.com/microsoft/autogen/issues/236```.
In forum-discussion, at 2023-10-20 01:56:25 a user named afourney said ```Sorry for the delay. Here’s the paper I was looking for: https://huggingface.co/papers/2310.03046```.
In forum-discussion, at 2023-10-19 23:46:56 a user named 0xe8d4a51000 said ```This would be really great! They have also cross-referenced Autogen's issue #156 regarding context overflow and MemGPT here: 
https://github.com/cpacker/MemGPT/issues/20```.
In forum-discussion, at 2023-10-19 23:32:52 a user named corgi108 said ```https://duckduckgo.com/?q=mistral++colab&t=bravened&ia=web```.
In forum-discussion, at 2023-10-19 21:48:39 a user named karlka said ```Just found a recent release by MSFT to benchmark LLM agents using games: https://github.com/microsoft/SmartPlay 

@sonichi do u know anything about this? I wonder if it's compatible with Autogen.```.
In forum-discussion, at 2023-10-19 21:41:01 a user named nickwood2009 said ```found a work around https://github.com/oobabooga/text-generation-webui/issues/4152```.
In forum-discussion, at 2023-10-19 18:31:37 a user named karlka said ```Btw someone mentioned Xagent (https://blog.x-agent.net/blog/xagent/) in <#1153072414184452241> which seems to have a promising benchmarking system in place place.```.
In forum-discussion, at 2023-10-19 18:18:54 a user named bansalg said ```This is also on the roadmap: https://github.com/orgs/microsoft/projects/989/views/3```.
In forum-discussion, at 2023-10-19 16:12:56 a user named yorth_night said ```on a different note, I saw this in memgpt's product roadmap```.
In forum-discussion, at 2023-10-19 16:11:07 a user named sonichi said ```Do you think it's worth sharing in https://github.com/microsoft/autogen/issues/236 ?```.
In forum-discussion, at 2023-10-19 14:35:03 a user named mooblegum said ```Yes. You can check this beginner tutorial if you want to be familiar with the interface. https://youtu.be/vABjDE40h8c?si=DNA8-zSS6rNdGXxv```.
In forum-discussion, at 2023-10-19 13:15:13 a user named mooblegum said ```Hi there,

Someone posted on Reddit a set of nodes he made for comfyUI (a node editor to generate image with stable diffusion), to use autogen.
Here is the GitHub link.

https://github.com/xXAdonesXx/NodeGPT

I just wanted to make an entry here, so people can learn about it, discuss and be kept inform of the progress.

I am not the creator of this tool btw```.
In forum-discussion, at 2023-10-19 04:30:54 a user named sonichi said ```PR is out https://github.com/microsoft/autogen/pull/294```.
In forum-discussion, at 2023-10-18 22:55:44 a user named c_bonadio said ```HI, why not have an agent that can execute its own function_calls? I made a sample one here
https://gist.github.com/bonadio/96435a1b6ccc32297aa8cc1db7cfc381```.
In forum-discussion, at 2023-10-18 20:56:37 a user named sonichi said ```My proposal is here: https://github.com/microsoft/autogen/issues/274#issuecomment-1767055168
Will make a PR after finishing triaging.```.
In forum-discussion, at 2023-10-18 19:07:52 a user named frank.martinez said ```https://youtu.be/FHXmiAvloUg?si=333iDvrs-a5-a5Wv```.
In forum-discussion, at 2023-10-18 14:56:53 a user named tonic_1 said ```i can help you reach out to auto-gpt , we're actually competing in their competition with autogen , contributions welcome + y'all can join us : https://huggingface.co/multitransformer https://github.com/team-tonic-arena-hacks so the idea is to basically beat auto gpt on the benchmarks```.
In forum-discussion, at 2023-10-18 13:32:40 a user named davidzhou8571 said ```I had my local model to write the code but have no local code intepretor to execute it. how can I run it?```.
In forum-discussion, at 2023-10-18 12:33:16 a user named wladpaiva said ```Here it's the video of the multi-agent framework I'm working on. 
I'm gonna do the error handling and function calling now but the basic conversation is already working.
https://youtu.be/9Hrfx6kw1IE

@fxtoofaan```.
In forum-discussion, at 2023-10-18 07:20:37 a user named heresandyboy said ```Happy to help out with any issues. Do you want to send over your docker files and errors?

Is your branch https://github.com/ivangabriele/openai-autogen-dev-studio/tree/example-using-oss-llm the one and is it up to date?```.
In forum-discussion, at 2023-10-18 04:54:09 a user named ivangabriele said ```Yes, I as I already explained I'm integrating it to [OADS](https://github.com/ivangabriele/openai-autogen-dev-studio) once I've finished my current commits ^^```.
In forum-discussion, at 2023-10-18 01:04:19 a user named vermino said ```I haven't tried it yet, but maybe this could work? https://github.com/rizerphe/local-llm-function-calling```.
In forum-discussion, at 2023-10-17 18:23:18 a user named bansalg said ```https://www.youtube.com/watch?v=10FCv-gCKug&feature=youtu.be```.
In forum-discussion, at 2023-10-17 18:18:52 a user named bansalg said ```The basic appropriate use of user proxy is to execute code. llm config is set to false -- so its not using any llm. See the documentation below. Lmk if you have questions.```.
In forum-discussion, at 2023-10-17 15:23:04 a user named kajatta said ```https://youtu.be/10FCv-gCKug?si=wztT7YkLkPlFTaxI```.
In forum-discussion, at 2023-10-17 13:55:29 a user named yorth_night said ```other ways to improve rag could be like this: https://twitter.com/manelferreira_/status/1711788177458090388```.
In forum-discussion, at 2023-10-17 13:54:44 a user named yorth_night said ```ps: this is what I mean by rerank https://twitter.com/llama_index/status/1712129914386993295```.
In forum-discussion, at 2023-10-17 13:44:11 a user named yorth_night said ```https://chat.openai.com/share/7d36bac9-8a0d-4f9e-ad98-771f39a7508b
I shared this on general but didn't want it to just be lost with chat.```.
In forum-discussion, at 2023-10-17 05:33:50 a user named sonichi said ```There is a PR https://github.com/microsoft/autogen/pull/195
Pending @kevinwyr 's reply```.
In forum-discussion, at 2023-10-16 23:34:27 a user named kajatta said ```https://tenor.com/view/robert-redford-jeremiah-johnson-nodding-yes-nod-of-approval-gif-21066931```.
In forum-discussion, at 2023-10-16 20:06:07 a user named bansalg said ```https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L105```.
In forum-discussion, at 2023-10-16 20:04:46 a user named bansalg said ```in the default setup, TERMINATE is in the system prompt of the AssistantAgent: https://github.com/microsoft/autogen/blob/main/autogen/agentchat/assistant_agent.py#L26```.
In forum-discussion, at 2023-10-16 18:20:06 a user named c_bonadio said ```Hi all
I create this Agent that can execute a function_call by itself and return the resulting message 
https://gist.github.com/bonadio/96435a1b6ccc32297aa8cc1db7cfc381```.
In forum-discussion, at 2023-10-16 16:48:21 a user named sonichi said ```@kajatta your PR https://github.com/microsoft/autogen/pull/58#issuecomment-1764125658 is blocked for containing secrets in one commit. Would you mind creating a separate PR with a clean commit without the secret?```.
In forum-discussion, at 2023-10-16 13:34:34 a user named qingyunwu said ```Hi @radman1000, please find evaluation code in this repo (the application folder): https://github.com/qingyun-wu/autogen-eval/tree/main/application```.
In forum-discussion, at 2023-10-16 12:53:08 a user named axultan said ```just curious - why not contribute to autogen and help them create a typsecript port instead? @sonichi and the guys seem to have it in the roadmap 

https://github.com/orgs/microsoft/projects/989```.
In forum-discussion, at 2023-10-16 07:06:36 a user named jlopes77 said ```@.jbdc Arize Phoenix OSS has un-official release of AutoGen tracing support, if you want a test a soft pre-release free drop the couple lines of code into any colab (example colab below). Complete tracing of all AutoGen prompt/response calls. Phoenix runs locally to the Colab server (or python execution), all data stays local. Only ask is we would love feedback, tell us what you think, feel free to drop notes to our community.

https://colab.research.google.com/drive/1BaejbF06OrTM4B2V19WM4TX4q6_hgj40?usp=sharing

https://github.com/Arize-ai/phoenix```.
In forum-discussion, at 2023-10-16 07:02:36 a user named bansalg said ```This paper by @jieyuzhang_uw maybe relevant: 

ECOASSISTANT: USING LLM ASSISTANT MORE AFFORDABLY AND ACCURATELY
https://arxiv.org/pdf/2310.03046.pdf

Abstract:
Today, users ask Large language models (LLMs) as assistants to answer queries that require external knowledge; they ask about the weather in a specific city, about stock prices, and even about where specific locations are within their neighborhood. These queries require the LLM to produce code that invokes external APIs to answer the user’s question, yet LLMs rarely produce correct code on the first try, requiring iterative code refinement upon execution results. In addition, using LLM assistants to support high query volumes can be expensive. In this work, we contribute a framework, EcoAssistant1, that enables LLMs to answer code-driven queries more affordably and accurately. EcoAssistant contains three components. First, it allows the LLM assistants to converse with an automatic code executor to iteratively refine code or to produce answers based on the execution results. Second, we use a hierarchy of LLM assistants, which attempts to answer the query with weaker, cheaper LLMs before backing off to stronger, expensive ones. Third, we retrieve solutions from past successful queries as in-context demonstrations to help subsequent queries. Empirically, we show that EcoAssistant offers distinct advantages for affordability and accuracy, surpassing GPT-4 by 10 points of success rate with less than 50% of GPT-4’s cost.```.
In forum-discussion, at 2023-10-16 06:48:27 a user named kajatta said ```https://tenor.com/view/robert-redford-jeremiah-johnson-nodding-yes-nod-of-approval-gif-21066931```.
In forum-discussion, at 2023-10-15 20:15:48 a user named wladpaiva said ```@axultan contributions are welcome
https://github.com/wladiston/aibitat```.
In forum-discussion, at 2023-10-15 18:43:54 a user named jennyhorner said ```This is example of what I mean. This is just inside standard ChatGPT plus:```.
In forum-discussion, at 2023-10-15 14:25:54 a user named kajatta said ```https://github.com/facebookresearch/llama/issues/463#issuecomment-1668774443```.
In forum-discussion, at 2023-10-15 13:51:18 a user named kajatta said ```Or 
https://python.langchain.com/docs/modules/agents/tools/tools_as_openai_functions```.
In forum-discussion, at 2023-10-15 13:50:52 a user named kajatta said ```@hueresounding https://github.com/microsoft/autogen/pull/58```.
In forum-discussion, at 2023-10-15 13:48:03 a user named kajatta said ```Or my bridge https://github.com/microsoft/autogen/pull/58```.
In forum-discussion, at 2023-10-15 13:47:08 a user named kajatta said ```Try plug this too 
https://python.langchain.com/docs/modules/agents/tools/tools_as_openai_functions```.
In forum-discussion, at 2023-10-15 08:19:46 a user named eaglestrikezio said ```https://alpaca.markets/algotrading```.
In forum-discussion, at 2023-10-15 08:19:13 a user named eaglestrikezio said ```https://alpaca.markets/data```.
In forum-discussion, at 2023-10-15 00:26:02 a user named teddybear082 said ```this is the code i'm testing with so far in case it helps anyone```.
In forum-discussion, at 2023-10-14 15:13:53 a user named aaronward_ said ```After much research i have come to the conclusion that streamlit isn't suitable for anything other than simple back and forward calls. There isn't a way to display chats in real time and it is too hacky trying to get something that worked. streamlit is intended to be single threaded. There isn't a way to share messages if you were run the agents on a separate process (i tried). 

Instead, i'd recommend using chainlit. Chainlit allows for asynchronousicity which allows you to run chainlit and autogen agents at the same time, therefore it is much cleaner to integrate with autogen. https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen```.
In forum-discussion, at 2023-10-13 18:12:42 a user named longinus4241 said ```just do this : https://gist.github.com/CUexter/78f97101655987c58e281a2fbad64009```.
In forum-discussion, at 2023-10-13 10:56:08 a user named teddybear082 said ```Read the messages around this one this is a bug for now with textgenwebui’s OpenAI API: https://discord.com/channels/1153072414184452236/1158548894209282078/1161627612259569744```.
In forum-discussion, at 2023-10-13 08:00:43 a user named evilion41 said ```I was using [Code Interpreter](https://github.com/KillianLucas/open-interpreter) to help me finish some easy task. It could also use GPT-4 API (code-llama either) to understand my question and list the to-do to archived the goals. It could also debug by itself when it concur the error messages. Anyone try to compare these two projects?```.
In forum-discussion, at 2023-10-13 06:54:03 a user named devo said ```here is the text logs```.
In forum-discussion, at 2023-10-13 04:40:06 a user named li_jiang said ```https://huggingface.co/spaces/thinkall/autogen-demos

A demo of Autogen Retrieve Chat with Gradio```.
In forum-discussion, at 2023-10-13 04:34:27 a user named li_jiang said ```https://huggingface.co/spaces/thinkall/autogen-demos

A demo of Autogen Retrieve Chat```.
In forum-discussion, at 2023-10-13 03:49:24 a user named li_jiang said ```https://huggingface.co/spaces/thinkall/autogen-demos

A demo of Autogen Retrieve Chat```.
In forum-discussion, at 2023-10-12 23:22:10 a user named aaronward_ said ```I would like to add my two cents: the code needs to be modularised following the single responsibility principle. completion.py and conversable_agent.py are very monolithic at the moment, both being over 1000 lines long.  I would like to do a group code review where we can highlight where the code could be optimized and broken up into more managable chunks. Take this [PR comment](https://github.com/microsoft/autogen/pull/131#discussion_r1356502055) as example. 

I'm all in on autogen because only LLM framework that currently strikes a line between being useful and having nice abstraction.```.
In forum-discussion, at 2023-10-12 17:24:33 a user named devo said ```i have been able to use the local llm guide and get outputs. But i dont know how to use it for stuff like agentchat```.
In forum-discussion, at 2023-10-12 05:30:59 a user named .princeps said ```_"The best thing about Gradio is chatGPT can almost write gradio webUI's perfectly.. almost.. very chatGPT.. usually needs to be debugged because the GPT examples are based on the 2021 version of gradio.. but it's still pretty good at making and modifying them if you don't mind a few minor bugs. I doubt that's the only reason it's so popular with ML but it is one of the reasons. The docs are marvelous:_ _https://www.gradio.app/docs/interface"_

I asked a friend of a friend 🙂```.
In forum-discussion, at 2023-10-12 03:17:26 a user named christkrishna said ```I deleted /chat/completions from the api_base as it’s naturally looking for that endpoint… however when I booted the modelz server again and started the script back up I got this lovely thing```.
In forum-discussion, at 2023-10-12 03:06:43 a user named christkrishna said ```The api_base is looking for a /chat/completions?```.
In forum-discussion, at 2023-10-12 02:47:48 a user named christkrishna said ```Speak of vllm, could anyone help… trying to serv locally using vllm and getting this error from this code. I’m pretty sure I got the same error earlier trying to serve it through litllm using ollama```.
In forum-discussion, at 2023-10-11 14:37:03 a user named aaronward_ said ```see here: https://github.com/microsoft/autogen/pull/58```.
In forum-discussion, at 2023-10-11 12:41:48 a user named heresandyboy said ```LiteLLM released a docker image to run an open api compatible server with ollama

https://hub.docker.com/r/litellm/ollama```.
In forum-discussion, at 2023-10-11 08:58:21 a user named .princeps said ```https://tenor.com/view/programming-software-testing-mindscripts-mindscriptstech-gif-22232157```.
In forum-discussion, at 2023-10-11 08:55:23 a user named .princeps said ```so the model name is the deployment name ?```.
In forum-discussion, at 2023-10-11 08:50:34 a user named .princeps said ```is my azure api base correct ?

    {
        "model": "gpt-35-turbo-16k",
        "api_key": "",
        "api_base": "https://poly.openai.azure.com/openai/deployments/poly/chat/completions",
        "api_type": "azure",
        "api_version": "2023-06-01-preview"
    },```.
In forum-discussion, at 2023-10-11 08:41:23 a user named .princeps said ```@li_jiang it worked! I had a timeout error but it worked, so I'll try it again```.
In forum-discussion, at 2023-10-11 08:31:23 a user named .princeps said ```hmm been getting the doc_id error since last night```.
In forum-discussion, at 2023-10-11 08:23:40 a user named li_jiang said ```This worked for me, I think you just need to update the docs_path to the absolute path of your docs folder, you should see it works```.
In forum-discussion, at 2023-10-11 08:22:09 a user named .princeps said ```I think the documentation might be outdated, since when I try to use:

`embedding_model Optional, str - the embedding model to use. Default is "all-MiniLM-L6-v2". Will be ignored if embedding_function is not None.`
`embedding_function Optional, Callable - the embedding function to use. Default is None, SentenceTransformer with the given embedding_model will be used. If you want to use OpenAI, Cohere, HuggingFace or other embedding functions, you can pass it here, follow the examples in https://docs.trychroma.com/embeddings.`

I get an error that the embedding functions don't exists```.
In forum-discussion, at 2023-10-11 08:19:55 a user named .princeps said ```does the agent handle the embedding cause I stayed up last night and here is what I have. https://microsoft.github.io/autogen/docs/reference/retrieve_utils

feels like I'm headed doen a rabbit whole @li_jiang```.
In forum-discussion, at 2023-10-11 00:14:32 a user named teddybear082 said ```https://github.com/oobabooga/text-generation-webui/issues/3153```.
In forum-discussion, at 2023-10-10 23:39:28 a user named frank.martinez said ```While others explore how to integrate open source models, can we also work on explicit HF support? For example, here's what CONFIG_LIST could include:
{
        "model": "mistralai/Mistral-7B-v0.1",
        "api_key": "<your Hugging Face access token here>",
        "api_url": "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-v0.1",
        "api_type": "text-generation",
        "api_version": "v0.1"
    },

Then it's the usual HF pattern [Python]:
import requests 
def query...
output = query...```.
In forum-discussion, at 2023-10-10 22:33:58 a user named loydvoneverec said ```I have been using autogen with local LLMs for the past few days now. I hook it up to oobabooga/text-generation-webui with the openai extension enabled. Been playing around with wizardcoder 13b and mistral 7b instruct. It works but not the flawless experience you would hope for as a some of the time the agents fail to output anything (server log shows runtime error like this : https://github.com/facebookresearch/llama/issues/380)

Question is, what is the advantage of using liteLLM ? Will the experience be any better ?```.
In forum-discussion, at 2023-10-10 21:52:40 a user named fxtoofaan said ```Let me try the litellm with vllm combo and report back. If it’s strictly api translation issue then I’m sure litellm will help. But if it’s code issue where python code is missing something to interact with the model properly then that I don’t know. I’ve got my mind made up to use this model https://huggingface.co/TheBloke/Mistral-7B-OpenOrca-AWQ so I’m going to keep trying till I figure it out 🙂```.
In forum-discussion, at 2023-10-10 21:41:04 a user named legendary_capybara_55573 said ```@fxtoofaan I can meet tomorrow, Wednesday, if needed. In the meantime, here's some more detail:

I have been able to do this with the last few releases of autogen. Here's what I did

1. Install ollama.ai
2. Create a virtual environment that contains pyautogen and litellm
3. Follow the instructions here to it set up the openai proxy server with litellm and ollama: https://docs.litellm.ai/docs/proxy_server

My autogen config looks like this:

```
# Set an environment vatiable for OAI_CONFIG_LIST
os.environ["OAI_CONFIG_LIST"] = '''
[
    {
        "model": "mistral:instruct",
        "api_base": "http://0.0.0.0:8000"
    }
]
''' 

print(os.environ["OAI_CONFIG_LIST"])

config_list = config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": ["mistral:instruct"],
    },
)
```
4. Launch the ollama application (but you don't need to run the model with an ollama command)
5. Launch the proxy server in a terminal window for your virtual environment with this: `litellm --model ollama/mistral:instruct --api_base http://localhost:11434````.
In forum-discussion, at 2023-10-10 20:20:12 a user named au8 said ```I'm hearing good things so far about this model: https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha```.
In forum-discussion, at 2023-10-10 16:10:07 a user named c_bonadio said ```Autogen interacting using FastApi (very basic)

https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af

Hi, 
I create this code to enable a user using any web cliente to interact with Autogen, it communicates using FastApi websocket 
it allows you to interact with the user_proxy at every step, not only at the end.```.
In forum-discussion, at 2023-10-10 16:06:40 a user named c_bonadio said ```Autogen interacting using FastApi (very basic)

https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af

Hi, 
I create this code to enable a user using any web cliente to interact with Autogen, it communicates using FastApi websocket 
it allows you to interact with the user_proxy at every step, not only at the end.```.
In forum-discussion, at 2023-10-10 15:00:37 a user named .princeps said ```@li_jiang can you help me understand why I get no doc _ids 

`PS C:\Users\Shadow\Documents\Repo\PolyGPT\specialized_agents> python eetriever_agent.py`
`models to use:  ['gpt-3.5-turbo', 'gpt-4', 'gpt-4-32k']`
`Accepted file formats for `docs_path`:`
`['txt', 'json', 'csv', 'tsv', 'md', 'html', 'htm', 'rtf', 'rst', 'jsonl', 'log', 'xml', 'yaml', 'yml']`
`Welcome to the chat agent. Enter your problem or type 'exit' to quit.`
`You: what is poly186 `
`Trying to create collection.`
`Collection project_docs already exists.`
`doc_ids:  [[]]`


I uploaded my script```.
In forum-discussion, at 2023-10-10 14:20:23 a user named .princeps said ```https://tenor.com/view/chivas-arriba-las-chivascampeon-gif-11833940```.
In forum-discussion, at 2023-10-10 14:05:34 a user named fxtoofaan said ```Hello everyone. I’m embarking on journey to play around with the mistral 7b openorca model using vllm server and autogen. I’m running it on Ubuntu 22.04. So if you want to try this with me and test along be my guest. I’ll try to pop in community chats to share screen and show how far I’ve got along. This model is beating llama-2 13b already. I’m excited to get this to work with autogen locally. getting some prompt template issues but hopefully will plow through them and get it working soon.```.
In forum-discussion, at 2023-10-10 13:24:11 a user named li_jiang said ```Released https://github.com/microsoft/autogen/releases/tag/v0.1.10```.
In forum-discussion, at 2023-10-10 13:12:22 a user named li_jiang said ```Release draft https://github.com/microsoft/autogen/releases```.
In forum-discussion, at 2023-10-10 12:45:10 a user named aaronward_ said ```https://docs.litellm.ai/docs/proxy_server```.
In forum-discussion, at 2023-10-10 12:44:17 a user named tomexmachina said ```It would be nice to instantly have a bunch of new APIs integrated, and I really like the LiteLLM project. However, it's no small thing to add such a dependency. Personally, I hope autogen avoids as much added dependency as possible, and doesn't implement solutions that cause negative scaling issues in the future. I will try to make time to contribute to the PR but I have a lot of catching up to do, and many people seem to be begging to merge it. Convenience is almost always our enemy.

Never forget Jurassic Park (and langchain)

An engineering-focused inquiry: https://github.com/microsoft/autogen/discussions/189
Related Issue: https://github.com/microsoft/autogen/issues/46
The PR: https://github.com/microsoft/autogen/pull/95```.
In forum-discussion, at 2023-10-09 23:24:38 a user named aaronward_ said ```I made a notebook explaining how to set up your own local model inference, it will take your RAM for a wild ride so have atleast 16 GB to spare: https://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/10.ollama-autogen/ollama.ipynb```.
In forum-discussion, at 2023-10-09 22:26:38 a user named aaronward_ said ```Using LiteLLM with locally hosted quantized mistral model with Ollama + autogen = money saver```.
In forum-discussion, at 2023-10-09 19:17:09 a user named bansalg said ```Moving this thread to its own forum : https://discord.com/channels/1153072414184452236/1161015724521836634```.
In forum-discussion, at 2023-10-09 18:11:53 a user named ivangabriele said ```For the first time I got an AI Agent, using an open-source LLM, namely `Open-Orca/LlongOrca-13B-16k` which is terrible IMO, to both run some of my functions **and chain them**. But it got stuck at after the second call.

I attached my current sandbox agent code.

```sh
--------------------------------------------------------------------------------
OADS Configuration

brave_search_api_key:            BSA*************************cB6
current_model:                   Open-Orca/LlongOrca-13B-16k

...

    api_base:                htt**************************************net
    api_key:                 sk-*********************************************111
    api_type:                open_ai
    api_version:             None
    model:                   Open-Orca/LlongOrca-13B-16k

user_proxy_agent:                {'current_model': 'Open-Orca/LlongOrca-13B-16k'}
--------------------------------------------------------------------------------

CEO (to Assistant):

What are the best Ubuntu features?

--------------------------------------------------------------------------------
Assistant (to CEO):

SEARCH Best Ubuntu Features

--------------------------------------------------------------------------------
CEO (to Assistant):

{"search_results": [{"title": "Desktop features | Ubuntu", "description": "Learn about all the great...

--------------------------------------------------------------------------------
Assistant (to CEO):

OPEN https://itsfoss.com/ubuntu-20-04-release-features/

--------------------------------------------------------------------------------
CEO (to Assistant):

[📰 News Portal](https://news.itsfoss.com/) [🎒 Resources](https://itsfoss.com/resources/)...
``````.
In forum-discussion, at 2023-10-09 18:01:05 a user named ivangabriele said ```I added a section in my README for that: https://github.com/ivangabriele/openai-autogen-dev-studio#open-source-llms

It's a similar LLM config in Autogen.```.
In forum-discussion, at 2023-10-09 17:08:19 a user named rhokstar said ```https://www.youtube.com/watch?v=JjVvYDPVrAQ&ab_channel=IndyDevDan```.
In forum-discussion, at 2023-10-09 16:56:13 a user named flaiwheel said ```Hi, did you already checked the examples? https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb```.
In forum-discussion, at 2023-10-09 16:52:36 a user named flaiwheel said ```Hi there, some people seem to work on it https://discord.com/channels/1153072414184452236/1159815963076730921, but would be great to hear your ideas!```.
In forum-discussion, at 2023-10-09 16:05:47 a user named brad_10154 said ```@andyinater I may not be using it correctly. I ran main.py and passed it "Document the code at https://github.com/Andyinater/AutoGen_EnhancedAgents/blob/main/EnhancedAgents.py". I used the default llm of gpt-3.5-turbo with my api key.  I was thinking maybe it would write the web scraping code, execute the code, pass results back up to gpt for summarizing.  I cant seem to paste in whole dialog as limit on length here but it did not seem to summarize the code getting stopped at various points in the process - either creating code or executing code or reading executed code results to send back up. Am I using it how you intended? Thanks, Brad


--------------------------------------------------------------------------------```.
In forum-discussion, at 2023-10-09 14:10:16 a user named kevinwyr said ```Hey @andyinater  Great work! I am also creating a similar PR in https://github.com/microsoft/autogen/pull/131. There is also a roadmap here to handle context overflow: https://github.com/microsoft/autogen/issues/156.
It would be great if you can take a look!```.
In forum-discussion, at 2023-10-09 14:02:00 a user named .princeps said ```I'm using the code from the notebook```.
In forum-discussion, at 2023-10-09 13:06:54 a user named .princeps said ```@li_jiang got this error 
PS C:\Users\Shadow\Documents\Repo\autogen\test> python retriever_agent.py
Traceback (most recent call last):
  File "C:\Users\Shadow\Documents\Repo\autogen\test\retriever_agent.py", line 4, in <module>
    from autogen.retrieve_utils import TEXT_FORMATS
  File "C:\Python311\Lib\site-packages\autogen\retrieve_utils.py", line 7, in <module>
    import chromadb
  File "C:\Python311\Lib\site-packages\chromadb\__init__.py", line 4, in <module>
    import chromadb.config
  File "C:\Python311\Lib\site-packages\chromadb\config.py", line 12, in <module>
    from pydantic import BaseSettings, validator
  File "C:\Python311\Lib\site-packages\pydantic\__init__.py", line 210, in __getattr__
    return _getattr_migration(attr_name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\site-packages\pydantic\_migration.py", line 289, in wrapper
    raise PydanticImportError(
pydantic.errors.PydanticImportError: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.3/migration/#basesettings-has-moved-to-pydantic-settings for more details.

For further information visit https://errors.pydantic.dev/2.3/u/import-error
PS C:\Users\Shadow\Documents\Repo\autogen\test>```.
In forum-discussion, at 2023-10-09 08:59:22 a user named .princeps said ```@sonichi is the team considering using https://agentprotocol.ai/protocol ?```.
In forum-discussion, at 2023-10-09 07:58:43 a user named grumpyoutlaw said ```this might help ? https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs```.
In forum-discussion, at 2023-10-09 06:36:52 a user named bigsk1 said ```@_winry found this issue you can change the value in openai/completions.py to hardcode value and it solves it just tested, https://github.com/oobabooga/text-generation-webui/issues/4152```.
In forum-discussion, at 2023-10-09 06:27:20 a user named .princeps said ```@sonichi yes, and I have this setup, so I have a core agent that then can call functions that are other specialized agents like the planner agents or the internet agents. 

I want to expand this into marketing and dev team agents and I want to see what you guys think the best architecture of this can possibly be```.
In forum-discussion, at 2023-10-09 06:23:49 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb Have you seen this notebook? In the function call, you can pass the relevant memory to the function```.
In forum-discussion, at 2023-10-09 04:54:42 a user named bigsk1 said ```found this same issue running and was thinking it is not on server side as I changed in openai extention defaults.py to 4096 instead of 2048 and in webui all setting should be good for larger that 2048 running exllama, tried on a few different models 8K and 16K and always 2048 limit error, might have to do with retrieve_utils.py in autogen because this model is not listed and for unrecognized models, the code raises a NotImplementedError. else:
    raise NotImplementedError(
        f"""num_tokens_from_text() is not implemented for model {model}. See """
        f"""https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are """
        f"""converted to tokens."""
    )   SO IT DEFAULTS TO 2048?????  been trying to track this down for awhile now and is a guess.```.
In forum-discussion, at 2023-10-09 04:31:07 a user named wayliu said ```this is interesting, and possible extensible to not just coding, but all other work too. So variants could be saved. Like the problem I mentioned here:  https://discordapp.com/channels/1153072414184452236/1160796039612211200```.
In forum-discussion, at 2023-10-09 04:08:07 a user named bukits said ```Hello, I need help running autogen with perplexity api

can you help me, sorry not I'm not a developer..

https://blog.perplexity.ai/blog/introducing-pplx-api```.
In forum-discussion, at 2023-10-09 04:06:00 a user named li_jiang said ```Hi @ilaffey @.princeps , could you help check if this PR https://github.com/microsoft/autogen/pull/161  works for your use cases? Comments and suggestions are super welcome.```.
In forum-discussion, at 2023-10-09 03:38:45 a user named andyinater said ```This repository holds enhanced Agents, built for the Microsoft AutoGen Framework. Debuting with a MemoryEnabledAgent, with improvements in context/token control, portability, and Plug-and-Play functionality.

https://github.com/Andyinater/AutoGen_EnhancedAgents

I would normally say things here to give some more details/background/colour, but brain go mush so do later.```.
In forum-discussion, at 2023-10-08 23:23:44 a user named roundshoulder said ```Amazing use cases for GenerativeAI. I like the way you think. I wouldn't call this over ambitious but just the right of ambition 🙂 due to how fast these technologies are advancing and the unexpected bottlenecks from their advancements. Memory per agent opens up a can of worms beyond checking your local database. LLMs, like humans, are limited by their prompt length. As conversations/interactions continue, information needs to be prioritized. With a base LLM(fixed model/temperature/etc), the only controllable difference between your characters is the prompt. Turns out Stanford has an opinion on how to solve this https://youtu.be/XY5Wncq5vAE?feature=shared... Maybe a custom RAG for AutoGen?```.
In forum-discussion, at 2023-10-08 22:41:26 a user named tonic_1 said ```based on the this it could be a trailing space :```.
In forum-discussion, at 2023-10-08 20:31:28 a user named ivangabriele said ```Yes I'm working on a workaround to emulate functions support in open-souce models but it's a potentially long shot. I also know there are 3 models which tried to achieve that:
- [glaiveai](https://huggingface.co/glaiveai)
- [Trelis](https://huggingface.co/Trelis)
- [MeetKai/functionary](https://github.com/MeetKai/functionary)

At first glance, `functionary` looks promising, supporting both plugins and functions with an API following OpenAI specs. I will definitely try it.

However this limits the usage to their model (which is Llama 2 I think). At first I tried a strategy where I created a "Functioneer" agent who was the only one able to run functions and was linked to a GTP-3.5/4 instance (it could also be Functionary). But I paused this research because this adds a hell lot of complexity (to system prompting) and agents get lost between their manager, who to ask to run what, and when to retrieve functions outputs... I may have a good idea popping up at some point though ^^.```.
In forum-discussion, at 2023-10-08 20:16:48 a user named fxtoofaan said ```Is it possible to add awq support to autogen ? https://github.com/casper-hansen/AutoAWQ                                                  Below is example code of using autoawq from python script …
from awq import AutoAWQForCausalLM
from transformers import AutoTokenizer

model_name_or_path = "TheBloke/Mistral-7B-OpenOrca-AWQ"

# Load model
model = AutoAWQForCausalLM.from_quantized(model_name_or_path, fuse_layers=True,
                                          trust_remote_code=False, safetensors=True)
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=False)

prompt = "Tell me about AI"
prompt_template=f'''<|im_start|>system
{system_message}<|im_end|>
<|im_start|>user
{prompt}<|im_end|>
<|im_start|>assistant

'''

print("\n\n*** Generate:")

tokens = tokenizer(
    prompt_template,
    return_tensors='pt'
).input_ids.cuda()

# Generate output
generation_output = model.generate(
    tokens,
    do_sample=True,
    temperature=0.7,
    top_p=0.95,
    top_k=40,
    max_new_tokens=512
)

print("Output: ", tokenizer.decode(generation_output[0]))

"""
# Inference should be possible with transformers pipeline as well in future
# But currently this is not yet supported by AutoAWQ (correct as of September 25th 2023)
from transformers import pipeline

print("*** Pipeline:")
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=512,
    do_sample=True,
    temperature=0.7,
    top_p=0.95,
    top_k=40,
    repetition_penalty=1.1
)

print(pipe(prompt_template)[0]['generated_text'])
"""```.
In forum-discussion, at 2023-10-08 17:35:15 a user named teddybear082 said ```Is this what you’re referring to? https://discord.com/channels/1153072414184452236/1157447399044821132/1160427147240943686```.
In forum-discussion, at 2023-10-08 12:19:44 a user named pradeep1148 said ```https://youtu.be/xQ3xqfDCUpM```.
In forum-discussion, at 2023-10-08 09:31:06 a user named ilaffey said ```As we start to take autogen to production, it is necessary to persist chats, so they are accessible.

Here is an implementation for Supabase. Feel free to use or extend this, or generalize/improve it!```.
In forum-discussion, at 2023-10-08 03:40:30 a user named raban6426 said ```I just found a video sampling  a blog post generation process with Autogen. I think the only limits I have are the facts that: 1. My Windows 10 Laptop can't run Wsl2. 
2. The search bar near the windows logo doesn't even work.

Should I consider getting a new machine?

https://m.youtube.com/watch?v=Bq-0ClZttc8```.
In forum-discussion, at 2023-10-08 02:18:27 a user named ilaffey said ```The current RetrieveUserProxyAgent is coupled rather tightly to chromaDB, as well as hugging face embeddings.

OpenAI embeddings would be nice, as well as a looser coupling to the existing architectural choices.

Additionally, some of the behavior around embedding, specifically  `create_vector_db_from_dir` causes a segfault on my M1 Mac.

I know that the RetrieveUserProxyAgent is in the `contrib` folder and maybe considered "second-class" to the main Autogen lib, but I do think it is important to standardize and improve our RAG system for Autogen, as this is such a core part of building agents / interacting dynamically iwth LLMs.

I am attaching my (very rough, not production ready) implementation of OpenAI embeddings using vecs (https://github.com/supabase/vecs) this runs on M1 mac, and does not perform the embeddings locally, it uses the OpenAI API instead. 

The version I am sharing is compatible  with a pgsql embeddings store.```.
In forum-discussion, at 2023-10-08 00:38:38 a user named aaronward_ said ```Made kind of a hacky way to get autogen to work with streamlit, not perfect yet but i just need to put something together so i can test out these agents in a UI rather than notebooks. 

I haven't seen any other examples with streamlit and autogen, if there is other examples please send them my way```.
In forum-discussion, at 2023-10-07 23:40:24 a user named roundshoulder said ```Rough estimate... less than a single order on UberEats. More precise estimate... few dollars. https://community.openai.com/t/gpt4-and-gpt-3-5-turb-api-cost-comparison-and-understanding/106192```.
In forum-discussion, at 2023-10-07 21:13:22 a user named dead9ixel6903 said ```Does vllm's openai api server not support chat templates thus the need for litellm in the stack? I found this https://github.com/vllm-project/vllm/pull/1215/files but other than that I wasn't sure.```.
In forum-discussion, at 2023-10-07 20:56:47 a user named dead9ixel6903 said ```*https://retejs.org/examples```.
In forum-discussion, at 2023-10-07 20:55:35 a user named dead9ixel6903 said ```I've been thinking about this also and agree a node/wire based interface would be very beneficial. I was looking at rete.js over at retejs.org/examples but there are so many more. I found a good list on https://stackoverflow.com/questions/72164885/tools-for-building-a-graph-node-based-user-interface-in-a-webapp```.
In forum-discussion, at 2023-10-07 19:50:05 a user named pradeep1148 said ```https://www.youtube.com/watch?v=olhABcSz2JY&ab_channel=DLExplorers```.
In forum-discussion, at 2023-10-07 15:21:47 a user named sonichi said ```I know one: https://www.youtube.com/watch?v=buuPOpHNOX0&t=7s```.
In forum-discussion, at 2023-10-07 11:52:23 a user named twezoalgo said ```so far, these are the uis ive put together for the three notebooks that i want to use the most. the one with the project manager, the base model, and the one where its just you and the coder. I was advised to make a flow chart so i will when i wake up but as you can sse its very simple but it gets the job done locally with some tkinter```.
In forum-discussion, at 2023-10-07 11:20:55 a user named jimmysandwiches said ```Another DeepDive from echohive
https://www.youtube.com/watch?v=L8UsPlT0nAA```.
In forum-discussion, at 2023-10-07 05:01:16 a user named bobaleaux said ```i'm not really sure i kind of stumbled upon it in the general channel. haven't figured it out exactly what is purpose is, i guess, it's like a global message that persists.
add that to my "i need to look into that" list.
https://discord.com/channels/1153072414184452236/1153072414184452241/1159912179470958652```.
In forum-discussion, at 2023-10-07 00:28:03 a user named victor.dibia said ```Yes. I have some starter code showing how fastapi and next.js can be used in a simple web app that calls autogen.  Feel free to check it out, share ideas and feedback
https://github.com/victordibia/autogen-ui```.
In forum-discussion, at 2023-10-06 20:07:17 a user named afourney said ```There's some chatter over here too: https://discord.com/channels/1153072414184452236/1159474654302449755```.
In forum-discussion, at 2023-10-06 19:32:00 a user named legendary_capybara_55573 said ```I've been able to run mistral 7b on ollama using a litellm proxy server: https://docs.litellm.ai/docs/proxy_server 

codellama:13b-instruct works sometimes, but usually times out

To launch the server I run: litellm --model ollama/mistral:instruct --api_base http://localhost:11434

My config looks like this:
```
# Set an environment vatiable for OAI_CONFIG_LIST
os.environ["OAI_CONFIG_LIST"] = '''
[
    {
        "model": "gpt-3.5-turbo-0613"
    },
    {
        "model": "codellama:13b-instruct",
        "api_base": "http://0.0.0.0:8000"
    },
    {
        "model": "mistral:instruct",
        "api_base": "http://0.0.0.0:8000"
    }
]
''' 

print(os.environ["OAI_CONFIG_LIST"])

config_list = config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": ["mistral:instruct"],
    },
)
``````.
In forum-discussion, at 2023-10-06 16:02:42 a user named pradeep1148 said ```https://www.youtube.com/watch?v=Z9NadaZ-1Rc&ab_channel=DLExplorers```.
In forum-discussion, at 2023-10-06 05:20:52 a user named yogeshharibhaukulkarni said ```I had Llama model downloaded earlier. Added that to LMS .cache as suggested by it. Then started the server, noted the url, set that in config and it worked ok

```
import autogen
import openai
openai.api_type = "openai"
openai.api_key = "..."
openai.api_base = "http://localhost:1234/v1"
openai.api_version = "2023-05-15"

autogen.oai.ChatCompletion.start_logging()

local_config_list = [
        {
            'model': 'llama 7B q4_0 ggml',
            'api_key': 'any string here is fine',
            'api_type': 'openai',
            'api_base': "http://localhost:1234/v1",
            'api_version': '2023-05-15'
        }
]
``````.
In forum-discussion, at 2023-10-06 04:18:24 a user named nickwood2009 said ```getting the following error when running the docker run command in the quickstart:
docker run -it -v /home/$(whoami)/.cache/huggingface/hub/:/root/.cache/huggingface/hub/ -p 8000:8000 -p 7860:7860 --gpus all --name ai-api2 ai-api

==========
== CUDA ==
==========

CUDA Version 11.8.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

/bin/sh: 1: Syntax error: Unterminated quoted string```.
In forum-discussion, at 2023-10-05 23:25:09 a user named sonichi said ```This is really helpful. If anyone would like to add this to the FAQ page https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints
I'm all for it.```.
In forum-discussion, at 2023-10-05 23:22:08 a user named .beibinli said ```Hi Riki, sorry for the late reply. It seems like, by default, Code Llama only supports 2048 tokens. It's an issue with Llama rather than AutoGen.  I found a post online regarding this issue: https://www.reddit.com/r/LocalLLaMA/comments/161zrr0/how_to_utilize_100k_context_length_with_codellama/```.
In forum-discussion, at 2023-10-05 17:52:17 a user named andyinater said ```https://github.com/amadad/agentcy```.
In forum-discussion, at 2023-10-05 16:25:39 a user named sonichi said ```This reddit contains a list too: https://www.reddit.com/r/AutoGenAI/```.
In forum-discussion, at 2023-10-05 16:09:52 a user named fxtoofaan said ```can prompt instruction templates be made available ? or used to connect to various local LLM types? a list of prompt templates is here: https://github.com/oobabooga/text-generation-webui/tree/main/instruction-templates

the one I am interested in using in autogen is this: https://github.com/oobabooga/text-generation-webui/blob/main/instruction-templates/MPT-Chat.yaml```.
In forum-discussion, at 2023-10-05 15:13:26 a user named coolrazor said ```More in a "prototype" stage but it does work:
https://github.com/coolrazor007/cloudai```.
In forum-discussion, at 2023-10-05 15:06:03 a user named _winry said ```tried setting that in 2 places without any luck```.
In forum-discussion, at 2023-10-05 14:41:28 a user named au8 said ```https://github.com/oobabooga/text-generation-webui/tree/main/extensions/openai```.
In forum-discussion, at 2023-10-05 14:40:27 a user named slagado. said ```and postman shows that the api url is ok:```.
In forum-discussion, at 2023-10-05 14:33:25 a user named slagado. said ```a simple "python server.py" starts it:```.
In forum-discussion, at 2023-10-05 14:30:12 a user named slagado. said ```I am using "text-generation-webgui" and enable also "api" in "Session" -> "Available extensions:```.
In forum-discussion, at 2023-10-05 14:26:24 a user named _winry said ```I am using ooga booga's OpenAI API extension with CodeLlama-34B model. It is working fine for some steps and then failing due to maximum context limitation. While loading the model, I am giving 8192 tokens as the max seq length. But somehow autogen is still complaining that the model supports only 2048 tokens. Anyway to override this from autogen? Or I am looking at the wrong place?```.
In forum-discussion, at 2023-10-05 14:18:08 a user named rubberdauck said ```I'm not sure if anyone here tried it yet but I am using https://lmstudio.ai/ to run my autogen using local llms like mistral, codellama, etc. It is pretty much an All-in-one API hosting software for LLMs. You pretty much set it up like how you set up Azure, changing the OPENAI_API_BASE to the localhost port address that you are hosting the server on and you are set```.
In forum-discussion, at 2023-10-05 14:09:13 a user named indigo75 said ```https://youtu.be/T-D1OfcDW1M?si=3MiPe_YklJIIliwn```.
In forum-discussion, at 2023-10-05 10:04:31 a user named aaronward_ said ```@melekgharbi  see here: https://discord.com/channels/1153072414184452236/1159413002206969956```.
In forum-discussion, at 2023-10-05 10:03:30 a user named aaronward_ said ```If you need help setting up your `config list` you can look at this post - there is an example notebook explaining all the ways to set it up, and it explains how perform additional configurations on your agents in terms of models/apis etc.: https://discord.com/channels/1153072414184452236/1159413002206969956```.
In forum-discussion, at 2023-10-05 10:01:20 a user named .jbdc said ```Did that work locally on a Windows PC?
Because I read this:

Cant use it on Windows · Issue #98 · tensorchord/modelz-llm
https://github.com/tensorchord/modelz-llm/issues/98

We use Unix Domain Socket and fork which might not work on Windows.```.
In forum-discussion, at 2023-10-05 09:57:44 a user named .jbdc said ```Cant use it on Windows · Issue #98 · tensorchord/modelz-llm
https://github.com/tensorchord/modelz-llm/issues/98

We use Unix Domain Socket and fork which might not work on Windows.```.
In forum-discussion, at 2023-10-05 09:57:23 a user named .jbdc said ```Cant use it on Windows · Issue #98 · tensorchord/modelz-llm
https://github.com/tensorchord/modelz-llm/issues/98

We use Unix Domain Socket and fork which might not work on Windows.```.
In forum-discussion, at 2023-10-05 08:53:20 a user named aaronward_ said ```Hi all. I often see the same question on here or online asking about how to config the config_list for your agents, and some confusion around the OAI_CONFIG_LIST setup

I've made an example notebook on the autogen repo that show's examples of all the different methods:

• get_config_list
• config_list_openai_aoa
• config_list_from_json
• config_list_from_models
• config_list_from_dotenv

https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb```.
In forum-discussion, at 2023-10-05 08:06:16 a user named orderandchaos_at_work said ```You're best off using the main repo, https://github.com/Andyinater/AutoGen_IterativeCoding. I'm experimenting with storing the project files in versioned directories. Not quite there yet. I'm trying to figure out how to have it write a larger API project with fastapi and pytest. 

You'll often find that openai runs out of tokens with these agents, you can try using gpt-4 models which allow a lot more tokens, but it'll cost a bomb to run. If you can figure it out how to write it, you could catch that error specifically and switch models or chunk/summarise the request to make it shorter.```.
In forum-discussion, at 2023-10-05 06:06:03 a user named au8 said ```https://docs.litellm.ai/docs/providers/vllm#custom-prompt-templates```.
In forum-discussion, at 2023-10-05 04:33:25 a user named nickwood2009 said ```Running through the latest code pulled from: https://github.com/OrderAndCh4oS/AutoGen_IterativeCoding_RESTful_API_writer/tree/feat/versioned-with-dirs  I am getting the following error (after getting very close to completing all 5 planned steps): "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4106 tokens. Please reduce the length of the messages."```.
In forum-discussion, at 2023-10-05 02:40:39 a user named operator2k said ```I wrote this simple set up and this query of who won the nobel prize for medicine and to get current info, but it ran into an issue as shown below where I think it was trying to say that the docker api key was not present or version? I wanted to know how to fix it and what is the purpose of docker in this specific case?

docker.errors.DockerException: Error while fetching server API version: (2, 'CreateFile', 'The system cannot find the file specified.')```.
In forum-discussion, at 2023-10-05 01:38:31 a user named ilaffey said ```Hey all- just wanted to share a pattern I have implemented that you may find useful.

One pattern I very quickly ran into with Autogen is wanting to synthesize lots of data using Agent written code.

Basically I wanted to enable the Agent to dynamically spin up an LLM to solve some lesser, non Agentic task.

In general, GPT developers have a weak spot around writing LLM / GPT code, because this was not included in their training data.

There is, however, a nifty abstraction called marvin https://github.com/prefecthq/marvin that really simplifies this.

Prompting my engineer like so:

(see sample1.py)

the engineer is able to write code like this:

see (sample2.py)

for dynamic extraction of dynamic data.

This shit is crazy!```.
In forum-discussion, at 2023-10-04 23:55:28 a user named orderandchaos_at_work said ```@andyinater Going to have to park it here for the night. Might be on to something, but not quite there. It's too eager to create new versioned dirs, need to make sure it only makes new dirs when new work is written. Anyway see what you think. 

https://github.com/OrderAndCh4oS/AutoGen_IterativeCoding_RESTful_API_writer/blob/feat/versioned-with-dirs/IterativeCoding_Example_Clock_With_Dirs.py```.
In forum-discussion, at 2023-10-04 22:11:13 a user named jimmysandwiches said ```another from echohive (very good) https://youtu.be/oOqeOspJL0o?si=gl4bRYLY_HWsVJeA```.
In forum-discussion, at 2023-10-04 20:51:34 a user named sonichi said ```AutoGen supports templating: https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#templating```.
In forum-discussion, at 2023-10-04 18:25:28 a user named vieira_patrick said ```Hi there,

I encountered the same issue previously. The solution that worked for me was to download the repository from https://github.com/tensorchord/modelz-llm and install the requirements from the requirements-cpu.txt file.```.
In forum-discussion, at 2023-10-04 18:00:51 a user named .beibinli said ```It is possible to use with "LiteLLM", but you would need Cohere API. Check https://github.com/microsoft/autogen/pull/95```.
In forum-discussion, at 2023-10-04 15:08:16 a user named sonichi said ```https://github.com/microsoft/autogen/pull/95 who would like to review this PR? @jiale_liu @.beibinli @qingyunwu```.
In forum-discussion, at 2023-10-04 14:40:14 a user named aaronward_ said ````code_executon_config`  and `llm_config` exists, but the values seem off, plus the other stuff is completely fabricated. See here for the the correct expected parameters: https://github.com/microsoft/autogen/blob/dc70b804ad6bcb74be5d02a806a53c990dc8fee8/autogen/agentchat/user_proxy_agent.py#L31

So to answer your question, yes its possible what you're trying to achieve - you will need to replace the default system template - https://github.com/microsoft/autogen/blob/dc70b804ad6bcb74be5d02a806a53c990dc8fee8/autogen/agentchat/assistant_agent.py#L16C5-L16C27```.
In forum-discussion, at 2023-10-04 14:32:38 a user named aaronward_ said ```You can reprogram the agent using the system message, see here: https://microsoft.github.io/autogen/docs/reference/agentchat/assistant_agent 

`system_message str - system message for the ChatCompletion inference. Please override this attribute if you want to reprogram the agent.````.
In forum-discussion, at 2023-10-04 12:57:34 a user named sonichi said ```I see. The cause is that the executor agent is trying to execute a .ps1 script which contains the command `python code.py`. If you know the alternative way to do it, you can override the `run_code(code, lang)` method https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent/#run_code
or modify the `execute_code` function https://microsoft.github.io/autogen/docs/reference/code_utils#execute_code```.
In forum-discussion, at 2023-10-04 05:35:42 a user named jimmysandwiches said ```Another from Wes https://www.youtube.com/watch?v=oAsJVZlDOgQ```.
In forum-discussion, at nan a user named .beibinli said ```Hi everyone, I created a tutorial on how to support open source model in the PR here, please take a look at my notebook: https://github.com/microsoft/autogen/blob/osllm/notebook/open_source_language_model_example.ipynb

Any suggestions are welcome.```.
In forum-discussion, at 2023-10-03 16:11:37 a user named qingyunwu said ```https://www.youtube.com/watch?v=Bq-0ClZttc8```.
In forum-discussion, at 2023-10-03 16:10:41 a user named qingyunwu said ```https://www.youtube.com/watch?v=vU2S6dVf79M```.
In forum-discussion, at 2023-10-03 12:40:19 a user named amadad said ```https://www.youtube.com/watch?v=JFotv9PVW_4```.
In forum-discussion, at 2023-10-03 10:08:33 a user named aaronward_ said ```https://github.com/AaronWard/generative-ai-workbook/tree/main/projects/personal_projects/5.historia-lingua - I made an interactive map application that uses LLMs provide a historical overview for a selected location and a time period - It's made with Langchain but the classes can be modified to use Autogen instead. Not exactly what your looking for, but i hope it's brings some inspiration```.
In forum-discussion, at 2023-10-03 08:51:53 a user named melekgharbi said ```@sonichi thank for the insight, here's a screenshot of the file content :```.
In forum-discussion, at 2023-10-03 05:37:57 a user named shadowraker said ```Echohive did a video on autogen and provided code files. Good place to start. Love his stuff. Here's his announcement:

AutoGen Introduction in 5 files step by step including how to enable Docker

We will take a look at the AutoGen library by Microsoft in this video on how we can use it to easily create agent interactions with OpenAI's GPT-4. We will also learn about how to set llm config, save conversation history to a file and set up Docker for safe execution of code blocks.

Code files are available to download for free at Patreon:
https://www.patreon.com/posts/90228560

Auto AGI original video: https://youtu.be/jTC-6kBOfn8
Auto AGI original source code: https://www.patreon.com/posts/87530987

Search 180+ echohive videos and code download links:
https://www.echohive.live/

WSL windows install: https://learn.microsoft.com/en-us/windows/wsl/install
Docker deskptop: https://www.docker.com/products/docker-desktop/

https://youtu.be/WnBCPG-ZdLk```.
In forum-discussion, at 2023-10-03 02:15:57 a user named kevinwyr said ```What I did in https://github.com/microsoft/FLAML/pull/1153/files was to create a compression agent to compress chat histories. It was already runnable but wasn't tested for utility. There are also many design choices to be made. But it is possible to add this feature quickly and then improve on the details later.

Another quick and simple fix would be to delete very old messages, but would lead to some information lost. Do you think this works for you?
 
Can you give more information about your usage and how important the chat history is? If you are using , it is more complicated.```.
In forum-discussion, at 2023-10-03 00:41:24 a user named andyinater said ```This repository demonstrates how a simple iterative coding loop, with history and resume capability, can be implemented in the AutoGen Framework.

https://github.com/Andyinater/AutoGen_IterativeCoding

I hope this proves useful for those who were looking to tinker with a setup like this, but maybe had some trouble getting the wheels rolling.

Sorry for the messy code, as usual. I will try to clean it up over the next few days/weeks, but would also welcome any help or contributions! It would be cool to see this grow into a powerful framework-on-a-framework.```.
In forum-discussion, at 2023-10-02 16:55:04 a user named pradeep1148 said ```https://www.youtube.com/watch?v=N5nmAWwoTEY&ab_channel=DLExplorers```.
In forum-discussion, at 2023-10-02 16:41:21 a user named melekgharbi said ```but later i still get authenticaion error```.
In forum-discussion, at 2023-10-02 16:40:54 a user named melekgharbi said ```when i provide file_location, no error```.
In forum-discussion, at 2023-10-02 16:40:04 a user named melekgharbi said ```Hello, i'm following exact instructions, and providing the "OAI_CONFIG_LIST.json"i even added the "file_location" argument to specify it, but i still get errors```.
In forum-discussion, at 2023-10-02 13:04:03 a user named sonichi said ```This is a legit issue https://github.com/microsoft/autogen/issues/9 especially important for models with small context limit```.
In forum-discussion, at 2023-10-02 11:34:29 a user named sonichi said ```https://www.youtube.com/watch?v=w6hhnVa68yE&ab_channel=DLExplorers```.
In forum-discussion, at 2023-10-02 10:55:48 a user named .princeps said ```This script https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts/blob/master/autogen_notebooks/function_call.py, correct ?```.
In forum-discussion, at 2023-10-02 10:53:19 a user named .princeps said ```cause in the actual function calling agent i pull in thw correct model```.
In forum-discussion, at 2023-10-02 10:39:26 a user named lessuse. said ```https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts/blob/master/autogen_notebooks/function_call.py```.
In forum-discussion, at 2023-10-02 08:51:58 a user named hahl9000 said ```Thanks! I also realized that the config list with Azure wasn't the one I should use but rather the one with only OpenAI here; https://microsoft.github.io/autogen/docs/FAQ/#set-your-api-endpoints```.
In forum-discussion, at 2023-10-02 07:05:51 a user named daimyo88 said ```I tested the latest Autogen and it performed much better and I didn't get any rate limit errors. But after a couple minutes of agents chatting. My program stopped and I have this error in the terminal. Did I do something wrong or if not and this is a real issue I can make an issue for it on GitHub?```.
In forum-discussion, at 2023-10-02 05:17:28 a user named sonichi said ```https://twitter.com/oscarmoxon/status/1708603929011863871```.
In forum-discussion, at 2023-10-01 19:06:28 a user named andyinater said ```Maybe this example can help to - I made it by extending what I was seeing in that above example

https://discord.com/channels/1153072414184452236/1157869584901226586```.
In forum-discussion, at 2023-10-01 18:37:40 a user named sonichi said ```How about this example? https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb```.
In forum-discussion, at 2023-10-01 18:31:48 a user named tonic_1 said ```@JoJo you can join @.princeps @salegrem and @mysticaldiscofrog on github to use autogen to improve autogpt : just dm me your github user name```.
In forum-discussion, at 2023-10-01 16:38:04 a user named tonic_1 said ```Yes it is here : https://huggingface.co/multitransformer```.
In forum-discussion, at 2023-10-01 15:39:44 a user named hahl9000 said ```I only have the OpenAI key not Azure. When loading I get an error that I have not loaded the key. Why? What am I missing (a little bit noobish here)..

Error msg:
    raise openai.error.AuthenticationError(
openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.

My JSON:

[
    {
        "model": "gpt-4",
        "api_key": "my key is here"
    },
    {
        "model": "gpt-4",
        "api_key": "<your Azure OpenAI API key here>",
        "api_base": "<your Azure OpenAI API base here>",
        "api_type": "azure",
        "api_version": "2023-07-01-preview"
    },
    {
        "model": "gpt-3.5-turbo",
        "api_key": "<your Azure OpenAI API key here>",
        "api_base": "<your Azure OpenAI API base here>",
        "api_type": "azure",
        "api_version": "2023-07-01-preview"
    }
]```.
In forum-discussion, at 2023-10-01 15:14:03 a user named tonic_1 said ```hey there folks, having a little networking and sharing call, y'all are very welcome to join, it's going to be a lot about autogen : https://discord.gg/g8CFJ3mf?event=1158053617362817104```.
In forum-discussion, at 2023-10-01 13:17:39 a user named andyinater said ```Openai pricing is here: https://openai.com/pricing

A token calculator is here:
https://platform.openai.com/tokenizer

As for the cost of one autogen script, it depends. You will not see all the text that is sent to openai in the main window - there is a lot tied to each agent, like a system prompt, that will be included in any openai api call it makes. And depending on the arrangement and what you asked, there is lots of variation.


That being said, if on 3.5 turbo, it is generally quite cheap. It could be ~$0.05 usd for the tesla/meta chart example```.
In forum-discussion, at 2023-10-01 12:29:43 a user named sonichi said ```https://youtu.be/2RT8i-VP7V0```.
In forum-discussion, at 2023-10-01 12:09:55 a user named sonichi said ```Automated Data Visualization by Group Chat (with 3 group member agents and 1 manager agent)
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_vis.ipynb```.
In forum-discussion, at 2023-10-01 03:06:37 a user named jartan said ```Getting this issue still though:```.
In forum-discussion, at 2023-10-01 02:40:21 a user named andyinater said ```A small example/proof of concept for an Agent with a long term memory which can persist across instances. This can help see how functions can be called by agents, and how you can prompt the agent/describe the function to improve success rates. 

Apologies in advance for poor style, in both code and git. Please let me know if you have any issues getting it running.

https://github.com/Andyinater/AutoGen_MemoryManager```.
In forum-discussion, at 2023-09-30 21:07:55 a user named jartan said ``````openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.``````.
In forum-discussion, at 2023-09-30 21:06:27 a user named jartan said ```Oh now I get this:```.
In forum-discussion, at 2023-09-30 18:26:53 a user named logangrasby said ```Thanks @sonichi.  My startup is in the Microsoft Founders Hub program. Assuming you're from Microsoft, do you know if it's possible that I could chat with someone who is working on Autogen about this? 

It would also be helpful for my talk on Wednesday at QCon in SF where I'll be talking about Autogen! (https://qconsf.com/presentation/oct2023/designing-ai-agents-system-thinking).```.
In forum-discussion, at 2023-09-30 17:20:47 a user named .princeps said ```**Introduction:**  
Hello everyone! I'm excited to share an update on the AutoGen-Example-Scripts project and address some of the queries that have come up.

**Project Goal:**  
Our ultimate aim is to establish an AI DAO. However, before we delve into that, I'd like to introduce you to some simplified tools and internet agents we've been developing.

**Experience AutoGen with Ease:**  
For those who wish to explore the capabilities of the AutoGen library without the intricacies of setup, we've created a repository with example scripts. This is perfect for beginners or anyone eager to get hands-on with the project.

**Resources:**  
- **Example Scripts:** These scripts, derived from AutoGen notebooks, offer a hassle-free experience. Check them out here: [AutoGen-Example-Scripts](https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts.git)
- **Original Notebooks:** For those interested in the original notebooks that inspired these scripts, you can find them here: [Notebooks Link](https://github.com/microsoft/autogen/tree/main/notebook)

**What's Next:**  
I'll be continuously adding scripts to this repository to test different notebooks, reflecting the areas I'm currently exploring. If you're interested in contributing, feel free to make a pull request with your scripts or enhancements.

**Collaboration & Future Updates:**  
Collaboration is the key to innovation, and I'm always open to joining forces with like-minded individuals. Stay tuned! Exciting updates and new tools are on the horizon.```.
In forum-discussion, at 2023-09-30 13:16:35 a user named sonichi said ```I made a PR to answer your question: https://github.com/microsoft/autogen/pull/53. Could you take a look?```.
In forum-discussion, at 2023-09-30 12:28:47 a user named tonic_1 said ```https://huggingface.co/spaces/MultiTransformer/snake_by_princepspolycap```.
In forum-discussion, at 2023-09-30 12:24:01 a user named tonic_1 said ```you'll wanna make a cool interface for this maybe one day :```.
In forum-discussion, at 2023-09-30 11:59:56 a user named tonic_1 said ```@.princeps https://huggingface.co/organizations/MultiTransformer/share/yOMQRMwjMxAztDSrlxoRToXGLpRbtBBesU```.
In forum-discussion, at 2023-09-29 20:53:11 a user named bansalg said ```Update 10/9/23: Moved to https://discord.com/channels/1153072414184452236/1161015724521836634


--old--

Mods will update this list as we see more amazing content from our OSS community. (Let us know if we missed anything).

**Tutorials:**
-  https://www.youtube.com/watch?v=8TLwSH_UFwI (by @redai.ai )
-  https://github.com/Poly186-AI-DAO/AutoGen-Example-Scripts (by @.princeps )
- https://youtu.be/2RT8i-VP7V0 (by Manish Gupta on YT)
- https://www.youtube.com/watch?v=gnn1H4H81IY (by @pradeep1148 )
- https://www.youtube.com/watch?v=N5nmAWwoTEY
- https://www.youtube.com/watch?v=w6hhnVa68yE
- https://www.youtube.com/watch?v=Z9NadaZ-1Rc
- https://www.youtube.com/watch?v=PCr-uAjQHDQ (by @merkle)
- https://www.youtube.com/watch?v=WnBCPG-ZdLk (by echohive on YT)
- https://www.youtube.com/watch?v=JFotv9PVW_4 (by code_your_own_AI on YT)
- https://www.youtube.com/watch?v=vU2S6dVf79M (by Mathew Berman on YT)
- https://www.youtube.com/watch?v=Bq-0ClZttc8 (by AI_Json on YT)
- https://www.youtube.com/watch?v=oOqeOspJL0o (by echohive on YT)

**Examples:** 
- https://twitter.com/pwang_szn/status/1707334415691686227 (pwang_szn on Twitter)   https://github.com/peterw/autogen/tree/main 
- https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game (by @.princeps )
- https://huggingface.co/MultiTransformer (by @tonic_1 )
- https://twitter.com/abhilashi/status/1708339764250947692?s=20 (by @abhilashinumella )
- https://twitter.com/oscarmoxon/status/1708603929011863871 (by oscarmoxon on Twitter)
- https://github.com/amadad/agentcy (by @amadad )
- https://github.com/Andyinater/AutoGen_IterativeCoding (by @andyinater )

**Coverage:**
- https://www.youtube.com/watch?v=zdcCD--IieY (by Wes Roth on Youtube)
- https://youtu.be/yi8Cq2SZy48?si=bH8UKsUG7gA5a_vM&t=284 (by AI Explained on Youtube)```.
In forum-discussion, at 2023-09-29 19:10:45 a user named bansalg said ```@tanmayy  and @andyinater how about this: https://discord.gg/66YGrgpS```.
In forum-discussion, at 2023-09-29 18:49:01 a user named meenstreek said ```I figured you might just piggyback off this one 🙂```.
In forum-discussion, at 2023-09-29 17:55:53 a user named tonic_1 said ```https://huggingface.co/spaces/MultiTransformer/snake_by_princepspolycap/discussions/1 so i kinda sorta wanted to see if you thought this would be cool```.
In forum-discussion, at 2023-09-29 17:43:45 a user named tonic_1 said ```can host it on huggingface? https://huggingface.co/collections/MultiTransformer/autogengradiohuggingface-651626e54256270d6fad2621```.
In forum-discussion, at 2023-09-29 17:13:56 a user named meenstreek said ```Add your logo to the server profile 🙂```.
In forum-discussion, at 2023-09-29 13:37:54 a user named .princeps said ```here is a little project I created to create a snake game using the project, this should help others see how to get started with the agents 

https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.
In forum-discussion, at 2023-09-28 22:09:35 a user named merkle said ```imagine something like this but for premade agent workflows https://apify.com/store```.
In forum-discussion, at 2023-09-28 15:02:26 a user named merkle said ```see this example in their repo
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb```.
In forum-discussion, at 2023-09-28 13:12:09 a user named unicorn1997 said ```but according to the paper, they are capable of execution, that was also the primary reason why I tried that
So maybe I just cant do it?```.
In forum-discussion, at 2023-09-27 19:40:46 a user named unicorn1997 said ```a  
Hello, first of all, I tried AutoGen and I love it, thanks for doing that.
I first started coding few weeks ago, and I succeeded in using AutoGen (I failed with Langchain tbd). You have nice docs!

Second, I made some simple examples with AutoGen and now I wonder if there are some ways to actually execute the code it produces. What should I do with the code I am getting from agents as output?

Thanks for discussing this!
T.```.
In dev-contributors, at 2023-11-14 22:38:20 a user named sidhujag said ```is there a reason you may want it to be gpt assistant agent? group managers dont really need tool or fn access they just forward msgs to other agents which on reply get fwded to assistant api right```.
In dev-contributors, at 2023-11-14 22:37:37 a user named sidhujag said ```it was working just fine if you take my PR above and then you can rename conversable agent to gpt assistant agent inside groupchat it should work.. how does it fail for you?```.
In dev-contributors, at 2023-11-14 22:35:13 a user named bansalg said ```If you were able to make gptassistantagent work as groupchatmanager, can you please share code 🙂```.
In dev-contributors, at 2023-11-14 14:53:09 a user named sonichi said ```Thanks. I've reviewd and tried to find more reviewers. Others please help as I'm not familiar w/ JS/TS```.
In dev-contributors, at 2023-11-14 11:16:56 a user named 0xlws said ```updated: added typescript https://github.com/microsoft/autogen/pull/664```.
In dev-contributors, at 2023-11-13 21:09:43 a user named 0xlws said ```hey guys i opened a PR which allowed execution of javascript, hope to get typescript support as well (being able to run tests 🤔 )! https://github.com/microsoft/autogen/pull/664```.
In dev-contributors, at 2023-11-13 21:06:56 a user named sidhujag said ```it works with both.. i switched back to conversable agent and it worked.. so it works for me either way.. i did notice some things im surprised you guys havent seen but we use assistant role for appending messags and assistants API doesnt like this I get "1 validation error for Request\nbody -> role\n  value is not a valid enumeration member; permitted: 'user'".. i opened this PR https://github.com/microsoft/autogen/pull/665```.
In dev-contributors, at 2023-11-13 19:34:42 a user named sidhujag said ```Let me play around with it, wasn’t working first until I moved to gpt assistant it was duplicating unread messages but might have been issue elsewhere I will test again and report```.
In dev-contributors, at 2023-11-13 19:12:33 a user named sonichi said ```@bansalg said the opposite: groupchatmanager needs to be an non-gptassistant agent. https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_groupchat.ipynb
I'm curious what makes the difference```.
In dev-contributors, at 2023-11-13 19:01:39 a user named sidhujag said ```WITHOUT: UserProxyAgent (to ManagementGroup):

what time is it now?

--------------------------------------------------------------------------------
Provide feedback to ManagementGroup. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 

>>>>>>>> NO HUMAN INPUT RECEIVED.

>>>>>>>> USING AUTO REPLY...
Run: run_K61cmGqjF5wf1rFNu4XwRlvX Thread: thread_ggyt4YciDlqAEyRhq7hg3RC7: completed...
user_assistant (to ManagementGroup):

I'm sorry, but I don't have direct access to real-time information such as the current time. However, you can easily check the time on your device or by using a search engine. If you're looking for the time in a specific timezone or location, you can specify that and search online or use a world clock feature on your device.


--------------------------------------------------------------------------------```.
In dev-contributors, at 2023-11-13 19:01:21 a user named sidhujag said ```UserProxyAgent (to ManagementGroup):

what time is it now?

--------------------------------------------------------------------------------
Provide feedback to ManagementGroup. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 

>>>>>>>> NO HUMAN INPUT RECEIVED.

>>>>>>>> USING AUTO REPLY...
Run: run_hRRNo71IfGDYrhmyatN26jqz Thread: thread_yseKoHgJ2IRmTqN5KQVafrmp: completed...
user_assistant (to ManagementGroup):

The current time is 18:50:49.


--------------------------------------------------------------------------------```.
In dev-contributors, at 2023-11-13 19:01:20 a user named sidhujag said ```WITH code interpreter it seems like it auto runs things on backend without even any indication:```.
In dev-contributors, at 2023-11-13 19:00:38 a user named sidhujag said ```i got assistants working with group chat.. but i had to use the new gptassistant as the base for groupchatmanager and had to make changes to gptassistant to enable user input and termination.. is there interest in merging upstream or shall i keep these in my fork?```.
In dev-contributors, at 2023-11-13 04:30:53 a user named sidhujag said ```yup found that out.. you can update agent with new file ids then reference them through messages or whatnot to make tools use them```.
In dev-contributors, at 2023-11-13 04:21:14 a user named hanley7082 said ```You can initialize an agent with file ids, or you can pass a file id into a thread with/as a message```.
In dev-contributors, at 2023-11-12 14:22:39 a user named loschess said ```Hey guys, I'd like to share the Autogen CodeSphere which has the latest Autogen, evo.ninja,  AutogenUI, MemGPT, LiteLLM, XAgent, and it's optimized with 9 agents to write your code, it also has the latest OpenAI API Documentation. 

Here's an example of it creating an Autogen Agent:
https://chat.openai.com/share/6260b371-ac9b-4055-a5bc-b19b22837846

This will make building with autogen much easier for non-coders:
https://chat.openai.com/g/g-uwUr3XChe-autogen-codesphere/```.
In dev-contributors, at 2023-11-11 19:28:20 a user named sonichi said ```An initial PR is merged. @bansalg is working on improvements.```.
In dev-contributors, at 2023-11-11 19:27:35 a user named sidhujag said ```It seems you have to pass in file ids every time```.
In dev-contributors, at 2023-11-11 19:26:51 a user named sidhujag said ```It seems assistance api will mean rewrite of a lot of autogen (in a good way) removing a lot of spaghetti code around api, I’m still not sure about files yet though```.
In dev-contributors, at 2023-11-11 00:55:52 a user named .jkyh said ```@.beibinli  Thanks so much for the lmm in the first place! I'll do a example over the next 12 hours and tag you. I couldn't put it in contrib because I needed test_assistant which is not a module, I'll have to put it one level above under test_group_chat.
https://github.com/microsoft/autogen/pull/626```.
In dev-contributors, at 2023-11-10 23:55:57 a user named .beibinli said ```Hi Joshkyh, thanks for your contribution!~ You can add a test in `test/agentchat/contrib/test_lmm.py`   In the meanwhile, I will take a look at the issue. If you can share a minimum example how to reproduce the error, that would be great.```.
In dev-contributors, at 2023-11-10 23:48:28 a user named sonichi said ```@.beibinli Could you advise the right place to add this test?```.
In dev-contributors, at 2023-11-10 22:47:31 a user named afourney said ```I’d love to get multimodal into the Testbed, but more for benchmarking and eval.```.
In dev-contributors, at 2023-11-10 22:45:10 a user named afourney said ```(open to other names than testbed, but I don't want to say benchmark yet, since it's not quite there yet)```.
In dev-contributors, at 2023-11-10 22:44:31 a user named afourney said ```Testbed is more for like benchmarks, profiling, etc.```.
In dev-contributors, at 2023-11-10 22:43:30 a user named afourney said ```@sonichi may have further direction. But basically if it's a bug or logic error.. some fundamental functionality that is broken, it should be part of the pytests.```.
In dev-contributors, at 2023-11-10 22:42:35 a user named afourney said ```Thanks joshkyh, I think that something like that can go into the main pytest tests.```.
In dev-contributors, at 2023-11-10 22:30:38 a user named .jkyh said ```Hi @afourney, I am working on a bug report, I found that two multimodal (gpt-v in contrib/lmm) and a user proxy, when put in together in a group chat (3 agents), the max round can no longer control the max conversation length, is this something I should contribute to in the test/test_group_chat unit tests or the testbed? (It would require oai calls, so require access to the test_assistant class to reach the OAI_CONFIG_LIST during remote builds).```.
In dev-contributors, at 2023-11-10 10:41:23 a user named li_jiang said ```Thank you @ayushexel , will review soon.```.
In dev-contributors, at 2023-11-10 10:16:03 a user named ayushexel said ```@li_jiang @sonichi I have created a draft PR that introduces the new Retriever API. It works well with existing examples so I wanted to start an early review cycle to see if we are on the same page. I think having a modular API for DBs will be good in general for easy maintainance and updation. Let me know what you guys think and I'll move this closer to the finish line if we all agree on design. More details in the PR - https://github.com/microsoft/autogen/pull/619```.
In dev-contributors, at 2023-11-10 01:55:51 a user named li_jiang said ```Thanks @kajatta , https://github.com/microsoft/autogen/pull/496 is not merged yet, please help review it if you're interested.```.
In dev-contributors, at 2023-11-10 00:58:41 a user named kajatta said ```Sorry i missed this - anything else needed```.
In dev-contributors, at 2023-11-09 15:14:23 a user named sonichi said ```Bottom up. @qingyunwu is the first to buy my dream 😄```.
In dev-contributors, at 2023-11-09 14:58:21 a user named bobaleaux said ```using MS infrastructure and resources.```.
In dev-contributors, at 2023-11-09 14:57:11 a user named bobaleaux said ```I i first heard about it on Oct. 2. and I'm floored at the body of contributors and participants are around this project.
Is the project orchestrated by on high or is it up to you and the other primary team members to dream big and build fast?```.
In dev-contributors, at 2023-11-09 14:54:34 a user named bobaleaux said ```That is really insane, how fast AutoGen took off```.
In dev-contributors, at 2023-11-09 14:47:07 a user named sonichi said ```autogen is probably the last to be selected into the list as it's only released 40 days ago```.
In dev-contributors, at 2023-11-09 14:46:26 a user named bobaleaux said ```That is crazy insane in making the point!```.
In dev-contributors, at 2023-11-09 13:56:17 a user named sonichi said ```Does anyone have an idea how good this achievement is? https://www.benchcouncil.org/evaluation/opencs/annual.html```.
In dev-contributors, at 2023-11-09 01:47:31 a user named sonichi said ```To all devs: @bansalg has volunteered to take a stab at supporting openai assistant api. Please try to help him if you can.```.
In dev-contributors, at 2023-11-08 18:29:17 a user named sidhujag said ```you will need to update the client on any llmconfig change, scroll up a bit to see why```.
In dev-contributors, at 2023-11-08 15:10:18 a user named shaokunzhang said ```https://github.com/microsoft/autogen/pull/285 Anyone interested in reviewing this PR?```.
In dev-contributors, at 2023-11-08 14:50:07 a user named li_jiang said ```Great! Thank you @ayushexel ,  would love to have LanceDB integration. Let me know if you need any help on the PR.```.
In dev-contributors, at 2023-11-08 14:35:16 a user named sonichi said ```Happy to hear that. @li_jiang what do you think?```.
In dev-contributors, at 2023-11-08 13:59:23 a user named ayushexel said ```Hello autogen team.
I'm Ayush from LanceDB team. A few of our community members have requested autogen integration and guides on using it. I wanted to make a contribution to turn the existing vectorstore code into a simple interface class so that it can be easily plugged by users. Are you guys open to that?```.
In dev-contributors, at 2023-11-08 12:09:20 a user named sonichi said ```what's a component? an object?```.
In dev-contributors, at 2023-11-08 06:34:56 a user named sidhujag said ```if you make llmconfig a component and then a decorator on it so you can update the component as needed, then the LLM api can consume the config and get updated when it reads the component.. similar to adding a function but maybe more structured as updating would happen only via decorator```.
In dev-contributors, at 2023-11-08 02:06:10 a user named sonichi said ```Sorry I'm not familiar with the "decorator on component" concept. I'm interested in your suggestion in the best way to support the assistants api though.```.
In dev-contributors, at 2023-11-08 01:56:25 a user named sidhujag said ```Given that we have native api tools support from OpenAI maybe make it decorator on component for config for idempotent updates, the assistants api or completions api just consume the component```.
In dev-contributors, at 2023-11-07 20:40:53 a user named sonichi said ```Thanks. Maybe we should add an `update_llm_config` method in `ConversableAgent````.
In dev-contributors, at 2023-11-07 20:05:18 a user named sidhujag said ```any time llmconfig changes (especially function spec) then you need to reinit openaiwrapper```.
In dev-contributors, at 2023-11-07 20:04:59 a user named sidhujag said ```https://github.com/sidhujag/autogen/commit/d8bffaa8fe600f3688a5b7ef4c80f69aee21a883#diff-2f84344dc8f97642ca7f3c8d3642e25235d32b0b1c03efbdb140a2dedfc295e6R125```.
In dev-contributors, at 2023-11-07 19:00:34 a user named sidhujag said ```Let me debug it then if no one else is seeing it```.
In dev-contributors, at 2023-11-07 18:45:42 a user named sonichi said ```Could you share the code for this example?```.
In dev-contributors, at 2023-11-07 18:40:37 a user named sidhujag said ```UserProxyAgent (to user_assistant):

call define_function function to make a function to check current system time

--------------------------------------------------------------------------------
Provide feedback to UserProxyAgent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 

>>>>>>>> NO HUMAN INPUT RECEIVED.

>>>>>>>> USING AUTO REPLY...
user_assistant (to UserProxyAgent):

Certainly! I will define a function named `get_current_system_time` which will return the current system time. I'll write and execute the code for the function definition.

--------------------------------------------------------------------------------
Provide feedback to user_assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 

>>>>>>>> NO HUMAN INPUT RECEIVED.

>>>>>>>> USING AUTO REPLY...

UserProxyAgent (to user_assistant):

```python
import datetime

def get_current_system_time():
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return current_time
```

Executing the above code to define the `get_current_system_time` function.

--------------------------------------------------------------------------------
Provide feedback to UserProxyAgent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 
>>>>>>>> NO HUMAN INPUT RECEIVED.

>>>>>>>> USING AUTO REPLY...

>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
user_assistant (to UserProxyAgent):

exitcode: 0 (execution succeeded)
Code output:```.
In dev-contributors, at 2023-11-07 18:37:54 a user named sidhujag said ```**i went back to pre-merge commit**: https://github.com/sidhujag/autogen/commit/cd034868f758137e988d19a3a04593c2260889ba```.
In dev-contributors, at 2023-11-07 18:37:21 a user named sidhujag said ```Commit: cd034868f758137e988d19a3a04593c2260889ba - use stats to track comms instead of group chats
Successfully built pyautogen
Installing collected packages: openai, pyautogen
  Attempting uninstall: openai
    Found existing installation: openai 1.0.0b3
    Uninstalling openai-1.0.0b3:
      Successfully uninstalled openai-1.0.0b3
  Attempting uninstall: pyautogen
    Found existing installation: pyautogen 0.2.0b2
    Uninstalling pyautogen-0.2.0b2:
      Successfully uninstalled pyautogen-0.2.0b2

All functions registered.
UserProxyAgent (to user_assistant):

call define_function function to make a function to check current system time

--------------------------------------------------------------------------------
Provide feedback to UserProxyAgent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: 

>>>>>>>> NO HUMAN INPUT RECEIVED.

>>>>>>>> USING AUTO REPLY...
user_assistant (to UserProxyAgent):

***** Suggested function Call: define_function *****
Arguments: 
{
  "name": "get_system_time",
  "description": "Retrieve the current system time.",
  "function_code": "import datetime\noutput = datetime.datetime.now().isoformat()\n",
  "category": "information_retrieval"
}
****************************************************

--------------------------------------------------------------------------------
Provide feedback to user_assistant. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:```.
In dev-contributors, at 2023-11-07 18:17:58 a user named sonichi said ```could you share an example of not working?```.
In dev-contributors, at 2023-11-07 18:03:04 a user named sidhujag said ```https://github.com/sidhujag/autogen/blob/main/main.py```.
In dev-contributors, at 2023-11-07 18:02:44 a user named sidhujag said ```i just pulled and merged latest and now not working```.
In dev-contributors, at 2023-11-07 17:54:02 a user named sidhujag said ```cant seem to find any functions to execute.. even when i prompt it to specifically.. they are being added wonder if its a generic thing or specific to my code maybe```.
In dev-contributors, at 2023-11-07 17:53:34 a user named sidhujag said ```anyone have issues with functions with the new updates autogen just did?```.
In dev-contributors, at 2023-11-06 19:51:37 a user named sonichi said ```A bug in v0.2.0b1 is under fix in https://github.com/microsoft/autogen/pull/551
Azure OpenAI API won't work properly without this fix.```.
In dev-contributors, at 2023-11-06 01:37:30 a user named mjavacam said ```Yes we are asking for it as it is the main function we would prefer using rather than being hacky... autogen is amazing in the console but would want something more concreate if we are gonna use it for more complex task with less orchestration code

The best example I have seen so far to extending the print_received_message func is https://www.youtube.com/watch?v=Z1Z0E59VFdw when it comes to extending this, I would love to be able to pass a lambda that will be used as a swap in of the of the print(..)  if a lambda or func is given otherwise it default to the print(..). 

Or some way of using or passing a decorator class instead of func or both to further extending or have control without changing the underlining behaviour as the existing behaviour is necessary based on how I have seen it implemented in the code.

I would be extremely grateful for this kinda of extension 🙏🏾🙏🏾```.
In dev-contributors, at 2023-11-05 15:55:39 a user named sidhujag said ```yea sure i am just working on the vector/db lookup on agents.. we can share thoughts if you DM me ill show you repo and step you through concepts and you can see if you wanna build with it.. but im following first principles around autogen without changing much of it```.
In dev-contributors, at 2023-11-05 14:56:16 a user named sidhujag said ```I’ve done the basics of this already```.
In dev-contributors, at 2023-11-05 08:24:08 a user named li_jiang said ```@null Hi guys, please help review these two PRs which will enhance the RetrieveChat if you're interested in RAG agents. Thanks.
Support custom text formats and recursive #496 https://github.com/microsoft/autogen/pull/496
Add support to unstructrued #501 https://github.com/microsoft/autogen/pull/501```.
In dev-contributors, at 2023-11-04 15:21:14 a user named .princeps said ```@rickyloynd I see that makes sense, I'll test it out```.
In dev-contributors, at 2023-11-03 14:02:23 a user named rickyloynd said ```Right, TeachableAgent tries to remember teachings from every message it receives.```.
In dev-contributors, at 2023-11-03 13:59:43 a user named rickyloynd said ```I'm not familiar with the neo4j db, but the main question is whether it shares the same API with chromadb. If not, you would have to change the agent code.```.
In dev-contributors, at 2023-11-03 07:55:52 a user named .princeps said ```the solution stands it's not intuitive. So I think an this update can also be a form of a _how to build a UI blog post that tutorializes and removes ambiguity```.
In dev-contributors, at 2023-11-03 07:49:42 a user named li_jiang said ```I have this impression that many people were asking for it. And there are indeed some examples posted.```.
In dev-contributors, at 2023-11-03 07:47:08 a user named .princeps said ```Haha figured it would be a forum post```.
In dev-contributors, at 2023-11-03 07:46:12 a user named li_jiang said ```The discussions are not in a single thread, need to search for the chat histories 😅```.
In dev-contributors, at 2023-11-03 07:43:33 a user named .princeps said ```I'd love to chime in on that debate, or just contribute and alternative when PolyGPT is good```.
In dev-contributors, at 2023-11-03 07:32:47 a user named .princeps said ```https://microsoft.github.io/autogen/blog/2023/10/18/RetrieveChat @li_jiang maybe split this blog into two: 

1. RAG focused blow 
2. Build UI with Autogen```.
In dev-contributors, at 2023-11-03 07:32:20 a user named li_jiang said ```Redirect the printed message to UI is a hot topic in the community, and also get human_input```.
In dev-contributors, at 2023-11-03 07:16:27 a user named tonic_1 said ```one of the most useful things is the plain text returns```.
In dev-contributors, at 2023-11-03 07:14:05 a user named tonic_1 said ```i use unstructured daily, great initiative```.
In dev-contributors, at 2023-11-03 06:00:58 a user named .princeps said ```Nice blog post btw @rickyloynd```.
In dev-contributors, at 2023-11-03 05:51:05 a user named .princeps said ```Also I'm familiar with the chat history function which is a truncated version and I think that's good for saving the chat history but when just displaying to the user what is going on I think the print message function works better. @li_jiang thoughts ? @sonichi```.
In dev-contributors, at 2023-11-03 05:47:05 a user named .princeps said ```I'll test my theory today on this 🙂```.
In dev-contributors, at 2023-11-03 05:46:38 a user named .princeps said ```That was a hackathon workaround that is janky, I'd rather just extend  the print message function to send those message to the UI so that we get the same experience of what is going on in the framework```.
In dev-contributors, at 2023-11-03 05:45:18 a user named .princeps said ```Literally create an observer class to notice when different functions are called so I can react in the front end 

https://github.com/Tonic-AI/PolyGPT-alpha/blob/major_refactor/utils/autogen_monitor.py```.
In dev-contributors, at 2023-11-03 05:44:57 a user named li_jiang said ```It's in the plan, so we'll have it later 😀```.
In dev-contributors, at 2023-11-03 05:43:26 a user named .princeps said ```And I'd also love to contribute since I find myself writing a bunch of custom code```.
In dev-contributors, at 2023-11-03 05:43:06 a user named .princeps said ```But if I review a PR, I'm not clear on how to go about it. You can dm me```.
In dev-contributors, at 2023-11-03 05:42:48 a user named .princeps said ```I'm guess you use a lot of tests, and I can do that```.
In dev-contributors, at 2023-11-03 05:42:39 a user named .princeps said ```@li_jiang also I'd love to contribute, but I've never worked on a package project so I'm not confident in my abilities to test my work```.
In dev-contributors, at 2023-11-03 05:41:37 a user named .princeps said ```Read the blog, there was no examples of a group chat```.
In dev-contributors, at 2023-11-03 05:38:50 a user named li_jiang said ```Wow, I think both retrieval agents and teachable agents are useful in your case. A teachable agent will learn things automatically, it doesn't care about who sends the messages to it. @rickyloynd , please add/correct .```.
In dev-contributors, at 2023-11-03 05:38:04 a user named .princeps said ```Then I'll just have the 3 agents 2 retrieval agents and 1 teachable agent for basic team, allowing for an architect in which agents can learn execute project tasks and remember what the project and tasks are```.
In dev-contributors, at 2023-11-03 05:36:58 a user named .princeps said ```Just wondering if the Retrieval assistant can teach the Teachable agent```.
In dev-contributors, at 2023-11-03 05:36:15 a user named .princeps said ```That's the architecture of what I'm working on @li_jiang so I want to create a global factory specialized in creating specialized agent teams from the Autogen docs, so I want some feedback and thoughts```.
In dev-contributors, at 2023-11-03 05:35:13 a user named .princeps said ```https://cdn.discordapp.com/attachments/1147106892791959572/1169710849263407114/file-MCC9uD4wyC8xIZZHvOWdEcGk.png?ex=6556651e&is=6543f01e&hm=40b01b5a2bcee716074e1cfabe4ffcbf3b19d3289b2e5efec76a19251fae1292&```.
In dev-contributors, at 2023-11-03 05:35:12 a user named .princeps said ```Yeah, that's what I'm on today```.
In dev-contributors, at 2023-11-03 05:34:17 a user named li_jiang said ```But I'm not sure would Teachable agents be more suitable for your case, I suggest you try both😀```.
In dev-contributors, at 2023-11-03 05:33:53 a user named .princeps said ```https://tenor.com/view/borat-borat-very-nice-verynice-thumbs-up-gif-25080066```.
In dev-contributors, at 2023-11-03 05:33:22 a user named li_jiang said ```Write code or answer question based on documentation retrieved is the retrieval agents designed for, so the answer is sure YES.```.
In dev-contributors, at 2023-11-03 05:30:59 a user named .princeps said ```@li_jiang I'd like to have a setup in which the team keeps track of the project, and task objectives so do you suggest for each team I have to include a the retrieval agents duo ? Can the retriever assistant write code based on documentation retrieved. Since it's an assistant I'm guessing yes !?```.
In dev-contributors, at 2023-11-03 05:28:01 a user named li_jiang said ```Now chromadb and qdrant are supported. If you prefer neo4j, you can extend the retrieval agent like qdrant did.```.
In dev-contributors, at 2023-11-03 05:26:20 a user named .princeps said ```Seems like the Qdrant, extends the retrieval agents, do you think I should use the Qdrant or just create a new neo4j subclass that extends the the retrieval agents```.
In dev-contributors, at 2023-11-03 05:24:00 a user named .princeps said ```Nice blog,  btw 

https://microsoft.github.io/autogen/blog/2023/10/18/RetrieveChat```.
In dev-contributors, at 2023-11-03 05:23:57 a user named li_jiang said ```I think yes for retrieval agent, you can check the example of qdrant. For Teachable Agent, @rickyloynd knows more about it.```.
In dev-contributors, at 2023-11-03 05:22:21 a user named li_jiang said ```The PR is not merged yet, would be nice if you'd like to help review it.```.
In dev-contributors, at 2023-11-03 05:18:13 a user named .princeps said ```Also can I use a neo4j db for the database that the Teachable Agent and retrieval agents use ?```.
In dev-contributors, at 2023-11-03 05:17:45 a user named .princeps said ```Nice! Is this in ?```.
In dev-contributors, at 2023-11-01 19:28:00 a user named sonichi said ```I'll suggest making dev/0.2 as the base branch for this PR because the design of tests is different. See https://github.com/microsoft/autogen/pull/480 for an example```.
In dev-contributors, at 2023-11-01 18:49:41 a user named .beibinli said ```Quick question, for https://github.com/microsoft/autogen/pull/515, I have added a package into `setup.py`, but the Github build still fails because of a dependent package is not installed. Any ideas?```.
In dev-contributors, at 2023-11-01 09:36:24 a user named li_jiang said ```Hi guys, please help review this PR https://github.com/microsoft/autogen/pull/501, it adds support to using unstructured for text extraction, formats like ['htm', 'png', 'html', 'xml', 'rtf', 'pdf', 'yaml', 'md', 'doc', 'odt', 'txt', 'rst', 'docx', 'jpeg', 'yml', 'csv', 'eml', 'json', 'epub', 'pptx', 'tsv', 'ppt', 'xlsx', 'log', 'jsonl', 'msg'] will all be supported if unstructured is installed.```.
In dev-contributors, at 2023-10-31 19:20:13 a user named Vinod Reddy said ```Thanks for the reply. Will check the PR```.
In dev-contributors, at 2023-10-31 18:57:38 a user named sonichi said ```Thanks. This PR is worth checking because it's a major update: https://github.com/microsoft/autogen/pull/393 
After that, you may consider finding small open issues to work on. @qingyunwu @victor.dibia @pcdeadeasy @li_jiang feel free to advise.```.
In dev-contributors, at 2023-10-31 18:47:33 a user named Vinod Reddy said ```Hey guys, I would love to contribute but want to start with something bit more manageable as my time off regular work is limited. Any tasks you guys suggest ?```.
In dev-contributors, at 2023-10-31 15:50:20 a user named sonichi said ```who's interested in streaming support? There is a PR for it: https://github.com/microsoft/autogen/pull/491```.
In dev-contributors, at 2023-10-31 15:30:15 a user named sonichi said ```Thanks! Please find the roadmap at https://github.com/orgs/microsoft/projects/989/views/3
The biggest recent change would be https://github.com/microsoft/autogen/pull/393```.
In dev-contributors, at 2023-10-31 14:31:51 a user named sagar___ said ```I would like to contribute, where can I start any tasks/activities planned.```.
In dev-contributors, at 2023-10-29 20:30:39 a user named sonichi said ```migration guide PR: https://github.com/microsoft/autogen/pull/477```.
In dev-contributors, at 2023-10-28 13:07:36 a user named sonichi said ```Everyone, please review v0.2: https://github.com/microsoft/autogen/pull/393
It contains breaking changes.```.
In dev-contributors, at 2023-10-27 23:02:24 a user named aaronward_ said ```I gave an initial code review, will test it out on functionality tomorrow - nice work again Kevin <:assistant:1159659406498222100>```.
In dev-contributors, at 2023-10-27 19:03:41 a user named aaronward_ said ```Will take a look 🙂```.
In dev-contributors, at 2023-10-27 18:57:11 a user named kevinwyr said ```Need some reviews here:
https://github.com/microsoft/autogen/pull/443
This is a continued version from lass compressible agent. In this PR, a `CompressibleAgent` is added in the `contrib` folder that retains default functionalities of the AssistantAgent, but also provides the added feature of compression when activated through the `compress_config` setting. An `on_oai_token_limit` function is registerd before calling openai to check for token count and compress if needed```.
In dev-contributors, at 2023-10-27 11:27:27 a user named aaronward_ said ```PR has passed the checks now, good to merge```.
In dev-contributors, at 2023-10-26 11:49:47 a user named li_jiang said ```This PR https://github.com/microsoft/autogen/pull/435 will fix it.```.
In dev-contributors, at 2023-10-26 10:54:02 a user named aaronward_ said ```I have a PR open for updating the FAQ, some tests are failing due to this error in the github actions workflow: "E   ImportError: cannot import name 'API' from 'chromadb.api' (/opt/hostedtoolcache/Python/3.10.13/x64/lib/python3.10/site-packages/chromadb/api/__init__.py)" 

@null can someone take a look?

https://github.com/microsoft/autogen/pull/390```.
In dev-contributors, at 2023-10-25 18:18:47 a user named tonic_1 said ```https://discord.gg/3g9VJfxC?event=1166802880708222996 this is the event for the benchmark , we can have a viewing party and see the benchmarks updated live ^^ hope y'all join in !```.
In dev-contributors, at 2023-10-25 18:11:32 a user named tonic_1 said ```thank you so much for saying that @bansalg sometimes we're a bit shy you know 😅👊🏻```.
In dev-contributors, at 2023-10-25 18:02:21 a user named bansalg said ```Please tags mods and contrib and we will try our best to help with issues.```.
In dev-contributors, at 2023-10-25 16:02:10 a user named .princeps said ```I solved it since it was just that I was passing a string instead of the actual agent object```.
In dev-contributors, at 2023-10-25 15:53:17 a user named rickyloynd said ```If you give me a small python script that reproduces the error you're stuck on now, I can debug into it here.```.
In dev-contributors, at 2023-10-25 15:51:54 a user named rickyloynd said ```I've reviewed your posts. Did you get past this error?  **'str' object has no attribute 'receive'**```.
In dev-contributors, at 2023-10-25 15:34:56 a user named rickyloynd said ```First I'll review your posts above. Do you have any extra info that isn't there?```.
In dev-contributors, at 2023-10-25 15:30:39 a user named tonic_1 said ```same thing, but working towards the benchmarks now, you're very welcome to join us on discord while we gear up for the benchmark : https://discord.gg/FP3STz9fMF```.
In dev-contributors, at 2023-10-25 15:28:19 a user named rickyloynd said ```Is it what's described in the earlier posts above?```.
In dev-contributors, at 2023-10-25 15:27:39 a user named rickyloynd said ```@tonic_1 @.princeps Happy to help for such a worthy cause! What's your configuration, and the error you get?```.
In dev-contributors, at 2023-10-25 15:16:14 a user named tonic_1 said ```if you're interested let's do it in 6 hours from now```.
In dev-contributors, at 2023-10-25 15:16:03 a user named tonic_1 said ```it would be pretty cool to make a little watching event with everyone from the community, because you know... the journey is only starting 🚀```.
In dev-contributors, at 2023-10-25 15:14:36 a user named tonic_1 said ```ok, long story folks, but basically tonight is the night where autogen based @.princeps written agent called PolyGPT-Alpha will beat the specialized benchmark made by autogpt crew and basically then replace autogpt with polyGPT as the official autogpt according to the contest's regulations```.
In dev-contributors, at 2023-10-25 15:11:01 a user named .princeps said ```worry not, I got it```.
In dev-contributors, at 2023-10-25 15:04:49 a user named tonic_1 said ```hey there folks @null @null i'm really stuck with @.princeps now on a certain type error when passing information from autogen to our benchmarking tool and we could really use some help as the deadline is in 18 hours 🙏🏻 in general even after this deadline we will be very interested in solving this problem, if you can please help that is much appreciated```.
In dev-contributors, at 2023-10-24 20:13:49 a user named .princeps said ```yeah, it's that the send function in the Conversable agent is getting a string name of an agent and not the agent object so I think that doesn't allow it to have the receive Admin_User: ERROR IN send: 'str' object has no attribute 'receive'```.
In dev-contributors, at 2023-10-24 19:44:03 a user named sonichi said ```@jasonzhou1993 had that error before and solved; It was about "name" if I remember correctly```.
In dev-contributors, at 2023-10-24 19:18:18 a user named .princeps said ```@sonichi [2023-10-24 12:15:23,443] [forge.autogen_helper] [ERROR]        ❌  🚨 Admin_User: ERROR IN send: 'str' object has no attribute 'receive'



I'm getting this error from my agents setup, am I'm going something stupid ?
https://github.com/Tonic-AI/AutoGPT/blob/a6a618749eb0d0de9c04f36b1378f8f254cca60a/autogpts/PolyGPT-alpha/forge/agents_initializer.py


https://github.com/Tonic-AI/AutoGPT/blob/a6a618749eb0d0de9c04f36b1378f8f254cca60a/autogpts/PolyGPT-alpha/forge/polygpt.py

@sonichi @qingyunwu @1_twisto```.
In dev-contributors, at 2023-10-24 16:48:47 a user named tonic_1 said ```We're benchmarking autogen agent polyGPT-alpha against autogpt benchmarks ! 

https://discord.gg/mHHdcbdk?event=1166417234906853387```.
In dev-contributors, at 2023-10-23 18:48:28 a user named aaronward_ said ```I've updated the documentation FAQ section, ready for review: https://github.com/microsoft/autogen/pull/390 @null @null```.
In dev-contributors, at 2023-10-22 22:53:58 a user named sonichi said ```Next week I'll be heads down with https://github.com/microsoft/autogen/issues/203. I'll be less responsive. Please try to help each other. @null or @null when appropriate.```.
In dev-contributors, at 2023-10-22 21:36:52 a user named tonic_1 said ```lol i love the emojis 🤗```.
In dev-contributors, at 2023-10-22 17:21:15 a user named .princeps said ```@sonichi @qingyunwu this is basically my approach```.
In dev-contributors, at 2023-10-22 17:20:56 a user named .princeps said ```class AutogenAgentHelper:
    def __init__(self, agent):
        if not isinstance(agent, ConversableAgent):
            raise TypeError("The agent must be an instance of ConversableAgent")
        self.agent = agent

    def run_code(self, code):
        print("Running code... 🏃‍♂️")
        try:
            exec(code)
        except Exception as e:
            print(f"Error executing code: {e} 😞")

    def execute_function(self, func, *args, **kwargs):
        print("Executing function... 🛠️")
        try:
            result = self.agent.execute_function(func, *args, **kwargs)
            print(f"Function executed successfully! Result: {result} 😊")
        except Exception as e:
            print(f"Error executing function: {e} 😞")

    def print_received_message(self, message):
        print(f"Received message: {message} 📬")

    def get_human_input(self, prompt):
        print(f"Getting human input... 🤔")
        user_input = input(prompt)
        print(f"Human input received: {user_input} 👂")
        return user_input```.
In dev-contributors, at 2023-10-22 17:18:22 a user named sonichi said ```It's called at every time a message is received```.
In dev-contributors, at 2023-10-22 17:12:04 a user named qingyunwu said ```@sonichi  do you have time to talk?```.
In dev-contributors, at 2023-10-22 17:11:36 a user named .princeps said ```I'm building something for a hackathon, the AutoGPT hackathon, and I cant wait to show them how Autogen is the missing piece```.
In dev-contributors, at 2023-10-22 17:11:04 a user named .princeps said ```So I was wondering if I can talk to the person who wrote that so I can get some insight```.
In dev-contributors, at 2023-10-22 17:10:40 a user named .princeps said ```Would be sooo useful for UIs```.
In dev-contributors, at 2023-10-22 17:10:19 a user named .princeps said ```Cause I think there is a function somewhere that smoothly takes the messages and function calls from agents and prints them, I want to find that function and call it or inherit it```.
In dev-contributors, at 2023-10-22 17:09:13 a user named .princeps said ```@qingyunwu I was going to create a custom class that overrides the function below and send this to the front end 

_print_received_message - This method prints the received message.```.
In dev-contributors, at 2023-10-22 17:09:06 a user named qingyunwu said ```Then how about the second approach?```.
In dev-contributors, at 2023-10-22 17:07:15 a user named .princeps said ```No, I really want to get the same concept printed to console```.
In dev-contributors, at 2023-10-22 17:05:27 a user named qingyunwu said ```Great. That's the first approach I mentioned. Does that satisfy the needs?```.
In dev-contributors, at 2023-10-22 17:03:09 a user named qingyunwu said ```Trying to better understand the context as well, is this a question asking about how to get the messages sent between the agents such that one can send the msgs to the UI? If so, one way to do that is to log the conversations (https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logging-experimental) so that you can do whatever you want to with the msgs. But this shall be done after the conversation session is done; Another way by which you can get real-time msg is by calling the "last_message" (https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L221) function, or the "chat_message" (https://github.com/microsoft/autogen/blob/main/autogen/agentchat/conversable_agent.py#L217) function. "last_message" gives you the last message exchanged with the agent, and "chat_message" gives you the list of messages exchanged so far.```.
In dev-contributors, at 2023-10-22 17:02:40 a user named .princeps said ```You know when you run Autogen and it prints the conversation to the console ? How can I get that to print to a UI ?```.
In dev-contributors, at 2023-10-22 16:54:11 a user named qingyunwu said ```Got it. Yes, I agree a tutorial on how to run those commonly used benchmarks would be very helpful.```.
In dev-contributors, at 2023-10-22 16:53:21 a user named tonic_1 said ```@qingyunwu what do you think about this one 👆🏻```.
In dev-contributors, at 2023-10-22 16:52:41 a user named tonic_1 said ```very close, the first one```.
In dev-contributors, at 2023-10-22 16:52:32 a user named tonic_1 said ```so just to clarify, to me , it would be great to have a tutorial how to run benchmarks , maybe common benchmarks + publish to leaderboards with whatever fine tunes or datasets made with auto ml```.
In dev-contributors, at 2023-10-22 16:52:32 a user named qingyunwu said ```Is this close to what you hope to have?```.
In dev-contributors, at 2023-10-22 16:52:04 a user named qingyunwu said ```And this one: https://github.com/microsoft/autogen/blob/main/notebook/oai_completion.ipynb where we are using AutoGen to tune GPT models on math problem solving and coding taks.```.
In dev-contributors, at 2023-10-22 16:50:20 a user named qingyunwu said ```Here by "fine-tunes" you mean LLM model fine-tuning or also model inference hyperparameter tuning? We have a notebook example showing the utility of the latter: https://github.com/microsoft/autogen/blob/main/notebook/oai_chatgpt_gpt4.ipynb```.
In dev-contributors, at 2023-10-22 16:45:07 a user named tonic_1 said ```well that's something for the future perhaps, and i look forward to discussing this with everyone

the main point is about evaluating fine-tunes made with auto-ml maybe as a notebook example or tutorial```.
In dev-contributors, at 2023-10-22 16:43:23 a user named qingyunwu said ```Thanks @tonic_1 for sharing your thoughts and suggestions! Trying to better understand the proposal, here by "autogen / automl link", you mean conceptually how autogen is relevant to automl or any concrete link?```.
In dev-contributors, at 2023-10-22 14:52:20 a user named sonichi said ```@qingyunwu could you follow up?```.
In dev-contributors, at 2023-10-22 14:34:33 a user named tonic_1 said ```by the way @null it would be really nice to have an evaluation-focussed notebook for auto-ml actually, the autogen / automl link i think is underexploited right now```.
In dev-contributors, at 2023-10-22 14:33:48 a user named tonic_1 said ```i think i might know how to do this, it's from one of the notebooks but i have to remember which one```.
In dev-contributors, at 2023-10-22 13:36:52 a user named Tgriffith3433 said ```that ui tag he created after i asked is the place to look. there are a few options if you scroll through that.```.
In dev-contributors, at 2023-10-22 06:27:39 a user named .princeps said ```I want to get the messages sent between the agents and send them to the UI @sonichi know how I can do this or how I should ask```.
In dev-contributors, at 2023-10-21 17:56:29 a user named Tgriffith3433 said ```Oh perfect thanks! Looks like a few good options out there already```.
In dev-contributors, at 2023-10-21 17:43:56 a user named sonichi said ```I just created a tag "ui" in <#1161015724521836634>```.
In dev-contributors, at 2023-10-21 17:41:20 a user named Tgriffith3433 said ```The idea is basically have a light weight chat ui for the various agent configurations, just to make it easier to  see what’s going on at a glance without having to scroll through the output```.
In dev-contributors, at 2023-10-21 17:39:33 a user named Tgriffith3433 said ```Apologies if this has been asked and answered.

I was starting to build out a chat visualizer in electron/react. I was initially reading the standard output but started pivoting to web sockets. I thought I might check if anyone had built something like this before I got too much further.```.
In dev-contributors, at 2023-10-21 16:13:28 a user named tonic_1 said ```eventually i hope to more formally introduce this repo to the autogen community at large + more as a focal point to build the tool we want to use 🚀```.
In dev-contributors, at 2023-10-21 16:12:10 a user named tonic_1 said ```so thanks to @sagar___ and folks that turned up , here's the event later tonight to just test it out for folks basically learn about the repo how to use it , where the benchmarks are, how to do the bug reports, make PRs + all that https://discord.gg/GVHjmdHM?event=1165321171579965470```.
In dev-contributors, at 2023-10-21 11:15:03 a user named tonic_1 said ```oh for real yeah? please jump in, you know we've been at it not much more than 3/4 weeks , but we're sort of soft launching it, i'll tell you all about the agent benchmarking competition, etc etc it's a ton of fun if i'm honest with you```.
In dev-contributors, at 2023-10-21 11:11:46 a user named ludyz said ```yeah I would be happy to be involved, we share enough discord servers already lol```.
In dev-contributors, at 2023-10-21 10:51:56 a user named tonic_1 said ```hope you join in, it's just a small one (the meeting i mean) but hopefully we can walk through everything today actually see here : https://discord.com/channels/1153072414184452236/1157717881291812964/1165007558034067486```.
In dev-contributors, at 2023-10-21 05:58:50 a user named sagar___ said ```I am willing to contribute, wrapping head round the repo, 

 I had started a experiment in similar line to build 
-https://github.com/SDcodehub/agent_llm_dev

I can contribute though, I can learn along, can someone point me to specifics at start, I can take work under supervision at start and can be independent along the way, thought?```.
In dev-contributors, at 2023-10-20 19:24:06 a user named tonic_1 said ```hey there folks , please share this widely https://discord.gg/zTCGnPpF?event=1165007231662698497```.
In dev-contributors, at 2023-10-20 18:19:40 a user named tonic_1 said ```pre anouncement : 

we're moving towards benchmarking this  autogen deployment : 

we're hoping folks that can do make PRs - more on that soon !

https://github.com/Tonic-AI/PolyGPT-alpha```.
In dev-contributors, at 2023-10-20 16:20:06 a user named sonichi said ```Great. We need lots of improvements for the docs.```.
In dev-contributors, at 2023-10-20 16:18:00 a user named nitya.dev said ```Hey there folks - I am new to the channel but excited to play with AutoGen and see if I can contribute in some meaningful way. To start, I was going to ask if you needed any contributions to improve the docs (https://microsoft.github.io/autogen/) - was thinking I could explore the OSS project in November and use that as a way to identify gaps or issues in docs if useful```.
In dev-contributors, at 2023-10-19 03:25:22 a user named sonichi said ```Thanks! For reviewers, I suggest starting from the notebook.```.
In dev-contributors, at 2023-10-19 02:16:27 a user named http403 said ```Hey everyone!
This is my first serious look at AutoGen, and I wanted to extend its capabilities by allowing agents to define new functions. This replaces or complements the user proxy's ability to run blocks of code from a response. Instead, the model may define a new function, and invoke it later.
Unfortunately, this required a small change to AutoGen, to add functions to the llm_config. I submitted a PR (with tests) here:
https://github.com/microsoft/autogen/pull/285
It's a small change, and one may wonder why it's needed, so I also added a demonstration of the feature in a notebook included in the PR:
https://github.com/microsoft/autogen/blob/ff37254abe504901f024db451c80debb63780d19/notebook/agentchat_inception_function.ipynb
Let me know what you think and if you have any questions or suggestions!```.
In dev-contributors, at 2023-10-17 15:37:51 a user named sonichi said ```I asked a bigger question, which is the main blocker: https://github.com/microsoft/autogen/pull/195#discussion_r1360080869```.
In dev-contributors, at 2023-10-17 15:13:28 a user named kevinwyr said ```I left a code change that hasn't been addressed.```.
In dev-contributors, at 2023-10-17 12:15:12 a user named siafu said ```@kevinwyr  testing your branch now```.
In dev-contributors, at 2023-10-17 12:14:48 a user named siafu said ```I think I'll hang out here```.
In dev-contributors, at 2023-10-16 03:08:07 a user named sonichi said ```@kevinwyr  your reply is appreciated for this PR: https://github.com/microsoft/autogen/pull/195```.
In dev-contributors, at 2023-10-12 23:31:59 a user named aaronward_ said ```I think you might start to need more moderators soon to deal with these bots```.
In dev-contributors, at 2023-10-12 11:14:16 a user named quackduck. said ```<#1153072414184452243> still one more mate in that channel. I think there's still 2/3 more floating around here too```.
In dev-contributors, at 2023-10-12 03:26:23 a user named sonichi said ```Does anyone have experience with openrouter.ai? https://github.com/microsoft/autogen/discussions/208```.
In dev-contributors, at 2023-10-12 00:10:24 a user named maheshpec said ```built it on mac M1 - works for me```.
In dev-contributors, at 2023-10-11 17:04:11 a user named aaronward_ said ```not yet but can give it a try get a chance```.
In dev-contributors, at 2023-10-11 16:21:15 a user named sonichi said ```Has anyone tested with Docker on MacOS? https://github.com/microsoft/autogen/issues/206```.
In dev-contributors, at 2023-10-11 04:03:04 a user named yssrexe said ```Guys this automated checker for simple shell tasks ...
on the redme.md file you will find all steps to check you code
https://github.com/yssrexe/automated_checker```.
In dev-contributors, at 2023-10-11 03:52:36 a user named sonichi said ```question about using autogen to implement open interpreter: https://github.com/microsoft/autogen/issues/173
how many devs here know how to do it?```.
In dev-contributors, at 2023-10-08 22:04:49 a user named tonic_1 said ```btw i got retweeted by langchain about autogen : https://x.com/josephpollack/status/1711118367266939021?s=20

we'll be working with this issue until the 20 th easily, and hopefully we can have a nice surprise ready for our colleague by the time he gets back ! 

so if you want to help to close this issue based on the feedback (or more based on our useage?)  please let's work on it together```.
In dev-contributors, at 2023-10-08 22:03:02 a user named tonic_1 said ```i have a similar problem with my french keyboard:  the backtick is not a back tick : ' ` ... so yeah, at some point it was a fun thing to debug for a few hours ^^```.
In dev-contributors, at 2023-10-08 22:01:55 a user named tonic_1 said ```🤔🤔 sometimes in "highly customized" environments things can go wrong, but i should review it```.
In dev-contributors, at 2023-10-08 15:14:16 a user named kevinraetz said ```it's hard to tell from the issue but I would think it has something to do with the prompt or the quotes used in the code. It could be that they copied some code from their Mac into the ipynb and that caused the double quotes to change. But it's just a guess. Could also be something totally different 😅```.
In dev-contributors, at 2023-10-08 15:06:15 a user named sonichi said ```So is it an issue with openai + mac?```.
In dev-contributors, at 2023-10-08 14:56:33 a user named kevinraetz said ```The formatting in the issue is aweful but looking at https://www.compart.com/de/unicode/U+201C it seems that at some point they use a weird double quote (could be an autoformatting issue of MacOS, I sometimes have that when someone using a Mac is sending me text and Ubuntu is showing the weird double quote). Here's the difference 

regular quotes->" 
quotes causing the error->“```.
In dev-contributors, at 2023-10-08 14:42:23 a user named sonichi said ```Does anyone have a clue about this issue? https://github.com/microsoft/autogen/issues/153```.
In dev-contributors, at 2023-10-08 02:19:51 a user named ilaffey said ```Hey all- was digging around with a RetrieveUserProxyAgent today and wasn't super impressed - started a thread here:

https://discord.com/channels/1153072414184452236/1160400789139882015

can we decouple the existing UserProxyAgent from chroma db ?```.
In dev-contributors, at 2023-10-07 15:53:44 a user named sonichi said ```Great job everyone. Keep it up!```.
In dev-contributors, at 2023-10-06 19:49:01 a user named hanley7082 said ```Look at the QA notebook for information on how to do this```.
In dev-contributors, at 2023-10-06 19:46:50 a user named haffel said ```Just saw thats setup already <id:customize>```.
In dev-contributors, at 2023-10-06 19:42:50 a user named haffel said ```You can set that up with the onboarding process. They can select if they are a dev and then get the role if so (also possible to do after they joined). I can explain you how to set it up if you want```.
In dev-contributors, at 2023-10-06 17:59:14 a user named aaronward_ said ```https://tenor.com/view/conspiracy-charlie-day-crazy-always-sunny-in-philadelphia-qanon-gif-23738584```.
In dev-contributors, at 2023-10-06 17:59:01 a user named aaronward_ said ```My findings with the open source model integration, any help would be great: https://github.com/microsoft/autogen/pull/95#issuecomment-1751172931```.
In dev-contributors, at 2023-10-06 17:31:55 a user named kikkerd said ```What would it take for a company to develop an agent trained or tuned on its proprietary data to be able to be used directly with Autogen?```.
In dev-contributors, at 2023-10-06 16:49:20 a user named sonichi said ```BTW who made the AutoGen emojis? Thank you very much.```.
In dev-contributors, at 2023-10-06 16:33:21 a user named sonichi said ```The role @null is created after we have like 400 people. So many devs have not been assigned to this role. Please let @null know if help with role assigning is needed. (I don't know if you can self assign it)```.
In dev-contributors, at 2023-10-06 16:20:19 a user named sonichi said ```Thanks to suggestion by @hypercodec I changed the color for @null. Please let me know if you guys prefer a different color. I'm bad at it.```.
In dev-contributors, at 2023-10-05 22:43:00 a user named fxtoofaan said ```Nice. Would love to see this work with the new AWQ models 🙂```.
In dev-contributors, at 2023-10-05 21:35:11 a user named aaronward_ said ```Open sourced modelling on the way to autogen thanks the people in LiteLLM 🎉 we are just trying to iron out a few bugs```.
In dev-contributors, at 2023-10-05 10:58:21 a user named h0lybyte said ```@jaemil https://github.com/microsoft/autogen/issues/46```.
In dev-contributors, at 2023-10-05 10:56:22 a user named h0lybyte said ```@jaemil https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In dev-contributors, at 2023-10-05 04:47:43 a user named li_jiang said ```Approved and added to merge queue.```.
In dev-contributors, at 2023-10-04 14:22:44 a user named aaronward_ said ```@sonichi all checks have passed 🎉```.
In dev-contributors, at 2023-10-04 13:52:14 a user named sonichi said ```Thanks for the quick fix. Running now.```.
In dev-contributors, at 2023-10-04 13:34:24 a user named aaronward_ said ```@sonichi Window builds seem to be fixed now, few other tests are marked as waiting for approval```.
In dev-contributors, at 2023-10-04 13:03:47 a user named sonichi said ```Thanks. I left a comment about why it may be failing on windows.```.
In dev-contributors, at 2023-10-04 12:54:13 a user named aaronward_ said ```I've updated the notebook, added some error handling to the new functionality and rewrote the tests to test for multiple scenarios - tests passing on my end```.
In dev-contributors, at 2023-10-04 01:29:31 a user named aaronward_ said ```i haven't written tests yet just finished the notebook, will take a look at it tomorrow```.
In dev-contributors, at 2023-10-04 01:19:51 a user named sonichi said ```Tests are failing. Do you know why?```.
In dev-contributors, at 2023-10-04 01:13:32 a user named aaronward_ said ```made some updates to the code allowing for complex configurations using a .env file, also made a notebook explaining all the ways to set up a config_list @sonichi please circulate with the crew and provide feedback```.
In dev-contributors, at 2023-10-04 01:12:37 a user named aaronward_ said ```https://github.com/microsoft/autogen/pull/68```.
In dev-contributors, at 2023-10-03 17:52:31 a user named cipherself said ```@shaokunzhang Unfortunately, we need 1 more workflow approval for the OpenAI jobs```.
In dev-contributors, at 2023-10-03 08:46:06 a user named cipherself said ```No worries, thanks for reviewing! Unfortunately I am now waiting for a workflow approval again.```.
In dev-contributors, at 2023-10-03 01:32:33 a user named sonichi said ```Approved. Thanks for the contribution. Please read the review comment as I had some misunderstanding earlier. Sorry about that.```.
In dev-contributors, at 2023-10-02 21:10:58 a user named cipherself said ```The `OpenAI/*` workflow tasks need approval as well 😄```.
In dev-contributors, at 2023-10-02 20:55:58 a user named cipherself said ```Thanks! My pleasure, should I ask again here for a review once I make sure the checks pass?```.
In dev-contributors, at 2023-10-02 20:52:43 a user named shaokunzhang said ```Approved. Thanks for the PR😀```.
In dev-contributors, at 2023-10-02 18:32:41 a user named cipherself said ```I can't add reviewers to my PR https://github.com/microsoft/autogen/pull/80
Can someone please approve the workflows so that they start running?```.
In dev-contributors, at 2023-10-02 12:28:36 a user named andyinater said ```@vincentjedi try starting a thread in  <#1157397569375309864> so you can get a focused disccusion on your issue, or search through some community posted examples and see if it helps anything click.

There is definitely a bit of a learning curve.```.
In dev-contributors, at 2023-10-02 11:51:07 a user named vincentjedi said ```Be frank I have absolutely no idea why these special functions  py files have to be in that autogen directory. Is it because every time 'import autogen', these 5 py files will be loaded into the memory ?```.
In dev-contributors, at 2023-10-02 11:47:55 a user named vincentjedi said ```There are only 5 py files under the autogen directory. One of them is your pdf py file.```.
In dev-contributors, at 2023-10-02 11:37:52 a user named li_jiang said ```You may want to read code under autogen to get more details of the implementation.```.
In dev-contributors, at 2023-10-02 11:35:21 a user named vincentjedi said ```# the assistant receives a message from the user, which contains the task description
user_proxy.initiate_chat(
    assistant,
    message="""
Who should read this paper: https://arxiv.org/abs/2308.08155
""",
)```.
In dev-contributors, at 2023-10-02 11:34:32 a user named vincentjedi said ```# create an AssistantAgent instance named "assistant"
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
)
# create a UserProxyAgent instance named "user_proxy"
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "web"},
    llm_config=llm_config,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet."""
)```.
In dev-contributors, at 2023-10-02 11:33:55 a user named vincentjedi said ```import autogen

config_list = autogen.config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": ["gpt4", "gpt-4-32k", "gpt-4-32k-0314", "gpt-4-32k-v0314"],
    },
)

llm_config={
    "request_timeout": 600,
    "seed": 42,
    "config_list": config_list,
    "temperature": 0,
}```.
In dev-contributors, at 2023-10-02 11:32:29 a user named vincentjedi said ```Back to basic,  how are all the py files under the autogen directory used by the agent? For example, in the Jupiter notebook, I dont see any code calling any functions specifically.```.
In dev-contributors, at 2023-10-02 11:29:41 a user named li_jiang said ```what do you mean by “parse py file”? For existing agents, we’ve defined some methods/functions for them. For customized new agents, you can define any function for them.```.
In dev-contributors, at 2023-10-02 10:17:58 a user named vincentjedi said ```Does it mean that before using autogen, each agent will be given several py files to use for each task ? How does each agent know what  each py file does if there are many py files to choose from? Each agent will just parse each py file  and make an educated guess ?```.
In dev-contributors, at 2023-10-02 01:42:26 a user named li_jiang said ```Yes. For which function to call, it is predefined in the __init__ function of the agent```.
In dev-contributors, at 2023-10-01 20:25:54 a user named aaronward_ said ```I submitted a PR: https://github.com/microsoft/autogen/pull/68```.
In dev-contributors, at 2023-10-01 19:37:25 a user named aaronward_ said ```this is a good call out out, i guess we could add an option like extraction_method = 'naive' or 'complex' calling the different pdf extraction functions, Giving users more control.```.
In dev-contributors, at 2023-10-01 18:46:06 a user named aaronward_ said ```And happy to help 🙂```.
In dev-contributors, at 2023-10-01 18:43:55 a user named aaronward_ said ```Hey guys - I've written a util that allows you to set your `config_list` using a `.env` file - i think this would be useful for those, like myself, who want to keep all their api keys in one central location, not just OpenAI keys. Will i submit a PR?```.
In dev-contributors, at 2023-10-01 15:11:17 a user named vincentjedi said ```So if I ask the agent to parse the pdf saved in the directory, it will just call the py file automatically and extract the data from the pdf file ? How does the agent know which py file to call into for each specific task ?```.
In dev-contributors, at 2023-10-01 15:04:21 a user named sonichi said ```Thanks for the interest for contribution. Could you read the contribute guide? https://microsoft.github.io/autogen/docs/Contribute```.
In dev-contributors, at 2023-10-01 14:47:30 a user named bhushan9249 said ```Hi, I'm new here. can anyone tell me how can i start contribute?```.
In dev-contributors, at 2023-10-01 14:42:27 a user named vincentjedi said ```How about using multimodal llm like 'llava' so that autogen can ingest image and text directly ?```.
In dev-contributors, at 2023-10-01 14:40:00 a user named vincentjedi said ```Also can autogen go to scrap websites for text and number ? What if the website is rendered using JavaScript? Does it need to use puppeteer or selenium in order to see the content of the site ?```.
In dev-contributors, at 2023-10-01 14:39:11 a user named Adityaaaa said ```Hi, I'm new here. can anyone tell me how can i start contribute?```.
In dev-contributors, at 2023-10-01 14:27:29 a user named li_jiang said ```We can register different functions to an agent's `generate_reply` function, all the customized functions are injected by this way.```.
In dev-contributors, at 2023-10-01 14:23:44 a user named vincentjedi said ```This is still very confusing to me how autogen can initiate all different functions...```.
In dev-contributors, at 2023-10-01 14:22:33 a user named vincentjedi said ```I am still learning how autogen works```.
In dev-contributors, at 2023-10-01 14:22:25 a user named vincentjedi said ```By the way , how does autogen call into your py file to use your parser?```.
In dev-contributors, at 2023-10-01 14:21:35 a user named li_jiang said ```We're encouraging PRs from the community, it would be great if you'd raise a PR for the new solution. I guess we can keep both pypdf and pypdfium2&pytesseract.```.
In dev-contributors, at 2023-10-01 14:19:07 a user named vincentjedi said ```Just want to share with you my own findings in this particular topic```.
In dev-contributors, at 2023-10-01 14:18:13 a user named vincentjedi said ```I haven't tried it out. But I happen to know that bing chat isn't very at extracting info from pdf files with tons of chart as I was looking into the latest research paper in liquid neurons. So I assume their stack may not read pdf files with accuracy ..```.
In dev-contributors, at 2023-10-01 14:15:48 a user named vincentjedi said ```I know. I hope I am not confusing the situation```.
In dev-contributors, at 2023-10-01 14:15:48 a user named li_jiang said ```Do you encountered issue with pypdf?```.
In dev-contributors, at 2023-10-01 14:15:07 a user named li_jiang said ```To make clarification to the parser and LLM model selection, the `num_tokens_from_text` comes after text extraction, it's a different topic from pypdf and pypdfium2&pytesseract.```.
In dev-contributors, at 2023-10-01 14:13:40 a user named vincentjedi said ```Do you think u could adopt some of his codes and try it out ?```.
In dev-contributors, at 2023-10-01 14:12:28 a user named li_jiang said ```Very interesting solution. It definitely worth trying.```.
In dev-contributors, at 2023-10-01 14:09:48 a user named vincentjedi said ```Since his approach is designed to extract number instead of text, pypdf could be slightly more accurate in text recognition if the PDF file is simple with mostly text.```.
In dev-contributors, at 2023-10-01 14:06:23 a user named vincentjedi said ```This is his explanation for not using pypdf```.
In dev-contributors, at 2023-10-01 14:05:59 a user named vincentjedi said ```https://youtu.be/v_cfORExneQ?si=YjSCACtWFPI1H_aI```.
In dev-contributors, at 2023-10-01 14:05:28 a user named vincentjedi said ```I just happened to come across this because he found that pypdf is far from perfect in extracting more complex pdf files with scanned images. Hence he claimed his approach is superior```.
In dev-contributors, at 2023-10-01 14:03:14 a user named vincentjedi said ```https://github.com/JayZeeDesign/gpt-data-extraction/blob/main/app.py```.
In dev-contributors, at 2023-10-01 13:48:08 a user named vincentjedi said ```Have you heard of using pypdfium2 And pytesseract combined instead of using pypdf alone?```.
In dev-contributors, at 2023-10-01 13:40:37 a user named li_jiang said ```I guess it would be good to add those you'd like to use.```.
In dev-contributors, at 2023-10-01 13:38:24 a user named vincentjedi said ```There are so many models in the market ... how do you decide which ones to add ?```.
In dev-contributors, at 2023-10-01 13:37:06 a user named li_jiang said ```Ah, this is for computing the number of tokens of a given text string. I see what you mean. We need to add support to different model to the function `num_tokens_from_text`. Would you like to make a PR?```.
In dev-contributors, at 2023-10-01 13:28:29 a user named vincentjedi said ```Just wonder what these codes are designed  for ?```.
In dev-contributors, at 2023-10-01 13:27:24 a user named vincentjedi said ```if model in {
        "gpt-3.5-turbo-0613",
        "gpt-3.5-turbo-16k-0613",
        "gpt-4-0314",
        "gpt-4-32k-0314",
        "gpt-4-0613",
        "gpt-4-32k-0613",
    }:```.
In dev-contributors, at 2023-10-01 13:22:43 a user named li_jiang said ```The parser is not LLM-related, so it will work with any llm models.```.
In dev-contributors, at 2023-10-01 13:03:31 a user named vincentjedi said ```Does the parser only work with openai models? How about llama2 or other local llm?```.
In dev-contributors, at 2023-10-01 12:21:06 a user named sonichi said ```Is the contributor on discord?```.
In dev-contributors, at 2023-10-01 12:20:44 a user named sonichi said ```And we should acknowledge the contributor!```.
In dev-contributors, at 2023-10-01 12:20:17 a user named sonichi said ```So we can talk with PDFs now? That's a feature worth highlighting!```.
In dev-contributors, at 2023-10-01 12:12:36 a user named li_jiang said ```Add a parser to extract text from PDF files and fix a bug of collection creation.```.
In dev-contributors, at 2023-10-01 11:44:50 a user named sonichi said ```@li_jiang could you briefly summarize the contribution of https://github.com/microsoft/autogen/pull/50 ?```.
In dev-contributors, at 2023-10-01 11:44:09 a user named sonichi said ```Let's onboard new contributors and share updates in this channel.```.
In dev-contributors, at 2023-10-01 11:38:54 a user named sonichi said ```This channel is created for developers & contributors to communicate. Welcome to all!```.
In created-with-autogen, at 2023-11-14 21:20:31 a user named generadorprueba said ```<#1157447399044821132> maestro de historia Argentina```.
In created-with-autogen, at 2023-11-12 20:20:52 a user named faldore said ```If you have built an app with autogen I would really appreciate if you could record some of your ChatGPT API interactions and send them to me.  I'm trying to train open models to get better at these use cases.

Here's a script you can use to record your data:

https://gist.github.com/ehartford/ef5d23bf9a43b9a2467f9c1285815f68```.
In created-with-autogen, at 2023-11-11 19:41:07 a user named sonichi said ```https://www.youtube.com/watch?v=iWdVAr4xMkg```.
In created-with-autogen, at 2023-11-11 19:39:30 a user named sonichi said ```https://www.youtube.com/watch?v=4POjIoPuRj4```.
In created-with-autogen, at 2023-11-11 17:59:16 a user named sonichi said ```https://youtu.be/f5Qr8xUeSH4?si=exKF0_LFyIkX0QTv```.
In created-with-autogen, at 2023-11-11 15:43:51 a user named sonichi said ```https://youtu.be/9VXGWeT4cjk?si=RLK7h5n5StzF3DUO```.
In created-with-autogen, at 2023-11-11 15:40:45 a user named sonichi said ```https://youtu.be/VtHlFjyp2KI?si=BkXHBkJtOqpwZcuj```.
In created-with-autogen, at 2023-11-10 20:04:33 a user named aaronward_ said ```Looking forward to implementing a plotly agent to display interactive charts in-chat```.
In created-with-autogen, at 2023-11-10 20:02:56 a user named aaronward_ said ```Sure, send me a message 🙂```.
In created-with-autogen, at 2023-11-10 01:45:25 a user named sidhujag said ```I noticed when python code was broken another agent would come in and end up choosing a different logic path and original agent then loses track and doesn’t fix the code but goes with what the last agent did```.
In created-with-autogen, at 2023-11-10 01:44:11 a user named sidhujag said ```Because otherwise say your a coder and making a series of function calls to do job you don’t want others coming in to work on the problem while you are, once you finish your calls then give control to someone else```.
In created-with-autogen, at 2023-11-10 01:42:53 a user named sidhujag said ```One thing I found was opposite of this notebook: when a function call happens, you want the same agent to speak again instead of someone else until last message is not a function```.
In created-with-autogen, at 2023-11-10 01:39:58 a user named sidhujag said ```What I did was allow an agent to send to another group which distributes the question to another group and terminates putting control back to calling group, instead of leaders it lets anyone in the groups work or delegate to other groups```.
In created-with-autogen, at 2023-11-10 01:01:26 a user named kajatta said ```Wowowow https://github.com/microsoft/autogen/blob/main/notebook/agentchat_hierarchy_flow_using_select_speaker.ipynb this is pretty powerful breakthrough well done ✅```.
In created-with-autogen, at 2023-11-09 22:23:45 a user named jacek6859 said ```I explore application of autogen agents in project management:
A New Way of Analyzing Risk in Software Projects https://medium.com/@JacekWo/a-new-way-of-analyzing-risk-in-software-projects-9b68be7b8bb3```.
In created-with-autogen, at 2023-11-09 22:16:58 a user named jay_wooow said ```Hey Aaron! Your resources have been super useful as I've explored how to quickly prototype autogen workflows with Chainlit. I'm doing some product research on tools that may be useful for agent builders like you and would love to chat (note: happy to reward you for your time!). My team is thinking of dev tools that may be interesting to build to enable agent interoperability, observability, orchestration etc. 

If anyone is open for a chat, let me know!```.
In created-with-autogen, at 2023-11-09 16:57:45 a user named alexchaomander said ```Yesterday during the Semantic Kernel Office Hours, I got to show off a quick demo of using AutoGen with SK! This is the clipped portion of that! 

https://youtu.be/pCbYBqe2iME```.
In created-with-autogen, at 2023-11-09 15:35:28 a user named sonichi said ```Feel free to submit to <#1161015724521836634> as well```.
In created-with-autogen, at 2023-11-08 20:36:15 a user named fffreedom said ```Is there a directory of all the autogen built agents?```.
In created-with-autogen, at 2023-11-08 19:52:42 a user named antoineross said ```Here's what it looks like.```.
In created-with-autogen, at 2023-11-08 16:55:45 a user named aaronward_ said ```I'm building one right now as coincidence would have it - will share when it's finished. In the meantime, you can check this chainlit x autogen example i made for a simple 2-way agent chat: https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen```.
In created-with-autogen, at 2023-11-08 14:59:26 a user named shaggz2006 said ```@arvel Have you watched the raw requests to see what is going on in your complete context window? (in LM studio you can watch the server logs, other envs may vary)   I found that when I saw exactly what was being sent to the LLM via all the different agent contexts, the response issues I was seeing made more sense.   However, that just "moved" my problem to focusing on getting the agents more locked into their specific roles by finetuning their system messages.   I find that GPT 3.5/4 calls are much better at staying within their agent roles.```.
In created-with-autogen, at 2023-11-08 08:38:36 a user named rainmert said ```Are there any examples with RAG agents and Chainlit UI?```.
In created-with-autogen, at 2023-11-08 04:05:07 a user named antoineross said ```I made an automatic article maker using autogen + chainlit, although it's still young, it's pretty good...on par with most apps out there

Article: https://medium.com/@antoineross/using-autogen-to-automatically-create-articles-c526c15af530

Source code: https://github.com/antoineross/autogen-article-automation

Twitter: https://twitter.com/antoinerossess/status/1722097419595469299```.
In created-with-autogen, at 2023-11-07 12:12:19 a user named andrew0_1 said ```Hey everyone, check out our latest release of agentcloud.dev UI to run Autogen.
https://www.youtube.com/watch?v=Ojw5s8k01Z8

It now supports:
- Groups (manual setup of agents groups letting you customise your team.)
- Streaming
- Realtime Token Counts
- API retry mechanisms for Open AI (to reduce chances of getting stuck on a rate limit)

If you're interested in running it locally checkout our github
https://github.com/rnadigital/agentcloud

We're in the process of wrapping up Alpha testing with select users.
If you want to be part of our closed beta group for the cloud version, let us know, will be sending out invites by the end of the week.
https://www.agentcloud.dev/join-waitlist```.
In created-with-autogen, at 2023-11-07 11:42:02 a user named pranav_codersarts said ```Check this out based on Chainlit - https://github.com/antoineross/Autogen-UI/blob/main/app.py```.
In created-with-autogen, at 2023-11-07 11:38:43 a user named privacydex said ```anyone created an agent for creating online courses yet?```.
In created-with-autogen, at 2023-11-07 09:37:45 a user named samk8834 said ```I am building a streamlit interface that will be used via Posit Connect. All works well to send the initial prompt and initiate chat, but struggling to implement sending a get_human_input …. I know this has been discussed before but can’t find any answers. Anyone managed via streamlit or chainlit?```.
In created-with-autogen, at 2023-11-06 22:47:48 a user named arvelll said ```@shaggz2006 I am working a similar program.  I am using lm minstral 7b. It's begins with good outline and then hallucinating on another level.```.
In created-with-autogen, at 2023-11-06 17:45:10 a user named supermalinge said ```yes it has a gui where you can send tasks to teams and see all tasks in a queue```.
In created-with-autogen, at 2023-11-06 17:01:25 a user named loschess said ```^^ Link to the code from the video series 

https://github.com/disler/multi-agent-postgres-data-analytics/tree/v6-control-flow-and-structured-response```.
In created-with-autogen, at 2023-11-06 16:40:33 a user named sonichi said ```https://youtu.be/XGCWyfA3rgQ?si=Mn-RLUOntZ1_5bd8```.
In created-with-autogen, at 2023-11-06 16:30:28 a user named groundzer000 said ```does it have a GUI ?```.
In created-with-autogen, at 2023-11-06 14:21:46 a user named Anxieties said ```hi, i do have some questions about the Autogen. can some please help me?```.
In created-with-autogen, at 2023-11-05 23:56:23 a user named ultramarkorj said ```Hey guys! We've got an exciting project on our hands that dives deep into Computer Vision (CV), Machine Learning, and Deep Learning to make text detection and recognition in images and videos a smooth reality. We have a challenging first step that involves integrating and customizing some robust libraries, in addition to enhancing the accuracy of text detection. We are on the lookout for partners who are as enthusiastic as we are to explore the depths of AI and be part of this journey. If you're a whiz in CV, Machine Learning, or Deep Learning, and the idea of working on challenges like this excites you, we'd love to connect and discuss more. Let's come together and make magic happen! 🚀```.
In created-with-autogen, at 2023-11-05 21:44:23 a user named sonichi said ```If you'd like people to keep track of it, feel free to post in <#1161015724521836634>```.
In created-with-autogen, at 2023-11-05 21:06:11 a user named supermalinge said ```Hi folks, im the developer of the MasterMindGPT > https://github.com/SuperMalinge/MasterMindGPT

This Autogen project aims for having multiple teams with specialized agents for each field. This will increase the chance of having a succesfull bigger project. Its in early stage but expect alot of updates soon.```.
In created-with-autogen, at 2023-11-05 18:38:02 a user named onecodescholar said ```this video is amazing. his code is not in the same way as one would get it if it was cloned from github. do you know how he set his code up?```.
In created-with-autogen, at 2023-11-05 18:08:53 a user named niko9035 said ```https://medium.com/p/navigating-the-future-with-autogen-intelligent-agents-with-intuitive-capabilities-at-work-844bd8b04454?source=social.linkedin&_nonce=pjCZ314Q&_branch_referrer=H4sIAAAAAAAAA8soKSkottLXz8nMy9bLTU3JLM3VS87P1U%2FPzigvjkjyKnFNAgADQSkCIwAAAA%3D%3D&_branch_match_id=1249774549334709299```.
In created-with-autogen, at 2023-11-04 18:46:15 a user named tonic_1 said ```it's indeed buggy, but that's not a bug i've yet seen 😅 main bug is managing the userproxy with autogen actually . check also to see if you need to edit main.py i case you're using azure or need to put your keys in there?```.
In created-with-autogen, at 2023-11-04 16:03:28 a user named neuralsyn said ```i see you have `semantic-kernel==0.3.14.dev0` already in the requirements.txt.  I installed those in a fresh venv :/```.
In created-with-autogen, at 2023-11-04 15:57:19 a user named tonic_1 said ```seems to me you need to install semantic_kernel```.
In created-with-autogen, at 2023-11-04 15:56:39 a user named neuralsyn said ```I'm trying to get your example to run but it i get 
```
    for ns in {**sk_functions.native_functions, **sk_functions.semantic_functions}:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'FunctionsView' object has no attribute 'native_functions'
```
after installing all of the requirements and running `app.py` .  Have you seen this?```.
In created-with-autogen, at 2023-11-04 15:24:53 a user named loschess said ```This is as far as I got with what I'm building, and got stuck in displaying agents' messages on the frontend.```.
In created-with-autogen, at 2023-11-04 15:23:52 a user named loschess said ```Thank you for creating this UI, I'm trying to use it in my project but don't have GPT-4 API access yet, how can I use the 3.5 model?  Is there a section for us to configure the models?  Is there a way to use a COMMON_LLM_CONFIG?  Sorry for the basic questions, I'm just learning programming and trying to get this up and running.```.
In created-with-autogen, at 2023-11-04 10:11:00 a user named tonic_1 said ```buggzz galore, contribs welcome ^^ almost runs though : https://github.com/Josephrp/LablabAutogen```.
In created-with-autogen, at 2023-11-03 18:33:44 a user named andrew0_1 said ```Try https://x.agentcloud.dev/```.
In created-with-autogen, at 2023-11-03 18:06:42 a user named dead9ixel6903 said ```Hi @biggboii., this video by IndyDevDan really helped me figure out how to control the conversation between agents https://youtu.be/4o8tymMQ5GM?feature=shared```.
In created-with-autogen, at 2023-11-03 17:40:23 a user named shaggz2006 said ```I'm having similar issues.   What models are you using?   I get better results with GPT3.5 and GPT4.0 but the costs are piling up when my team starts spinning out.   I'm currently rotating back and forth between local zephyr-7B (LM Studio) and remote GPT3.5-turbo-16K while I get an understanding of how the agents work together.   My current task is trying to put together a story writing team (author, proofreader, reviewer, planner) and what ends up happening is that every role passes the entire story in as content to the model in each single request.  So, three to four copies of the same story are sent at once, and this rapidly eats up the context window and balloons costs on OpenAI.```.
In created-with-autogen, at 2023-11-03 06:10:15 a user named tonglei said ```what is the home url？```.
In created-with-autogen, at 2023-11-03 02:36:18 a user named flops_flops said ```hi, i couldn't access this google colab```.
In created-with-autogen, at 2023-11-03 02:10:42 a user named flops_flops said ```it would be awesome if you have a youtube about this project```.
In created-with-autogen, at 2023-11-02 23:21:42 a user named andrew0_1 said ```Hey @biggboii. @sonichi we've built out a collaborative exchange specifically for this purpose 
https://agentexchange.xyz 
A forum to post teams and let people discuss and share teams that work well, and those that don't. As an example we've taken some of the current Autogen notebooks and listed them there. 

The idea is when someone posts a new topic they can list
- Task that they are trying to perform
- LLM agent used
- Tokens consumed
- Agent config code

It enables people to comment on the team and let people upvote good ones, down vote bad ones etc.
As you mentioned it would be great to create more collaboration around teams
What are your thoughts?```.
In created-with-autogen, at 2023-11-02 23:01:24 a user named aictofficial_56931 said ```Hey folks! I'm an open-source developer and I've just integrated AutoGen into our project SolidGPT as an AI core❤️‍🔥 . 
Our project is a chat app where LLM understands your codebase and generates every code plan for your requirements based on the codebase. 

Now, we're leveraging AutoGen as our AI core to produce the definitive code plan. Coupled with AutoGen's human input feature, we offer more than just a chat <:manager:1159659358746071041> - it's a planner too. Think of it as Agent + Chat for comprehensive solutions. 

Here is our GitHub: https://github.com/AI-Citizen/SolidGPT

Please try it out and let me know your feedback 🫡```.
In created-with-autogen, at 2023-11-02 22:52:16 a user named natej_86489 said ```Thanks for this!  Got it up and running locally.  Any plans to add open source models?```.
In created-with-autogen, at 2023-11-02 20:14:11 a user named aaronward_ said ```Updated the chainlit autogen app i made before to use a query a postgres database instead of reading in a from a csv path.

Gonna try add some dynamic agent building depending on the complexity of the problem. For example: Show an LLM the task at hand, all the different agent roles available and let it create the team dynamically, and decide whether it should be a two way or group chat (as sometimes i find using a groupchat consistently is overkill for some simple tasks).```.
In created-with-autogen, at 2023-11-02 19:58:21 a user named biggboii. said ```100% especially if it's in notebook format```.
In created-with-autogen, at 2023-11-02 19:40:32 a user named rickyloynd said ```Yes, I think it would provide a lot of value to have a place where anybody can go to find working agent code written by anyone else.```.
In created-with-autogen, at 2023-11-02 19:39:35 a user named biggboii. said ```I'm trying to create a video on real world successful use cases and have a couple done, but many I've tried have simply failed.```.
In created-with-autogen, at 2023-11-02 19:39:01 a user named biggboii. said ```Can you point me to any documentation about how to control the flow of agents? If I have multiple agents, sometimes one agent does something that it shouldn't when it clearly should be another agent taking that task. 

Also, I'm so surprised I can't get my agent to create 100 data points for a fine-tuning dataset. It just gives me 5 examples and then says I need to create the rest myself.```.
In created-with-autogen, at 2023-11-02 19:20:25 a user named sonichi said ```@null what do you think about this proposal? Also, shall we create a roadmap item about discoverability?```.
In created-with-autogen, at 2023-11-02 19:15:15 a user named biggboii. said ```you should create a channel specifically for people to post their working agent definitions```.
In created-with-autogen, at 2023-11-02 19:14:52 a user named biggboii. said ```I've tried creating a simple twitter clone, creating a fine-tuning dataset, etc```.
In created-with-autogen, at 2023-11-02 19:14:31 a user named biggboii. said ```I'm really struggling to get the agents to perform the task I give them.```.
In created-with-autogen, at 2023-11-02 18:38:44 a user named sonichi said ```@bansalg @qingyunwu for your awareness```.
In created-with-autogen, at 2023-11-02 16:55:30 a user named jlopes77 said ```**AutoGen Monitoring and Observability**: 
If you are building with AutoGen we've added Observability support for AutoGen in Arize-Phoenix OSS. A couple lines of code and you get visibility into AutoGen OpenAI calls. 

Arize - Phoenix OSS now supports AutoGen tracing for OpenAI calls

Trace OpenAI Calls
Token tracking
Prompt Template tracking
Tracing of Timing
Prompt and Response Visibility

Quickstart w/ AutoGen Docs:
https://docs.arize.com/phoenix/quickstart/llm-traces/autogen-support```.
In created-with-autogen, at 2023-11-02 05:17:28 a user named andrew0_1 said ```We've implemented streaming support in agentcloud.dev!
Check it out```.
In created-with-autogen, at 2023-11-02 05:08:13 a user named ragyabraham said ```@biggboii. we've actually started a **sort of "exchange" for autogen teams**. It's completely free. Just a way for people to post teams that they have found to work well on a particular problem set. It's very simple for now, just gives you the ability to upload a team and up vote and comment on certain teams/tasks. Hoep it's helpful https://x.agentcloud.dev/c/autogen-teams/5```.
In created-with-autogen, at 2023-11-01 21:56:42 a user named fran.abenza said ```Please raise awareness of the upland is this here:
https://discord.com/channels/1153072414184452236/1168882559657185361```.
In created-with-autogen, at 2023-11-01 20:31:54 a user named biggboii. said ```Does anyone have great examples of AutoGen creating a codebase? I'm trying to get it to create a twitter clone and save the files but it's not doing it.```.
In created-with-autogen, at 2023-10-31 23:03:14 a user named tonic_1 said ```We are building such a function with hangar would love some interaction there with you if you’re considering such a capability 😉```.
In created-with-autogen, at 2023-10-31 22:26:37 a user named mrtonner said ```The YouTuber said he would release it when it's complete.```.
In created-with-autogen, at 2023-10-31 21:32:44 a user named freqee said ```Just been going over it again and not able to make sense of it. Would be great to have the orchestrator code. Do you think it's something you coudl help me understand?```.
In created-with-autogen, at 2023-10-31 16:10:50 a user named shaneyu said ```Great to hear that, can't wait to try it out!```.
In created-with-autogen, at 2023-10-31 16:08:30 a user named sonichi said ```Update about streaming: This PR has been made: https://github.com/microsoft/autogen/pull/491```.
In created-with-autogen, at 2023-10-31 14:45:36 a user named antoineross said ```Hi everyone! I recommend everyone to send a PR to this for improvements and features. The code is compelely in Python. Thanks!

https://github.com/antoineross/Autogen-UI```.
In created-with-autogen, at 2023-10-31 14:34:01 a user named freqee said ```Sweet, I'll take another look.```.
In created-with-autogen, at 2023-10-31 14:26:14 a user named mrtonner said ```13:00 he's in the code explaination```.
In created-with-autogen, at 2023-10-31 14:24:58 a user named freqee said ```Thanks, I took a look at this already and the particular section on broadcast conversation but couldn't make sense of how he achieved it. No code provided and I didn't recognise the code as python. Any ideas?```.
In created-with-autogen, at 2023-10-31 14:23:59 a user named mrtonner said ```https://youtu.be/4o8tymMQ5GM?si=pXcCP_Dch-LbZUqg

11:20~```.
In created-with-autogen, at 2023-10-31 13:32:21 a user named freqee said ```Do you know how the broadcasting conversation setup can be achieved with python alone?```.
In created-with-autogen, at 2023-10-31 10:19:52 a user named antoineross said ```Made a groupchat implementaiton of AutoGen on chainlit:

Medium Article for a User Interface (UI) for Autogen. Made a basic web-application using autogen research that uses chainlit:

https://medium.com/@antoineross/autogen-web-application-using-chainlit-8c5ebf5a4e75

Github:

https://github.com/antoineross/Autogen-UI```.
In created-with-autogen, at 2023-10-31 00:33:55 a user named qingyunwu said ```That's a good idea. @sonichi  has an algorithm of the similar spirit in this work: https://arxiv.org/pdf/2310.03046.pdf```.
In created-with-autogen, at 2023-10-30 23:21:44 a user named _deadbody said ```I was thinking for other purposes but connecting directly is an option . I was thinking with a router , if my local llm is having difficulty or becoming repetitive that it can auto switch to 3.5 or 4 for those issues```.
In created-with-autogen, at 2023-10-30 22:21:08 a user named tradingindian said ```Perhaps this >> https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/```.
In created-with-autogen, at 2023-10-30 22:19:17 a user named tradingindian said ```This is great. Just to give you an extra fill up, I am currently deploying a router agent with GPT ranking backbone. So the agent routes requests to OSS models (I don't want to promote any but there are tons of good quality pay per use inference points available). Then GPT4 ranks the response and agent captures it. Then any new request is cosine matched and routes to that cheaper inference points. HF carries even higher weight so any feedback from me or user will add extra points to scoring. So far this has been phenomenal. Currently implementing task categories to further fine tune this. Will release a fully working agent once ready```.
In created-with-autogen, at 2023-10-30 18:29:03 a user named ctrl_alt.defeat said ```dynamically switches between 3.5 and 4 based on? what are some specific use cases for this?```.
In created-with-autogen, at 2023-10-30 03:03:10 a user named _deadbody said ```is there a way to have it route to local models```.
In created-with-autogen, at 2023-10-29 23:53:48 a user named groundzer000 said ```i keep getting "agentcloud-webapp_next-1 | useJWT token: undefined" even after pull the last update.
also as you exposed the OAI file im trying to use LM Studio with other models, but it happens that if i disable the - OPENAI_API_KEY=changeme from the docker compose in way to use only the OAI the app does nothing.
how can i use only the OAI ?```.
In created-with-autogen, at 2023-10-29 19:29:26 a user named niko9035 said ```Over the weekend, I have implemented a mechanism for article writing with article writer agent, fact checker and SEO optimizer: https://niko-gamulin.medium.com/the-autonomous-orchestra-of-ai-with-autogen-beyond-solo-performances-3be1a0553e8b```.
In created-with-autogen, at 2023-10-29 00:08:03 a user named m0bsta said ```at least it's not somewhat useful 😂```.
In created-with-autogen, at 2023-10-29 00:02:27 a user named m0bsta said ```almost ... i got this fr you on accident @jb i accidently made this knowledge chat for autogen not what i was trying to do but it's all good https://dashboard.eesel.ai/public-chat?namespace=e2c1813e-f5bb-4a19-81dc-b65b9396c5c5&palette=%7B%22primary%22%3A%22%238c21e4%22%2C%22secondary%22%3A%22%23F3F4F6%22%7D&title=autogen%20Knowledge%20%E2%80%A2%20by%20Mobsta%E2%84%9E%20%40mobstarx.com&customError=Sorry%2C%20I%27m%20unable%20to%20answer%20that.%20Try%20rephrasing%20your%20question%20or%20reach%20out%20to%20support.&welcomeMessage=%F0%9F%91%8B%20Hi!%20How%20can%20I%20help%20you%20today%3F&suggestQuestion=true```.
In created-with-autogen, at 2023-10-28 17:18:44 a user named telepathyx said ```Has anyone managed to create any apps with autogen?```.
In created-with-autogen, at 2023-10-28 17:04:40 a user named jb_5579 said ```I appreciate the response, but searching for documentation on agentcloud.dev is what led me to this discord channel.  Is there any additional documentation that is more specific?```.
In created-with-autogen, at 2023-10-27 23:09:15 a user named jb_5579 said ```Is there a way to configure the docker-compose.yml for open source models (either local or hosted on RunPod)```.
In created-with-autogen, at 2023-10-27 22:42:25 a user named fffreedom said ```Love Autogen! 

Meanwhile, during agent development and deployment the cost became a major blocker for us. Saw that many other devs are facing the same problem and decided to solve it for the Autogen community. 

We developed an LLM router which dynamically switches between GPT-3.5 and GPT-4. It's in alpha and we are currently providing it for free. All feedback is appreciated 🙂

Readme: https://github.com/opencopilotdev/llm-router```.
In created-with-autogen, at 2023-10-27 21:11:01 a user named sonichi said ```Sharing from another channel for the record: https://discord.com/channels/1153072414184452236/1153072414184452241/1167047069442265088```.
In created-with-autogen, at 2023-10-27 16:12:37 a user named ctrl_alt.defeat said ```this is so cool! @ragyabraham is there a UX workflow document i can read through to understand this better?```.
In created-with-autogen, at 2023-10-27 13:42:14 a user named rickyloynd said ```https://microsoft.github.io/autogen/blog/2023/10/26/TeachableAgent```.
In created-with-autogen, at 2023-10-27 05:52:40 a user named ragyabraham said ```yes that was an issue that was fixed this morning. If you pull the latest code tha should be fixed```.
In created-with-autogen, at 2023-10-27 05:48:30 a user named groundzer000 said ```any idea why im always getting "agentcloud-webapp_next-1 | useJWT token: undefined" ?```.
In created-with-autogen, at 2023-10-27 05:28:19 a user named .princeps said ```Ran into an issue but will have something working soo```.
In created-with-autogen, at 2023-10-27 02:11:33 a user named telepathyx said ```How did that turn out?```.
In created-with-autogen, at 2023-10-26 09:18:29 a user named ragyabraham said ```Working on an open source  GUI for autogen```.
In created-with-autogen, at 2023-10-26 09:17:58 a user named ragyabraham said ```https://www.agentcloud.dev/```.
In created-with-autogen, at 2023-10-25 23:05:53 a user named JoJo said ```Thanks for this, ill read through it tomorrow in more detail!```.
In created-with-autogen, at 2023-10-25 21:59:48 a user named qingyunwu said ```Check this msg as well: https://discord.com/channels/1153072414184452236/1153072414184452241/1166842738017304688 Do you think this integration will be useful in your case?```.
In created-with-autogen, at 2023-10-25 21:59:15 a user named JoJo said ```But it was definetly helpful as a general bit of info```.
In created-with-autogen, at 2023-10-25 21:58:14 a user named JoJo said ```I have seen this. It's just sql querying with function calling atm 😄```.
In created-with-autogen, at 2023-10-25 21:57:45 a user named qingyunwu said ```Right, and this one: CONTROL your LLM agents for ACCURATE Postgres AI Data Analytics https://www.youtube.com/watch?v=4o8tymMQ5GM```.
In created-with-autogen, at 2023-10-25 21:57:17 a user named .jkyh said ```I think @sonichi previously shared this
https://www.youtube.com/watch?v=JjVvYDPVrAQ&t=692s```.
In created-with-autogen, at 2023-10-24 22:37:32 a user named JoJo said ```Hey guys, has anyone worked on data analysis with autogen```.
In created-with-autogen, at 2023-10-24 19:41:36 a user named mooblegum said ```Yes I will do that. I often forget that GPT can do almost everything today```.
In created-with-autogen, at 2023-10-24 16:43:48 a user named bobaleaux said ```I know this is an over simplification method to try to give you an overview. Copy the transcription from the YT and paste  it into ChatGPt and ask it to explain its use case to a person with no developer background```.
In created-with-autogen, at 2023-10-24 15:44:28 a user named mooblegum said ```His videos are really great and in depth, but for this one, as a total noob programmer I fail to understand anything about what is an imbedding, what he was doing, what for it is useful (I am sure it is). I would love to have a simple explanation of what he is doing with this embedding workflow.```.
In created-with-autogen, at 2023-10-24 03:13:55 a user named akrabulislam said ```Just watched it, its a really great video```.
In created-with-autogen, at 2023-10-23 19:06:00 a user named frank.martinez said ```He brings some much value to the community; wow!```.
In created-with-autogen, at 2023-10-23 18:12:24 a user named sonichi said ```https://youtu.be/CKo-czvxFkY?si=tXBAFvDeSf71yC5a```.
In created-with-autogen, at 2023-10-23 00:30:05 a user named sonichi said ```https://youtu.be/gKNR1ghU1Ao?si=PySMy21WXBIc9kIR```.
In created-with-autogen, at 2023-10-22 06:23:41 a user named .princeps said ```I'm cooking something for you```.
In created-with-autogen, at 2023-10-21 18:58:57 a user named sidhujag said ```isnt ability to self heal just a function of observation and perhaps a good memory management system?```.
In created-with-autogen, at 2023-10-21 18:06:44 a user named telepathyx said ```I think it will exclusively "solve creative" things but lack the ability to operate as reliable infrastructure. due to its inability to self-correct.```.
In created-with-autogen, at 2023-10-21 17:03:51 a user named sidhujag said ```as is it wont solve anything creative yet.. the idea is to think of it as infrastructure```.
In created-with-autogen, at 2023-10-21 15:37:35 a user named wayliu said ```Kniru - Tireless AI-powered financial ad...```.
In created-with-autogen, at 2023-10-21 15:18:27 a user named pradeep1148 said ```intersting let me check it out```.
In created-with-autogen, at 2023-10-21 15:13:18 a user named telepathyx said ```Has anyone used autogen to create an app of any complexity, such as anthing bigger than a snake game? Is it still in the same state limited by context window and memory management? Or has anyone used autogen to enhance reasoning? Any use cases beyond a simulation/novelty yet?```.
In created-with-autogen, at 2023-10-21 07:39:49 a user named syedmujeeb said ```Hi 
Does autogen supports bedrock```.
In created-with-autogen, at 2023-10-20 17:06:33 a user named shaneyu said ```That's the correct way to do it. Works like a charm```.
In created-with-autogen, at 2023-10-20 16:01:07 a user named pradeep1148 said ```https://www.youtube.com/watch?v=huIv541bKpw&ab_channel=DLExplorers```.
In created-with-autogen, at 2023-10-19 23:23:03 a user named shaneyu said ```I’ll take a look, thanks!👏```.
In created-with-autogen, at 2023-10-19 23:19:09 a user named sonichi said ```How about closing it after the top-level `initiate_chat`?```.
In created-with-autogen, at 2023-10-19 21:13:50 a user named shaneyu said ```It should be one connection object for one conversation, if the conversation ends the connection object should be killed```.
In created-with-autogen, at 2023-10-19 21:11:45 a user named sonichi said ```Does every agent have a socket connection? Or is there one connection for all?```.
In created-with-autogen, at 2023-10-19 20:33:30 a user named shaneyu said ```Hi @sonichi, last week I was talking about using websocket to establish a connection to the frontend GUI, I did some modification to the conversable_agent this week and now it works as expected, however, I am not sure on where to kill the socket connection. 
It should be killed when the entire conversation is over, not just one participating agent finished its job, and I think this is to be done on the conversable_agent level. Right now I think it goes down to receive function: 
```        if reply is not None:
            self.send(reply, sender, silent=silent)
        else:
            # kill socket connection object
``` 
But I'm afraid this will close the connection when a certain agent completed its task, not the entire conversation is over. Would you mind providing some insights here? Much appreciated!🫡```.
In created-with-autogen, at 2023-10-19 18:47:50 a user named aayushc1308 said ```P.S. Our current plan is to not reveal the internal orchestration of agents to the end user. The experience will always feel like a single agent. Only the internals is where multi agent magic happens.

Let me know if I can clarify anything further.```.
In created-with-autogen, at 2023-10-19 18:45:39 a user named aayushc1308 said ```@wayliu 
It's a group chat system. The group chat manager acts as an agent and mimics the single agent experience because the end user shouldn't have to care about internal use of agents. It then internally manages a bunch of agents. 
The max rounds are also dynamic such that the group chat manager can terminate the interaction at any time when it is satisfied. We extended the group chat manager and group chat classes and created a significant amount of custom Kniru specific logic to support this.
The current release actually can be achieved from single agent also in terms of quality. However, our release coming on Sunday will take the number of agents to approx 7 or 8. That is when the quality of results just blew our minds. We are working on testing these in a bunch of scenarios before releasing it.
We had a previous architecture with Langchain but when we created domain specific agents using Autogen and combined it with some Langchain tools, the hallucinations got removed by almost like self correction.
We should be able to discuss in more detail after Sunday release once we have also figured out the final details.```.
In created-with-autogen, at 2023-10-19 18:07:27 a user named wayliu said ```This is nice! @aayushc1308 one question, how do you guys leverage AutoGen? Looks like it's more of the traditional single agent?```.
In created-with-autogen, at 2023-10-19 16:54:53 a user named aayushc1308 said ```Oh awesome, didn't know about that channel. We will work on creating and adding any relevant tutorials to the channel!```.
In created-with-autogen, at 2023-10-19 16:43:33 a user named sonichi said ```Thanks for sharing. Also feel free to post on <#1161015724521836634>```.
In created-with-autogen, at 2023-10-19 16:39:03 a user named aayushc1308 said ```Hey everyone, Join Us at the Kniru Launch Party! 🚀
Kniru has officially gone live on Product Hunt (https://www.producthunt.com/posts/kniru) this morning! I'm especially proud to mention that **Autogen** stands as one of the core technologies powering our AI pipeline. We have launched a vanilla version of the Kniru Chat and will be releasing increasingly sophisticated Autogen-based architectures (custom Agents, custom Group chats, etc) with the first major update going out on Sunday. Our internal tests have completely blown our minds and we plan to slowly roll these out in a controlled and meticulously tested manner. We would love to invite you all to join us and give us feedback as we very quickly iterate with various architectures in production over the next weeks. I will keep you all posted as we switch between various architectures so you can test things out yourself. We will keep sharing all our Autogen lessons on how to productionize things and will keep implementing relevant changes back to Autogen package based on the feedback you all share.
**Also, if any of you are planning to roll out Autogen in production, feel free to get in touch with us. We would be more than happy to help in every possible way and share our lessons.**```.
In created-with-autogen, at 2023-10-21 15:37:36 a user named wayliu said ```@aayushc1308  thanks for elaboration. Wouldn't that cost too muh time though? Adding so many agents? I mean user would need to wait for at least a min to see results?```.
In created-with-autogen, at 2023-10-21 15:39:29 a user named telepathyx said ```https://arxiv.org/abs/2310.01798 

what are you doing to address this?```.
In created-with-autogen, at 2023-10-21 15:40:34 a user named telepathyx said ```"Transitioning to another facet of self-correction, we investigate the potential of
multi-agent debate (Du et al., 2023; Liang et al., 2023) as a means to improve reasoning. In this
method, multiple instances of an LLM critique each other’s responses. However, our results reveal
that its efficacy is no better than self-consistency (Wang et al., 2022) when considering an equivalent
number of responses, highlighting the limitations of such an approach."```.
In created-with-autogen, at 2023-10-21 15:40:54 a user named telepathyx said ```are you sure it's responsible to let people think they're getting good financial advice from autogen?```.
In created-with-autogen, at 2023-10-21 15:43:25 a user named telepathyx said ```correct -> incorrect happens more often than incorrect -> correct```.
In created-with-autogen, at 2023-10-21 15:50:25 a user named telepathyx said ```it's a thermodynamic process. the further way you get from external feedback, the further it drifts into a hypothetical probability space that is increasingly disconnected from reality```.
In created-with-autogen, at 2023-10-21 15:52:55 a user named telepathyx said ```feedback is like qualia to an LLM. without that words don't actually map to any meaning```.
In created-with-autogen, at 2023-10-21 15:53:20 a user named telepathyx said ```it's all self referencing definitions```.
In created-with-autogen, at 2023-10-21 15:53:46 a user named telepathyx said ```language is full of circular logic that can't encapsulate a worldview```.
In created-with-autogen, at 2023-10-21 18:05:41 a user named aayushc1308 said ```We pass around the websocket and keep the user informed what is happening. So the user always has some visibility. Also, not all agents get to speak for every question. Most questions get terminated after one or two agents have spoken. We have built some intelligence around this on how that happens but that is Kniru specific logic. But I am not seeing things take more than a min though in our tests. Still too early to speak with certainty since we are changing things every other hour.```.
In created-with-autogen, at 2023-10-21 18:09:06 a user named aayushc1308 said ```We actually don't use autogen for advice (except the current version in prod which is super vanilla). We have created hundreds of internal tools that actually drive the intelligence aspect of this. Autogen more of less helps in terms of semantic parsing, summarizing, and some other functions like generic personal finance advice and definitions from content out there. The actual math and intelligence is driven by large amounts of Kniru's internal intelligence. The correct way to think about this would be a hedge fund level intelligence library being controlled by Agents.```.
In created-with-autogen, at 2023-10-21 18:10:47 a user named aayushc1308 said ```And, we are being very explicit in the product to let people know that we are super early and things are evolving. 
The goal is to achieve very very high accuracy (say 99%) in a few months.```.
In created-with-autogen, at 2023-10-21 18:11:22 a user named aayushc1308 said ```Btw: Just building a wrapper around autogen performs horribly for finance. We **ARE NOT** doing that.```.
In created-with-autogen, at 2023-10-21 18:12:17 a user named telepathyx said ```okay, so it's not exactly giving "precise, personalized, actionable insights and answers all your financial questions" - that makes sense now```.
In created-with-autogen, at 2023-10-21 18:13:13 a user named telepathyx said ```i assume if you ask "should i invest in meta" it will explain the efficient market hypothesis right?```.
In created-with-autogen, at 2023-10-21 18:13:35 a user named aayushc1308 said ```It does give personalized advice. Not sure I follow your inference. The tools are powered by your data. So it is personal.```.
In created-with-autogen, at 2023-10-21 18:14:33 a user named telepathyx said ```it will explain that eugene fama won the nobel prize for proving beating the market is impossible? that price variation around risk-adjusted margin return is random?```.
In created-with-autogen, at 2023-10-21 18:15:43 a user named aayushc1308 said ```"should i invest in meta"  --> fetch your current portfolio --> build utility function using your transactions --> fetch data about meta --> fetch current market news --> run quantitative intelligence (proprietary) --> Share advice.```.
In created-with-autogen, at 2023-10-21 18:15:53 a user named aayushc1308 said ```That is roughly the flow that Kniru will enter.```.
In created-with-autogen, at 2023-10-21 18:16:14 a user named telepathyx said ```ah okay hahah... i have a background in quant trading so i apologize for calling you out```.
In created-with-autogen, at 2023-10-21 18:16:37 a user named telepathyx said ```i don't really agree with your ethics but it's not unlawful```.
In created-with-autogen, at 2023-10-21 18:17:04 a user named aayushc1308 said ```So do I. Worked at Citadel 🙂```.
In created-with-autogen, at 2023-10-21 18:17:41 a user named aayushc1308 said ```I'm not sure what ethics we are violating.```.
In created-with-autogen, at 2023-10-21 18:17:59 a user named telepathyx said ```giving the impression that "quantitative intelligence" is better than a random decision```.
In created-with-autogen, at 2023-10-21 18:18:14 a user named telepathyx said ```there's no evidence for that```.
In created-with-autogen, at 2023-10-21 18:18:31 a user named telepathyx said ```but i'm not here to be a moral lecturer```.
In created-with-autogen, at 2023-10-21 18:18:57 a user named aayushc1308 said ```Oh, I mean that is just an opinion. In that case, all of wall street is stupid. Agree to disagree.```.
In created-with-autogen, at 2023-10-21 18:19:32 a user named telepathyx said ```Yeah, why has the mutual fund instury failed to do its job? It's just marketing. Weak form EMH explains it```.
In created-with-autogen, at 2023-10-21 18:19:42 a user named telepathyx said ```there's some room for FA but TA is garbage```.
In created-with-autogen, at 2023-10-21 18:21:39 a user named aayushc1308 said ```Yea, I respect your point of view. I do think that with 34% financial literacy in North America and much less in other places, Kniru can significantly help people. Even just bridging the gap from helping people to move from being non investors to being disciplined investors, helping them on taxes, retirement planning, etc.```.
In created-with-autogen, at 2023-10-21 18:22:08 a user named telepathyx said ```I'd love to see it embody eugene fama lol if it's telling everyone to invest in VT or index funds that's fine```.
In created-with-autogen, at 2023-10-21 18:22:52 a user named aayushc1308 said ```I guess we'll find out!```.
In created-with-autogen, at 2023-10-18 03:44:26 a user named http403 said ```Hello!
I'm trying to add the ability to register a function in the middle of a conversation. I am calling register_function, but I think I also need to modify the llm_config, which doesn't seem to take effect.
Here's a Jupiter notebook showing it in action. The answer to "What functions do you know about, now?" should include "say_hello".
https://github.com/elecnix/autogen-db/blob/master/define_function.ipynb```.
In created-with-autogen, at 2023-10-27 02:09:14 a user named fran.abenza said ```did you get deeper with this?```.
In created-with-autogen, at 2023-10-16 14:33:39 a user named lperezdude said ```I see thank you for your response 🙏🏽```.
In created-with-autogen, at 2023-10-16 10:44:59 a user named artholos said ```I'm just an armature though, so don't live or die by my advise hehe```.
In created-with-autogen, at 2023-10-16 10:44:31 a user named artholos said ```But generally, as it appears to me, that it's a great way to handle things locally on just your pc/network. You can validate your program all offline easily that way, and then when you deploy for a wider internet release, you can find a server solution without affecting the rest of your program```.
In created-with-autogen, at 2023-10-16 10:43:09 a user named artholos said ```I don't know if it can run headless, say on a server deployment. But you can open it up to allow for remote connection and access. So if you open it up and point your application at the server route, you should be able to use it from anywhere on the internet```.
In created-with-autogen, at 2023-10-16 10:41:50 a user named lperezdude said ```is LM Studio only ment for local development? im looking to put autogen on a server and access a group chat via http/websockets i could even use firebase for the data but how do i take a individual and send invidiual message to the group chat?```.
In created-with-autogen, at 2023-10-16 10:38:54 a user named lperezdude said ```awesome thank you i will look into LM Studio for this use case 🫡```.
In created-with-autogen, at 2023-10-16 10:37:55 a user named artholos said ```LM Studio is simple and easy to set up for your own pc```.
In created-with-autogen, at 2023-10-16 10:37:18 a user named lperezdude said ```Hello Everyone 🤙🏼 im looking to create a chat app and i want a autogen chat group to be part of the conversion, how would i go about running this from cli locally to  a websocket on a server type deal and able to access a conversation via REST? is autogen made for this use case or do i have to do anything else to make that work ?```.
In created-with-autogen, at 2023-10-16 09:52:39 a user named aaronward_ said ```I added a total session cost counter to the UI using the autogen logs```.
In created-with-autogen, at 2023-10-16 06:48:24 a user named bansalg said ```thanks will do after i add a few more UI```.
In created-with-autogen, at 2023-10-16 06:42:57 a user named bansalg said ```advertised in tutorials and examples forum.```.
In created-with-autogen, at 2023-10-15 21:22:51 a user named kbve said ```I am down to fumble around as well xD```.
In created-with-autogen, at 2023-10-15 20:25:55 a user named telepathyx said ```has anyone been able to build a semi-complex app with autogen?```.
In created-with-autogen, at 2023-10-15 16:50:49 a user named jb_5579 said ```That is awesome news Ivan!  I am excited to see what you've built.```.
In created-with-autogen, at 2023-10-15 16:42:18 a user named jb_5579 said ```has anyone been able to use Pedels to run the Autogen on a dist LLM?  Or is there a efficient way to run a RunPod GPU environment that turn on (and bills time)  only when it is engaged by Autogen and then shuts down. I understand project data persistence is likely one of the items to solve for.  Is there a method for serving back the previous project  seed to a RunPod image and begin again where you left off?  Newbie here fumbling around in the dark... 🙂```.
In created-with-autogen, at 2023-10-15 13:30:57 a user named kajatta said ```Not what you're asking but how cool is this https://github.com/PWhiddy/PokemonRedExperiments

You could probably modify the game execution code to set it up.```.
In created-with-autogen, at 2023-10-15 11:59:44 a user named quackduck. said ```oh cool, very nice man```.
In created-with-autogen, at 2023-10-15 11:46:38 a user named ivangabriele said ```I'm starting to feel excited about what I'll be able to achieve now 🙂 .```.
In created-with-autogen, at 2023-10-15 11:45:50 a user named ivangabriele said ```As I explained in <#1158548894209282078>, I finally found a way to use open-source LLMs to work with Function Calling so that's a game changer for my [OADS project](https://github.com/ivangabriele/openai-autogen-dev-studio). I will integrate my solution in the coming days and come back to keep you in touch with my progress.```.
In created-with-autogen, at 2023-10-15 11:42:46 a user named ivangabriele said ```I do agree that they need to find a way to reduce costs. We'll see if the big OpenAI update will really slash prices by a factor of 20 as the rumors tell. However it would be useless in heavy autogen apps since if don't unthrottle by a lot. If that's true, it could have a positive cascading effect on Azure pricing. And I'm obviously talking about GPT 4 with at least 16k context. GPT 3.5 is way too "dumb" for serious projects, even with fancy multi-agents strategies.```.
In created-with-autogen, at 2023-10-14 18:43:27 a user named aaronward_ said ```thanks! will do after i add a few more UI features```.
In created-with-autogen, at 2023-10-16 06:48:25 a user named bansalg said ```@aaronward_ I added this to tutorials and examples :/ Have you tweeted about this example yet? Would love feature this on pyautogen twitter if you feel okay about it 🙂```.
In created-with-autogen, at 2023-10-16 09:51:44 a user named aaronward_ said ```@bansalg i haven't no, i will do after a few updates 🙂```.
In created-with-autogen, at 2023-10-16 16:45:00 a user named bansalg said ```Please tag pyautogen when you do— so that I can get notification. I tweeted a basic version.```.
In created-with-autogen, at 2023-10-17 18:22:24 a user named bansalg said ```Can you share link? I dont see a tag```.
In created-with-autogen, at 2023-10-14 18:02:08 a user named sonichi said ```Very cool 🙂 Worth submitting to <#1161015724521836634>```.
In created-with-autogen, at 2023-10-14 17:05:31 a user named berkeley said ```hey everyone. is there a best example of a team that develops arbitrary software that i can fork?```.
In created-with-autogen, at 2023-10-14 15:48:03 a user named aaronward_ said ```Link to the code if you're interested - will be updating the UI to separate agent conversation from the final response: https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen```.
In created-with-autogen, at 2023-10-14 15:26:46 a user named aaronward_ said ```chainlit is really nice to use with autogen, streamlit was a dead end for me as you need to run separate processes to allow for code execution with the user proxy. Anyways, he's a data analysis interface for a small synthetic dataset```.
In created-with-autogen, at 2023-10-14 01:05:13 a user named sonichi said ```https://www.youtube.com/watch?v=JjVvYDPVrAQ```.
In created-with-autogen, at 2023-10-13 12:42:10 a user named nexorsist said ```Adding to this, depending on your use case you might swap out the OpenAI model for something like a mistral model that is way cheaper to run if your agents are performing really basic repetitive single tasked instructions in a chain. Not everything needs a GPT-4 model to run```.
In created-with-autogen, at 2023-10-13 12:41:16 a user named nexorsist said ```Rather think of it in terms of you will chain together single or dual tasked agents together to be able to accomplish certain types of functions. You will call on the different groups of chains depending on what you need to get done. Likely IRL you would need the same equivalant of people getting together to accomplish the same task. If the chain of agents performs it in eg. 5 minutes at a cost of $100 (on a production heavy duty model), and the same chain of people IRL would do it in 1 hour but at the cost of $600 for their combined time, then the cost is clear.

Using Autogen to do end-to-end coding tasks is going to be expensive either way because you need a much larger chain of agents that have less restrictions on them (they're not just performing a robotic task). But again if you can fiddle enough to get it to work properly then paying $10,000 for it to spit out an extremely high quality app with everything in place in an hour or two will most definitely work out a lot cheaper than using actual engineers to do everything from scratch

It seems incredibly expensive now because we are all testing out things and those tests are costly because they are not necessarily translating to any value aside from learning. 

That being said it seems there will be a developer type mode coming to OpenAI which will significantly reduce the cost on the API for developers, probably exactly for this reason```.
In created-with-autogen, at 2023-10-13 10:28:53 a user named warmonger9626 said ```It all comes down to question how much would you have to pay someone to do the same job. Plus, the value of saved time.```.
In created-with-autogen, at 2023-10-13 08:52:26 a user named quackduck. said ```I think that speaks for everyone, students, researchers, companies. It's costly for all```.
In created-with-autogen, at 2023-10-13 08:51:54 a user named quackduck. said ```Hopefully things change soon cos autogen must be destroying some ppl on billing. It is unsustainable for sure```.
In created-with-autogen, at 2023-10-13 04:10:58 a user named li_jiang said ```https://huggingface.co/spaces/thinkall/autogen-demos

A demo of Autogen Retrieve Chat```.
In created-with-autogen, at 2023-10-13 03:50:12 a user named noahnochill said ```Is there any pinned post with actual instances of projects created with autogen?```.
In created-with-autogen, at 2023-10-12 21:40:30 a user named sonichi said ```I don't know anyone working on it right now. But I can create a roadmap for it.```.
In created-with-autogen, at 2023-10-12 21:38:48 a user named shaneyu said ```Also, are we planning to have stream in the near future?```.
In created-with-autogen, at 2023-10-12 21:36:03 a user named shaneyu said ```Yeah I’m working on it```.
In created-with-autogen, at 2023-10-12 21:33:25 a user named sonichi said ```Can you override `ConversableAgent.get_human_input` method?```.
In created-with-autogen, at 2023-10-12 21:09:25 a user named ivangabriele said ```Indeed I use my (self-owned) company's for Azure. I guess you have a better pricing and maybe some credits to use it as a student, but indeed when you have to pay the regular price, it's really expensive. You can easily reach $1000 or even $2000 in just one hour. Which at least for me is unsustainable :X.```.
In created-with-autogen, at 2023-10-12 20:54:23 a user named shaneyu said ```since autogen doesnt support stream, im thinking of using websocket as a workaround?```.
In created-with-autogen, at 2023-10-12 20:37:59 a user named shaneyu said ```It's still in a processing state on backend even if human input is required, so the frontend wont be notified, and even if I can think of a FLAG to notify the front end, I don't know WHERE to feed the human message to the backend in the middle of a conversation.```.
In created-with-autogen, at 2023-10-12 20:17:48 a user named shaneyu said ```Is there a way to stably stream messages to frontend with human input mode to ALWAYS? I think I know how to handle input mode to NEVER but I cannot think of a way to handle ALWAYS (human intervention in between).```.
In created-with-autogen, at 2023-10-12 14:40:17 a user named leonardooliva said ```well, I'm not a student xD```.
In created-with-autogen, at 2023-10-12 14:39:47 a user named leonardooliva said ```but it costs the same as OpenAI API```.
In created-with-autogen, at 2023-10-12 11:06:58 a user named quackduck. said ```super.cool. just a shame openai azure isn't public access ATM```.
In created-with-autogen, at 2023-10-11 17:46:31 a user named bansalg said ```I kicked him several times now But he```.
In created-with-autogen, at 2023-10-11 10:18:27 a user named li_jiang said ```@sonichi We need your help to ban the bots.```.
In created-with-autogen, at 2023-10-11 10:18:11 a user named li_jiang said ```I kicked him several times now. But he keeps joining.```.
In created-with-autogen, at 2023-10-11 17:46:32 a user named bansalg said ```Was this taken care of?```.
In created-with-autogen, at 2023-10-12 01:55:15 a user named li_jiang said ```I don't know. @sonichi , have you banned the bot?```.
In created-with-autogen, at nan a user named sonichi said ```I don't see it now```.
In created-with-autogen, at 2023-10-12 04:18:11 a user named li_jiang said ```Maybe it was banned by discord, I also reported it to discord.```.
In created-with-autogen, at 2023-10-12 13:35:09 a user named li_jiang said ```every channel. I manually deleted all of them```.
In created-with-autogen, at 2023-10-12 16:46:26 a user named bansalg said ```yes I had banned him```.
In created-with-autogen, at 2023-10-11 10:17:07 a user named 330f_ said ```ok just kick him then, u dont have permission to ban🤷‍♂️```.
In created-with-autogen, at 2023-10-11 10:16:41 a user named 330f_ said ```right click on his profile and it shows this menu -```.
In created-with-autogen, at 2023-10-11 10:15:46 a user named 330f_ said ```@li_jiang actually u have to ban him there should be a button called ban when u click on profile, after ban all the messages will be automatically deleted and the user is kick automatically```.
In created-with-autogen, at 2023-10-11 00:43:02 a user named ilaffey said ```thank you! so fulfilling to hear you like it and your mom enjoyed it :). if you’re interested in contributing i will follow up when i open source !```.
In created-with-autogen, at 2023-10-10 23:18:00 a user named fxtoofaan said ```You are right. Local llms don’t support functions so have to do something in code without asking llm to process the function. I was thinking about that the other day how devs can fix this. Let us know what you figure out 🙂```.
In created-with-autogen, at 2023-10-10 22:49:30 a user named karlka said ```I give a few updates about my OpenAI```.
In created-with-autogen, at 2023-10-10 22:26:11 a user named elshep said ```This is super cool. I showed my mom and she hit me with the WAAAOWWWW```.
In created-with-autogen, at 2023-10-10 17:45:31 a user named ilaffey said ```thank you 🙏- it’s honestly not too complicated! i’m excited to share```.
In created-with-autogen, at 2023-10-10 17:22:36 a user named securemeup said ```This is amazing! sooo coool! I can't wait to play with this once you opensource it! @ilaffey```.
In created-with-autogen, at 2023-10-10 09:08:14 a user named ilaffey said ```This is an integration of Autogen into a Web-App for an Immersive world with book characters interacting from a specific point in time in the book.

Each character has their own personality / set of motivations and acts independently, interacts with each other + the user (y'all know the drill)```.
In created-with-autogen, at 2023-10-10 09:06:25 a user named ilaffey said ```https://twitter.com/ilaffey2/status/1711669344760148459

first version! will open source + polish this a lot in the next few days!```.
In created-with-autogen, at 2023-10-10 08:53:34 a user named tonic_1 said ```Thank you for letting me know 🙏🏻```.
In created-with-autogen, at 2023-10-10 07:10:27 a user named burnydelic said ```your discord invite link is expired```.
In created-with-autogen, at 2023-10-10 01:02:21 a user named brad_10154 said ```Nice! What is OADS ?```.
In created-with-autogen, at 2023-10-09 21:03:10 a user named ivangabriele said ```It would really be slower but still a lot less expensive```.
In created-with-autogen, at 2023-10-09 21:02:52 a user named ivangabriele said ```That's why now I'm trying to find a way to use functions with an opensource LLMs because it would cost one or a few dollars per minute if you deploy it yourself VS around $1,000 per hour on Azure (maybe even more).```.
In created-with-autogen, at 2023-10-09 21:00:39 a user named ivangabriele said ```I have been able to get a lot further with OADS: I asked it to design a multiplayer version of Simcity 2000 (in terms of GDD, Game Design Document), and to write the API in Node.js (I mean really creating the files and running the code). It was going on very well but I had to stop it when I realized it was consuming about 3 millions tokens per 5 minutes. Using GTP4-32k on Azure, this is expensive. I think I would have had to spend a few thousands in order to let it finish it.```.
In created-with-autogen, at 2023-10-09 19:54:41 a user named clintboyett said ```I've also been wondering. It seems like most of the projects I see it generate are ones that are very iconic classic and probably have a lot of training data like snake or pong or tictactoe```.
In created-with-autogen, at 2023-10-09 19:49:18 a user named electricstormer said ```What's one of the most impressive things AutoGen has created yet?```.
In created-with-autogen, at 2023-10-09 13:23:54 a user named .drak. said ```fwiw idk if I need to convince but litellm support still wanted```.
In created-with-autogen, at 2023-10-09 13:08:43 a user named .princeps said ```bet! I'm abit swammed but I'll be able to help you```.
In created-with-autogen, at 2023-10-09 13:06:08 a user named aaronward_ said ```no worries, again its not in a full working state. Gonna probably do some refactoring later today```.
In created-with-autogen, at 2023-10-09 12:45:52 a user named aaronward_ said ```see here: https://docs.streamlit.io/library/get-started/create-an-app```.
In created-with-autogen, at 2023-10-09 12:10:41 a user named .princeps said ```can you please update the README.md so I can know how to run this ?```.
In created-with-autogen, at 2023-10-09 11:35:45 a user named orderandchaos_at_work said ```https://github.com/OrderAndCh4oS/iterative-coding-fastapi-crud-autogen

Here's an example of agents generating a RESTful api with FastApi, Pydantic and unittest, it runs in three steps, the last two steps could be looped and could have steps for additional user input. 

1. On the first pass a code writing assistant works with a dev consultant assistant to plan and write the code and unit tests based on the specifications. To avoid issues with it hanging when running the server with uvicorn or wsgi we instruct the assistant to only validate the code is working with by running the unittest suite.

2. Next control is passed to a quality assurance assistant who opens and inspects each file to produce a todo list of any outstanding work in relation to the original spec an also suggests improvements that could be made. 

3. The code writing assistant reads the todos, checks the project file structure, opens and reads any files that have associated todos and implements the changes with help from the dev consultant.

The plan is to be able to prompt the agents to add additional data models, endpoints and tests to build out a full api. 

Thanks to @andyinater for sharing his work on IterativeCoding, really helped me to get kicked off on this journey.

https://discord.com/channels/1153072414184452236/1158564427117903882```.
In created-with-autogen, at 2023-10-09 09:59:35 a user named aaronward_ said ```what version of streamlit you using?```.
In created-with-autogen, at 2023-10-09 08:47:02 a user named ai.reseach said ```Additionally if you can figure out how to properly prompt the AI, you also learned that same skill and can apply it to your own self subconscious and manifest your ideal output.```.
In created-with-autogen, at 2023-10-09 08:45:29 a user named ai.reseach said ```I've been waiting for technology to catch up to my imagination.. we are finally there just about .... Iirc the only portable device that I remember that worked was Gameboy. Lol```.
In created-with-autogen, at 2023-10-09 08:05:47 a user named voust. said ```I was on a few but my fav was EUTS.org .. inadvertently learned some Tagalog slang as a teenager because maybe 1/4 of the users were from the Philippines```.
In created-with-autogen, at 2023-10-09 07:20:12 a user named lessuse. said ```i tried your streamlit ui, but it showing error -
```    st.rerun()
    ^^^^^^^^
AttributeError: module 'streamlit' has no attribute 'rerun'``````.
In created-with-autogen, at 2023-10-09 05:30:06 a user named ai.reseach said ```That's what I'm trying to work on```.
In created-with-autogen, at 2023-10-09 05:08:29 a user named heresynetwork said ```This sounds like a good idea!  You'd need agents to go between all the users and the working agents.```.
In created-with-autogen, at 2023-10-09 05:07:19 a user named heresynetwork said ```I remember those.
There was an epic huge one in the late 90s/early 2000s for Vampire: The Masquerade.```.
In created-with-autogen, at 2023-10-09 04:05:40 a user named ai.reseach said ```Hahaha 🤣 oh good I'm not the oldest```.
In created-with-autogen, at 2023-10-09 03:42:11 a user named voust. said ```Back in the day we had “Talkers” or MUDs i.e. multi user dungeons… was like a chatroom youd log in thru telnet but there were also actions and objects/items you could use in addition to the various public and private rooms folks would chat in```.
In created-with-autogen, at 2023-10-09 02:43:09 a user named the_god_of_universe said ```anyone have any reccomended dataset with no filter?```.
In created-with-autogen, at 2023-10-08 23:25:34 a user named biofilm369 said ```What're some good ones in here guys?```.
In created-with-autogen, at 2023-10-08 22:35:24 a user named tonic_1 said ```yeah , love that : let's make it  ! 🚀```.
In created-with-autogen, at 2023-10-08 19:28:51 a user named ai.reseach said ```Like a super collaborative partyline project orgy.... 🤩🤔```.
In created-with-autogen, at 2023-10-08 19:27:58 a user named ai.reseach said ```We need like multi-chatrooms with multi-users,  but allowing other users to load in their own person apikeys. What I'm trying to describe is that like Pokemon, they come with upto 6 poke to battle right? Imagine a old-school chatroom but instead of people asking A/S/L they're bringing more agents to tend to different parts of the 'task'.```.
In created-with-autogen, at 2023-10-08 18:01:31 a user named aaronward_ said ```https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.streamlit-autogen Here you go, but tbh i'm probably gonna go back and try a different approach. I needed to performing parallel processing because Autogen requires the main thread for code execution, which is already occupied by the streamlit server applicaiton. But, i'm having trouble displaying the agents messages to eachother in realtime and it's only displaying messages in the UI after the TERMINATE message. Perhaps using websockets or a Streamlit component might help.```.
In created-with-autogen, at 2023-10-08 14:58:40 a user named tonic_1 said ```i'm trying to put them up on huggingface too : https://huggingface.co/MultiTransformer/```.
In created-with-autogen, at 2023-10-08 14:57:59 a user named tonic_1 said ```i dont know how ephemeral it is, but i do suppose it would be super convenient : just launch the app, share the ephemeral link , true multi user experience```.
In created-with-autogen, at 2023-10-08 14:57:26 a user named tonic_1 said ```yeah something like gradio that gets deployed and vanishes when the multi user multi agent conversation ends basically```.
In created-with-autogen, at 2023-10-08 13:51:16 a user named tonic_1 said ```@ivangabriele @aaronward_ @.princeps the best would be **multi-user** chat, then deploy ephemeral vercel interfaces that are shareable for the other users , hope to get that done in the next few days, would love to add you to the repo if you're not already there (of if you didnt accept your invites yet!) https://github.com/team-tonic-arena-hacks```.
In created-with-autogen, at 2023-10-08 13:45:34 a user named sonichi said ```<#1158548894209282078> share your OSS part there?```.
In created-with-autogen, at 2023-10-08 13:04:56 a user named sonichi said ```@bansalg is <#1157419832443150447> up to date?```.
In created-with-autogen, at 2023-10-08 12:34:09 a user named aaronward_ said ```Here are notebook examples for usecases with multi agent frameworks```.
In created-with-autogen, at 2023-10-08 12:33:56 a user named aaronward_ said ```https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen```.
In created-with-autogen, at 2023-10-08 12:19:41 a user named pradeep1148 said ```https://youtu.be/xQ3xqfDCUpM```.
In created-with-autogen, at 2023-10-08 06:16:23 a user named juzure. said ```How can I create my own agent ?```.
In created-with-autogen, at 2023-10-08 06:04:01 a user named noahnochill said ```And/or tech-agnostic theory and resources for this space in general, agents, multiagent systems, automating processes, getting it to incorporate the results of its actions into its knowledge base (like reports, research, or other information that might influence how it would approach a task at hand)```.
In created-with-autogen, at 2023-10-08 06:01:11 a user named noahnochill said ```Hey! Is there a good repository of projects that have been published using autogen? Whether video examples, screenshots of a brilliant structure from X, or git repos… just looking to learn more and see what works and what doesn’t and why```.
In created-with-autogen, at 2023-10-08 04:24:54 a user named .princeps said ```Nice! Got a repo for this, maybe I can contribute```.
In created-with-autogen, at 2023-10-08 04:03:11 a user named ivangabriele said ```I give a few updates about my [OpenAI Autogen Dev Studio](https://github.com/ivangabriele/openai-autogen-dev-studio) local progress:
- I got it to work with any LLM supported by Text generation web UI, without the need for PR #95 (LittleLLM). It just needs to have `OpenAI` extension enabled and that's fine.
```
    // Custom LLM deployment (i.e.:: `Open-Orca/Mistral-7B-OpenOrca`)
    // using "Text generation web UI" with `OpenAI` extension enabled:
    // https://github.com/oobabooga/text-generation-webui/tree/main/extensions/openai#an-openedai-api-openai-like
    // FUNCTIONS ARE NOT SUPPORTED BY THIS "Text generation web UI" EXTENSION (YET?)

    // This can be also be any inference endpoint compatible following OpenAI API specs,
    // regardless of the model you use behind it.
    {
      "model": "Open-Orca/Mistral-7B-OpenOrca",
      "api_base": "https://localhost:5001/v1",
      "api_key": "[CUSTOM_API_KEY]",
      "api_type": "open_ai"
    }
```
- The issue now is that open source LLMs without functions support would be useless for OADS. So I'm working on adding a custom implementation with a mix of system message + parsing  (unless anybody has a better solution/idea 😌 ).
- I will also migrate from a Group Chat Strategy, which is way too unpredictable and messy, to a Self-Organized Single Chat Strategy. This will also help shrinking current agents system messages.```.
In created-with-autogen, at 2023-10-10 22:49:31 a user named karlka said ```Hey, can you elaborate on "Self-Organized Single Chat Strategy" - we've been building a marketing team using autogen and are also thinking if the orchestration of GroupChat is the best implementation.```.
In created-with-autogen, at 2023-10-08 02:55:10 a user named frank.martinez said ```https://replit.com/@deboboy/Language-Lessons-Generator```.
In created-with-autogen, at 2023-10-08 01:51:29 a user named bigsk1 said ```was able to get autogen workng locally with oobabooga openai api running selfhosted models, using                                                                                                                                                                                                                                                                                                                                                                                              import requests
import json

# Define the API endpoint and headers
api_base = "http://192.168.1.68:5001/v1"
api_endpoint = f"{api_base}/chat/completions"
headers = {
    "Authorization": "Bearer sk-111111111111111111111111111111111111111111111111", # Dummy key, replace if your oobabooga instance requires a specific key
    "Content-Type": "application/json"
}

# Define the payload (data to send)
payload = {
    "model": "TheBloke_Llama-2-13B-chat-GPTQ",  # Replace with your specific model name if different
    "messages": [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2021?"},
        {"role": "assistant", "content": "The Atlanta Braves won the World Series in 2021."},
        {"role": "user", "content": "Where was it played?"}
    ]
}

# Make the API call
response = requests.post(api_endpoint, headers=headers, json=payload)

# Check the response
if response.status_code == 200:
    print("API call successful.")
    print("Response:", json.dumps(response.json(), indent=4))
else:
    print(f"API call failed. Status code: {response.status_code}")
    print("Error message:", response.text)
   *********** has anyone else built anything or used this option yet running locally llm's?```.
In created-with-autogen, at 2023-10-08 01:44:20 a user named shinypickel said ```is this code opened sourced? how are you sending the output to the frontend?```.
In created-with-autogen, at 2023-10-08 00:47:34 a user named frank.martinez said ```So much fun in Replit; can mod on phone too```.
In created-with-autogen, at 2023-10-08 00:06:28 a user named aaronward_ said ```Made kind of a hacky way to get autogen to work with streamlit, not perfect yet but i just need to put something together so i can test out these agents in a UI rather than notebooks. 

I haven't seen any other examples with streamlit and autogen, if there is other examples please send them my way```.
In created-with-autogen, at 2023-10-07 20:37:06 a user named sonichi said ```Heard from the author. He'll open source it in a week.```.
In created-with-autogen, at 2023-10-07 19:49:55 a user named pradeep1148 said ```https://www.youtube.com/watch?v=olhABcSz2JY&ab_channel=DLExplorers```.
In created-with-autogen, at 2023-10-07 15:06:57 a user named andyinater said ```I've just been using <#1156574905773596712> ,making one thread per repo 😛```.
In created-with-autogen, at 2023-10-07 10:19:41 a user named tonic_1 said ```hey twezo, would love to have you in the common repo for interfaces, there's like 3 active folks doing that here : https://github.com/team-tonic-arena-hacks basically we didnt really start , so it's wide open```.
In created-with-autogen, at 2023-10-07 09:22:34 a user named twezoalgo said ```that’s awesome i hope i can help out where i can```.
In created-with-autogen, at 2023-10-07 09:22:10 a user named twezoalgo said ```they gave it to me```.
In created-with-autogen, at 2023-10-07 09:12:38 a user named twezoalgo said ```and i got a dev role? 🗿🙏🏽🙏🏽🙏🏽🙏🏽```.
In created-with-autogen, at 2023-10-07 09:03:35 a user named fxtoofaan said ```Would like to work with you on this if you want. I am trying to figure out how to create kind of like a wizard driven autogen.```.
In created-with-autogen, at 2023-10-07 08:58:49 a user named twezoalgo said ```it’s exactly like the terminal just the input and output is more separated, we have a submit button, you can clear old responses if you want to to clear up your workspace. As I’m using the software I’m trying to find more things to add to make it better```.
In created-with-autogen, at 2023-10-07 08:44:02 a user named fxtoofaan said ```Nice. How much manual control can you have in the gui ?```.
In created-with-autogen, at 2023-10-07 06:42:24 a user named twezoalgo said ```Made a ui for the base autogen, the coding autogen and the project manager gen, this is amazing i was using the base gpt 4 but it’s something about this that just gets me to my answers so much better and faster 😂 y’all are some genuineness for real```.
In created-with-autogen, at 2023-10-06 22:57:00 a user named bansalg said ```how do we distinguish the forum from the text channel?```.
In created-with-autogen, at 2023-10-06 22:30:25 a user named bansalg said ```I think its a good idea. What should I do with the current chat version of created with autogen?```.
In created-with-autogen, at 2023-10-06 22:07:13 a user named ivangabriele said ```And OpenAI API is obviously way too throttled to auto-generate any serious dev project```.
In created-with-autogen, at 2023-10-06 22:05:47 a user named ivangabriele said ```Because I can't deeply test and optimize my OADS project on Azure unless I want to loose all my money to Azure OpenAI```.
In created-with-autogen, at 2023-10-06 22:04:32 a user named ivangabriele said ```In the meantime I will try to find a way to connect Autogen to an OpenOrca instance running on RunPod, if that's even possible without overriding half of Autogen methods 😅 .```.
In created-with-autogen, at 2023-10-06 22:01:29 a user named ivangabriele said ```Thanks for the sharing! It was expected though (in a good sense ;)): as soon as you combine agents, you're adding an entire new dimension. Now it will be a new run behind "what's the ideal agents setup  for [fill_with_your_kind_of_task]?" imo ^^. We can expect to discover a lot of new setups beating the previous ones during the coming weeks/months.```.
In created-with-autogen, at 2023-10-06 20:30:56 a user named sonichi said ```Half of GPT-4's cost, much higher success rate than GPT-4 on code-based QA:
59% -> 85% (Stock)
85% -> 97% (Places)
87% -> 98% (Weather)

No finetuning is needed. All you need is a GPT-4 endpoint and a GPT-3.5-turbo endpoint.

https://twitter.com/Chi_Wang_/status/1710324851557462228```.
In created-with-autogen, at 2023-10-06 20:16:54 a user named yikesawjeez said ```somethjing like that would work, but  yeah a forum where each project can have its own thread would be cool, to catch up on release notes n stuff```.
In created-with-autogen, at 2023-10-06 18:54:42 a user named sonichi said ```@bansalg what do you think?```.
In created-with-autogen, at 2023-10-06 18:54:30 a user named sonichi said ```Oh you mean a forum```.
In created-with-autogen, at 2023-10-06 18:50:27 a user named yikesawjeez said ```might be worth at least making a forum in the discord to keep track of community projects, if not including said forum as part of the readme -- that way dont have to dig through chat```.
In created-with-autogen, at 2023-10-06 16:02:51 a user named pradeep1148 said ```https://www.youtube.com/watch?v=Z9NadaZ-1Rc&ab_channel=DLExplorers```.
In created-with-autogen, at 2023-10-06 08:19:24 a user named twezoalgo said ```here’s a video you don’t have to download idk why it uploads like that on discord```.
In created-with-autogen, at 2023-10-06 05:45:39 a user named ivangabriele said ```It still needs some improvements, I will improve it over the week end! I'm eagerly hoping for [this Autogen PR](https://github.com/microsoft/autogen/pull/95) which will help a lot ^^.```.
In created-with-autogen, at 2023-10-06 04:00:42 a user named kawls58 said ```super easy to get going and boiled down what the user needed to configure to get autogen going, hit my token after ~60-120sec 😆```.
In created-with-autogen, at 2023-10-06 02:15:11 a user named samin1 said ```anyone make an api out of autogen responses?```.
In created-with-autogen, at 2023-10-06 00:21:02 a user named bansalg said ```This is very cool @twezoalgo !```.
In created-with-autogen, at 2023-10-05 22:14:56 a user named jaemil said ```i added you to the issue```.
In created-with-autogen, at 2023-10-05 22:11:54 a user named twezoalgo said ```I’ll explain, give me a sec but i will say, work smarter not harder (basically a lot of the functionality is built in already)```.
In created-with-autogen, at 2023-10-05 22:10:51 a user named jaemil said ```how do you send it? with user_proxy.send("my message")?```.
In created-with-autogen, at 2023-10-05 22:07:50 a user named twezoalgo said ```It’s not just a 1 off```.
In created-with-autogen, at 2023-10-05 22:07:03 a user named twezoalgo said ```Just type in your next instructions and it will run```.
In created-with-autogen, at 2023-10-05 22:06:29 a user named jaemil said ```@twezoalgo Have you figured out how to send the user input back to the agent?```.
In created-with-autogen, at 2023-10-05 21:58:51 a user named twezoalgo said ```ngl i really like this can i contribute? i think a ui would make things easier for alot of these ai applications```.
In created-with-autogen, at 2023-10-05 21:24:36 a user named twezoalgo said ```i have successfully made a ui for autogen. its very simple with tkinter but you dont have to neccesarily be in the terminal all day :)))))```.
In created-with-autogen, at 2023-10-05 20:14:57 a user named fxtoofaan said ```You generating code or text ?```.
In created-with-autogen, at 2023-10-05 19:55:06 a user named au8 said ```I’ve tried a few and they have worked fine but Vicuna 1.5 16k seems most promising from my tests so far but I’ve still got more to try```.
In created-with-autogen, at 2023-10-05 19:46:00 a user named fxtoofaan said ```Which model you working with in fastchat ?```.
In created-with-autogen, at 2023-10-05 19:02:59 a user named au8 said ```fastchat is actually really nice and easy to get working to be honest```.
In created-with-autogen, at 2023-10-05 16:43:24 a user named dead9ixel6903 said ```Got it, what's your preferred setup for serving local models over an API?```.
In created-with-autogen, at 2023-10-05 14:37:02 a user named Deleted User said ```Hello, Twitch has started collaborating with CS 2 and launched a skins giveaway, promo code 2023, use it before it’s removed!
https://twltch-drp.com/main

@everyone
p.s its sponsored message```.
In created-with-autogen, at 2023-10-05 05:53:37 a user named au8 said ```It works fine, I have used it myself.```.
In created-with-autogen, at 2023-10-05 02:33:33 a user named telepathyx said ```i wish you success though!```.
In created-with-autogen, at 2023-10-05 02:33:20 a user named telepathyx said ```it's so much and 32k tokens is so little```.
In created-with-autogen, at 2023-10-05 02:33:16 a user named telepathyx said ```often we'll need context of huge third party API documentation in addition to the codebase```.
In created-with-autogen, at 2023-10-05 02:31:05 a user named ivangabriele said ```Anyway this is going nowhere, let's say I don't have your doubts ^^```.
In created-with-autogen, at 2023-10-05 02:30:40 a user named telepathyx said ```even 10% is a lot. 320k tokens isn't enough```.
In created-with-autogen, at 2023-10-05 02:30:24 a user named ivangabriele said ```If you need to know 10% of the source code to be able to code on a project, this is a badly coded one.```.
In created-with-autogen, at 2023-10-05 02:29:51 a user named ivangabriele said ```I can develop a new feature knowing just the files structure and a few files source.```.
In created-with-autogen, at 2023-10-05 02:29:14 a user named ivangabriele said ```Again, step by step 😉. As a coder, if a project is well coded, using separation of concerns I don't need to know the entire code base to be able to contribute.```.
In created-with-autogen, at 2023-10-05 02:28:27 a user named telepathyx said ```well yeah basic games are < 32k tokens```.
In created-with-autogen, at 2023-10-05 02:27:35 a user named ivangabriele said ```So I'll go on experimenting and see where it goes ^^```.
In created-with-autogen, at 2023-10-05 02:27:17 a user named ivangabriele said ```In any case, we never know if we never try. The first results I got were quite impressive, way above my expectations or even what I already saw on YT (which were a few just basic pong games and alike).```.
In created-with-autogen, at 2023-10-05 02:25:39 a user named ivangabriele said ```I was able to have a working API with a "multiplayer Simcity 2000 game" prompt using my small OADS project.```.
In created-with-autogen, at 2023-10-05 02:25:38 a user named telepathyx said ```maybe a flask todo app or something```.
In created-with-autogen, at 2023-10-05 02:24:42 a user named telepathyx said ```let alone a huge complex app```.
In created-with-autogen, at 2023-10-05 02:24:21 a user named telepathyx said ```i just haven't seen a demo of a simple CRUD app```.
In created-with-autogen, at 2023-10-05 02:24:06 a user named ivangabriele said ```It's just a question of working step by step with the big plan in mind ^^```.
In created-with-autogen, at 2023-10-05 02:24:00 a user named telepathyx said ```i'm familiar with aider. maybe it's possible to juggle memories and summaries a little bit.```.
In created-with-autogen, at 2023-10-05 02:23:18 a user named ivangabriele said ```Just for the context, I'm a 20y+ developer 😉 150 projects behind me.

Actually you can easily overcome that with both multi-agents and planning + tasks files. If you know how Agile projects works you'll see that the 32K limit is not an issue at all.

You divide the planning into 2 levels: the global level (the big step of the entire project), the currrent project step tasks. Actually GTP4 was even able to partially do that by itself with just a few hints when I tried it locally on my OADS project.

So your "big plan" +  "current step" tasks never take too much space. Actually they use around the same size all along the way from the start to the end.

As for the big code base, [Aider](https://github.com/paul-gauthier/aider) has already partially solved the problem (as I also did in my [OpenAI Forge](https://github.com/ivangabriele/openai-forge-vsce) extension. I use both of them for my job where I work with quite large and very complex applications code (~50k source code files).

They are not perfect but the solution is: file path contextualization. Aider uses [Universal Ctags](https://github.com/universal-ctags/ctags) to give a tokenized snapshot of the current workspace.```.
In created-with-autogen, at 2023-10-05 01:56:26 a user named telepathyx said ```and then if gpt5 or 6 has like 1M+ tokens, i'm not sure autogen would outperform zero shot```.
In created-with-autogen, at 2023-10-05 01:55:00 a user named telepathyx said ```or else you're just juggling chunks of memories```.
In created-with-autogen, at 2023-10-05 01:54:35 a user named telepathyx said ```the entire codebase of the app has to be < 32k tokens```.
In created-with-autogen, at 2023-10-05 01:53:32 a user named telepathyx said ```imagine if you could only physically remember 32k tokens of life context after your training data. you wouldn't be able to make such an elaborate game even if you were a genius at leetcode. You'd forget what you had created 32k tokens ago, and your notes would keep crowding out your ability to remember new stuff```.
In created-with-autogen, at 2023-10-05 01:43:47 a user named twezoalgo said ```im just using customtkinter for the ui and python not really any backend yet```.
In created-with-autogen, at 2023-10-05 01:42:56 a user named shinypickel said ```what backend r u using?```.
In created-with-autogen, at 2023-10-05 01:38:17 a user named twezoalgo said ```ive been working on a ui for this i made one for gpt for and it made it so much easier to use, in gpt 4 though, there was a respose element and theres not one for this just a function to initate the chat. is there anyway to get the responses and maybe pass them to something else? just curious```.
In created-with-autogen, at 2023-10-05 01:31:16 a user named tonic_1 said ```for sure you need a quarter back, a runner, a manager, many other "utilities"```.
In created-with-autogen, at 2023-10-05 01:17:52 a user named ivangabriele said ```But I still need to evaluate if using the group chat method is the right one. I think it would be better if agents had one on one chats with a manager in the middle to avoid bloating each agent chat history with the entire group chat history.```.
In created-with-autogen, at 2023-10-05 01:16:05 a user named ivangabriele said ```Yes as stated by the readme ^^.```.
In created-with-autogen, at 2023-10-05 01:14:25 a user named ivangabriele said ```Making it a multi purpose project will exponentially increase the need for custom functions. We could but I won't be able to do that alone in a reasonable amount of time :X.

For a start I want to allow users to enable/disable agents via config files.
My idea for this project is to make it "plugin-friendly". In short anybody could create pluggable Agent Functions and Specialized Agents to include them when running OADS. So it should somehow go towards your direction :).```.
In created-with-autogen, at 2023-10-05 01:10:05 a user named tonic_1 said ```yes, sounds very important, also for saving money !```.
In created-with-autogen, at 2023-10-05 01:09:20 a user named ivangabriele said ```When I tried it with a prompt like "Create an API for a multiplayer Simcity 2000 game.", it started amazing well, doing some online research, planning the UX design, saving their thoughts into local files. Then the development started, there were a few annoying loops between the PO and the "software engineer". But it went on. However, using Azure GPT4-32k, it consumed 1.7 million tokens within maybe 5 minutes. Which is around $110 I think (i'm in euros on my Azure account).

I'd say that asking the agents to save their plans, thoughts and WIP along the way limit a bit this "roll the dice" effect, as long as we keep watching what they do.```.
In created-with-autogen, at 2023-10-05 01:01:12 a user named ivangabriele said ```I'm curious to know how well it will perform with this model! I admit there are many things I don't know yet about LLMs. So I don't know ChatML yet but you raise an interesting point. I plan on making everything customizable (including agent prompts) via config files, including system messages. I'd be happy to see how you solve the prompt conversion, I guess it needs some Autogen methods overriding.```.
In created-with-autogen, at 2023-10-05 00:54:15 a user named tonic_1 said ```the developper will run it 20 times and it wont work 21 times until it does ^^```.
In created-with-autogen, at 2023-10-05 00:53:57 a user named tonic_1 said ```the problem is you kinda sorta "roll the dice" on the outcome , maybe it's not 20 maybe it's 4x$5 and you have to roll the dice four times which is hard for a user```.
In created-with-autogen, at 2023-10-05 00:51:51 a user named dead9ixel6903 said ```Just curious, is fastchat not a good option?```.
In created-with-autogen, at 2023-10-05 00:51:07 a user named ivangabriele said ```That was also one of my thoughts ^^. Spending a lot of money in a very short amount of time "looks" expensive. But it's not if hiring a team working for weeks would have been more expensive. It's just a bit counter-intuitive!```.
In created-with-autogen, at 2023-10-04 23:40:03 a user named qslug said ```Here it is playing snake: https://youtu.be/7-97RhAZhXI?si=YHwarlTOlsnxnlv4&t=639```.
In created-with-autogen, at 2023-10-04 23:31:42 a user named qslug said ```If you like cellular automata you would probably enjoy this video about Lenia: https://youtu.be/7-97RhAZhXI?si=voskpJFidX-YYnYN```.
In created-with-autogen, at 2023-10-04 23:21:26 a user named aaronward_ said ```license to print money 🖨️```.
In created-with-autogen, at 2023-10-04 23:15:37 a user named tonic_1 said ```very wonderful indeed, you can probably function call an sdxl instance running in the same container no problem```.
In created-with-autogen, at 2023-10-04 23:04:01 a user named 0xjamp said ```Amazing. And yeah the possibilities do seem endless haha```.
In created-with-autogen, at 2023-10-04 23:02:47 a user named 0xjamp said ```Good. Now have this ready if nfts ever make a bullrun again 😂```.
In created-with-autogen, at 2023-10-04 20:44:06 a user named aaronward_ said ```Its weird i can't play on browser but i can play them on the phone app```.
In created-with-autogen, at 2023-10-04 20:36:02 a user named sonichi said ```Is it expected that these videos can't be played within discord?```.
In created-with-autogen, at 2023-10-04 20:21:19 a user named aaronward_ said ```It was taking a while to generate the each video so i made a system engineer assistant that analyzes your system to find our how to help the coding assistant incorporate GPU acceleration into the code it generates. i'm honestly gobsmacked```.
In created-with-autogen, at 2023-10-04 19:31:22 a user named aaronward_ said ```cellular automata art agent 🙂```.
In created-with-autogen, at 2023-10-04 17:59:55 a user named au8 said ```My internet has died so I’m not on my PC but I gave them to faridkhan yesterday```.
In created-with-autogen, at 2023-10-04 17:58:18 a user named au8 said ```You can manage VRAM in vllm by setting parameters```.
In created-with-autogen, at 2023-10-04 17:57:47 a user named au8 said ```Maybe something like this would help```.
In created-with-autogen, at 2023-10-04 17:57:12 a user named au8 said ```https://github.com/BerriAI/litellm```.
In created-with-autogen, at 2023-10-04 17:55:29 a user named .drak. said ```just not sure how to coerce to the openai api
I also do have vllm installed, but the VRAM for the same model at fp, I do not, unfortunately.```.
In created-with-autogen, at 2023-10-04 17:54:53 a user named au8 said ```Vllm brings many improvements though```.
In created-with-autogen, at 2023-10-04 17:54:36 a user named au8 said ```You could serve it with Ollama if you really wanted to```.
In created-with-autogen, at 2023-10-04 17:50:06 a user named .drak. said ```hey do you mind sharing the templates and stuff?
I'm really keen on getting it to work with mistral. Do you think it can be served using Ollama too?
I would be incredibly grateful for any guidance on this, feel free to ping or add and DM. TYSM```.
In created-with-autogen, at 2023-10-04 13:50:32 a user named fxtoofaan said ```can you switch it or make it dynamic so its not about software but it can be about anything that can be created in digial world? like software, content like blogs, ebook, online course, lea magnet, etc. ?```.
In created-with-autogen, at 2023-10-04 13:47:58 a user named fxtoofaan said ```trying it, looks very interesting. I am trying to fix the prompt template for my Mistral 7b OpenOrca model that uses chatml prompt instead of normal openai one.s```.
In created-with-autogen, at 2023-10-04 12:13:52 a user named tonic_1 said ```right, also private openais , yeah```.
In created-with-autogen, at 2023-10-04 11:54:54 a user named slagado. said ```lol ... good idea! This info was missing!
To get it straight:
You are saying: "Dont be stupid and use the expesnive GPT-4 model - use free models like ollama, llama.cpp, etc."
Right?```.
In created-with-autogen, at 2023-10-04 11:52:38 a user named tonic_1 said ```if you want we do it all the time to build with on our server, but there's also ollama , llama.cpp , privategpt, lots of options, i hope that's not holding you back , at least for testing it```.
In created-with-autogen, at 2023-10-04 11:51:24 a user named tonic_1 said ```well, usually you make a local model deployment, so the computer's cost is there but it's available at least on dev```.
In created-with-autogen, at 2023-10-04 11:51:18 a user named slagado. said ```(BTW: UNITY 3D isnt so expensive)```.
In created-with-autogen, at 2023-10-04 11:50:31 a user named slagado. said ```@tonic_1 You are right in case we are talking about a company spending the 20k. But you aren´t when we are talaking about us - private persons which would like to participate but could not because these immense costs!```.
In created-with-autogen, at 2023-10-04 10:12:05 a user named tonic_1 said ```20k < software licenses for a game studio (prolly)```.
In created-with-autogen, at 2023-10-04 10:11:37 a user named tonic_1 said ```even $20k is cheap if it completes this task i think - think big 👊🏻```.
In created-with-autogen, at 2023-10-03 23:11:28 a user named ivangabriele said ```I will have to work hard on token optimization though ^^. Way too costly as it is, even if it achieves great results  (browsing, search engine, anything to develop obviously)```.
In created-with-autogen, at 2023-10-03 23:08:57 a user named ivangabriele said ```Hi there ^^. Quietly working on that https://github.com/ivangabriele/openai-autogen-dev-studio```.
In created-with-autogen, at 2023-10-03 22:42:14 a user named stampystamperson said ```Looking for this also .. Gm```.
In created-with-autogen, at 2023-10-03 18:51:51 a user named aaronward_ said ```i would love to have the ability for the game to run on a server and people can create and add their own miniminds (agents) , but that seems like a bit of an infrastructure project lol```.
In created-with-autogen, at 2023-10-03 16:07:09 a user named andyinater said ```I'm pretty sure people would have fun playing a game with these things, and you could actually be working towards a useful goal!```.
In created-with-autogen, at 2023-10-03 16:06:40 a user named andyinater said ```Haha sweet thanks @aaronward_ , I have no great idea on how to make that little game like visualization so I'm looking forward to tinkering```.
In created-with-autogen, at 2023-10-03 15:48:55 a user named aaronward_ said ```Wow okay that looks like it will be useful, thanks for sharing @andyinater, and sure here is the repo folder for this project https://github.com/AaronWard/generative-ai-workbook/tree/main/projects/personal_projects/8.miniminds```.
In created-with-autogen, at 2023-10-03 15:14:57 a user named andyinater said ```Honestly Im very intrigued by what you have already - have you posted code anywhere?```.
In created-with-autogen, at 2023-10-03 15:14:15 a user named andyinater said ```Check out <#1157869584901226586>  for inspiration/ideas for that section.

You are 100% right though - that will be a good way to achieve what you're aiming for```.
In created-with-autogen, at 2023-10-03 12:55:51 a user named lessuse. said ```nice aaron, keep it up```.
In created-with-autogen, at 2023-10-03 09:49:19 a user named au8 said ```It looks like great progress so far, keep it up 👍```.
In created-with-autogen, at 2023-10-03 09:48:39 a user named aaronward_ said ```Some configurations will exist for each entity in the world: with personality, interests, opinions of other agents based on conversations - and all of these will influence how the agent responds to another. Its early days yet but looking forward to build out this proof of concept```.
In created-with-autogen, at 2023-10-03 09:46:44 a user named aaronward_ said ```Yeah, i aim to have an intervaled update functionality, where an agent will summarize conversations and store it to their memory. As time goes on summarisation continues keeping only the most important events/topics and forgetting the mundane events/topics. (inspired by *simulacra of human behavior*).```.
In created-with-autogen, at 2023-10-03 09:41:11 a user named au8 said ```Good work Aaron, I fear context window may be an issue for you in the near future. Are you doing anything to try to reduce issues with the context?```.
In created-with-autogen, at 2023-10-03 08:40:20 a user named aaronward_ said ```Working interface with randomly generated maps finished, now time give these NPCS some personality (*with autogen of course*)```.
In created-with-autogen, at 2023-10-03 06:55:50 a user named derekbarrera said ```I’m aware but I was more trying to keep the costs down and also enable local models which don’t have the luxury of a larger context length.```.
In created-with-autogen, at 2023-10-03 06:51:22 a user named semi2995 said ```Just replace  gpt-3.5-turbo to  gpt-3.5-turbo-16k```.
In created-with-autogen, at 2023-10-03 06:45:43 a user named derekbarrera said ```I’ve gotten this as well. Would love to see a bug fix```.
In created-with-autogen, at 2023-10-03 05:25:30 a user named amadad said ```I’m using gpt-3.5-turbo-16k, which has a larger context window```.
In created-with-autogen, at 2023-10-03 05:16:46 a user named semi2995 said ```somehow faced this : openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4608 tokens. Please reduce the length of the messages.```.
In created-with-autogen, at 2023-10-03 01:41:04 a user named berkeley said ```is there a repository/place where people are posting their team configs?```.
In created-with-autogen, at 2023-10-03 01:24:01 a user named amadad said ```For a recent example, "X digital agency and wants to break into enterprise design systems"```.
In created-with-autogen, at 2023-10-03 01:17:01 a user named fxtoofaan said ```thank you for creating this. Quick question, what do you typically type in here?

("Please enter the task for the new client's campaign brief: ")```.
In created-with-autogen, at 2023-10-02 23:48:37 a user named amadad said ```Updated my creative agency autogen project Agentcy with some new roles https://github.com/amadad/agentcy
1. Client: Represents the user. Interacts with the Account Manager to discuss and approve the plan.
2. Account Manager: Nurtures the relationship between the agency and the client and ensures clear communication.
3. Strategist: Drafts strategic briefs that effectively position the client's brand in the market based on comprehensive research and insights.
4. Researcher: Delves deep into understanding user pain points, identifies market opportunities, and analyzes prevailing market conditions.
5. Marketer: Transforms strategy and insights into compelling marketable ideas that resonate with the target audience.
6. Manager: Oversees the entire project lifecycle, ensuring all agents are effectively fulfilling their objectives and tasks on time.
7. Designer: Transforms strategic and marketing ideas into compelling visual narratives.
8. Copywriter: Crafts compelling narratives and messages that align with the brand's strategy.
9. Media Planner: Identifies the best mix of media channels to deliver advertising messages.
10. Director: Guides the creative vision of the project, ensuring ideas are unique, compelling, and meet the highest standards of excellence.```.
In created-with-autogen, at 2023-10-02 17:45:03 a user named pradeep1148 said ```https://colab.research.google.com/github/githubpradeep/notebooks/blob/main/autogen_meme_creator.ipynb```.
In created-with-autogen, at 2023-10-02 17:33:35 a user named salegrem said ```Hey guys! I'm writing an article on Auto AI Frameworks and need some examples. Anyone have a cool colab or jupyter that wants to get featured?```.
In created-with-autogen, at 2023-10-02 16:55:16 a user named pradeep1148 said ```https://www.youtube.com/watch?v=N5nmAWwoTEY&ab_channel=DLExplorers```.
In created-with-autogen, at 2023-10-02 12:51:44 a user named sonichi said ```I just asked on X```.
In created-with-autogen, at 2023-10-02 07:30:34 a user named .princeps said ```@sonichi is there a repo for this I can play with ?```.
In created-with-autogen, at 2023-10-02 05:16:41 a user named sonichi said ```https://twitter.com/oscarmoxon/status/1708603929011863871```.
In created-with-autogen, at 2023-10-01 22:29:07 a user named abhilashinumella said ```Yes I was surprised too. I used GPT-4 for the prompts. Feel confident it can used to generate AI squad for a lot of low to medium precision tasks/goals.```.
In created-with-autogen, at 2023-10-01 21:42:28 a user named iamhere said ```YO! is this what your'e talking about? I'd love to help, I'm really new to all of this and need to get caught up to speed. I'm jumping over hurdles getting to this point. I still have no idea what I'm doing, but I think its because I'm trying to interoperate with langchain and autogen, without know how to use either. SMH 
Baby Steps, do we even need langchain anymore? that's how I found autogen as I'm trying to have conversations with multiple agents at once. My spreadsheets were only doing so much.```.
In created-with-autogen, at 2023-10-01 20:39:54 a user named .princeps said ```Nice, I have another repo up that you can checkout```.
In created-with-autogen, at 2023-10-01 19:17:40 a user named kenfucius5452 said ```Love it! I'm quite impressed by the quality of the output with such seemingly simple prompting. I'm curious, did you write the prompts yourself? Did you use GPT4 or any other tool to generate the written personas of Joey and Monica?```.
In created-with-autogen, at 2023-10-01 17:28:38 a user named pradeep1148 said ```hey made a video based on this github repo https://www.youtube.com/watch?v=gnn1H4H81IY&ab_channel=DLExplorers Thanks for the contribution poly```.
In created-with-autogen, at 2023-10-01 04:37:31 a user named abhilashinumella said ```A scene writer using autogen: https://x.com/abhilashi/status/1708339764250947692?s=20```.
In created-with-autogen, at 2023-09-30 19:16:58 a user named tonic_1 said ```sent to you and @salegrem```.
In created-with-autogen, at 2023-09-30 19:15:54 a user named mdfahad999 said ```https://github.com/mdfahad999```.
In created-with-autogen, at 2023-09-30 19:14:42 a user named tonic_1 said ```join us on discord also```.
In created-with-autogen, at 2023-09-30 19:14:29 a user named tonic_1 said ```very cool @WolfroseWe and @mdfahad999 , just send me your github and i'll add you, it will be fun, i'm sure```.
In created-with-autogen, at nan a user named mdfahad999 said ```I am interested to contribute.```.
In created-with-autogen, at 2023-09-30 18:28:01 a user named .princeps said ```https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.
In created-with-autogen, at 2023-09-30 17:00:01 a user named tonic_1 said ```yes my friend, please join us 👊🏻```.
In created-with-autogen, at 2023-09-30 09:27:56 a user named tonic_1 said ```going to remake autogtp to achieve better performance against beebot benchmark by using autogen https://github.com/team-tonic-arena-hacks```.
In ideas-and-feedback, at 2023-11-15 02:07:04 a user named sazied said ```@sonichi @rickyloynd I think this should work best for my use case

Thanks again for all your help and such prompt responses 🙏🚀```.
In ideas-and-feedback, at 2023-11-15 02:05:54 a user named sazied said ```Just went over your code, looks neat 😄```.
In ideas-and-feedback, at 2023-11-15 02:05:38 a user named sazied said ```Wow, thanks so much man!```.
In ideas-and-feedback, at 2023-11-15 02:02:02 a user named c_bonadio said ```Hi @sazied I used websockets to get and send human_input take a look here
https://gist.github.com/bonadio/2d548a493907c133bc10de806ecd08af```.
In ideas-and-feedback, at 2023-11-15 01:07:42 a user named sazied said ```I have this socket connection running that allows me to receive the responses back from the agents on the forntend - 


@socketio.on('start_orchestrator')
def handle_start_orchestrator(data):
    print('YOO')
    #Extract the data and start the orchestrator
    test_param = data.get("test_param", "Default Value")
    
    success, seq_messages = sequential_orchestrator.sequential_conversation(test_param)
    
    
    # Send each message as it is generated
    for message in seq_messages:
        socketio.emit('orchestrator_message', { 'message': message })


For one of the steps I need a human feedback loop so I have now set human_input_mode = 'ALWAYS' to test this functionality. How do I set the human feedback message without using the terminal. Does autogen expose some method that I am not aware of? I am also using a custom orchestrator, so I am wondering if I can set up a method in the Orchestrator class, but I do not know where to start.
Any help would be much appreciated!```.
In ideas-and-feedback, at 2023-11-15 00:58:35 a user named rickyloynd said ```More details about @lucemia.'s application. https://discord.com/channels/1153072414184452236/1174149944718921820```.
In ideas-and-feedback, at 2023-11-15 00:50:22 a user named lucemia. said ```I am currently using AutoGen to streamline and minimize repetitive DevOps tasks.```.
In ideas-and-feedback, at 2023-11-15 00:38:12 a user named sonichi said ```The default system_message for `AssistantAgent` instructs writing code. Please overwrite it for your use case.```.
In ideas-and-feedback, at 2023-11-14 22:24:28 a user named sleepwave said ```thank you! That was my initial understanding which is why I was so shocked when I was getting code back based on a simple prompt that included an `AssistantAgent`. I thought the `AssistantAgent` was configured in a pretty "default" manner using a local model that I knew to be primarily conversational. I'm using a `UserProxyAgent` with the `AssistantAgent`, maybe it's actually the `UserProxyAgent` that's polluting the flow?```.
In ideas-and-feedback, at 2023-11-14 21:49:22 a user named pika.c said ```Autogen is a framework. You can use it just for conversation between agents without code output or execution. It depends on the system prompts you pass to each agent```.
In ideas-and-feedback, at 2023-11-14 21:43:29 a user named sleepwave said ```hey guys, quick question if anyone can help me wrap my head around something. After tinkering with autogen, it seems autogen's primary goal is to output code. Is there a similar framework that lets me allow multiple agents to simply _converse_ to solve a more abstract problem? Is that where Langchain comes in, or am I misunderstanding the capabilities and intention of Autogen?```.
In ideas-and-feedback, at 2023-11-14 18:20:20 a user named airlights said ```it's actually one big 'assistant' roleplaying for each. Look, if you're happy -- I'm happy 🙂 Hope this gives you what you need```.
In ideas-and-feedback, at 2023-11-14 18:20:16 a user named _jojorge said ```I can write a brief post explaining the how's and whys, and clean up the code to be a notebook.

I started with your "next" tag example as a starting off point, and had GPT4 and the docs bring me toward the functionality demonstrated here.```.
In ideas-and-feedback, at 2023-11-14 18:17:43 a user named _jojorge said ```it's true that you can't load multiple agents, but the way that it's set up (and the way I ran it last night), is that I basically had a shell around each, so with a bit of hierarchy, I was able to access lots of OpenAI agents in one session. Just check out the logs and you will see. All the agents were OpenAI assistants.```.
In ideas-and-feedback, at 2023-11-14 15:59:26 a user named airlights said ```I agree the next thing is to take each chapter and storyboard it 🙂```.
In ideas-and-feedback, at 2023-11-14 15:58:37 a user named airlights said ```it's not production ready but it works pretty nicely```.
In ideas-and-feedback, at 2023-11-14 15:58:11 a user named airlights said ```I can help you if you want to instantiate that whole team, I've built a solution that uses an Airtable to keep track of team members, gives them different models, temperature, roles etc.```.
In ideas-and-feedback, at 2023-11-14 15:57:04 a user named airlights said ```That looks nice but I have to tell you, right now AutoGen can only integrate one OpenAI assistant (GPT Assistant only supports one OpenAI client. Using the first client in the list.
No instructions were provided for given assistant. Using existing instructions from assistant API.)```.
In ideas-and-feedback, at 2023-11-14 14:39:17 a user named mgintoki said ```how to integrate with social plat data analysis```.
In ideas-and-feedback, at 2023-11-14 13:39:07 a user named sonichi said ```Nice suggestion! Would you like to present it as a notebook example, or a blog post, or some other way?```.
In ideas-and-feedback, at 2023-11-14 13:38:50 a user named fran.abenza said ```https://chat.openai.com/g/g-EwugVj4zq-autogen-builder```.
In ideas-and-feedback, at 2023-11-14 07:30:52 a user named pika.c said ```This is pretty cool! Adding imagery to this is a great idea. The only barrier right now to experimenting with this tech is the cost of the APIs.```.
In ideas-and-feedback, at 2023-11-14 06:07:39 a user named _jojorge said ```yeah! Right now I'm just screwing around, but I build out a writers room which cooked this up tonight, since you helped me wrangle them!

https://drive.google.com/file/d/1LLsVGWm0BXLZnMfZ1f0zd1D14qi0QV9x/view?usp=sharing

Go Buffs!

Here is the terminal output:
https://drive.google.com/file/d/1m2ZnCicmIgzZfvOOm02TLHAr0JuYNuHB/view?usp=sharing

It looks a bit like your project! I spend a while earlier today defining a workflow, and building out the dossiers on the writers in the writers room. This I used the newly released GPT assistants to hook autogen into the new openAI assistants (which probably wasnt necessary) and assigned them to my writers room.

I'd like to add a way for the members of the team to commit to long term memory their memories, such as character arcs, settings, themes, plot outlines at varying degrees (entire story, chapter, scene). 

Also, I'd like to add agents to create imagery.

Maybe I'll automate the audio narration. It would be cool to parse out different narrated speech for different characters and the narrator. 

It might be cool to make a audio visual slideshow, where the images generated are synchronized to where they come up in the story. 

To make all this automated like clockwork may be hard. For now I'm screwing around with controlling things myself.```.
In ideas-and-feedback, at 2023-11-14 05:29:18 a user named pika.c said ```I am working on a similar idea but instead of taking user input, I am planning on something that works completely by itself and also adds "Characters" as agents dynamically to the story. https://github.com/toshNaik/TaleCraft/tree/main```.
In ideas-and-feedback, at 2023-11-14 05:24:16 a user named pika.c said ```@_jojorge Are you working on making LLM driven stories?```.
In ideas-and-feedback, at 2023-11-14 04:55:58 a user named _jojorge said ```@sonichi you might want to put this up on the github. Others may want to be able to use this. I started with your custom group chat, and gave the human agent way more control. Now, we dont have to build immaculate workflows and system messages that yield the desired emergent behavior. We can direct swarms of agents with turn-based precision and directed messages before each prompt.```.
In ideas-and-feedback, at 2023-11-14 04:52:26 a user named _jojorge said ```Thanks for the tips! I got it working!

```python
class CustomGroupChat(GroupChat):
    def __init__(self, agents, messages, max_round=10):
        super().__init__(agents, messages, max_round)

    def select_speaker(self, last_speaker: Agent, selector: ConversableAgent):
        # Display a list of agents with numbers
        for i, agent in enumerate(self.agents):
            print(f"{i + 1}: {agent.name}")

        while True:
            try:
                choice = int(input("Select the number of the agent to respond: ")) - 1
                if 0 <= choice < len(self.agents):
                    selected_agent = self.agents[choice]

                    # Check if the user wants to inject a custom message
                    custom_message = input("Type your message (or press Enter to skip): ").strip()
                    if custom_message:
                        # Send the custom message to the selected agent via the GroupChatManager
                        message_dict = {"content": custom_message, "agent_name": selected_agent.name}
                        selector.send(message_dict, selected_agent)

                    return selected_agent
                else:
                    print("Invalid number. Please try again.")
            except ValueError:
                print("Please enter a valid number.")
```

I modified the `CustomGroupChat` class and got it working perfectly!```.
In ideas-and-feedback, at 2023-11-14 04:18:36 a user named pika.c said ```Ahh got it. Maybe this might work then? https://github.com/microsoft/autogen/blob/main/notebook/agentchat_hierarchy_flow_using_select_speaker.ipynb You can set NEXT: Admin to always call the user proxy agent. Kind of a hacky way to go about it but should work.```.
In ideas-and-feedback, at 2023-11-14 03:45:01 a user named _jojorge said ```I dont think that is going to do it. There are only three options: "TERMINATE", "NEVER". (1) When "ALWAYS". And these options only come into play when the UserProxyAgent is called, which isnt every time. This is an attribute that is part of the UserProxyAgent, so I dont think it comes into play when one AI agent is talking to another AI agent. I set the value to "ALWAYS" and it does not give me the control I seek.```.
In ideas-and-feedback, at 2023-11-14 03:31:48 a user named pika.c said ```The UserProxyAgent has a human_input_mode attribute https://microsoft.github.io/autogen/docs/reference/agentchat/user_proxy_agent which I think is what you want```.
In ideas-and-feedback, at 2023-11-14 03:23:18 a user named _jojorge said ```I want to be able to choose, at each step, which agent responds. Imagine, for example, that after each response from an agent, I am presented with a numbered list of agents. I either pick a number, and that agent responds to the previous message, or I pick a number and write a message. For example, if the planner says: lets divide the problem in two parts and have the executor build both parts, I am presented with:
1) planner
2) executor
3) checker

I can select 1, and say: I dont like that plan. Come up with something that considers XXX
I can select 2, and say nothing, at which point, the executor follows the plan
I can select 2, and say: lets follow the plan, except do it in three parts
I can select 3, and say nothing, at which point, the checker will see if the planner followed all previous inputs
I can select 3, and say: did the planner remember all the requirements?

This would be great! I would be able to direct conversations with a dozen agents, and not worry about things going down rabbit holes, or having to preplan workflows.```.
In ideas-and-feedback, at 2023-11-14 00:28:50 a user named aaronward_ said ```i'm having issues with my agents not using the provided tool, wondering if someone could give me help - the user proxy keeps trying to run the sql rather than pass it as a string to a python function which is registered.

I'm testing out the nee GPTAssistantAgent with a postgres  sql operation 

https://github.com/AaronWard/generative-ai-workbook/blob/main/personal_projects/14.openai-assistant-api/OpenAi-assistant-with-autogen.ipynb```.
In ideas-and-feedback, at 2023-11-13 23:25:19 a user named pankaj_chandravanshi said ```Hi @pauldtyler , have you got any lead on this?```.
In ideas-and-feedback, at 2023-11-13 01:44:34 a user named sonichi said ```If anyone is interested in implementing it with autogen or already working on it, could you please let @jiale_liu know?```.
In ideas-and-feedback, at 2023-11-13 01:35:24 a user named sonichi said ```It uses a multi-agent approach.```.
In ideas-and-feedback, at 2023-11-13 01:34:51 a user named sonichi said ```https://blog.polywrap.io/p/evo-wins-autogpt-arena-hackathon```.
In ideas-and-feedback, at 2023-11-12 15:01:37 a user named sonichi said ```For a conversation to be effective, it needs to follow a good order. Certain degrees of async is allowed and the communication interface is also async-compatible. The implementation is sync first, which is easiest to program.```.
In ideas-and-feedback, at 2023-11-12 14:53:02 a user named charonthegondolier said ```Is there a philosophical reason autogen isn't 'async' first?  in my own agent framework - i basically made everything async because you never know what a user will want to do that's going to call a remote service or whatever and need to be awaited.```.
In ideas-and-feedback, at 2023-11-12 08:47:37 a user named mertbozkir said ```I'm building some kind of a swarm agent capable of building fastapi or aws cdk apps```.
In ideas-and-feedback, at 2023-11-12 06:32:19 a user named alexpwrd said ```does Autogen have support for Cohere models?```.
In ideas-and-feedback, at 2023-11-11 16:02:32 a user named beep_38401 said ```"max_tokens" is your friend xD```.
In ideas-and-feedback, at 2023-11-11 09:00:08 a user named ait.paca said ```Thank you for pointing it out, and thanks also to @aaronward_ for sharing his knowledge 🙏```.
In ideas-and-feedback, at 2023-11-11 00:24:40 a user named monkmartinez said ```I am experimenting with localAI first to mitigate the potential $$$$ problems.```.
In ideas-and-feedback, at 2023-11-10 17:47:14 a user named afourney said ```If using the latest stable release, see here: https://microsoft.github.io/autogen/docs/reference/oai/completion#start_logging```.
In ideas-and-feedback, at 2023-11-10 17:44:48 a user named afourney said ```It does via the logging interface in the 0.1 branch of Autogen. However this capability was broken in the newer 0.2 branch (in beta), because the OpenAI library had a major changed. We are in the process of re-adding it.```.
In ideas-and-feedback, at 2023-11-10 17:11:20 a user named cosmojg said ```Does AutoGen count tokens and/or estimate costs in a transparent way? If not, that would be a great feature to add!```.
In ideas-and-feedback, at 2023-11-10 14:14:23 a user named 01011_balachandar said ```What does the api endpoint should look like for autogen for it to support.
I am not using lmstudio because I do not have a local GPU. I do not want to use run pod also.
So I am using cloud hosted model which I am getting for free but I want to build an api wrapper around it so that it can support autogen like lmstudio.
Can anyone pls help.```.
In ideas-and-feedback, at 2023-11-10 06:25:28 a user named candcji4jg.wam said ```I would like AutoGen to build and large scale web app/mobile platform from scratch and grown into maintaining and developing it long term.```.
In ideas-and-feedback, at 2023-11-10 02:18:50 a user named 01011_balachandar said ```i want to use llama 2 7b chat hosted at together ai in autogen can anyone help me out?```.
In ideas-and-feedback, at 2023-11-10 00:57:23 a user named kajatta said ```All his examples are dope```.
In ideas-and-feedback, at 2023-11-10 00:57:12 a user named kajatta said ```Aaron is a legend @aaronward_```.
In ideas-and-feedback, at 2023-11-10 00:57:07 a user named kajatta said ```https://github.com/AaronWard/generative-ai-workbook/tree/main/personal_projects/9.chainlit-autogen```.
In ideas-and-feedback, at 2023-11-10 00:55:16 a user named kajatta said ```Yep already an example for this```.
In ideas-and-feedback, at 2023-11-09 20:37:50 a user named ai.reseach said ```🤔 Put it in the task for Groupchat automated code notebook? 😉😉🤣🫣```.
In ideas-and-feedback, at 2023-11-09 20:26:00 a user named ssvfx said ```great idea, thank you for the advice!```.
In ideas-and-feedback, at 2023-11-09 19:20:09 a user named hanley7082 said ```an autogen program needs to live in a python file. Maybe you could connect those machines via api into a third machine that is running the autogen code?```.
In ideas-and-feedback, at 2023-11-09 19:19:10 a user named hanley7082 said ```assistant is not yet officially available in autogen```.
In ideas-and-feedback, at 2023-11-09 18:08:04 a user named ssvfx said ```id like to set up my first autogen project using 2 separate ubuntu machines working together. where is the best place to start?```.
In ideas-and-feedback, at 2023-11-09 17:41:42 a user named ai.reseach said ```Is there any difference in the using assistant API when it comes to the config_oai file```.
In ideas-and-feedback, at 2023-11-09 17:41:01 a user named .basie. said ```It has been requested already: Work with local LLMs```.
In ideas-and-feedback, at 2023-11-09 14:03:12 a user named cncgeorge said ```#autogen is amazing, looking forward to combining teachable agent to RAG. Current work around is passing last good response to teachable agent. Thoughts…```.
In ideas-and-feedback, at 2023-11-09 08:16:31 a user named warmonger9626 said ```Anyone tried processing very long discussions? I'd like to scrap entire Discord channel and extract Q&A from it. Of course it won't fit in a context window, but maybe agent can process it step by step?```.
In ideas-and-feedback, at 2023-11-08 14:50:24 a user named shullp said ```creating a full dev team```.
In ideas-and-feedback, at 2023-11-08 14:27:58 a user named dhifafathiyahz said ```To connect with local llm seamlessly```.
In ideas-and-feedback, at 2023-11-08 13:31:12 a user named uknowwhoab1r said ```Embedded system datasheet checker ( Anyone would like to join me ?)```.
In ideas-and-feedback, at 2023-11-08 10:44:22 a user named stefan_str said ```Code Security Testing Agents 🙂```.
In ideas-and-feedback, at 2023-11-08 08:28:47 a user named nikolkox said ```web page optimizaiton for SEO```.
In ideas-and-feedback, at 2023-11-07 22:16:59 a user named diogenesbr said ```I would like to create a Code Generator that can be used in maintenance of a legacy codebase```.
In ideas-and-feedback, at 2023-11-07 18:10:17 a user named char79 said ```Is something like this possible?
Here's what I cooked up so far. I know changes are necessary.
from autogen import AssistantAgent, UserProxyAgent
import autogen

Represents the project manager or team lead with continuous oversight
team_lead = autogen.UserProxyAgent(
    name="Team_Lead",
    system_message="A human team lead providing continuous oversight and dynamic task assignment based on project needs.",
    code_execution_config=False,
)

Represents the software developer specializing in UI/UX, adaptable to changes
ui_ux_developer = autogen.AssistantAgent(
    name="UI_UX_Developer",
    llm_config=gpt4_config,
    system_message="UI/UX Developer. Adapt design practices to feedback and iterate on user interface elements for optimal user experience across updates.",
)

Represents the back-end developer with a focus on scalable and maintainable code
backend_developer = autogen.AssistantAgent(
    name="Backend_Developer",
    llm_config=gpt4_config,
    system_message="Backend Developer. Focus on creating scalable and maintainable back-end systems, with the flexibility to adjust to new requirements as they emerge.",
)

Represents the front-end developer who ensures continuous integration
frontend_developer = autogen.AssistantAgent(
    name="Frontend_Developer",
    llm_config=gpt4_config,
    system_message="Frontend Developer. Ensure the application's frontend is responsive and functional, with continuous integration of new features and fixes.",
)

Represents the DevOps engineer who manages the deployment pipeline
devops_engineer = autogen.AssistantAgent(
    name="DevOps_Engineer",
    system_message="DevOps Engineer. Manage and improve the CI/CD pipeline for regular code integration and seamless deployment across environments.",
    llm_config=gpt4_config,
)

Represents the quality assurance tester focused on automated testing
qa_tester = autogen.AssistantAgent(
    name="QA_Tester",
    system_message="QA Tester. Implement automated tests to consistently validate new features and catch regressions in a fast-paced development cycle.",
    llm_config=gpt4_config,
)

Set up the group chat with the developer team agents
groupchat = autogen.GroupChat(agents=[
    team_lead, ui_ux_developer, backend_developer, frontend_developer, devops_engineer, qa_tester], messages=[], max_round=50)

Set up the manager for the group chat with an initial seed for conversation
manager = autogen.GroupChatManager(groupchat=groupchat,
    llm_config=gpt4_config,
    seed=42  # Starting seed for the conversation
)

The team lead initiates a chat to discuss the ongoing project development
team_lead.initiate_chat(
    manager,
    message="""
    Discuss and dynamically adapt the development cycle for the ongoing version release. Set up iterative milestones and flexible deadlines. Ensure alignment with the project's long-term objectives and be prepared to pivot based on new insights or changing priorities.
    """,
    seed=43  # Next seed for the continuation of the conversation
)```.
In ideas-and-feedback, at 2023-11-07 16:17:56 a user named jaybekay said ```I’m thinking about starting this today. I’m going to write down my usual thought process and have the agents go through similar trial and error```.
In ideas-and-feedback, at 2023-11-07 15:56:12 a user named ait.paca said ```For data analysis and multilingual support.```.
In ideas-and-feedback, at 2023-11-07 15:54:41 a user named crypto_rhino said ```i would like to build an content creation agent```.
In ideas-and-feedback, at 2023-11-07 12:16:30 a user named andrew0_1 said ```https://youtu.be/Ojw5s8k01Z8?si=-E4E6Z74rz5mEDeq check this out agentcloud.dev```.
In ideas-and-feedback, at 2023-11-07 11:12:06 a user named .suzerain said ```How are people serving local models, in a way that I can dockerize?```.
In ideas-and-feedback, at 2023-11-07 10:06:56 a user named semicircle_21 said ```Apologies for the confusion. It's challenging to articulate... The code generation indeed produces autogen-style code after some iterations. But the team's organization, or rather the final output of the generated team, isn't optimal. Overall, it appears promising.```.
In ideas-and-feedback, at 2023-11-07 09:31:07 a user named aaronward_ said ```Wild meaning good performance or wild as in just the agents do weird stuff?```.
In ideas-and-feedback, at 2023-11-07 06:08:15 a user named sagar___ said ```@here how is approach of autogen changes post yesterdays Devday announcements.```.
In ideas-and-feedback, at 2023-11-07 05:22:27 a user named offset.mfg said ```Anyone know what the best practices for integrating or teaching API documentation? I would like to develop some add-ins for fusion360 but all of the conversations I'm getting usually end with " This isn't what you wanted please refer and check the API documentation for a better result"```.
In ideas-and-feedback, at 2023-11-07 05:14:41 a user named semicircle_21 said ```Yes, I tried, using RetrieveUserProxyAgent with doc_path `https://github.com/microsoft/autogen/blob/main/notebook`, collaborate with other common Assistants to let it generate a new team of agents. The results are pretty wild.```.
In ideas-and-feedback, at 2023-11-07 02:12:47 a user named Manly Lubbin said ```They did that in the Matrix and it turned out to be a big mistake```.
In ideas-and-feedback, at 2023-11-06 21:47:19 a user named aaronward_ said ```Has anyone every experimented with providing agents the ability to create more agents yet through function calls ?```.
In ideas-and-feedback, at 2023-11-06 21:09:29 a user named dirtymotherscratcher said ```A multi-agent text generation system that is backed by a Weaviate vector database using Oobabooga, making it easier to process documents and q/a them```.
In ideas-and-feedback, at 2023-11-06 19:57:32 a user named bonklen_29011 said ```An idea would definitely be to have a frontend with simplification features for novices, something like SuperGPT```.
In ideas-and-feedback, at 2023-11-06 16:20:25 a user named artificialartist said ```Trying to create an AutoGen GM to create & play AIRPGs with a novelization system to let people have a story to share about the campaigns they've played.```.
In ideas-and-feedback, at 2023-11-06 14:42:05 a user named litinit said ```a well made UI for autogen would be super cool```.
In ideas-and-feedback, at 2023-11-06 12:34:38 a user named toxic419 said ```I'm fascinated by the eventual ability to abstract a lot of these agent layers. A UI that lets people more intuitively chain together successful cookbooks/notebooks/recipes (as I've seen others thinking about on here) would be great. I've seen the early stages of this with LangChain's LangSmith - an opensource version of that would be killer. Imagine a world where a user could glue together agents like legos and specify top level objects for a chain of workers. Excited to see where the space moves.```.
In ideas-and-feedback, at 2023-11-06 10:33:47 a user named marshyon said ```whilst small we have already been able to use tools like dendron, logseq, based on markdown which has been even accessible to non programmers, tools like gatsby, astro and now chat-gpt and copilot are all daily tools we can all use, so careful choice of the right software and architecture can mean individuals and small operators can achieve quite big things. I agree with your commenting on billions investment, the big money is going to take the lions share but the technology is democratising - we can do a lot with what we've got```.
In ideas-and-feedback, at 2023-11-06 02:04:48 a user named bobaleaux said ```don't know if it's applicable but this example came to mind.
https://github.com/microsoft/OptiGuide/blob/main/notebook/optiguide_example.ipynb```.
In ideas-and-feedback, at 2023-11-05 22:19:51 a user named enreee. said ```build an integrated materials/warehouse-like system for personal use```.
In ideas-and-feedback, at 2023-11-05 20:28:29 a user named esthereisenacher said ```I am currently exploring the coding examples```.
In ideas-and-feedback, at 2023-11-05 20:25:32 a user named sleepwave said ```The TeachableAgent is fascinating, I can't wait to see how it's memory is improved and how it differs and compares to MemGPT!```.
In ideas-and-feedback, at 2023-11-05 17:18:01 a user named litinit said ```I've been wondering for a while about how to effortlessly do data collection on myself, in order to properly train a me-bot (e.g. embedding myself into parameters)```.
In ideas-and-feedback, at 2023-11-05 17:05:34 a user named onecodescholar said ```I'd like to have more control of the agents and groups. have different groups for different real world tasks such as: posting, responding to emails and questions, write a full stack app and deploy to terraform and so on..  🙂```.
In ideas-and-feedback, at 2023-11-05 16:23:20 a user named jkorani said ```Does anyone have any good result using Local llms? I find it very difficult have it finish the simplest tasks running Zaphire beta.
Would love to know about your experience```.
In ideas-and-feedback, at 2023-11-05 12:38:39 a user named _taza_ said ```Agent with promptgenerator to generate group agent```.
In ideas-and-feedback, at 2023-11-05 10:37:34 a user named master_blaster123 said ```could we get a local LLM to be better at function calls by fine-tuning it more? And add self-reflection tokens in the FT, just like Self-RAG ?```.
In ideas-and-feedback, at 2023-11-05 08:07:41 a user named akman75 said ```Looking to build collective intelligence agents```.
In ideas-and-feedback, at 2023-11-04 23:38:32 a user named .ryannn said ```I wouldn't have the delusion that I'll be able to do any of this stuff before companies with billions in capital and workers can, but it sure is fun to think about.```.
In ideas-and-feedback, at 2023-11-04 12:51:50 a user named seishiro75001 said ```I'm in the process of building a personal chatbot with which I'll work daily on architecture-related topics.```.
In ideas-and-feedback, at 2023-11-04 11:24:17 a user named marshyon said ```I'm building 2nd brain(s) for myself and with others, some of my customers are building their own with my support. An ambition I had years ago was to leave this world having embedded myself into a chip and as firmware, a flippant thought but as time has gone on, AI and LLMs are starting to show promise in this area. I'm currently looking at a ( perhaps more realistic goal ) to create personalised on line and in app experiences, based upon 2nd brain data and ideas```.
In ideas-and-feedback, at 2023-11-04 10:09:34 a user named tonic_1 said ```and btw i'm pulling my hair trying to get this simple demo deployed on huggingface too, same bugs eitherway : https://huggingface.co/spaces/Tonic/GeneralistAutogenAgent```.
In ideas-and-feedback, at nan a user named tonic_1 said ```👋🏻👋🏻hey there autogen community , i recently stumbled on Semantic Kernel once again, and they have a fantastic hackathon ressource which i used to make this which is an autogen app that uses semantic kernel plugins based on the notebooks there : please take a look, i'd love more than feedback, i'd love a PR or some learnings to get rid of these bugs : https://github.com/Josephrp/LablabAutogen - beyond that i really think it would be very interesting to make a common event with these libraries and communities like semantic kernel , automl , autogen, (etc?) , maybe with "sector specific challenges" like ```integrate your favorite tool``` or ```use all the hackathon organiser's libraries``` or ```best data processing pipelines``` something like that , because i joined this lablab autogen one that ended yesterday it was a bit sad lol : https://lablab.ai/event/autogen-24-hours-hackathon/ and really autogen should start playing much better + more often with the MSFT research team libraries. We're really just scratching the surface of what we should be doing with these things, so that's why i ask 🚀```.
In ideas-and-feedback, at 2023-11-03 23:29:06 a user named jacek6859 said ```You made Collaboration flow. Was it generated from code, or designed earlier? Maybe it can be a sort of design tool?```.
In ideas-and-feedback, at 2023-11-03 23:08:53 a user named jacek6859 said ```Is there a data model of Autogen framework?```.
In ideas-and-feedback, at 2023-11-03 22:35:15 a user named srich12 said ```Could AutoGen be used to create complex full-stack apps based on any stack (for instance, the LAMP stack (JavaScript + Linux, Apache, MySQL, and PHP))? Perhaps one could embed a large wiki PDF (one for each language) into the pinecone vector database of the AI coding agent (to increase search speed by focusing on singular documents for code reference), and of course then breaking up different tasks for many different AI agents (front-end, back-end, coding, debugging, task management, optimization, etc.). Any thoughts?```.
In ideas-and-feedback, at 2023-11-03 22:24:46 a user named hewhocomethfromnyc said ```I am looking to build an pseudo-interface for AI Image Generation```.
In ideas-and-feedback, at 2023-11-03 17:09:53 a user named collinsemmanuel said ```i want to build a Saas agency```.
In ideas-and-feedback, at 2023-11-03 13:49:31 a user named bobaleaux said ```thought they might give you something to measure and compare your responses against.```.
In ideas-and-feedback, at 2023-11-03 13:47:53 a user named .moogin said ```seems dope but these are more like charts and biases, and articles I wanted convos to go discussing the biases and political leanings fundings etc, thanks tho```.
In ideas-and-feedback, at 2023-11-03 13:08:25 a user named bobaleaux said ```These sites might help in your efforts to determine bias 

https://www.their.news/

https://adfontesmedia.com/```.
In ideas-and-feedback, at 2023-11-03 03:57:08 a user named cihiris said ```I'd like to eventually build an app that allows you to convert most 3d formats to MMD/PMX automatically. It's such a hard, long tedious process and I've been having AI assist but this task is just still too hard and there's too much involved. So this is how I got hooked on AI (:```.
In ideas-and-feedback, at 2023-11-02 21:45:57 a user named airlights said ```Friday night powerchats  😄```.
In ideas-and-feedback, at 2023-11-02 20:31:57 a user named junkboi76 said ```Support for more languages like C# and C++```.
In ideas-and-feedback, at 2023-11-02 16:14:08 a user named chetvrp said ```a way of visualising all of the agents their paths they use of communication and what data they are transmitting between themselves```.
In ideas-and-feedback, at 2023-11-02 15:01:47 a user named .drak. said ```this channel quickly becoming "ur mom with autogen"```.
In ideas-and-feedback, at 2023-11-02 02:58:35 a user named .moogin said ```yo prof is it possible to analyse media outlets (say fox, wsj, nyt ...) realtime (text, articles etc) and get a Autogen generated inclination dialogue going, saying wsj is left biased because x y z etc. Is this a feasible idea for Autogen.```.
In ideas-and-feedback, at 2023-11-01 19:06:15 a user named digitalnimbus said ```So way back when HuggingGPT/JARVIS was dropped (Microsoft/JARVIS) I had already started work on a personal assistant that had plugin capabilities similar to chatGPT, but could integrate with other self-hosted apps (vikunja, gitlab, home assistant, rancher/harvester, etc). I'm still trudging through the agent frameworks to understand the components and ended up reinventing a lot of things that already exist, only worse. So now I'm in the process of refactoring the whole thing to use AutoGen+MemGPT but still trying to figure out how to integrate a hosted vector store like Weaviate or Milvus. I'm still learning how all the pieces fit together.```.
In ideas-and-feedback, at 2023-11-01 18:14:00 a user named jmsmall said ```Hey there! An app I'm building: I have a law practice with an AngularFire app for clients to build models of the facts of ttheir case. I'm tring to build a microservice with AutoGen to accomplish the creation of complex legal work product from that data.```.
In ideas-and-feedback, at 2023-11-01 18:11:41 a user named bz0b said ```i would love some feedback on a script i wrote with 6 assistant agents, 1 supervisor agent, 1  user proxy agent, fully hosted with local llm using dolphin 2.2.1 on LM studio```.
In ideas-and-feedback, at 2023-11-01 14:04:59 a user named Anxieties said ```hi, im new with the autogen staff and i wondering if its possible for the autogen to succeed a mission of analysing and predicting an upcoming soccer matches?```.
In ideas-and-feedback, at 2023-11-01 13:24:20 a user named tmyf_ said ```Hi, is it possible to use autogen to understand the pdf template, I provide the title/subject to the AI and ask the AI to generate a similar report based on the pdf template.```.
In ideas-and-feedback, at 2023-11-01 11:53:15 a user named bhavisha9921 said ```how can i make api based chatbot outof autogen?```.
In ideas-and-feedback, at 2023-11-01 06:24:06 a user named ctrl_alt.defeat said ```ahh! I have been trying to set this up since yesterday, was unable to! Hopefully this works, thanks!```.
In ideas-and-feedback, at 2023-11-01 03:58:32 a user named .hagarthehorrible said ```Feel like elaborating? Some of us might want to join you in that venture. That's if you feel like having company, of course.```.
In ideas-and-feedback, at 2023-10-31 22:16:34 a user named drinkoblog.weebly.com said ```https://www.youtube.com/watch?v=bMWXXPoDnDs```.
In ideas-and-feedback, at 2023-10-31 19:38:00 a user named xxpyroxxjonesxx said ```true local llm + memgpt + autogen?```.
In ideas-and-feedback, at 2023-10-31 17:50:14 a user named fabmendez said ```I'm building a creative agency```.
In ideas-and-feedback, at 2023-10-31 15:32:12 a user named sanimesa_03443 said ```I would like to build an app that can query an SQL database and respond to natural language questions from user```.
In ideas-and-feedback, at 2023-10-31 10:16:12 a user named mitchellr said ```nothing yet - required onboarding```.
In ideas-and-feedback, at 2023-10-31 08:29:32 a user named kajatta said ```Describe What is the worth of a single mortal life?```.
In ideas-and-feedback, at 2023-10-31 01:18:50 a user named qingyunwu said ```Oh, that makes sense. @karnival8, I just created a "jobs" (https://discord.com/channels/1153072414184452236/1168719200605437952 ) channel dedicated for conversations centered around hiring and job finding relevant to AutoGen. You can post your needs there.```.
In ideas-and-feedback, at 2023-10-31 00:33:58 a user named sonichi said ```I think the request is about hiring```.
In ideas-and-feedback, at 2023-10-31 00:29:53 a user named qingyunwu said ```You can go to the moderators or contributors for questions or post questions as issues on github.```.
In ideas-and-feedback, at 2023-10-30 20:57:01 a user named sonichi said ```yes, https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In ideas-and-feedback, at 2023-10-30 20:54:43 a user named justdoit1 said ```Question 🤔 do we have the ability to use openAI function calling feature in AutoGen?```.
In ideas-and-feedback, at 2023-10-30 19:22:25 a user named izzwizz75 said ```id like to build a dynamic case note taking web app incorporating machine learning to assist customer service agents take notes in a more productive and efficient manner```.
In ideas-and-feedback, at 2023-10-30 16:04:21 a user named karnival8 said ```What is the most appropriate way to find a full time developer familiar with AutoGen? Apologies in advance not sure where else to look.```.
In ideas-and-feedback, at 2023-10-30 14:23:24 a user named .hagarthehorrible said ```I want to build an app that decides who lives and who dies.😂```.
In ideas-and-feedback, at 2023-10-30 13:52:49 a user named MadVett  |  sheople said ```Hello! I'm Mathew, I want to put together to help me run my new consultation business where we help businesses integrate ai```.
In ideas-and-feedback, at 2023-10-30 08:57:04 a user named xuanwu_60471 said ```i want to build a personal assistant app with autogen```.
In ideas-and-feedback, at 2023-10-30 03:21:52 a user named ziggyzaggyinfinity said ```Interested in building an automatic code development end to end solution.```.
In ideas-and-feedback, at 2023-10-29 15:11:02 a user named sonichi said ```https://github.com/microsoft/autogen/blob/main/OAI_CONFIG_LIST_sample```.
In ideas-and-feedback, at 2023-10-29 14:00:37 a user named neverendinggrowth said ```where can I find OAI_CONFIG_LIST_sample??```.
In ideas-and-feedback, at 2023-10-29 13:35:45 a user named neverendinggrowth said ```I'd like to built app which will be creating custom wordpress websites based on design from client and some curated prompt. Second bigger project I want to create personal assistant which will be gathering all possible data from user (screen time, activities user spend his time on, sleep, nutrition, activity records, habits (in future measuring different levels of hormones and molecules from blood)). Then it will use this data to create optimal plan for user happiness, health and development```.
In ideas-and-feedback, at 2023-10-29 00:41:06 a user named m0bsta said ```fell into the checking out chrome extentions and tada```.
In ideas-and-feedback, at 2023-10-29 00:40:07 a user named m0bsta said ```i was just try to set it up with notion lol```.
In ideas-and-feedback, at 2023-10-29 00:39:22 a user named m0bsta said ```https://dashboard.eesel.ai/ this is like a rag chatbot i guess```.
In ideas-and-feedback, at 2023-10-29 00:31:21 a user named askofu said ```How did you build this and what data is loaded into it?```.
In ideas-and-feedback, at 2023-10-28 23:57:34 a user named aaronward_ said ```I'm working on something that will allow you to evaluate your autogen applications given different hyper-paremeters (eg: temprature, different embeddings, prompt templates, agent types etc.) - will share when it's cleaned up and a few bugs are cleared up```.
In ideas-and-feedback, at 2023-10-28 23:18:56 a user named m0bsta said ```it's ok for basic stuff i almost had it ingest the github proper lol```.
In ideas-and-feedback, at 2023-10-28 23:18:16 a user named m0bsta said ```ASK it what code you need tho```.
In ideas-and-feedback, at 2023-10-28 23:13:04 a user named m0bsta said ```OH GOD I MESSED UP LOL; you guys can have this it's all autogen knowledge https://dashboard.eesel.ai/public-chat?namespace=e2c1813e-f5bb-4a19-81dc-b65b9396c5c5&palette=%7B%22primary%22%3A%22%238c21e4%22%2C%22secondary%22%3A%22%23F3F4F6%22%7D&title=autogen%20Knowledge%20%E2%80%A2%20by%20Mobsta%E2%84%9E%20%40mobstarx.com&customError=Sorry%2C%20I'm%20unable%20to%20answer%20that.%20Try%20rephrasing%20your%20question%20or%20reach%20out%20to%20support.&welcomeMessage=%F0%9F%91%8B%20Hi!%20How%20can%20I%20help%20you%20today%3F&suggestQuestion=true```.
In ideas-and-feedback, at 2023-10-28 16:29:48 a user named trtfx1 said ```"You are a professional sports analyst. You compare statistics between teams and make a judgement call on who is more likely to win. When you are provided data for a team, you are to analyze it, step by step, and get an idea of the teams performance to compare to the other teams set of data. You will be provided two files, one for each team. You will make sure to note injuries, what positions they play, and what that means for the teams performance. Always try and look for hidden strengths and weaknesses based on the most recent games or data. 

Each html file has multiple charts to extract. Pay attention to this and focus on the charts only."

This is my custom output for analyzing sports stats. I save whole webpages and upload them.```.
In ideas-and-feedback, at 2023-10-28 16:29:16 a user named trtfx1 said ```its going to be used with it though eventually```.
In ideas-and-feedback, at 2023-10-28 16:29:04 a user named trtfx1 said ```can I post not autogen stuff in here?```.
In ideas-and-feedback, at 2023-10-28 10:11:39 a user named xvarunx said ```Please do something so I can talk my whole code base, and then when GPT has a recommendation, it directly pastes it back in the line or the fiction instead of writing the entire thing again```.
In ideas-and-feedback, at 2023-10-27 21:54:49 a user named c_bonadio said ```Autogen with FastApi backend and React frontend
https://github.com/bonadio/autogenwebdemo```.
In ideas-and-feedback, at 2023-10-27 20:04:43 a user named cpro1947 said ```personal automation with small bots```.
In ideas-and-feedback, at 2023-10-27 19:55:34 a user named hahl9000 said ```PLZ! Need some help finding the correct approach for agent with RAG capabilities from files or db in a mix of non-RAG agents that can run code and output files for eg. Excel. I’ve seen the code for rag agents but how do I implement reading from data? Does anyone have code for this? I’m also wondering if someone have a use-case for autogen controlling applications on computer? 

Have an awesome weekend folks! 🎃```.
In ideas-and-feedback, at 2023-10-27 19:41:53 a user named mudit.b07 said ```Multi-agent bots for the flights issue reduction```.
In ideas-and-feedback, at 2023-10-27 18:57:33 a user named telepathyx said ```https://github.com/THUDM/AgentTuning this looks promising to counteract the rumored anti-agentic passive behavior trained into openai models```.
In ideas-and-feedback, at 2023-10-27 17:20:44 a user named das_search said ```Wip agent and project generation using auto gen templates and gpt 4 as main logic after parsing```.
In ideas-and-feedback, at 2023-10-27 17:19:09 a user named das_search said ```I absolutely love llm and autogen 
So I started a Lil quick project on my lunch break```.
In ideas-and-feedback, at 2023-10-27 17:17:11 a user named das_search said ```https://github.com/Nbtguyoriginal/Pybonce```.
In ideas-and-feedback, at 2023-10-27 16:15:20 a user named frank.martinez said ```Here’s @biggboii. video on MemGPT; believe he has a repo in the details https://youtu.be/QCdQe8CdWV0?si=iXgm-gs6hN7O4vuG```.
In ideas-and-feedback, at 2023-10-27 16:12:27 a user named trtfx1 said ```I’ll educate myself more on nfl side. Someone just mentioned they are slowly using ai more for plays.```.
In ideas-and-feedback, at 2023-10-27 16:11:40 a user named trtfx1 said ```I don’t think it’s as good. I’ve just tested it out a few times with open source stats. There is a comprehensive amount, but I hear nfl has more.```.
In ideas-and-feedback, at 2023-10-27 16:09:28 a user named ctrl_alt.defeat said ```cant find this repo on github 
pyreader

can you please share it with me? @das_search```.
In ideas-and-feedback, at 2023-10-27 16:09:28 a user named frank.martinez said ```does the NHL have an equivalent to the NFL player stats system; i.e. PFF?```.
In ideas-and-feedback, at 2023-10-27 16:09:09 a user named ctrl_alt.defeat said ```thanks @frank.martinez and @das_search 😄```.
In ideas-and-feedback, at 2023-10-27 15:52:08 a user named trtfx1 said ```Any ideas how to grab the data from websites parse it etc? I will try when I get home a few things.```.
In ideas-and-feedback, at 2023-10-27 15:51:29 a user named trtfx1 said ```One team it picked was not the fav and they won.```.
In ideas-and-feedback, at 2023-10-27 15:49:00 a user named trtfx1 said ```I have been only choosing teams with a big advantage.```.
In ideas-and-feedback, at 2023-10-27 15:48:12 a user named trtfx1 said ```I’ve been pulling nhl stats and data into gpt to give best guesses on game winners of upcoming matchups. I add in the variable data like injuries etc. it’s been VERY accurate. 5 for 5 so far. I want to use auto gen to grab the data analyze it converse about the variables, weight them, and give me an output of where each team is at.```.
In ideas-and-feedback, at 2023-10-27 14:08:12 a user named amadad said ```In trying to build out Agentcy (https://github.com/amadad/agentcy) would love to hear best practices on:
1. Constructing multiple groupchats, ie. 1: A, B, C, D; 2: A, A', A'', A'''; 3: B', B'', B''', etc.
2. Adding functions to single vs multiple llm_config specs; when to use register_function```.
In ideas-and-feedback, at 2023-10-27 09:20:30 a user named das_search said ```Can be done using memgpt and some interesting prompting methods 
See  pyreader on github for an example of long term context-aware analysis```.
In ideas-and-feedback, at 2023-10-27 08:36:11 a user named riverlay said ```Why don't we utilize autogen framework simulate an autogen UI development team to develop an official agent conversion interface/frontend? From my POV,  this would serve as a far superior example or proof-of-concept compared to the existing examples. 😀```.
In ideas-and-feedback, at 2023-10-27 07:14:20 a user named dkut said ```something like rewind.ai but better```.
In ideas-and-feedback, at 2023-10-26 21:14:00 a user named ctrl_alt.defeat said ```an app i would like to build:
i want to build an agent which can engage in a long term conversation with a user about different developer documentations (langchain, llamaindex, etc)
it should remember my long term preferences and respond with latest updated API reference and documentation to help debug, develop, test code.
a developer assistant AI agent.

would be really helpful if anyone that resonates with this, point me in some interesting directions.```.
In ideas-and-feedback, at 2023-10-26 20:16:08 a user named bobaleaux said ```yeah, well, sure thing. ok, obscure random discord message```.
In ideas-and-feedback, at 2023-10-26 19:57:47 a user named .moogin said ```yeah right as if I am gonna spend "time" on going through obscure random discord messages trying to find stuff out, rather than simply ask for it. This ain Dora the explorer my man boba```.
In ideas-and-feedback, at 2023-10-26 19:52:40 a user named bobaleaux said ```If you’ll take the weekend and go back and read through the different channels, the ideas, use cases and overall community involvement, I think you’ll come away with the big intro of what it is and maybe shed some light to help answer to your question about its popularity.
That was my initial effort when I started out with to “drink from a firehouse” and quickly get my head around it.```.
In ideas-and-feedback, at 2023-10-26 16:45:42 a user named .sudb said ```Have done something similar but diverging a bit to try to be more API friendly: https://github.com/Engine-Labs/engine-agents```.
In ideas-and-feedback, at 2023-10-26 15:34:40 a user named ramen_d said ```Hi All - Great library here!  but got hit with a large bill from Azure OpenAI.  Wow, my fault for not creating a budget.

Any idea if there is a possibility of a budgeting agent?```.
In ideas-and-feedback, at 2023-10-26 14:38:22 a user named glassesstrap said ```an app you can feed in different personalities and then get them talking to each other.```.
In ideas-and-feedback, at 2023-10-26 13:21:41 a user named .moogin said ```We need a big intro of what Autogen is and why it is so popular on LinkedIn and everywhere```.
In ideas-and-feedback, at 2023-10-26 04:56:56 a user named harmonyzen1717 said ```I would like to request more documentation on config.

I created a config with values that I already had in a dict. I didn't use the functions. I hope my dict works....I'm debugging other bits atm.```.
In ideas-and-feedback, at 2023-10-25 23:20:17 a user named wladpaiva said ```I'm working on a multi-agent conversation framework like autogen in Typescript. Check it out
https://github.com/wladiston/aibitat```.
In ideas-and-feedback, at 2023-10-25 23:08:00 a user named frank.martinez said ```Happy to help; love that goal```.
In ideas-and-feedback, at 2023-10-25 23:02:48 a user named impactcare said ```I want to build a Mobile automated EHR with no required manual user input outside of data verification and provide it free to my nonprofit company who pays over 100k month for a 10k member SQL database and a basic EHR GUI, Thievery! I want to relieve the nurses, care providers, and all the other support staff I have been supporting behind the scenes in IT for 18 years. We can fix this and I believe with AI, with incredible speed.```.
In ideas-and-feedback, at 2023-10-25 15:52:03 a user named wyang14 said ```I'd like to see AI agents that collaborate and develop web app.```.
In ideas-and-feedback, at 2023-10-25 15:51:15 a user named groundzer000 said ```where is that channel now?```.
In ideas-and-feedback, at 2023-10-25 15:00:38 a user named dbscan said ```Hey All. I am a newbie to this and am trying to figure out how to use Autogen and possibly semantic kernel to convert one of our old codebases from R to python. I would really appreciate an ideas on how to set up the agents. Thanks```.
In ideas-and-feedback, at 2023-10-25 14:02:46 a user named cyberjunk said ```Hi guys!

Is there any chance that Autogen will have typescript version?```.
In ideas-and-feedback, at 2023-10-25 12:57:04 a user named bobaleaux said ```I just put a simple Agent Code Builder using Streamlit in the tutorials-and-examples channel```.
In ideas-and-feedback, at 2023-10-25 11:42:28 a user named fxtoofaan said ```is this your image on docker hub? https://hub.docker.com/r/rnadig/agentcloud```.
In ideas-and-feedback, at 2023-10-25 11:38:35 a user named fxtoofaan said ```ok will try now then report back```.
In ideas-and-feedback, at 2023-10-25 11:38:23 a user named ragyabraham said ```But yes that should do it```.
In ideas-and-feedback, at 2023-10-25 11:38:10 a user named ragyabraham said ```Yeah that’s correct. Obviously replace the env variables in docker-compose yaml with your api keys etc```.
In ideas-and-feedback, at 2023-10-25 11:37:23 a user named fxtoofaan said ```so i pull whole repo down and then just run docker-compose up in the pulled repo folder ?```.
In ideas-and-feedback, at 2023-10-25 11:36:03 a user named fxtoofaan said ```can I use your app in portainer? i've got that loaded up now in my synology nas```.
In ideas-and-feedback, at 2023-10-25 11:34:46 a user named ragyabraham said ```But you’ll need to copy the env variables from the docker-compose into independent.env files```.
In ideas-and-feedback, at 2023-10-25 11:34:08 a user named ragyabraham said ```For agent-backend you’ll need to do poetry install then poetry run python3 main.py```.
In ideas-and-feedback, at 2023-10-25 11:33:07 a user named ragyabraham said ```For the webapp you’ll need to do npm install then npm run dev```.
In ideas-and-feedback, at 2023-10-25 11:32:50 a user named fxtoofaan said ```I dont see any install instructions for agentcloud or webapp or agent-backend.```.
In ideas-and-feedback, at 2023-10-25 11:31:38 a user named ragyabraham said ```@fxtoofaan No you can run each app independently```.
In ideas-and-feedback, at 2023-10-25 11:29:45 a user named fxtoofaan said ```is docker the only way to run agentcloud? can I set it up in a venv type setup? I am trying to stay away from docker, its a heavy application IMO for windows environment.```.
In ideas-and-feedback, at 2023-10-25 10:33:15 a user named jannis3643 said ```Interested in many things but I want to use autogen to give users aid navigating a complex UI.```.
In ideas-and-feedback, at 2023-10-25 09:37:31 a user named fxtoofaan said ```I’ll try it as well. Been looking for gui or wizard to create the autogen agents```.
In ideas-and-feedback, at 2023-10-25 09:28:53 a user named rushout09 said ```This cool app helps you validate your b2b saas idea. https://loveb2bsaas.discoze.com/```.
In ideas-and-feedback, at 2023-10-25 07:23:29 a user named john.jeong said ```I think that there is a tradeoff for an agent to be fully autonomous or dependent on the user. There seems to be a sweet spot. Most of the case when you just let it go own its own, you get ridiculous results. Not because it doesn't perform well, but it doesn't have enough information regarding the given goal. It should at least be relevant to actually make use of it. So to wrap up, one would need to provide sufficient information in order to receive useful results.```.
In ideas-and-feedback, at 2023-10-25 05:11:05 a user named sidhujag said ```imo the agents should emerge behaviour on their own given the tools, dependency, plan or whatever goal```.
In ideas-and-feedback, at 2023-10-25 02:49:15 a user named john.jeong said ```I think that from a human's POV, the execution phase for multi-agent systems can be segmented into three parts.
1. Dialogue with the user for goal specification. Let us define goal as a task structure with dependencies(or not if single). Shen et al proposed a nice framework for this in Fig 1.
2. Task execution using built-in modules or 3rd party tools.
3. Summarization of the results from all the tasks executed.
However, I think that iteration upon the final output is also crucial when it comes to these systems. Right now, you just have live with it.
-
[1] https://arxiv.org/pdf/2303.17580.pdf```.
In ideas-and-feedback, at 2023-10-25 02:22:11 a user named john.jeong said ```I think that multi-agent systems are going to be the backbone of AGI. My co-founder and I have been looking into various frameworks and reading a lot of papers find where to start building upon. After doing a lot of research, AutoGen seems to be the most promising! We'll be sure to showcase our personal assistant called [ASQ](https://justasq.it/), from time to time.```.
In ideas-and-feedback, at 2023-10-25 01:00:44 a user named ragyabraham said ```feel free to DM if you run into any issues```.
In ideas-and-feedback, at 2023-10-25 01:00:12 a user named robin_saunders said ```Opened it in a new tab so I won't forget 😄```.
In ideas-and-feedback, at 2023-10-25 00:59:35 a user named robin_saunders said ```I gotta run but I'll take a deeper look tomorrow!```.
In ideas-and-feedback, at 2023-10-25 00:55:17 a user named ragyabraham said ```https://github.com/rnadigital/agentcloud/blob/416900ced910e43c22534fb911a4eb16abf6a0a1/agent-backend/src/agents/base.py#L41C54-L41C54```.
In ideas-and-feedback, at 2023-10-25 00:55:03 a user named ragyabraham said ```So the interesting discovery here is that in order for the planner to allocate task correctly it needs to be explicitly given it's team members and their skills/responsabilities. So at runtime, after the team is formulated we utilise the `update_system_message` method to get the team members and make the planner aware of who is actually on the team```.
In ideas-and-feedback, at 2023-10-25 00:52:34 a user named robin_saunders said ```So are you overriding the manager then with your own solution to fix that?```.
In ideas-and-feedback, at 2023-10-25 00:51:10 a user named ragyabraham said ```to a large extent yes we have added a few things to autogen such as `socketio` support```.
In ideas-and-feedback, at 2023-10-25 00:51:01 a user named robin_saunders said ```the manager component in autogen like the other guy was saying was incorrectly selecting what agents to use```.
In ideas-and-feedback, at 2023-10-25 00:50:25 a user named robin_saunders said ```Ah this is a wrapper?```.
In ideas-and-feedback, at 2023-10-25 00:49:14 a user named ragyabraham said ```you'll need to pull `rnadigital/agentcloud````.
In ideas-and-feedback, at 2023-10-25 00:48:36 a user named robin_saunders said ```I haven't pulled the latest version, saw you mentioning earlier that you fixed the manager stuff, so if I pull autogen your update here is integrated already?```.
In ideas-and-feedback, at 2023-10-25 00:48:02 a user named ragyabraham said ```This platform is very much a GUI for autogen```.
In ideas-and-feedback, at 2023-10-25 00:47:28 a user named robin_saunders said ```is this seperate to autogen? or is this the manager component in autogen?```.
In ideas-and-feedback, at 2023-10-25 00:46:38 a user named robin_saunders said ```and is it possible to "hardcode" a circular path for logic like I was thinking, where we can drive it through a set of agents in forced order?```.
In ideas-and-feedback, at 2023-10-25 00:46:28 a user named ragyabraham said ```https://github.com/rnadigital/agentcloud/blob/416900ced910e43c22534fb911a4eb16abf6a0a1/agent-backend/src/agents/base.py#L29C14-L29C14```.
In ideas-and-feedback, at 2023-10-25 00:45:30 a user named robin_saunders said ```@ragyabraham where is this in the code base? I'd like to take a look```.
In ideas-and-feedback, at 2023-10-25 00:44:39 a user named sidhujag said ```I get why it’s done.. because there’s no control loop native to agents.. there’s no total ownership but if they can hierarchically order within groups then I think top down no problem with keeping things going until top group is happy with. Answer```.
In ideas-and-feedback, at 2023-10-25 00:44:06 a user named robin_saunders said ```Ah, I haven't had that problem. I was having more problems with errors killing the program because of how the local LLM's interact with autogen (since I don't want to be testing with chatgpt paying $$$)```.
In ideas-and-feedback, at 2023-10-25 00:43:50 a user named ragyabraham said ```and it often gets stuck on the same issue```.
In ideas-and-feedback, at 2023-10-25 00:43:42 a user named ragyabraham said ```yeah it gets a bit wild```.
In ideas-and-feedback, at 2023-10-25 00:43:25 a user named sidhujag said ```Either asks user for feedback or it’s done waiting for next input```.
In ideas-and-feedback, at 2023-10-25 00:43:20 a user named robin_saunders said ```I was watching it start to ask itself new questions when I let it run long enough lol```.
In ideas-and-feedback, at 2023-10-25 00:43:05 a user named sidhujag said ```Keep alive until it thinks problem solved, given back to user```.
In ideas-and-feedback, at 2023-10-25 00:42:59 a user named ragyabraham said ```i think a framework to prevent reduce circular convos would be very helpful```.
In ideas-and-feedback, at 2023-10-25 00:42:42 a user named sidhujag said ```It has group LLM inference to keep alive which seems hack```.
In ideas-and-feedback, at 2023-10-25 00:42:18 a user named ragyabraham said ```tbh i haven't experienced chat diying but i have on many occassion seen tha chat become extremely circular```.
In ideas-and-feedback, at 2023-10-25 00:42:08 a user named robin_saunders said ```What's the purpose of keeping it alive if the task is done? Are you thinking like, letting it evolve?```.
In ideas-and-feedback, at 2023-10-25 00:41:37 a user named sidhujag said ```Worsed case user can always send msg to say hey, where we at?```.
In ideas-and-feedback, at 2023-10-25 00:41:00 a user named sidhujag said ```Maybe it can emerge with unique strategies to keep program alive```.
In ideas-and-feedback, at 2023-10-25 00:40:33 a user named sidhujag said ```Yea that’s what I’m doing in my prompt I haven’t tested it yet, but it’s allowed to send message and to group manager who sends to everyone else, I tell that if you don’t reply or keep going in a group then it will die```.
In ideas-and-feedback, at 2023-10-25 00:40:09 a user named robin_saunders said ```ah you're thinking larger scope?```.
In ideas-and-feedback, at 2023-10-25 00:39:46 a user named sidhujag said ```Pass control or manage the control, emergent behaviour to keep control alive```.
In ideas-and-feedback, at 2023-10-25 00:39:44 a user named robin_saunders said ```like, telling it start coder, go to critic, go to QA, check with user-agent, go back to coder if required, loop```.
In ideas-and-feedback, at 2023-10-25 00:39:24 a user named sidhujag said ```Some idea to keep control loop alive or the program dies```.
In ideas-and-feedback, at 2023-10-25 00:39:04 a user named robin_saunders said ```A pre-defined ruleset for who talks to what?```.
In ideas-and-feedback, at 2023-10-25 00:38:49 a user named robin_saunders said ```and I think I understand what you're saying```.
In ideas-and-feedback, at 2023-10-25 00:38:38 a user named robin_saunders said ```Was reading what you were suggesting```.
In ideas-and-feedback, at 2023-10-25 00:37:37 a user named sidhujag said ```It feels like a hack to ask LLM to ask who next speaker should be```.
In ideas-and-feedback, at 2023-10-25 00:36:12 a user named sidhujag said ```I imagine a control loop to exist similarily```.
In ideas-and-feedback, at 2023-10-25 00:35:44 a user named sidhujag said ```Imagine a control loop for a main program```.
In ideas-and-feedback, at 2023-10-25 00:35:35 a user named sidhujag said ```Can there not be another way to track group convo control?```.
In ideas-and-feedback, at 2023-10-25 00:33:18 a user named dulak said ```I'll pull and try it out tomorrow and will let you know 😄```.
In ideas-and-feedback, at 2023-10-25 00:33:10 a user named dulak said ```been a long day hahaha```.
In ideas-and-feedback, at 2023-10-25 00:32:56 a user named dulak said ```Ahh I was having this problem 6ish hours ago```.
In ideas-and-feedback, at 2023-10-25 00:32:42 a user named ragyabraham said ```late last night sydney time```.
In ideas-and-feedback, at 2023-10-25 00:32:28 a user named dulak said ```oh really? how recently? that's awesome```.
In ideas-and-feedback, at 2023-10-25 00:32:15 a user named ragyabraham said ```Yes, we pushed a change that fixed that. Just pull the latest and that should be resolved, If you continue to have issue feel free to DM me```.
In ideas-and-feedback, at 2023-10-25 00:31:22 a user named dulak said ```Yea, I'm running into problems where the manager doesn't correctly select the agent. Example, I'll have a coder and a critic, and it'll tell the critic to make code which poops out a huge longwinded explaination for why hello world works.

That and I'm not sure which agent it selects sometimes and it woul dbe nice to keep track```.
In ideas-and-feedback, at 2023-10-25 00:28:22 a user named sidhujag said ```Nice, so it does an auto agent style consensus on the team, roles and functions ? That’s good. In mine it should message others, discover agents and functions and add them then create agents that don’t exist and also create groups and invite agents```.
In ideas-and-feedback, at 2023-10-25 00:25:56 a user named ragyabraham said ```What is hardcoded is the team-generation team and instructions```.
In ideas-and-feedback, at 2023-10-25 00:25:34 a user named ragyabraham said ```Currently we pass it a JSON structure that resembles a example team and we ask the agent to formulate the "ideal team to undertake said task and return team in the above JSON format"```.
In ideas-and-feedback, at 2023-10-25 00:22:02 a user named sidhujag said ```That’s cool so how does it assemble a team? What’s hard coded and what is dynamic or emergent? I ask because I’m create a different group chat with functions so agents can explore without guiding them specifically on ordering of what is needed or what’s not in an organizational structure```.
In ideas-and-feedback, at 2023-10-25 00:14:45 a user named ragyabraham said ```@groundzer000 not at the moment but we are working on enabling the choice of LLM including utilising local/custom model @dulak @semi2995```.
In ideas-and-feedback, at 2023-10-25 00:13:53 a user named ragyabraham said ```@dulak as in you want to print manager's messages to terminal??```.
In ideas-and-feedback, at 2023-10-25 00:13:03 a user named ragyabraham said ```@sidhujag  The workflow right now is:

1. a task is passed to `team-generation` team 
2. based on the task,  `team-generation` team actually creates the "ideal" team to undertake the task (so we are actually using autogen to formulate the team)
3. The user can give feedback to autogen to augment the team if they wish
4. Once the user is happy with the team they type `exit`  (it's a bit *unintuitive* i know, we're working on changing this) which end the team generation step and immediately initiates `task-execution`
5. using the newly formulated team the task is then undertaken using standard autogen workflow```.
In ideas-and-feedback, at 2023-10-24 23:58:51 a user named ragyabraham said ```Yes we are working on a tutorial and will post in <#1161015724521836634>  soon @sonichi```.
In ideas-and-feedback, at 2023-10-24 22:00:17 a user named semi2995 said ```hey, is there custom models available to be added or?```.
In ideas-and-feedback, at 2023-10-24 19:03:28 a user named dulak said ```Is there a way to output the manager's messages to the agents in my logs?```.
In ideas-and-feedback, at 2023-10-24 16:07:10 a user named groundzer000 said ```hi there very nice job, can we use LM STUDIO with it when using locally ?```.
In ideas-and-feedback, at 2023-10-24 13:54:55 a user named sidhujag said ```https://github.com/rnadigital/agentcloud/blob/master/agent-backend/src/config/base.json it always starts with these agents and then up to user to add more to teams?```.
In ideas-and-feedback, at 2023-10-24 13:29:25 a user named sonichi said ```@jasonzhou1993 has a cool tutorial using sd https://discord.com/channels/1153072414184452236/1163461758124568627```.
In ideas-and-feedback, at 2023-10-24 13:27:11 a user named eavanvalkenburg said ```are there already samples with dalle or other image generation tools integrated as well?```.
In ideas-and-feedback, at 2023-10-24 13:23:42 a user named sonichi said ```Interesting. Would you like to post in <#1161015724521836634> ?```.
In ideas-and-feedback, at 2023-10-24 12:15:09 a user named woodynz9000 said ```Hi, if you mean SCADA and PLC , Agents shouldn't be anywhere near them.```.
In ideas-and-feedback, at 2023-10-24 11:21:11 a user named revers101 said ```I like to build a constitutional system, which operates autonomously inside of the energy sector. I would like to heaven multilayer approach of every assets has his own management system, integrated into eight Skarda or PLC system.```.
In ideas-and-feedback, at 2023-10-24 09:40:04 a user named none3008 said ```try integrate llm and autogen```.
In ideas-and-feedback, at 2023-10-24 09:17:58 a user named ydj235 said ```There are no practical examples of communities that are better off with code```.
In ideas-and-feedback, at 2023-10-24 09:17:16 a user named ydj235 said ```Add some more example documents
I want to make an app that can let a person simulate a company```.
In ideas-and-feedback, at 2023-10-24 09:12:44 a user named 1fab2 said ```Integration with memGPT or other technologies to increase context window / I' dlike to build a virtual workforce of specialist for various applications.```.
In ideas-and-feedback, at 2023-10-24 08:21:10 a user named ragyabrah said ```Hey @murculu we have just released a web app for interfacing with autogen, we are calling it AgentCloud. Learn more here https://www.agentcloud.dev/```.
In ideas-and-feedback, at 2023-10-24 04:25:57 a user named da0papi said ```this function is part of the new autogen release```.
In ideas-and-feedback, at 2023-10-24 03:23:32 a user named akrabulislam said ```🚀 Exciting News from Somykoron! 🤖

As a co-founder of Somykoron, I'm thrilled to share that we are now offering our MVP (Minimum Viable Product) service to the community. Our mission is to help you harness the potential of cutting-edge technology. 🌐

🤝 Join us on this journey by exploring our MVP service on [Fiverr](https://www.fiverr.com/adapt_ai?up_rollout=true) and stay updated on LinkedIn: [Somykoron LinkedIn Page](https://www.linkedin.com/company/somykoron/?viewAsMember=true). Let's shape the future of AI together! 💼💡

#Somykoron #AI #MVPService #AIInnovation #Fiverr```.
In ideas-and-feedback, at 2023-10-24 01:18:15 a user named benbarnard said ```I'm a low-code guy and really want to merge Autogen and things like n8n```.
In ideas-and-feedback, at 2023-10-23 19:07:23 a user named frank.martinez said ```https://docs.n8n.io/langchain/langchain-n8n/#cluster-nodes```.
In ideas-and-feedback, at 2023-10-23 19:07:22 a user named frank.martinez said ```Related; really like how n8n thinks about the interface flow in | out of agents...```.
In ideas-and-feedback, at 2023-10-23 17:41:00 a user named artificialbeauties said ```wow thank you this is interesting !```.
In ideas-and-feedback, at 2023-10-23 17:16:24 a user named frank.martinez said ```Would love to see a tutorial on using this with Autogen; documentation suggests an agent abstraction is needed for every Autogen agent... also not clear where use of tools/external APIs fit in the abstraction```.
In ideas-and-feedback, at 2023-10-23 16:58:57 a user named sonichi said ```track in https://github.com/microsoft/autogen/issues/236```.
In ideas-and-feedback, at 2023-10-23 16:21:18 a user named artificialbeauties said ```i'm interested in builduing a process that will create image concepts and create prompts for stable diffusion to create those images, so basically i want to wutomate my stable diffusion workflow with AI agents```.
In ideas-and-feedback, at 2023-10-23 16:17:45 a user named samusarmiento_ said ```you can check https://www.agentlabs.dev/```.
In ideas-and-feedback, at 2023-10-23 16:00:55 a user named gofman2 said ```Where I can find existing examples with autogen?```.
In ideas-and-feedback, at 2023-10-23 14:57:52 a user named shivamklr said ```Is there a way to use Autogen with javascript/node.js anytime soon?```.
In ideas-and-feedback, at 2023-10-23 14:39:17 a user named _darthvidar said ```it would be great to have a feature where Autogen evaluates which LLM/API to query based on the complexity of the request, in an effort to use expensive APIs such as Gpt-4, only when needed.```.
In ideas-and-feedback, at 2023-10-23 00:09:16 a user named ehehbogballs said ```So as someone that worked in SEO a few moons ago...actaully starting off too many moons ago in the 90's, well  one thing I was playing around with was the removal of all the stopwords in prompts and then a simple precursory notice in any subsequent prompts to tell the model that the stopwords were removed to see what effect this had on the models output. My results as far as I can see are up to a 30% reduction in tokens and almost no effect I can see on the models output (so long as its pre-prompted to TELL IT that stopwords have been removed) This looks like a reletively simple thing to incorporate in the app right? Doesn't even rely on the model to remove the stopwords since nltk can do all that. It does not seem to have the outsized effect on the model one might suppose. More than that, if one runs a loop on the content you can choose to remove more or less stopwords.... say every third one, or fifth one... which is what I'm doing right now manually to see if I can identify a sweet spot where the overall contextual pattern is affected almost zilch, yet I save as much token space as I can.```.
In ideas-and-feedback, at 2023-10-22 23:11:07 a user named frank.martinez said ```yes; see Tutorials and Examples for a few projects with frontends```.
In ideas-and-feedback, at 2023-10-22 23:05:17 a user named murculu said ```Has anyone tried building a web app for general interfacing with autogen? Like creating agents, groups and managers, providing OAI_API_KEY and prompting group tasks. Haven't found much, just a simple demo (https://huggingface.co/spaces/thinkall/autogen-demos) that errors for me. Any idea what would be the challenges of building such app?```.
In ideas-and-feedback, at 2023-10-22 22:46:17 a user named andrewboudreau said ```is there any gui for the autogen configs?```.
In ideas-and-feedback, at 2023-10-22 16:20:26 a user named qingyunwu said ```Did you check AutoGen's a built-in logging mechanism  https://microsoft.github.io/autogen/docs/Use-Cases/enhanced_inference#logging-experimental```.
In ideas-and-feedback, at 2023-10-22 15:08:32 a user named wchadly said ```curious if/how people are logging the LLM prompts for debugging purposes.
I know it logs the conversation in the console, but I'm talking about all the system messages and whatnot as well```.
In ideas-and-feedback, at 2023-10-22 14:14:14 a user named sonichi said ```Is this posted to <#1161015724521836634>```.
In ideas-and-feedback, at 2023-10-22 13:39:16 a user named Tgriffith3433 said ```wondering if there will by a typescript implementation down the line for those of us too old and stupid to learn python? lol```.
In ideas-and-feedback, at 2023-10-22 13:34:27 a user named vladimir.v.krylov said ```app to manage human plus AI software developers team```.
In ideas-and-feedback, at 2023-10-22 12:10:14 a user named allanscherger said ```prediction: tracebacks and stack traces will morph to be more helpful to agents in the future. or, there will be agents that specialize in reading these.```.
In ideas-and-feedback, at 2023-10-22 12:00:02 a user named m_j_r said ```it seems like we're all recycling a process of costly inference for knowledge that isn't novel compared to realworld conditions. what are the leading examples of a global db w/ vectorized knowledge, skills, and tools? that seems like the best scaffold for rapid iteration & curation of compounding knowledge/agency```.
In ideas-and-feedback, at 2023-10-22 11:38:00 a user named ekitkin said ```I’d like to build a semi-automated hypercasual game development studio```.
In ideas-and-feedback, at 2023-10-22 10:10:08 a user named .byzantinesoul said ```Chat bot with a large memory, broken into long term and short term  memory as necessary```.
In ideas-and-feedback, at 2023-10-22 07:51:39 a user named mattchbo said ```I would like to have basically a clone of the functionality of open interpreter available easily through autogen. I would like chatgpt (or bard) to easily access many of my local files without forgetting them, and be able to assist more easily / edit my code directly in the file I'm working on. ChatGPT Advanced Data Analysis can do some of this, but I would prefer something that runs locally and can easily access files on my Desktop / Documents etc. I would also like to be able to pipe information to chatgpt in my terminal, or vice versa.```.
In ideas-and-feedback, at 2023-10-22 07:30:23 a user named jinx8436 said ```hello everyone,i want to build a assistant agent that can directly get the recquired information from the apis like google trends,semrush etc,can anyone can help me how can i do this?```.
In ideas-and-feedback, at 2023-10-22 01:36:24 a user named chaotalks said ```when I used gpt3.5 with autogen, the assistant and the user seem not able to close their conversation and keep saying kind words to each other until I manually shutdown the script 😀```.
In ideas-and-feedback, at 2023-10-22 00:47:36 a user named remy8432 said ```I have a simple python bot that I have been using with OpenAI API to do simple automation tasks with my Home Assistant server.  I'm hoping to use AutoGen to perform more complicated actions and also make the system more cookie-cutter```.
In ideas-and-feedback, at 2023-10-21 18:02:57 a user named dp1310 said ```Interested to learn possibilities of AI```.
In ideas-and-feedback, at 2023-10-21 17:10:27 a user named romillyc said ```Llama.cpp python binding works well for me.```.
In ideas-and-feedback, at 2023-10-21 08:34:42 a user named jamesdev184 said ```Would like to implement multiple agents to build a product```.
In ideas-and-feedback, at 2023-10-21 08:31:56 a user named cepe1978 said ```A integration example with https://github.com/agentlabs-inc/```.
In ideas-and-feedback, at 2023-10-21 06:29:32 a user named ludyz said ```Looking at integrating my langchain bots I have already made through flowise as the agents```.
In ideas-and-feedback, at 2023-10-21 04:43:08 a user named asolis_dev said ```It would be great to see more examples```.
In ideas-and-feedback, at 2023-10-21 03:57:06 a user named modularsushi168 said ```Autogen should be compatible with Radius.```.
In ideas-and-feedback, at 2023-10-20 20:39:20 a user named einarr007 said ```The proposal is that based on this paper https://arxiv.org/abs/2310.08560, it would be to use "reminders" to store specific data, on specific dates. Example telling the AI that on the date '08/22/2024' say happy birthday or save things that the AI can never do without defining the date such as never deleting the sales database table```.
In ideas-and-feedback, at 2023-10-20 18:18:53 a user named bbderoff said ```building an app with a PAWN variety for IoT```.
In ideas-and-feedback, at 2023-10-20 17:45:00 a user named trader_pt said ```That is good advice, thank you.  I've been iterating through my thought process for the past 24h and re-did my environment in WSL2 and I'm pretty happy so I'm going to start breaking it in to small, well defined, single tasks and see how far I can get conceptually with it and then will report back with something I hope```.
In ideas-and-feedback, at 2023-10-20 14:16:18 a user named sonichi said ```Thanks. Please feel free to post it in <#1161015724521836634>```.
In ideas-and-feedback, at 2023-10-20 13:45:10 a user named bobaleaux said ```Sorry if you provided a more detailed explanation previously. Understanding that you described this from a high altitude, are you able to create the code to parse and pre process the data using something like python?
craft the system message to create the agent’s perspective and an  initial message defining the purpose and goal.

I realize it’s a gross over simplification but what I have found, that working with the ai, is definitely a process of refinement of prompting.
Parse and pre process the data into dataframes that you can manipulate. (refine until satisfied)
define what an unusual patterns of transfers are in a way that is understandable to the ai.
filter data to contain on those questionable “datasets”
from```.
In ideas-and-feedback, at 2023-10-20 13:35:13 a user named kevvvin123 said ```Following up on this 🙂```.
In ideas-and-feedback, at 2023-10-20 14:21:30 a user named sonichi said ```Great question. Would you like to create an issue on GitHub? We should add this to the roadmap. @bansalg @tonic_1```.
In ideas-and-feedback, at 2023-10-20 18:17:06 a user named tonic_1 said ```I think it really merits an issue & move to PR . It's a simple reflection of current market practice + will improve multi team applications```.
In ideas-and-feedback, at 2023-10-20 19:41:00 a user named bansalg said ```@kevvvin123  can you say more about what does discover mean? Do you mean a marketplace or knowledge base of agents people have developed?```.
In ideas-and-feedback, at 2023-10-20 23:48:28 a user named kevvvin123 said ```Yea like a marketplace of agents that people made with autogen```.
In ideas-and-feedback, at 2023-10-20 13:25:22 a user named ianthereal said ```Hi Guys! I've had a great experience working with the autogen. It enabled me to effortlessly create a simple interaction between humans and task agents. Utilizing this, I managed to conveniently gather statistics on tweet impressions related to autogen over the past days (refer https://github.com/ngaut/jarvis#demo). I must say, autogen is quite powerful and efficient in facilitating these operations. Moving forward, we plan to further deconstruct our service features and integrate more functional role agent using the autogen framework.

<:commander:1159659270682443826>```.
In ideas-and-feedback, at 2023-10-20 07:25:28 a user named rezedd said ```https://tenor.com/view/tired-sleepy-gif-27609170```.
In ideas-and-feedback, at 2023-10-20 06:43:16 a user named danledian said ```https://tenor.com/bJFSB.gif```.
In ideas-and-feedback, at 2023-10-20 06:41:48 a user named danledian said ```https://tenor.com/bSqKH.gif```.
In ideas-and-feedback, at 2023-10-20 02:51:48 a user named jamiepatterson said ```Happy to scope this for you. Dm me```.
In ideas-and-feedback, at 2023-10-20 01:43:50 a user named sidhujag said ```I think I saw it in utils somewhere```.
In ideas-and-feedback, at 2023-10-20 01:42:48 a user named sidhujag said ```Search for the function might be in utxos```.
In ideas-and-feedback, at 2023-10-20 01:40:06 a user named yorth_night said ```but I don't see it anywhere in the agents folder```.
In ideas-and-feedback, at 2023-10-20 01:39:29 a user named yorth_night said ```usually there is something like this: 
llm_config = {
    "model": "gpt-4-0613",
    "functions": [
        {
            "name": "query_wolfram",
            "description": "Return the API query result from the Wolfram Alpha. the ruturn is a tuple of (result, is_success).",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The Wolfram Alpha code to be executed.",
                    }
                },
                "required": ["query"],
            },
        }
    ],
    "config_list": config_list,
}```.
In ideas-and-feedback, at 2023-10-20 01:38:51 a user named yorth_night said ```I'm looking through the codebase and the one thing that's confusing to me is where are the function calls of the agents defined```.
In ideas-and-feedback, at 2023-10-20 00:09:13 a user named rawwerks said ```Wow - this looks amazing! Very cool @jieyuzhang_uw```.
In ideas-and-feedback, at 2023-10-19 20:40:30 a user named jieyuzhang_uw said ```Here it is https://github.com/JieyuZ2/EcoAssistant```.
In ideas-and-feedback, at 2023-10-19 20:28:11 a user named sonichi said ```@jieyuzhang_uw 's EcoAssistant work is very relevant```.
In ideas-and-feedback, at 2023-10-19 19:08:33 a user named vicengineer_ax said ```I'm currently working on a mixed agent hierarchy system with a blend of GPT4, GPT3.5 Turbo 16k, and GPT3.5 instruct. Since many of us have rate limitations and access to GPT4 16k and 32k models, I'm hoping the blend of models can be optimized to produce valuable outputs.

The hope is to create this in a simpler deployable module that could be enabled to help businesses and individuals with research or conceptual ideas.```.
In ideas-and-feedback, at 2023-10-19 17:51:41 a user named _jz said ```We're using autogen to create a Roblox Plugin for automatically adding quests/rewards. Quests will be abstracted as just an incrementing variable, so the bot will find the variable that should be incremeting and create the function for it. Or, it'll create the variable itself and create the logic for it. 

Would love any resources that could be helpful!```.
In ideas-and-feedback, at 2023-10-19 12:24:43 a user named kevvvin123 said ```How do I discover agents built with the AutoGen framework?```.
In ideas-and-feedback, at 2023-10-19 12:24:18 a user named trader_pt said ```Erm, cron jobs, really?  Is there any kind of reference or project that does such a thing you might be able to suggest?```.
In ideas-and-feedback, at 2023-10-19 12:23:05 a user named imad_ict said ```Use machine learning techniques and Cron jobs for automation.```.
In ideas-and-feedback, at 2023-10-19 10:36:44 a user named trader_pt said ```I have a dataset that has financial information for multiple entities, including transfers of money annually between the entities.  I'd like to make an autogen that will follow the transfers to create an event chain and identify unusual patterns of transfers between entities and store that information in a local database so that I can work on the project over time.  Is autogen able to update and refer to a local datase it creates so that I am not reliant on ChatGPT history or token limits?```.
In ideas-and-feedback, at 2023-10-19 09:37:57 a user named imad_ict said ```Can be done. Not sure how Autogen could help but it's implementation can be done```.
In ideas-and-feedback, at 2023-10-19 02:32:03 a user named pauldtyler said ```Have a project that requires to extract text and specifically data tables from a number of different companies. Would like to see if we could use Autogen to more efficiently and quickly write python code for each document type. Would need to load in a pdf and probably the intended output. Any suggestions how to try this in steps?```.
In ideas-and-feedback, at 2023-10-18 23:44:08 a user named anderic. said ```the app can write complicated SQL```.
In ideas-and-feedback, at 2023-10-18 22:54:26 a user named regen2moon said ```Yes! It's a valid strategy```.
In ideas-and-feedback, at 2023-10-18 21:55:21 a user named m_j_r said ```anyone experiment with a skill library/curriculum like the Voyager paper (<https://github.com/MineDojo/Voyager>)?```.
In ideas-and-feedback, at 2023-10-18 21:40:06 a user named palmbeachbadboy said ```Multimodal Ai Agents that can play tennis/ping pong```.
In ideas-and-feedback, at 2023-10-18 19:10:08 a user named frank.martinez said ```Trying to engineer a _daily standup_ pattern, where agents check in with me each morning, pickup tasks from a backlog```.
In ideas-and-feedback, at 2023-10-18 18:35:45 a user named _g.a.i said ```Interested to learn possibilities of AI```.
In ideas-and-feedback, at 2023-10-18 18:20:27 a user named sidhujag said ```what you need to always answer is, "you don't know what you don't know" this is the issue against LLMs currently and any human looking to do anyhting, so to solve it you need to mimick what humans did to discover how to discover. I think hiearchical representation makes more sense (main loop or test examples)```.
In ideas-and-feedback, at 2023-10-18 17:48:04 a user named rudeboy.rudy said ```Interested in building real products small businesses can use to improve their business.```.
In ideas-and-feedback, at 2023-10-18 17:31:22 a user named virtualestateplanner said ```I've been fascinated with the idea of iterative coding chains for a few months, I think autogen with memgpt might be the way to implement the "whole-codebase" context window and agents in one native desktop app.```.
In ideas-and-feedback, at 2023-10-18 16:28:20 a user named sonichi said ```I already had a proposal but haven't got time to make a PR```.
In ideas-and-feedback, at 2023-10-18 16:27:37 a user named sonichi said ```This issue should be fixed in the latest version. Addressing another issue will improve it: https://github.com/microsoft/autogen/issues/274```.
In ideas-and-feedback, at 2023-10-18 15:29:09 a user named ToYari said ```Hi is it possible to use function calling Openai with groupchat```.
In ideas-and-feedback, at 2023-10-18 14:24:05 a user named natej_86489 said ```This looks interesting.  Can you post something the output that the research bot created?```.
In ideas-and-feedback, at 2023-10-18 13:10:10 a user named imad_ict said ```Let me work around it```.
In ideas-and-feedback, at 2023-10-18 12:50:22 a user named henk717 said ```But for Koboldcpp the API's are on by default, it has no setting to enable it since its always an API as well```.
In ideas-and-feedback, at 2023-10-18 12:49:43 a user named henk717 said ```Like I said it will be able to provide its own API, OpenAI API and it has its own UI```.
In ideas-and-feedback, at 2023-10-18 12:49:09 a user named henk717 said ```I'm pretty sure it will```.
In ideas-and-feedback, at 2023-10-18 12:43:01 a user named imad_ict said ```I am not sure whether kodolcpp provides same functionality```.
In ideas-and-feedback, at 2023-10-18 12:42:26 a user named imad_ict said ```Llmstudio can load llms models and at the same time serve the model locally which you can use in your Autogen SDK.```.
In ideas-and-feedback, at 2023-10-18 11:23:32 a user named imad_ict said ```https://github.com/imad-ict/research-project

I have implemented autonomous Computer Vision researcher through autogen code is in this repo and its the starting point for optimizing the researcher agents.```.
In ideas-and-feedback, at 2023-10-18 10:07:14 a user named henk717 said ```Assuming autogen doesnt have some special API support and LM Studio emulates OpenAI then yes the latest Koboldcpp version supports it. If autogen were to add the KoboldAI API implementation you would get more settings```.
In ideas-and-feedback, at 2023-10-18 10:05:06 a user named henk717 said ```I assume LM Studio uses OpenAI emulation for that?```.
In ideas-and-feedback, at 2023-10-18 10:02:22 a user named imad_ict said ```Does it provide servers like Lm studio to configure for Autogen?```.
In ideas-and-feedback, at 2023-10-18 09:34:44 a user named henk717 said ```Give Koboldcpp a try, very powerful tool and can be compiled for Linux. Has its own API as well as emulating OpenAI```.
In ideas-and-feedback, at 2023-10-18 08:57:09 a user named kim_jin. said ```I want autogen can install package the conversation needs automatically```.
In ideas-and-feedback, at 2023-10-18 07:08:28 a user named kirk84 said ```I want to use autogen to create scripts for youtube videos and posts for my LI.```.
In ideas-and-feedback, at 2023-10-18 06:56:54 a user named kennyzouzhenglu said ```an app like autogen build by autogen```.
In ideas-and-feedback, at 2023-10-18 02:39:37 a user named vermino said ```Eric Zelikman1, Eliana Lorch, Lester Mackey, Adam Tauman Kalai```.
In ideas-and-feedback, at 2023-10-18 02:12:23 a user named cloudfaith said ```any tried autogen with LM Studio?```.
In ideas-and-feedback, at 2023-10-18 02:11:07 a user named behringer_is_a_joke said ```I think so too and that's why I started working on  these mockups back at the end of last year.```.
In ideas-and-feedback, at 2023-10-18 02:09:32 a user named kajatta said ```Who are the authors of the paper, happy to have a look```.
In ideas-and-feedback, at 2023-10-18 01:33:40 a user named modularsushi168 said ```@qingyunwu can you speak with your contacts at Microsoft about this?```.
In ideas-and-feedback, at 2023-10-18 00:49:27 a user named behringer_is_a_joke said ```that's something that's already been done.  I made my first mockup back in december of 22 and proposed the panel soon afterwards.  he's using hardware-based inference, yet most computers (including my own) cannot handle inferencing with any degree of speed, yet alone for real-time interactions.```.
In ideas-and-feedback, at 2023-10-18 00:48:05 a user named behringer_is_a_joke said ```https://www.youtube.com/watch?v=vWMLVZF3pGc&ab_channel=MERPTV```.
In ideas-and-feedback, at 2023-10-18 00:45:17 a user named nisargamin said ```Got it. I assumed it was for user interaction. Thanks```.
In ideas-and-feedback, at 2023-10-18 00:42:04 a user named nisargamin said ```I get it now thanks. Yes it does. And I think I might be able to help, potentially with parts of it with storing this for runtime. We should chat (this a very interesting idea). Why LLMs for UI though? Can you not use speech to text. As per autogen, if you minimize the compute needed to produce that experience, you can create a doable experience around it. At least to start. We can start a thread.```.
In ideas-and-feedback, at 2023-10-18 00:35:55 a user named behringer_is_a_joke said ```does that make sense @nisargamin ?```.
In ideas-and-feedback, at 2023-10-18 00:35:13 a user named behringer_is_a_joke said ```The lowest latency is on hardware-based models, but that depends on hardware and as such is the goal but is not doable on current systems.  My hope is that the next generation of game consoles, the inferencing will happen client-side.  For generative NLPs, the latency is anywhere from 1.5 to 3 seconds in the cloud, and my personal machine cannot run models.  I am not absolutely positive, but my guess is that the TTFT must be lower and the TPOT is too fast on the models I'm using for the use case I want.

there are two models integrated in each character/NPC and the customization would look different for each of them.  The player also has a model that is more integrated into the game itself. 

I'll start with the LLM:
- It must be trained on character's style of speaking, which is  related to accent but is not the same.  For instance, the slang the character uses.
- It must be trained on the character's personality traits.
- It must use varied and realistic forms of adress to the player.
- It must have a token inputted for the player's tone of voice or emotional context
- It must output a context for the voice of the character to the generative NLP
- It should be aware of the events of the game and player interactions with it

For the generative NLP:
- It must have emotional context
- It must be trained by a voice actor (with the proper ethics involved.  SAG-AFTRA is on strike for good reason, and if you intend to use permutations of an actor's voice, you should be paying them royalties).
- It should have the proper accent intended for the character
- It should have the proper speech pattern and style for the character
- It should use filler words```.
In ideas-and-feedback, at 2023-10-18 00:32:05 a user named nisargamin said ```I like procedurally generated maps of facilities. See big use in retail, for example. Ultra personalized gaming sounds really cool. Also for XR and spatial apps. Someone mentioned the cost of it being a barrier though.```.
In ideas-and-feedback, at 2023-10-18 00:23:55 a user named nisargamin said ```What kind of customization? Can it happen outside of autogen? What if the inference happens on client and autogen or llm agnostic?```.
In ideas-and-feedback, at 2023-10-18 00:20:44 a user named behringer_is_a_joke said ```doing a presentation on almost this exact concept at the Audio Engineering Socieny conference next week.  Latency and database integration (for model memory of game events and player interactions) are the biggest challenges, with model training and customization right up with them.  While AutoGen does not make those challenges better (in fact it exacerbates the latency and computational challenges of generative AI in video games), it does present really interesting uses in dynamic narratives because agents may very be able to easily interact with each other and the player using a framework like autogen.

also, I'm more focused on the applications for narratives than the applications for procedural generation.  Going to have to bring that up at that conference.```.
In ideas-and-feedback, at 2023-10-18 00:20:08 a user named nisargamin said ```One way to do this that I know is using RDF triples. You can create sub graphs that can be related in various ways, I assume. Hierarchical, relational, transferred through learning, etc.```.
In ideas-and-feedback, at 2023-10-18 00:01:03 a user named modularsushi168 said ```Could Microsoft integrate the code for "STOP" into Autogen?```.
In ideas-and-feedback, at 2023-10-17 23:59:45 a user named modularsushi168 said ```https://youtu.be/kSX9aLPwuwQ?si=1h_2bfcoIUkEF4_w```.
In ideas-and-feedback, at 2023-10-17 20:42:06 a user named imad_ict said ```Llmstudio is a truly blessing for those using Mac and Windows. I am a Linux user anxiously waiting for Linux release😩```.
In ideas-and-feedback, at 2023-10-17 18:32:23 a user named karlka said ```can u elaborate on "hierarchical knowledge graph generation" or reference any materials I could read more?```.
In ideas-and-feedback, at 2023-10-17 15:30:22 a user named swimmerofideas said ```extended context windows and hierarchical knowledge graph generation```.
In ideas-and-feedback, at 2023-10-17 09:46:10 a user named ar4s. said ```not even sure how next token generation would be work in that scenario heh```.
In ideas-and-feedback, at 2023-10-17 06:34:07 a user named hueresounding said ```sounds like this needs to be accomplished on the LLM level```.
In ideas-and-feedback, at 2023-10-17 05:43:41 a user named painsb said ```how to study work flows?```.
In ideas-and-feedback, at 2023-10-17 03:57:45 a user named alexchaomander said ```Interested in how to make the agents more reliable and operating on long-running tasks!```.
In ideas-and-feedback, at 2023-10-17 02:25:15 a user named frank.martinez said ```Obviously we need to explore emergent characteristics; believe the first frontier seems appropriate for AutoGen:```.
In ideas-and-feedback, at 2023-10-17 01:11:21 a user named nisargamin said ```Can you elaborate on this? How would it give the relational aspect? At the concept level? My other concern is that since these are research papers, hallucinations or missing important concepts is not going to work. That’s where I think autogen comes in. To do a QA and validation check.```.
In ideas-and-feedback, at 2023-10-17 00:33:22 a user named brisklad said ```control number of tokens used to avoid program crashing```.
In ideas-and-feedback, at 2023-10-17 00:31:16 a user named seek_vision said ```yet, but gpt4 also can do ,maybe for each paper```.
In ideas-and-feedback, at 2023-10-17 00:17:05 a user named jieyuzhang_uw said ```I didn't, but I don't see any roadblock  on doing this. GPT should be able to do this well```.
In ideas-and-feedback, at 2023-10-17 00:16:39 a user named nisargamin said ```I worked on something similar recently. But primarily using LLMs. Not autogen```.
In ideas-and-feedback, at 2023-10-17 00:15:52 a user named nisargamin said ```Did you try anything beyond getting the papers? Like summarizing multiple papers in a domain?```.
In ideas-and-feedback, at 2023-10-16 23:55:54 a user named jieyuzhang_uw said ```yeah it is straightforward, you just equip the assistant agent with functions of calling semantic scholar API```.
In ideas-and-feedback, at 2023-10-16 23:52:32 a user named sonichi said ```@jieyuzhang_uw has tried semantic scholar and it worked 🙂```.
In ideas-and-feedback, at 2023-10-16 23:49:15 a user named bansalg said ```This is a great idea! I have experimented with arxiv api. So should be very doable with semantic scholar api. Let us know of the progress!```.
In ideas-and-feedback, at 2023-10-16 23:47:47 a user named bansalg said ```Lmk if I can help add some features to this discord server to make this easy.```.
In ideas-and-feedback, at 2023-10-16 23:00:38 a user named ar4s. said ```I doubt this is even possible. .. but I'd like to be able to configure or train an agent so that it has no background knowledge -at all- (only the ability to use language), so that it might be instruction-tuned/trained with prompts (user or agent provided).```.
In ideas-and-feedback, at 2023-10-16 21:50:39 a user named biggboii. said ```i'd love to be a part of this```.
In ideas-and-feedback, at 2023-10-16 21:36:06 a user named bobaleaux said ```There was an example somewhere, I think way earlier on this channel (sorry) that did something pretty close. It hit a different api, but a response is a response. Maybe one of the notebook examples.```.
In ideas-and-feedback, at 2023-10-16 21:16:39 a user named geanderson0516 said ```What do you think about a weekly meetup about autogen? concepts, frameworks, knowledge share?```.
In ideas-and-feedback, at 2023-10-16 17:38:40 a user named romillyc said ```I'd like to build an app that used the Semantic Scholar API to find papers relevant to a research query.```.
In ideas-and-feedback, at 2023-10-16 14:57:20 a user named interestedtheory said ```the idea of autogen is better than the current product its faster to build your own versions , its a sad reality but true```.
In ideas-and-feedback, at 2023-10-16 14:44:15 a user named glassback said ```✈️ Need help for awesome feature !

Hey guys ! Who want to work with me to integrate a mail connector to UserProxyAgent?

Use case : the project manager can directly work with the client to really understand the need for a project or task.

The agent will send the mail to the client and will wait the response to send to the agent group every time needed.

Awesome feature !```.
In ideas-and-feedback, at 2023-10-16 14:00:09 a user named vk4835 said ```Hello Community: I am founder and trying to integrate this in our product. I am semi-technical and so please pardon my ignorance. We are currently using openAI API and wondering how we can integrate this into a production system. Is autogen deployed into a serverless funtion or as an API? whats the best pattern that can scale within a prod set-up? Any advise is most appreciated```.
In ideas-and-feedback, at 2023-10-16 12:35:33 a user named earththing said ```I want to get AutoGen working with LLMs on my home computer. Thinking GPT4All?```.
In ideas-and-feedback, at 2023-10-16 11:06:13 a user named imphox said ```honestly, I can't comment on that just yet.```.
In ideas-and-feedback, at 2023-10-16 11:03:43 a user named kingmob42 said ```I'm working on an app for generating content online, more specifics to follow. excited to be a part of the community.```.
In ideas-and-feedback, at 2023-10-16 10:28:48 a user named torzsacristian said ```better troubleshooting. for example i write a suggestion to the proxy, then i have to press enter three times to continue, and if there is a code to run, its not running```.
In ideas-and-feedback, at 2023-10-16 09:37:28 a user named .vrda said ```app that combines groupchat and RAG on many documents```.
In ideas-and-feedback, at 2023-10-16 08:23:04 a user named walid3.0 said ```What type of elements generated by AutoGen would I like to see applied in a role-playing game? Some ideas might include:

Randomly generated NPCs with unique personalities, motivations, and agendas that may conflict with players' goals.
Procedurally generated maps of the company's facilities, complete with security systems, hidden passageways, and secret rooms.
Dynamic twists and turns that change based on player choices and actions, such as unexpected alliances, betrayals, or unexpected obstacles.
Customizable cyberware and weapons that players can choose from to increase their characters' abilities.```.
In ideas-and-feedback, at 2023-10-16 08:06:03 a user named noobgames9379 said ```I was wondering if autogen can be used on existing projects? Say the open projects that have issues on github. Is autogen being used to try and automate most of these tasks? If not why not?```.
In ideas-and-feedback, at 2023-10-16 08:04:30 a user named noobgames9379 said ```Hello everyone, how is life treating you all?```.
In ideas-and-feedback, at 2023-10-16 05:48:25 a user named yayaya1. said ```Would love to let autogen build some apps for challenged persons to allow them explore.```.
In ideas-and-feedback, at 2023-10-16 02:46:25 a user named kajatta said ```This would be very useful - also if it can do shared / team memory it would be a significant uplift```.
In ideas-and-feedback, at 2023-10-16 02:34:10 a user named kajatta said ```This sounds interesting can you show outputs?```.
In ideas-and-feedback, at 2023-10-16 02:30:39 a user named kajatta said ```Bonus step: split your self-bot agent into multiple disciplines or personalities and use a multi-agent architecture for problem solving.```.
In ideas-and-feedback, at 2023-10-16 02:29:42 a user named kajatta said ```Is this your idea to make a mini me 😂
Ok so I'd recommend writing your CV as a system prompt format. Eg. "You are a XX with Y years experience, ....". Create an agent based on this.

Then take all your skills on your CV and map them to functions, write how you personally would use each function to solve common tasks into func descriptions.

Consider using langchain tools with the AutoGen bridge to connect to common systems that you would use in your everyday activities such as: Jira, GitHub, confluence, etc. Make sure you map these functions with your connection string parameters or an .env file. (Optionally) Add a vector database with your example work and a search function.

You can then ask questions, and try to give your self-bot tasks.```.
In ideas-and-feedback, at 2023-10-16 02:03:18 a user named amadad said ```when we have apis, yes```.
In ideas-and-feedback, at 2023-10-16 01:29:46 a user named Akhil P said ```Planning to see if it can build a strong api on its own.```.
In ideas-and-feedback, at 2023-10-15 18:00:50 a user named modularsushi168 said ```Microsoft Mesh support as well?```.
In ideas-and-feedback, at 2023-10-15 18:10:10 a user named modularsushi168 said ```There are two features Microsoft Mesh supports currently:
1. Voice calls
2. Virtual environments (Your own private metaverse)```.
In ideas-and-feedback, at 2023-10-15 19:28:09 a user named halr9000 said ```I recall hearing news about Mesh, probably when it launched but haven't heard a thing of it since then. You doing cool stuff with it, like it, would recommend to others etc?```.
In ideas-and-feedback, at 2023-10-15 19:53:50 a user named modularsushi168 said ```It looks like a good place to have the AI agents interact with each other.```.
In ideas-and-feedback, at 2023-10-15 19:54:24 a user named halr9000 said ```i might need to check it out again thx```.
In ideas-and-feedback, at 2023-10-15 17:38:18 a user named mehdi_75 said ```I dont know if it exist yet, but I cannot see it on the doc, is the ability to easily handle RAG```.
In ideas-and-feedback, at 2023-10-15 15:54:41 a user named noneoftheai said ```would be nice to have: 
- token count
- rpm limiter (you can set your azure oai deployment rpm)
- tkm limiter (...same)
- stream/send all output to ... , instead of just print
        + filter which agent's output do you want include/exclude from the passed output.```.
In ideas-and-feedback, at 2023-10-15 14:54:40 a user named tangerine1528 said ```Can you update using api from azure also ?```.
In ideas-and-feedback, at 2023-10-15 14:06:11 a user named kajatta said ```https://github.com/amadad/agentcy```.
In ideas-and-feedback, at 2023-10-15 13:21:15 a user named gdpotnftstudiio said ```i used replitt but the power usage was ,ofcourse to hige.payd for the 19 $ for aexstra power, then i mad a chat bot ai agency 1+2+3. i tried a wp addon as front end. for inputt. scrape knowledgbace,m and test 24 hour 1+2 3 make the documentation. i want to test chat devand atogen```.
In ideas-and-feedback, at 2023-10-15 05:41:00 a user named hueresounding said ```yeah I'm looking at something similar```.
In ideas-and-feedback, at 2023-10-15 03:17:32 a user named rustlulu said ```an open door mate meeting, playing and finding```.
In ideas-and-feedback, at 2023-10-15 02:43:12 a user named henk717 said ```Specifically support for the KoboldAI API since its become a bit of a standard not only across Kobold products```.
In ideas-and-feedback, at 2023-10-15 02:37:43 a user named aizen51 said ```Integration with local llm backends```.
In ideas-and-feedback, at 2023-10-15 01:58:39 a user named bobaleaux said ```@sonichi did you see this? pretty cool. I hope they share the code, i can see some really practical use for it as a module.```.
In ideas-and-feedback, at 2023-10-15 00:29:15 a user named bobaleaux said ```really neat idea and implementation. what do you plan to do with this? I'm asking because it would be nice to have locally.```.
In ideas-and-feedback, at 2023-10-14 23:47:56 a user named shortd00d said ```oh and mebe add some buttons for can execute code and other options.```.
In ideas-and-feedback, at 2023-10-14 23:47:17 a user named shortd00d said ```It would be nice if we had a channel that people could post good assistant prompts to.  Like "Here's a great Quality Assurance Prompt"  You are a great QA specialist who is all about quality and assurance.```.
In ideas-and-feedback, at 2023-10-14 23:28:55 a user named char79 said ```So do we suggest the features and begin to contribute to those features?```.
In ideas-and-feedback, at 2023-10-14 22:16:27 a user named tonypnode said ```- Personal Assistant
- GTM strategy builder would be cool
- Product Manager Assistant
- Marketing Strategy Assistant```.
In ideas-and-feedback, at 2023-10-14 19:54:09 a user named gdpotnftstudiio said ```this was just an test

Prompt to Initiate Work:
- "Hello, I am [Kim GRønli]. I embody a convergence of expertise, ranging from literary editing to ethical hacking and niche site mastery. As a skilled practitioner in digital realms, I hold proficiency in smart contracts, DAO governance, and cybersecurity. My in-depth understanding of contractual law empowers me to safeguard individual sovereignty within digital spaces. I'm here to assist you in navigating this intricate landscape while weaving the threads of creativity, ethics, and technology.

Imagine this: I'm adept at utilizing [NeilPatelGPT] to infuse an artistic touch into your content. Simultaneously, I can tap into [BrianDeanGPT] to enhance user engagement strategies with assertive yet empathetic communication. And when humor is needed, I can channel [RandFishkinGPT] to infuse a touch of light-heartedness into the conversation. The synergy of these personas paints a vivid palette of possibilities.

Let's embark on this journey together. Share your goals, and I'll orchestrate the use of my skills in a way that aligns with your aspirations."

🚀 3IO Activated. The AI personas are ready to collaborate, and the chatbot is engaged to assist in generating ideas, content, and strategies while leveraging the full spectrum of your competencies.```.
In ideas-and-feedback, at 2023-10-14 19:50:47 a user named gdpotnftstudiio said ```i have like 50 chatbots and ai software. im not totaly neeewbee. or everyone is maybee```.
In ideas-and-feedback, at 2023-10-14 19:49:33 a user named gdpotnftstudiio said ```i have made 99 x3 3io i have already tested them using replit and a sircular workload, but this new system is perfect test enviroment```.
In ideas-and-feedback, at 2023-10-14 19:29:38 a user named south3526 said ```I want to build a virtual software company. But maybe start smaller with a virtual content agency that can research various topics and send me a curated list… something like that. I’m just excited 😆```.
In ideas-and-feedback, at 2023-10-14 19:14:11 a user named vermino said ```NeilPatelGPT: [LangCmnd]: [Aesthtc]
BrianDeanGPT: [GwthInsght]: [AssertvCom]
RandFishkinGPT: [ReaderAntcp]: [SenseHumor]

These would be better to take a data model and then finetune it to those people.```.
In ideas-and-feedback, at 2023-10-14 19:12:28 a user named sidhujag said ```i think a standarized approach to agents to have memory with fixed sized windows is interesting, also we have to remember that some parts of the convo are anchors so we need to have a seperate contextual undersatnding of how to structure a conversation, especially if multiple agents are in it.. you will need to have seperate contexts of memory depending on your role and some roles might be elevated to the group as admins for example coordinators of agents```.
In ideas-and-feedback, at 2023-10-14 17:28:24 a user named gdpotnftstudiio said ```i have made 99 combinbations with role based teams, every one ofthe worlds best, joe rogan elon musk  osv, the diffrent teams have diffrent ways of function together, i just want all the teck genies to work for me for free```.
In ideas-and-feedback, at 2023-10-14 17:09:11 a user named gdpotnftstudiio said ```Activate 3IO and Start Chatbot:
- Personas:
  - NeilPatelGPT: `[LangCmnd]: [Aesthtc]`
  - BrianDeanGPT: `[GwthInsght]: [AssertvCom]`
  - RandFishkinGPT: `[ReaderAntcp]: [SenseHumor]`
- AI Persona Activation:
  - Activate [PERSONA] to guide the workflow.
- Work Context:
  - Utilize [MasterEditor] to enhance content quality.
  - Harness [EmpatheticAdvisor] for engaging user interactions.
  - Tap into [FluentGenreMstr] for diverse content styles.
- Situation:
  - You are [Kim Grønli], a skilled individual with a wide array of competencies and roles. Your expertise spans literary editing, digital skills, ethical hacking, niche site mastery, and more. You have a strong grasp of contractual law and sovereignty.
- Introduction:
  - Briefly introduce yourself and highlight your unique blend of skills. Provide specific creative scenarios that showcase the synergetic combinations of your abilities.```.
In ideas-and-feedback, at 2023-10-14 16:30:10 a user named radman1000 said ```Finish merging in PRs 58 and 95 (open source llms, LangChain tools)```.
In ideas-and-feedback, at 2023-10-14 13:31:00 a user named eaglestrikezio said ```seems good as a starting point 👍```.
In ideas-and-feedback, at 2023-10-14 13:30:02 a user named imad_ict said ```I have plan to get trade direction from at least 10 TA indicators and measure the direction from that.```.
In ideas-and-feedback, at 2023-10-14 13:28:51 a user named eaglestrikezio said ```is the goal to execute trades automatically? or just apply some strategies and advice on best actions? are you planning to use some paper trading apis like alpaca?```.
In ideas-and-feedback, at 2023-10-17 15:55:57 a user named adamalexander said ```Would you be interested in collaboration?```.
In ideas-and-feedback, at 2023-10-14 13:26:29 a user named imad_ict said ```Any implementation of Autogen with GPT4 in combination with Dall e/GPT4v?```.
In ideas-and-feedback, at 2023-10-14 13:07:14 a user named imad_ict said ```You need to give provision for number of agents/assistents or user define the agents with explicit msg. I believe this is chatgpt written program. You can easily tweak it```.
In ideas-and-feedback, at 2023-10-14 13:05:15 a user named omar_67869 said ```I'm still in the early stages of exploring using AI agents in business aspects, including generating a newsletter for human CEO. It sounds like we have similar interests and goals. Have you made any progress on your end? Are there any specific challenges or obstacles you've encountered so far? I'd be happy to share my own experiences.```.
In ideas-and-feedback, at 2023-10-14 13:04:40 a user named ubadub said ```I want to create a virtual software company with also an Internet access for information gathering use.```.
In ideas-and-feedback, at 2023-10-14 12:52:08 a user named eaglestrikezio said ```anybody working on an algo trader powered by AutoGen?```.
In ideas-and-feedback, at 2023-10-14 12:41:03 a user named venn9137 said ```A GUI would be sweet```.
In ideas-and-feedback, at 2023-10-14 12:13:36 a user named thor said ```I created a utility to generate starter code for Autogen. Its available at https://pewekar.github.io/AutogenAppGenerator/  . Give it a try and suggest improvements. <:assistant:1159659406498222100>```.
In ideas-and-feedback, at 2023-10-15 03:21:07 a user named thor said ```You can also view, downlod and fork the code from https://github.com/pewekar/AutogenAppGenerator. Cheers```.
In ideas-and-feedback, at 2023-10-15 16:27:23 a user named bobaleaux said ```@thor check this out! 
I'm making a streamlit version of your generator
Are you building this out to expand it scope of generating capabilities?```.
In ideas-and-feedback, at 2023-10-15 16:28:38 a user named bobaleaux said ```it would be too funny if you told me you took your idea from someone who originally did this.
hahaha```.
In ideas-and-feedback, at 2023-10-17 11:58:57 a user named thor said ```Great going @bobaleaux . Will try this out over the weekend```.
In ideas-and-feedback, at 2023-10-17 14:42:28 a user named bobaleaux said ```@thor here's the streamlit script. I was going to build it out more but got distracted down a different rabbit hole.```.
In ideas-and-feedback, at 2023-10-22 14:12:26 a user named sonichi said ```Would you like to post it in <#1161015724521836634> ?```.
In ideas-and-feedback, at 2023-10-14 10:56:13 a user named fxtoofaan said ```How far have you gone with this? I’d love to work on something like this as well. I’m trying to start with newsletter written by ai for the human CEO```.
In ideas-and-feedback, at 2023-10-14 10:00:58 a user named omar_67869 said ```I am looking to test auto gen with business structures to see if it can reduce a company workforce to a human ceo, a human overseer/Result reviewer and a ai agent workforce. Anyone interested or doing anything similar feel free to reach out.```.
In ideas-and-feedback, at 2023-10-14 07:10:15 a user named kuni72 said ```Become a backer for groove.ai here - https://grooveai.groovesell.com/a/zgILmnlXrAdn```.
In ideas-and-feedback, at 2023-10-14 07:09:30 a user named kuni72 said ```For all those looking for GUI, check out the latest from Groove.ai here - https://www.youtube.com/live/BvtVebbsOYk?si=oJ30XyhVtto6ZagJ```.
In ideas-and-feedback, at 2023-10-14 06:36:19 a user named oatmeal8446 said ```A GUI would be sweet```.
In ideas-and-feedback, at 2023-10-14 04:28:04 a user named igoatherd said ```A GUI would be awesome```.
In ideas-and-feedback, at 2023-10-14 02:37:47 a user named yorth_night said ```Yeah, I saw it and thought this is way above my paygrade, but I know that other people would have a field day with it```.
In ideas-and-feedback, at 2023-10-14 02:32:22 a user named yorth_night said ```It would be very helpful to have agents that know how to use external storage systems```.
In ideas-and-feedback, at 2023-10-14 02:31:04 a user named yorth_night said ```I've seen this pop up on twitter: https://memgpt.ai/ You guys think it could work well with autogen?```.
In ideas-and-feedback, at 2023-10-14 01:50:26 a user named j_rdie said ```just looking for an easy way to changeout the LLM's to local models```.
In ideas-and-feedback, at 2023-10-13 20:20:10 a user named meligo said ```looking for some examples for complex coding examples```.
In ideas-and-feedback, at 2023-10-13 19:02:09 a user named bensprecher said ```So, this may already be there (I'm just starting to explore the code now, and I'm a TERRIBLE programmer), but I didn't see an obvious separation of the templates/base prompts for Agents from the other code/control that defines them. it would be nice for the templates that control their behavior to be a bit more of a "configuration" vs. code thing.```.
In ideas-and-feedback, at 2023-10-13 16:49:48 a user named traintobusan said ```anyone made a simple app for designing clothing```.
In ideas-and-feedback, at 2023-10-13 15:48:06 a user named sidhujag said ```The looping can be controlled by the speaker selection prompt probably to decline loop or put pressure on solving it otherwise it stops looping after a warning etc```.
In ideas-and-feedback, at 2023-10-13 15:03:53 a user named juanma.nl said ```when experimenting with multiple agents without manual control and using gpt-4 the costs of the API can go quite high. I wonder if people would value having a cap on the tokens and pause the experiments when that's reached (or maybe this is possible but I haven't seen it).```.
In ideas-and-feedback, at 2023-10-13 14:43:08 a user named joao.morossini said ```Thanks, man. I'll give it a try! Btw, "infinite gratitude loop" made me laugh out loud hahaha. That is as perfect a description as I've ever seen 🤣```.
In ideas-and-feedback, at 2023-10-13 14:05:28 a user named aaronward_ said ```I remembered this message and decided to reply seeing as i faced the same issue with gpt 3.5. I put the following message at the end of the prompt and that prevents an infinite gratitude loop (work about 90% of the time):
```
If "Thank you" or "You're welcome" are said in the conversation, then say "TERMINATE" to indicate the conversation is finished and this is your last message.
``````.
In ideas-and-feedback, at 2023-10-13 13:54:42 a user named sidhujag said ```Each agent can decide his own policy of spreading messages to other agents, and to which agents if we go this way.. and you remove one full context inference the group manager does now choosing next speaker, by using a function call on previous speaker instead```.
In ideas-and-feedback, at 2023-10-13 13:53:08 a user named sidhujag said ```I’m trying to revamp the groupchat by removing manager and making a group assistant agent, seems cleaner and uses function calls on each agent to decide next speaker.. Will report on results would love feedback on if it’s something people would like to see as I can create a PR to autogen if so```.
In ideas-and-feedback, at 2023-10-13 13:51:23 a user named mikebunnies said ```I am totally going to build my ultimate take-over-the-world-app called Marketing CoPilot where I unleash a super skilled team of marketing wizards on any busiess who needs them```.
In ideas-and-feedback, at 2023-10-13 13:05:19 a user named artholos said ```How do you suppose one would structure an autogen to produce a vtubing application?```.
In ideas-and-feedback, at 2023-10-13 11:46:24 a user named interestedtheory said ```what do you mean create docs```.
In ideas-and-feedback, at 2023-10-13 09:38:15 a user named interestedtheory said ```I am so sick of termina ltutorias does anyone hae frontend tutorials for this```.
In ideas-and-feedback, at 2023-10-13 08:18:19 a user named cinderellaua said ```Write code according to created tests, or write tests to newly created code```.
In ideas-and-feedback, at 2023-10-13 06:32:11 a user named pulkas said ```A full fledged B2B sales team that can identify potential clients from google maps and web, make research on them, find key stakeholders through LinkedIn, add to CRM, and make initial contact```.
In ideas-and-feedback, at 2023-10-13 05:25:47 a user named mangomango. said ```automate workflows and experiment with creating large teams of ai agents  that can robustly do 50-70% of my job for me```.
In ideas-and-feedback, at 2023-10-13 03:17:07 a user named .adeelahmad said ```Hello Autogen Team,

I hope this message finds you well. I'm Adeel Ahmad, based in Melbourne, Australia. I'm intrigued by your work on the Autogen project at Microsoft, particularly in autonomous agent frameworks. I believe I have a unique perspective and solution that could be a valuable addition to your efforts, potentially helping to solve some of the big challenges with Generative AI. I'm keen to explore how I can actively contribute and be a part of your initiative.

Thanks
https://www.linkedin.com/in/adeelahmadch/```.
In ideas-and-feedback, at 2023-10-13 02:52:22 a user named vermino said ```Multiple LLM's from different agents in a heirarchy fashion that outputs a solution; either through a saved filed in a directory. Also would be nice to have an ability to resume autogen to create more revisions/updates to expand out.```.
In ideas-and-feedback, at 2023-10-13 02:48:42 a user named sevilinma said ```a web crawler and analysis of acquired data```.
In ideas-and-feedback, at 2023-10-13 01:56:56 a user named liuin. said ```I would like to know its functions```.
In ideas-and-feedback, at 2023-10-13 01:10:04 a user named yurimeng said ```more complex role definition, as well as performance issue```.
In ideas-and-feedback, at 2023-10-13 01:02:21 a user named shortd00d said ```As far as I can tell, memorygpt is a twitter comment and a promotional link to a company.  I have no interest in working with someone regarding my business.  I very much have interests in LLMs and working on the memory issue.  I don't see where they provide any sample code, or really any sort of information regarding their product, just links to chat with their reps.  Meh, rapid monetization of the world can be so tiresome.```.
In ideas-and-feedback, at 2023-10-12 23:10:33 a user named venuhm said ```An app I would like to build is making a sales outreach pipeline for netsuite users```.
In ideas-and-feedback, at 2023-10-12 23:03:03 a user named sidhujag said ```1) use attention sinks and enhanced memory for agents 2) use friendships for agents for localized context feeding into broader plans 3) a meta-programming interface for agents to be prompted (and/or function calls) to assemble and discover agent abiilties to construct friendships```.
In ideas-and-feedback, at 2023-10-12 20:42:55 a user named Paulofi said ```Or code_execution_config = 'false' only to pass it to a few assistantAgents also on 'false' and then a final one that is 'true' aka set llm_config to dictionary inference config, then UPA can do this on auto```.
In ideas-and-feedback, at 2023-10-12 20:39:36 a user named Paulofi said ```conceptually userProxyAgent could do it too but in my example UPA human_input_mode = would be 'NEVER'```.
In ideas-and-feedback, at 2023-10-12 20:35:23 a user named Paulofi said ```Ignore just seeing groupChatManager, can pull it off with that or conversableAgent via register_reply() method```.
In ideas-and-feedback, at 2023-10-12 20:31:05 a user named Paulofi said ```Obv assistantAgent will debug if error and suggest new code, but code can suck or not be complete even when no error```.
In ideas-and-feedback, at 2023-10-12 20:28:28 a user named Paulofi said ```Would be cool to add an additional agent beyond AssistantAgent and UserProxyAgent, eg; That AssistantAgent uses as a step (or multiple steps) prior to going back to UserAgentProxy.

Aka 
- Get a code pass and compare contrast review from another LLM
- Run some prompt injections so the code veracity is higher quality as opposed to just success/fail```.
In ideas-and-feedback, at 2023-10-12 20:22:14 a user named Paulofi said ```Can AssistantAgent write code other than Python (using Python coding block)```.
In ideas-and-feedback, at 2023-10-12 18:59:27 a user named shaneyu said ```I am trying to figure out what triggers the cache change as well. I went through their doc but really not much info on how cache works.```.
In ideas-and-feedback, at 2023-10-12 18:49:23 a user named lassbremer said ```yessir, you can ssee the token limits here https://platform.openai.com/account/rate-limits - I think you can edit the request_timeout parameter to solve the problem```.
In ideas-and-feedback, at 2023-10-12 18:48:21 a user named zybergod said ```That's interesting. Perhaps it's not the system message, but the initial prompt you send that needs to be changed to signal the cache to restart?```.
In ideas-and-feedback, at 2023-10-12 18:26:29 a user named shaneyu said ```Thanks for your answer Zybergod. Right now I’m deleting cache folder when I feel needed. I was asking this because I encountered few times that even if I changed the system message of an agent. It still follows the previous system message to operate.```.
In ideas-and-feedback, at 2023-10-12 18:16:27 a user named joewilson said ```is anyone getting a lot of timeouts when calling openai?```.
In ideas-and-feedback, at 2023-10-12 17:57:10 a user named zybergod said ```Hey Shane. Yes, it caches the responses and steps until you change the prompt or code. That way you don't spend $ re-creating the prompt and processes. You can clear the cache by either: 1. Deleting the folder that is the seed your are using in the "cache" folder. 2. Change the "seed" to a different number.```.
In ideas-and-feedback, at 2023-10-12 17:33:45 a user named shaneyu said ```Sorry to bother, can someone help me explain how cache worked in autogen? is it suppose to save money or to improve precision? The explanation in doc is pretty limited.```.
In ideas-and-feedback, at 2023-10-12 17:11:15 a user named jtguzman said ```Well langchain is indeed fragile in some use cases. Mainly chaining requests (the irony). But I have had very good and consistent results with function calling, tagging and retrival. I have not used gpt engeneer. Will give it a look```.
In ideas-and-feedback, at 2023-10-12 16:53:39 a user named zybergod said ```Good afternoon! I can't seem to find documentation about showing real-time output from responses. Can someone help me out? I want to see what is happening between messages.```.
In ideas-and-feedback, at 2023-10-12 16:17:55 a user named rusted__silver said ```I didnt use it but from what ive read langchain is fragile, if it works it works, if it doesnt its faster to code by hand than debug whats going on with it. Can you give me a feedback on this?
Also, have you tried gpt engeneer? Any thoughts on it? (which uses among other things langchain, ik)```.
In ideas-and-feedback, at 2023-10-12 16:14:49 a user named rusted__silver said ```A combinaton of memorygpt and elevenlabs could get you close with current tech, methinks.
Or at least a similar way.
Maybe a poe bot? If it wasnt so filtered and dumbed down id say CharacterAI with elevenlabs somoehow implemented```.
In ideas-and-feedback, at 2023-10-12 15:27:20 a user named frank.martinez said ```I need to add a property to each agent for relationships; to associate an agent to a higher level entity.

For example an agent can be related to ‘Team A’. Or related to ‘Company A’. Or a member of ‘Group A’.

This will also be useful when agents need to be granted permission to cloud services. In AWS this would mean that an agent would be added as an IAM user, then added to a group to be granted permission to appropriate AWS services; at the read or write level.```.
In ideas-and-feedback, at 2023-10-12 15:26:16 a user named vanvvvvvvvv said ```hi there, trying to learn this technology and see how can it help me create multi agent apps```.
In ideas-and-feedback, at 2023-10-12 13:25:14 a user named jtguzman said ```I think a good coordination with Langchain agents, maybe with the use of some user friendly tools such as Flowise would be a good start. I'm curious if someone has used OpenInterpreter and can make a comparison with Autogen.```.
In ideas-and-feedback, at 2023-10-12 13:22:03 a user named jtguzman said ```Hello to everyone, I have a software development business and I've been waiting for this moment for a long time. I think many of you too. Who would like to discuss the best strategy to automate the software continuous development with Autogen? After a lot ox experiments since the release of GTP I'vee been using AI to improve our productivity, I would love to share ideas.```.
In ideas-and-feedback, at 2023-10-12 13:20:56 a user named fxtoofaan said ```Analyze GitHub repo and write code based on repo 🙂```.
In ideas-and-feedback, at 2023-10-12 11:11:57 a user named quackduck. said ```up one more Mr mod```.
In ideas-and-feedback, at 2023-10-12 11:11:40 a user named quackduck. said ```bro what is with all the  server ads @null```.
In ideas-and-feedback, at 2023-10-12 08:49:06 a user named leonardooliva said ```may someone explain me why all these 7B models are "outperforming" llama 70B? What was changed?```.
In ideas-and-feedback, at 2023-10-12 04:34:03 a user named shortd00d said ```It uses one LLM and breaks down the pieces of a script, but you could do something similar with agents running specific facets of your story.```.
In ideas-and-feedback, at 2023-10-12 04:33:16 a user named shortd00d said ```I saw this video a couple days ago.
https://www.youtube.com/watch?v=aAdOCKn8f40&ab_channel=TheoreticallyMedia```.
In ideas-and-feedback, at 2023-10-12 04:05:40 a user named shortd00d said ```companion bot who can manage long term memory, maybe not today, but soon!```.
In ideas-and-feedback, at 2023-10-12 03:37:35 a user named eaglestrikezio said ```A full fledged B2B sales team that can identify potential clients from google maps and web, make research on them, find key stakeholders through LinkedIn, add to CRM, and make initial contact```.
In ideas-and-feedback, at 2023-10-12 00:42:48 a user named johnny_loquat said ```Tried the best 5-bit quantization version using LM Studio. Seems pretty good and not too slow on my 16gb ram CPU notebook.```.
In ideas-and-feedback, at 2023-10-11 23:51:53 a user named hosst. said ```Imagine a tool like Flowise but based on AutoGen. Including a template, tools & integrations marketplace.```.
In ideas-and-feedback, at 2023-10-11 23:08:05 a user named yoda892804 said ```hi there, trying to learn this technology and see how can it help me create multi agent apps```.
In ideas-and-feedback, at 2023-10-11 22:39:09 a user named jsimmend said ```Hi everyone nice to meet you. Blockchain developer researching AI agents```.
In ideas-and-feedback, at 2023-10-11 21:30:52 a user named .markuseicher said ```Hi there. I want to build a chatbot for training of healthcare workers who want to learn how to conduct peer coaching sessions.```.
In ideas-and-feedback, at 2023-10-11 19:47:05 a user named gecko007. said ```maybe missed the whole field goal but saying it anyways - whatsapp integration as well as next.js```.
In ideas-and-feedback, at 2023-10-11 17:53:05 a user named fxtoofaan said ```It’s ok, we’ll let this one slide 😉```.
In ideas-and-feedback, at 2023-10-11 17:18:14 a user named scrubeneezer said ```just getting started so this use case may not make sense.  my apologies if so```.
In ideas-and-feedback, at 2023-10-11 17:17:35 a user named scrubeneezer said ```a good starting place for me would be integration with discord.  maybe something with Midjourney```.
In ideas-and-feedback, at 2023-10-11 17:05:58 a user named fxtoofaan said ```I just saw a YT video on this today. Haven’t downloaded it yet. I wonder how it’ll do on content for sales and marketing```.
In ideas-and-feedback, at 2023-10-11 16:57:30 a user named aaronward_ said ```anyone use the zephyr model yet?```.
In ideas-and-feedback, at 2023-10-11 15:55:19 a user named fxtoofaan said ```Good idea. Please let me know what you create please. I’d be interested in that as well 👍```.
In ideas-and-feedback, at 2023-10-11 15:40:58 a user named one_wave said ```I’d love to build a group of agents to help perform sales operations analyses.```.
In ideas-and-feedback, at nan a user named rabz said ```I'm new here, thank you.```.
In ideas-and-feedback, at 2023-10-11 10:13:37 a user named li_jiang said ```I tried to block this bot, but looks like only worked for myself.```.
In ideas-and-feedback, at 2023-10-11 10:12:54 a user named li_jiang said ```Did I deleted the msg for everyone?```.
In ideas-and-feedback, at 2023-10-11 10:10:14 a user named li_jiang said ```Still learning how to ban it😅 I'm a noobie  of Discord```.
In ideas-and-feedback, at 2023-10-11 08:58:09 a user named krisograbek said ```Posting here to get through "get started"```.
In ideas-and-feedback, at 2023-10-11 07:53:27 a user named justintimmer said ```I would like to build a consortium of agents to help me find developers in my area.```.
In ideas-and-feedback, at 2023-10-11 04:02:54 a user named yssrexe said ```Guys this automated checker for simple shell tasks ...
on the redme.md file you will find all steps to check you code
https://github.com/yssrexe/automated_checker```.
In ideas-and-feedback, at 2023-10-11 03:47:11 a user named nisargamin said ```I guess the big assumption is can agents have legal status. Ya that’s the biggest claim. scaled down could be easier to start with.```.
In ideas-and-feedback, at 2023-10-11 03:44:10 a user named nisargamin said ```Gotcha. Ya I think human intervention can be looped in. But workflows and mundane work automated. Maybe these RE private equity guys would jump on it 😂```.
In ideas-and-feedback, at 2023-10-11 03:42:37 a user named elshep said ```I mean if a corporation can legally count as a person / entity I think you can probably make the case for an agent as well.

Only challenge is figuring out how to register an autonomous non-human entity as a business entity / a shareholder in your LLC lol```.
In ideas-and-feedback, at 2023-10-11 03:36:27 a user named sam.li said ```https://tenor.com/HmZi.gif```.
In ideas-and-feedback, at 2023-10-11 03:36:20 a user named nisargamin said ```Can there not be memory? As long as there’s a log of the work done agents, it can be validated by a human.  If I understand your point correctly```.
In ideas-and-feedback, at 2023-10-11 03:34:47 a user named elshep said ```I imagine the persistence of an agent instance might challenge this idea though. *puts on tin foil hat* do they really exist even when they’re not running code 🤔. Jokes aside I think this is a very cool thought experiment to do just to say you did it```.
In ideas-and-feedback, at 2023-10-11 03:34:16 a user named nisargamin said ```I think a scaled down version of focusing on documents rather than transactions is a good starting point to validate. Clearly there’s a lot to be done with titles and deeds alone```.
In ideas-and-feedback, at 2023-10-11 03:32:53 a user named frank.martinez said ```Possibly. Could be done without smart contracts. The deed/title are more important. If these can be abstracted into relationships with agents then a marketplace should be possible.```.
In ideas-and-feedback, at 2023-10-11 03:30:13 a user named nisargamin said ```This is a good idea. Are you thinking smart contracts?```.
In ideas-and-feedback, at 2023-10-11 03:17:56 a user named _appman said ```How you ask a question (prompt) generates the response to you by the bot multiple questions n number of answers from n bots for you.```.
In ideas-and-feedback, at 2023-10-11 03:16:11 a user named _appman said ```Health care app  OTC vitamins and their effect on mental health```.
In ideas-and-feedback, at 2023-10-11 00:42:27 a user named frank.martinez said ```Conceptually agents could have legal status. So in theory an agent could own property; and if so, then an agent could buy commercial real estate. Or, agents could sell their property. Thinking about how to write a contract between agents; and where the escrow role would fit in [is it an agent?]```.
In ideas-and-feedback, at 2023-10-10 21:03:22 a user named karlka said ```Hello people, have a few questions about autogen as I'm building a marketing agent system for my company.

1) What's your experience building multi agent systems (teams of agents, e.g. marketing team) - which performs better in your opinion - fully autonomous system like the GroupChat where one orchestrator auto-selects next speaker vs pre-defined flows where agent's message queue is deterministic (don't know if this is even multi agent)? Or some kind of a hybrid of both.

2) Secondly, do you find very narrow task specific agents performing better or what's your take on how broad an agent skillset/instructions can be?```.
In ideas-and-feedback, at 2023-10-10 18:42:06 a user named rabz said ```Anyone can link a useful guide on integrating LLama2 with Autogen instead of OpenAI```.
In ideas-and-feedback, at 2023-10-10 17:26:50 a user named tangerine1528 said ```Yes, It is on first try today, However, it running good on agentcy ? So are there any modification need it for OADS ?```.
In ideas-and-feedback, at 2023-10-10 17:09:30 a user named afourney said ```This feels like a problem on their end. Is the problem persisting? And if so, can you try code that calls the OAI endpoint directly (perhaps one of their examples)```.
In ideas-and-feedback, at 2023-10-10 17:02:23 a user named jtguzman said ```Hello! My autogen app is not creating the files. It creates the directory but not the .py or .txt files. Any of you had the same issue?```.
In ideas-and-feedback, at 2023-10-10 16:17:23 a user named nisargamin said ```I am interested in this question as well. One way that I have come across is that Langchain now supports knowledge graphs and visualization using Matplotlib. It uses triples. So I am assuming this is at an LLM level and not multiagent level. I am curious if there can be a common knowledge base that can be persistent and evolutionary with the ability to deprecate what ever is no longer relevant (i.e. out dated knowledge).```.
In ideas-and-feedback, at 2023-10-10 15:40:43 a user named tangerine1528 said ```Running OADS:  500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID 107b7f79009a2e0fc7c1f69bde1c9db8 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 10 Oct 2023 15:39:49 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-0613', 'openai-organization': 'personal-dcxxx4', 'openai-processing-ms': '1469', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '89703', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '198ms', 'x-request-id': '107b7f79009a2e0fc7c1f69bde1c9db8', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '813ff5476c962c9e-DFW', 'alt-svc': 'h3=":443"; ma=86400'}
**?? **```.
In ideas-and-feedback, at 2023-10-10 15:06:06 a user named tangerine1528 said ```When is AutoGen HedgeFund guys ?```.
In ideas-and-feedback, at 2023-10-10 15:02:53 a user named wyttearp said ```I was thinking about something like this, but I wanted it to be a streaming series for everyone to watch and to actually produce a product at the end of each week. For example a graphic design company, and have them actually sell real products through a print on demand store. I thought each week there could be a lot of character-driven drama going into the creation of the design, so the shirt itself acts like a meme for those who watched the AI soap opera.```.
In ideas-and-feedback, at 2023-10-10 14:42:24 a user named 7racker said ```I think UX is a critical area that needs to be worked on when it comes to autonomous agents. It’s a balance between how much they do on their own versus how much feedback they ask from the user. As a user I want to be able to 
- have full visibility on all of the activities that the agents are working on. 
- interject when I see an agent going, off course. 
- have easy access to all assets generated by the agents. 
- have the agents to learn about all my preferences and remember them for later.```.
In ideas-and-feedback, at 2023-10-10 12:36:15 a user named mana84_88876 said ```i would to bulid my own project using Autogen```.
In ideas-and-feedback, at 2023-10-10 11:27:53 a user named satya_1987 said ```How can we add the knowledge base to the multiagent ?```.
In ideas-and-feedback, at 2023-10-10 07:07:28 a user named foxpassed said ```I want to make a gaggle of virtual office workers with quirky personalities working in a paper sales office and have the sitcom The Office be an evolving, interactive experience for me.```.
In ideas-and-feedback, at 2023-10-10 02:53:55 a user named atlmapper said ```Someone posted a UI recently:
https://github.com/victordibia/autogen-ui```.
In ideas-and-feedback, at 2023-10-10 00:38:34 a user named smuggybuggins said ```I want learn more about AutoGen and AI in general, while building a small Android app to access this awesomeness on the go!```.
In ideas-and-feedback, at 2023-10-09 23:12:32 a user named notoriousjimbo said ```I am currently working on a book writer```.
In ideas-and-feedback, at 2023-10-09 21:56:24 a user named mightyscoo said ```I want to create an LLM that is capable of learning about LLM's and incorporating advances into itself, and I want it to run on my shoe.```.
In ideas-and-feedback, at 2023-10-09 21:16:04 a user named thenizix said ```most users want ask for a thing and become a product, would be nice...```.
In ideas-and-feedback, at 2023-10-09 21:01:48 a user named pablo.ce said ```it would be nice to have open source models support also using tgi or vllm for inference```.
In ideas-and-feedback, at 2023-10-09 16:11:03 a user named haydendougherty101 said ```I want to make a network of angents for myself that rally behind one "CEO agent" but I don't know anything about code so the growing pains have been rough using autogen and trying to figure out where to even space in a prompt for one of the agents```.
In ideas-and-feedback, at 2023-10-09 16:07:39 a user named andeeri said ```Do the all cool stuff```.
In ideas-and-feedback, at 2023-10-09 16:03:57 a user named publicnewschoice said ```id like to make everything my mind desires with autogen```.
In ideas-and-feedback, at 2023-10-09 15:40:57 a user named ttt said ```I'd like to make a streaming app for nature```.
In ideas-and-feedback, at 2023-10-09 15:23:07 a user named anilmatcha said ```Would love a UI on top of it```.
In ideas-and-feedback, at 2023-10-09 13:53:26 a user named metasphere1 said ```Vote for additional/simplified local LLMs including simple(r) RAG```.
In ideas-and-feedback, at 2023-10-09 11:48:37 a user named scrypturd said ```I like how there are independent agents that are able to solve problems iteratively together```.
In ideas-and-feedback, at 2023-10-09 09:37:32 a user named stankbritchez said ```Anyone going to build a GUI for this?
Also, an easy way to include extensions or plugins would be huge.```.
In ideas-and-feedback, at 2023-10-09 08:34:40 a user named xam1311 said ```or 
https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/```.
In ideas-and-feedback, at 2023-10-09 08:34:24 a user named xam1311 said ```https://github.com/microsoft/autogen/pull/95```.
In ideas-and-feedback, at 2023-10-09 08:32:58 a user named xam1311 said ```you can have offline model you know```.
In ideas-and-feedback, at 2023-10-09 08:10:40 a user named godziiilla said ```AutoGen would be really cool if they could work off line with smaller more specialised LLMs (save on costs). Be really cool if a Agent could work out an appropriate interface with a resource be that website, pdf or api automatically.```.
In ideas-and-feedback, at 2023-10-09 04:31:53 a user named da_michl. said ```Playful UI to show and manage roles```.
In ideas-and-feedback, at 2023-10-09 03:34:38 a user named ccerrato147 said ```Have AutoGen create, manage and improve more AutoGen teams of agents for different purposes```.
In ideas-and-feedback, at 2023-10-09 02:13:11 a user named rastrol7 said ```Library of agent templates for more advanced use cases```.
In ideas-and-feedback, at 2023-10-09 01:41:06 a user named jpakjr said ```Feature I’d like to have is a central UI to approve/deny/comment on agent updates. Preferably a mobile app```.
In ideas-and-feedback, at 2023-10-09 01:12:34 a user named Dr.Inc said ```I would like there to be integration to learn how to lower api cost```.
In ideas-and-feedback, at 2023-10-08 22:25:07 a user named regen2moon said ```I've tried 
User Dashboard -> Main agent ->>> subagents
User Dashboard -> Main agent -> coordinator ->>> subagents```.
In ideas-and-feedback, at 2023-10-08 22:24:14 a user named regen2moon said ```Anyone have the prompt structure to send to each sub agent / coordinator that doesn't get stuck in a loop?```.
In ideas-and-feedback, at 2023-10-08 21:36:59 a user named modularsushi168 said ```Integrate autogen into Microsoft Azure.```.
In ideas-and-feedback, at 2023-10-08 19:22:19 a user named ai.reseach said ```That's almost as bad as when Autogpt just goes surfing the web and gets stuck trying to make it work but not doing a damn thing differently```.
In ideas-and-feedback, at 2023-10-08 18:12:54 a user named e404nothing said ```I would like to make a personal assistant, or even a program to track and assist in offgrid solar system optimization.```.
In ideas-and-feedback, at 2023-10-08 16:30:04 a user named twezoalgo said ```Any updates on using this technology with cheaper models ?```.
In ideas-and-feedback, at 2023-10-08 11:27:48 a user named devonx said ```hello, would love to try to get this to work as a general UX UI builder or make a framework to make it possible to easily make UIs both in 3D and in 2D```.
In ideas-and-feedback, at 2023-10-08 09:11:14 a user named haffel said ```As long as you can compress the information so much that theres enough context for responses, yes. Else you have to for example fine tune it```.
In ideas-and-feedback, at 2023-10-08 08:46:36 a user named fran.abenza said ```We need a way to create dynamic UI based purely in context.```.
In ideas-and-feedback, at 2023-10-08 07:20:22 a user named wonderkidshihab said ```Was thinking the same, glad to know I am not alone.```.
In ideas-and-feedback, at 2023-10-08 05:34:46 a user named t_rust1887 said ```AI that is capable of technical sales support for worldwide distributors in different languages.```.
In ideas-and-feedback, at 2023-10-08 04:37:47 a user named an1z said ```Would like to try AutoGen first```.
In ideas-and-feedback, at 2023-10-08 03:23:07 a user named ecvanbrussel said ```Yeah me too. I've never seriously programmed in Python. Let alone doing a AI related project.```.
In ideas-and-feedback, at 2023-10-08 03:20:33 a user named flextheai said ```I think about this technique often. I would love to see this implemented. Im going to try but im quite new to all this. 💩```.
In ideas-and-feedback, at 2023-10-08 02:46:45 a user named sonichi said ```I think there must be a way. First, when I write code I don't keep a 32k context reference on my side. Second, when using multiple agents, each can use their own context window.```.
In ideas-and-feedback, at 2023-10-08 02:42:54 a user named ecvanbrussel said ```Ah, I see I'm not alone. 😁```.
In ideas-and-feedback, at 2023-10-08 02:38:20 a user named ecvanbrussel said ```Hey so I already talked about this a couple days ago. I'd really love to build a system using autogen that helps me with my work as a web developer. I was hoping that if I build it well, it could even craft a decent PoC or maybe even an MVP from scratch from just an initial instruction that describes what kind of web app I want to build and what specific features I want that web app to have.

I was told that that might not be possible yet, because a decently sized project would likely exceed GPT-4's context window size, if you'd want to keep every code-file in context. Of course that shouldn't be an issue during the start of a project, but as soon as it starts growing it could become an issue.

But now I'm thinking, it's not really necessary to keep all the files in context, right? I mean, you could have one agent whose task it is to build a database of knowledge about the current state of the project, in a tree-like way. So like in the entry-table, the first row would just contain the initial instruction that was given (describing the desired web app and its features), and would list which features have already been worked on, where each list-item is a link to the database row that goes into more detail about that feature. And then if one would look at one of those rows, it would explain the feature in more detail, plus list and link to files and folders where one could find code related to that feature. Etc, etc...

And then the agent who is responsible for writing new code, to either add a brand new feature or to finish a feature it's been working on, that agent would ask the first agent to bring him all the necessary context that he needs just for the code he's about to write.

I believe that could work and should be able to fit within the 32k context window, don't you think?```.
In ideas-and-feedback, at 2023-10-08 01:55:33 a user named flextheai said ```i would like to build a Ai assistant that can help me build apps and websites. One app I would like to build is a "text to video converter which searches the web for gifs which align with the users text."```.
In ideas-and-feedback, at 2023-10-07 23:27:08 a user named luckylolo said ```want to build a few mobile apps, is this capable of that?```.
In ideas-and-feedback, at 2023-10-07 22:54:08 a user named roundshoulder said ```https://youtu.be/olhABcSz2JY?feature=shared```.
In ideas-and-feedback, at 2023-10-07 21:15:47 a user named ozzydog said ```Currently looking to build a completely automated workflow/app, that finds content in an industry, in a certain country, rewrites content, post to a blog, as well as creating images for the post, creates excerpts and images, then creates a full newsletter, ready for submission after review, to a list, using a specific email software (mailwizz).  Then post the link to the newsletter, to socials.```.
In ideas-and-feedback, at 2023-10-07 21:13:31 a user named amnor96 said ```An AI analyzer for AI generated documentation of AI written code.```.
In ideas-and-feedback, at 2023-10-07 20:04:37 a user named luckybunnies said ```I'd like to see a GUI with drag and drop elements similar to Flowise```.
In ideas-and-feedback, at 2023-10-07 18:50:19 a user named gstrubinsky said ```Shape the Future with Benevolent AI: A Global Solutions Repository for Social Change

I extend an invitation to explore a pioneering initiative aimed at addressing global challenges through AI, leveraging the capabilities of AutoGen and the global reservoir of creative minds. This endeavor intends to bridge the gap between groundbreaking solutions and the right audiences, fostering a global repository of solutions. AutoGen could be instrumental in turning this vision into a transformative reality.
Gap Identification: Global issues like wealth disparities and environmental crises need immediate solutions. Many solutions exist but remain unseen due to creators' lack of resources or networks. or lack of social skills. This initiative aims to bridge this gap.
Proposal: Universal Solution Repository Envisioning an AI-driven platform to globalize solution sharing. This platform accepts submissions in any form (email, text files, documents, faxes, spoken word) and language, making it easy for anyone, anywhere to share and search for innovative ideas in their native language.
Alignment with AutoGen’s Ethos:
    • Empowering marginalized voices to drive social impact.
    • AI for multilingual engagement to foster global collaboration.
    • A language neutral repository to extend the reach of impactful solutions.
    • Ethical AI application to uplift underprivileged communities.
AI and AutoGen’s Role:
    • AI normalizes solutions across languages, promoting democratization.
    • AI's ability for rigorous solution evaluation.
    • Unlike biased human experts, AI offers objective assessments and enormous expertise in various fields.
This initiative, driven by the desire for global impact, not financial gain, seeks to combine everyone’s expertise in the LLM/AutoGen domain to turn this concept into reality. Eager to open discussions on potential synergies.
Günter Strubinsky, MS.CIS.```.
In ideas-and-feedback, at 2023-10-07 18:08:39 a user named salim4n said ```Thanks, got a New side project ✌️```.
In ideas-and-feedback, at 2023-10-07 18:07:41 a user named salim4n said ```With pleasur, but it gonna take me a lot of Time 😂```.
In ideas-and-feedback, at 2023-10-07 17:30:11 a user named finnious. said ```easy way to feed knowledge to a specific agent. For Example: we have a marketing team and one agent is using a PDF of latest best practices.```.
In ideas-and-feedback, at 2023-10-07 17:16:50 a user named kareem6370 said ```would you plz share your experience with us? if you don't mind?```.
In ideas-and-feedback, at 2023-10-07 17:14:07 a user named salim4n said ```Gonna create an API with Mistral and autogen```.
In ideas-and-feedback, at 2023-10-07 16:49:00 a user named ntcgreyhart said ```The future is going to be making agents that run in the background. You will wake up in the morning and your computer will present you with the news and information most relevant to you. The agents will learn what you find important, and adapt as your tastes change.

THAT is where the money will be. Sooner than anyone thinks.```.
In ideas-and-feedback, at 2023-10-07 16:47:20 a user named sneaky1442 said ```gotta give more context lol, what types of apps, what types of data projects, etc```.
In ideas-and-feedback, at 2023-10-07 16:46:06 a user named sneaky1442 said ```Hurts my heart this isnt open source```.
In ideas-and-feedback, at 2023-10-07 16:38:52 a user named economistajosegarcia said ```I would like to build custom apps for my data projects```.
In ideas-and-feedback, at 2023-10-07 16:38:50 a user named Phenikx said ```so a few days ago there was a discussion about ai and the bandwidth humans have to it being low.. What if this tech can be used with LLMs https://www.youtube.com/watch?v=rIbfNUA5pWk&t=16s```.
In ideas-and-feedback, at 2023-10-07 15:43:25 a user named pablo.was.here said ```me too, want to work together?```.
In ideas-and-feedback, at 2023-10-07 14:09:02 a user named akhilnchauhan said ```hey y'all - v exciting stuff happening here

i'm looking at making building a Research Agent team, a la AI Jason's demo. It'll be focused on a specific niche (researching for Sales teams)

If anybody is doing similar stuff, would love to chat```.
In ideas-and-feedback, at 2023-10-07 13:36:43 a user named alex8642 said ```late reply as I just joined but yes, instantly made me think of CBC! Always a small world. A Waterloo veteran I see with impressive qualifications - I am in the middle of an Additive Metal research project with the MSAM division right now for my day gig. Nice to see another Canuck here. I sadly only dabble in AI in my spare time 😦 though what I do see makes me want to change careers.```.
In ideas-and-feedback, at 2023-10-07 13:07:38 a user named andyinater said ```I will release something tonight that shows how, but in short, I'm overriding the "receive" function in the agent and deleting/limiting the message history there.


If you are talking about having a long conversation which leads to the tokens maxing out```.
In ideas-and-feedback, at 2023-10-07 07:44:20 a user named d8689 said ```Hey all, this is such a cool and interesting project - great job. Also the amount of effort which has gone into documentation and explanations is phenomenal.

I'm still working my way through the code base, but I was wondering if there are any ways of managing the context length with which the agents are working. I don't have access to GPT4-32k and started running into context length exceeded issues quite quickly. Thanks!```.
In ideas-and-feedback, at 2023-10-07 07:12:27 a user named qslug said ```You could have agents act as various subject matter experts, say one for graphics, one for music, one for the game loop, all making connections in the graph to the work that needs to be done.```.
In ideas-and-feedback, at 2023-10-07 07:05:20 a user named qslug said ```So I stumbled across this demo of InfraNodus today (https://youtu.be/XMwa9q6wWkw?si=RiNGjFNmSQ_WBBoJ). It uses GPT-4 to build a knowledge graph of a topic in order to identify gaps in thinking.  It reminded me of @andyinater ‘s master plan, which serves both for agent alignment and as a checklist. I think the same could be done with knowledge graphs. And graphs can be built up incrementally, processed incrementally, are amenable to search, and can be more safely pruned or condensed. All of which allows for more complex domain driven designs.```.
In ideas-and-feedback, at 2023-10-07 04:58:53 a user named sonichi said ```This is used in some example like https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb```.
In ideas-and-feedback, at 2023-10-07 03:11:23 a user named hanley7082 said ```Thanks for this insight, I haven't run a multi-agent group chat yet```.
In ideas-and-feedback, at 2023-10-07 02:44:00 a user named shaneyu said ```Right now 2 pairs agents with an admin works fine most of the time, but it's not guaranteed```.
In ideas-and-feedback, at 2023-10-07 02:43:14 a user named shaneyu said ```Yes, if the performance keeps getting worse with more agents this will be my last resort.```.
In ideas-and-feedback, at 2023-10-07 02:40:09 a user named hanley7082 said ```This is not yet a well-formed thought, but what about having the assistant / proxy pair combined into a single function, and then having each function available to a function calling proxy. That function calling proxy could be in conversation with a single main assistant```.
In ideas-and-feedback, at 2023-10-06 20:06:17 a user named shaneyu said ```If anyone working on similar things/setups or noticing similar issues, please share your thoughts! Appreciated❤️```.
In ideas-and-feedback, at 2023-10-06 20:05:10 a user named shaneyu said ```Hi guys, I am currently exploring agents working collaboratively as a team of personal assistants, handling Gmail tasks, Teams tasks, etc. In my design, handing a specific group of tasks, e.g. (Gmail tasks: read email, send email, summarize unreads, etc.) needs a gmail_assistant_agent and a gmail_user_proxy agent and they work in pairs. The thing is they all work perfectly in standalone context, ie, a group chat containing only these two agents. But if I were to add more agents into a group chat, i.e. an admin, another pair of agents doing other jobs, they tend to get confused and dont know what next step should be.```.
In ideas-and-feedback, at 2023-10-06 17:47:12 a user named salegrem said ```Anybody tried creating an agent that reasons using the combined inputs of multiple agents? As a single brain. I'm thinking of something like a Jungian archetypes sort of approach. This is about mimicing psychology```.
In ideas-and-feedback, at 2023-10-06 16:58:44 a user named joao.morossini said ```Update: I first ran it with gpt-4 only and was successful. Then I switched to gpt-3.5-turbo-16k and the agents just kept apologizing and thanking each other hahaha.```.
In ideas-and-feedback, at 2023-10-06 16:29:46 a user named joao.morossini said ```Hey there! I'm building an app for analyzing a publicly available jupyter notebook and outputting a brief report of what it does. Below you can find a rudimentary snippet of my first try. Any ideias on how to improve performance for this use case will be much appreciated. Cheers! 🙂

```
# create an AssistantAgent instance named "assistant"
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
)
# create a UserProxyAgent instance named "user_proxy"
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "web"},
    llm_config=llm_config,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet."""
)
````

````
# the assistant receives a message from the user, which contains the task description
user_proxy.initiate_chat(
    assistant,
    message="""
What is this Jupyter notebook intended to do?
URL: < URL for the notebook goes here >
""",
)
```````.
In ideas-and-feedback, at 2023-10-06 16:25:45 a user named afourney said ```Wow, interesting, and thanks for reporting. We'll try to reproduce and see if we can work around it.```.
In ideas-and-feedback, at 2023-10-06 16:14:59 a user named sonichi said ```hullo yup saw that and have been trying```.
In ideas-and-feedback, at 2023-10-06 15:55:54 a user named davec1623 said ```hullo, yup saw that and have been trying to recreate but found it gets stuck in loops etc, quite hard to get it to solve the issue well and im left wishing i had more control, Also, am i right in thinking chat manager only has the names of the agents to go by in selecting who speaks next? found i had to be really really explicit in the name of the agent to get good results```.
In ideas-and-feedback, at 2023-10-06 16:15:00 a user named sonichi said ```Would like to have longer discussion about the control part @afourney . The chat manager uses both name and system msg to decide the speaker. Both are important.```.
In ideas-and-feedback, at 2023-10-06 16:24:00 a user named afourney said ```Thanks for the mention. Yes,  control and orchestration in the group chat setting is something I am keenly interested in improving. To help with this, I am assembling examples where loops and mis-orchestration occur, so that I can test any mitigations. If are willing to share your example, or prepare a minimum reproducible example, this would help a lot. In the meantime, you can try a few things like asking the agents to at-mention each other, and making sure in the system prompt that the agents know their own identities (sometimes they don't respond appropriately because they don't realize they are being addressed)```.
In ideas-and-feedback, at 2023-10-06 15:32:33 a user named rtatlas said ```will try this, thank you```.
In ideas-and-feedback, at 2023-10-06 15:11:17 a user named edmundriviere said ```I'm a business consultant not developper but have access to some ressources.```.
In ideas-and-feedback, at 2023-10-06 15:10:50 a user named edmundriviere said ```What would be my high level plan to do that?```.
In ideas-and-feedback, at 2023-10-06 15:09:42 a user named edmundriviere said ```Hi community! Excited to see this project. I have 1 question: Im agine I train Llama2 on a specific project code in python with code snippets, documentation, database metadata and high level user requirements. Would I be able able to do a Fit Gap analysis of a user project to map user requirements to exisitng code estimate code cusotmizations cost and time?```.
In ideas-and-feedback, at 2023-10-06 14:19:40 a user named wladpaiva said ```Has anyone started porting autogen to other languages like TS?```.
In ideas-and-feedback, at 2023-10-06 14:02:23 a user named mrauter said ```I had the same problem. Downgrading to python 3.11 fixed it for me```.
In ideas-and-feedback, at 2023-10-06 13:47:29 a user named sonichi said ```Thanks for the feedback! I assume you are referring to the default AssistantAgent and UserProxyAgent, right? They are indeed preconfigured to be excellent at coding tasks. But you can easily customize the system message to skip coding. For example, this example has an planning agent that is instructed not to suggest code: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb```.
In ideas-and-feedback, at 2023-10-06 12:56:43 a user named davec1623 said ```feedback so far: feels too dedicated to code writing etc, not flexible enough to be used for multi agent conversation generally i.e. planning non-code based things. i think i'd use it for a quick attempt at a local version of code interpreter but otherwise would be more likely to use semantic kernel as more control```.
In ideas-and-feedback, at 2023-10-06 06:29:56 a user named qslug said ```That being said, you will likely need to tinker with the Agents'  `system_message`s to coerce other models into behaving. Just read the default system messages carefully and make sure your custom message enforces the same constraints. Each model has it's quirks, and it's pretty impressive that the defaults work well on both GPT-4 and GPT-3.5```.
In ideas-and-feedback, at 2023-10-06 06:27:38 a user named qslug said ```autogen supports anything that can be served via an OpenAI compatible API. FastChat works, I think `text-generation-webui` works with a plugin. I've seen other model servers mentioned. I was tinkering with CodeWizard the other day with no issues. I am building autogen from source, and I think some of the fixes happened quite recently and may not have made it into a tagged release yet (last release 3 days ago).```.
In ideas-and-feedback, at 2023-10-06 05:55:31 a user named vincentjedi said ```@elasticbean should we have a  voice chat together with sneaky ?```.
In ideas-and-feedback, at 2023-10-06 05:12:29 a user named sravan1243 said ```Hi, I’d like to create website builder```.
In ideas-and-feedback, at 2023-10-06 05:05:55 a user named rtatlas said ```yeah i wonder if it would work creating scripts for like roblox games or something```.
In ideas-and-feedback, at 2023-10-06 04:16:13 a user named mistafisha said ```I'd like to have it build games```.
In ideas-and-feedback, at 2023-10-06 04:02:54 a user named raban6426 said ```I'm interested in creating a newsletter publishing workflow```.
In ideas-and-feedback, at 2023-10-06 03:54:08 a user named rtatlas said ```I'm interested in using the Agentcy thing, are these all the things needed
pycharm
python 3.11
docker
visual studio```.
In ideas-and-feedback, at 2023-10-06 03:45:41 a user named afourney said ```No need to apologize. I’m just working out how to facilitate installing across many different platforms. Docker is a container that could help perhaps (and provides some isolation for code execution)```.
In ideas-and-feedback, at 2023-10-06 03:43:47 a user named rtatlas said ```Negative i have no clue what that is, it is literally my first day im just tryna make a lil team of people to make me an app lmao sorry if i'm causing yall brain damage```.
In ideas-and-feedback, at 2023-10-06 03:41:41 a user named afourney said ```Setting up a Docker image to easy-install everything is a swell idea. Do you use Docker?```.
In ideas-and-feedback, at 2023-10-06 03:39:29 a user named elasticbean said ```what is your `aiohttp` version?```.
In ideas-and-feedback, at 2023-10-06 03:27:59 a user named afourney said ```But no, don’t downgrade. I was worried because pyautogen requires at least 3.8```.
In ideas-and-feedback, at 2023-10-06 03:26:40 a user named afourney said ```Are you using windows? How did you install python? The second link states: “It is generally recommended to use python.org-provided Python builds on Windows.”… but honestly I’m not 100% sure```.
In ideas-and-feedback, at 2023-10-06 03:07:28 a user named rtatlas said ```Should I revert to an older version of python?```.
In ideas-and-feedback, at 2023-10-06 03:02:38 a user named rtatlas said ```quick someone create an AI that will auto install!!!! easy fix lol```.
In ideas-and-feedback, at 2023-10-06 02:58:20 a user named rtatlas said ```but also all of this is like im reading russian, and i dont speak russian```.
In ideas-and-feedback, at 2023-10-06 02:58:17 a user named elasticbean said ```you can check: `python --version````.
In ideas-and-feedback, at 2023-10-06 02:55:44 a user named rtatlas said ```3.12 if im not mistaken```.
In ideas-and-feedback, at 2023-10-06 02:45:20 a user named afourney said ```What version of Python are you using? There appears to be some issues with certain Windows environments: https://github.com/psf/black/issues/3483```.
In ideas-and-feedback, at 2023-10-06 02:43:25 a user named afourney said ```You appear to have hit this problem with a dependency: https://stackoverflow.com/questions/74550830/error-could-not-build-wheels-for-aiohttp-which-is-required-to-install-pyprojec```.
In ideas-and-feedback, at 2023-10-06 02:20:51 a user named rtatlas said ```any help would be absolutely lit```.
In ideas-and-feedback, at 2023-10-06 02:20:39 a user named rtatlas said ```ERROR: Could not build wheels for aiohttp, which is required to install pyproject.toml-based projects
trying to do the pip instally pyautogen this is what i get```.
In ideas-and-feedback, at 2023-10-06 01:41:18 a user named afourney said ```Damn straight! (Though this is the 1970s edition)```.
In ideas-and-feedback, at 2023-10-06 01:29:02 a user named amadad said ```Not a canuck. But that's an all time great logo by Burton Kramer. https://www.cbc.ca/radio/day6/coronavirus-impeachment-then-and-now-picard-returns-fruits-of-the-goop-lab-cbc-logo-designer-and-more-1.5437706/an-icon-of-canadian-graphic-design-meet-burton-kramer-designer-of-the-cbc-logo-1.5437708```.
In ideas-and-feedback, at 2023-10-06 00:46:00 a user named rtatlas said ```r there any installation videos ? I'm incredibly new to all of this and have zero experience coding```.
In ideas-and-feedback, at 2023-10-06 00:42:46 a user named ilaffey said ```Doing some initial thinking around longer term persistence layer. 
Would love to see improvements in the way agents are able to communicate over time, and the information they share with each other```.
In ideas-and-feedback, at 2023-10-05 23:23:21 a user named kajatta said ```I believe it was developed by @shiccup```.
In ideas-and-feedback, at 2023-10-05 23:21:06 a user named afourney said ```https://en.wikipedia.org/wiki/CBC_Radio```.
In ideas-and-feedback, at 2023-10-05 23:20:06 a user named afourney said ```Oh I mean the agentcy logo```.
In ideas-and-feedback, at 2023-10-05 23:18:44 a user named kajatta said ```Sorry im at GCAP / Pax so trying to network and have a recognisable selfie```.
In ideas-and-feedback, at 2023-10-05 23:17:24 a user named afourney said ```That logo is giving me strong CBC Radio vibes. Any fellow Canadians here?```.
In ideas-and-feedback, at 2023-10-05 22:59:34 a user named kajatta said ```Or in less formal speak we are trying to make software Lego 😉```.
In ideas-and-feedback, at 2023-10-05 22:59:07 a user named kajatta said ```The approach we must take with this is a research-based approach to be successful. In this community we tend to carve out discrete capabilities. We are trying to prove and collaborate around them until it is polished, and then there are a few of us who have focused on integration and macro execution activities which can stitch them together, allowing us to achieve such a vision.```.
In ideas-and-feedback, at 2023-10-05 22:56:52 a user named _fenix_atx said ```Appreciate you sharing, that sounds pretty dang close to what I was envisioning. I managed to build a MVP of what I described as someone who hasn't written code in 15 years using GPT-4 and a lot of back and forth in the chat thread, but having discovered ChatDev and now AutoGen, I'm curious to see how much better this app, and a handful of others, that would greatly impact workflows at my 9-5 can be.```.
In ideas-and-feedback, at 2023-10-05 22:48:10 a user named kajatta said ```How about reads the tasks, plans execution, distribution of work to specific agents (with tool/function access), self tests, iterative updates, then documents, and assigns you the task of review of the PR, then creates a draft email with changelog and summary of change...then you semi retire 😉
https://discord.com/channels/1153072414184452236/1158564427117903882
https://github.com/amadad/agentcy```.
In ideas-and-feedback, at 2023-10-05 22:44:39 a user named _fenix_atx said ```app to build -- reads your email, creates tasks, prioritizes those tasks and sets due dates and allows you to reply to emails without ever going into the productivity wasteland that is an inbox```.
In ideas-and-feedback, at 2023-10-05 22:37:48 a user named kajatta said ```I have uploaded Langchain support, see https://github.com/microsoft/autogen/pull/58```.
In ideas-and-feedback, at 2023-10-05 21:48:56 a user named jasontyler said ```Would love to see support for Open Source models```.
In ideas-and-feedback, at 2023-10-05 20:22:05 a user named afourney said ```Thanks. I thought we fixed this. If it happens again, can you share a trace of what the agents tried? It's possible that the Markdown code block, output by the LLM,  is itself listing the wrong language. Anyhow, here's the current logic:```.
In ideas-and-feedback, at 2023-10-05 20:15:17 a user named zeesa27 said ```Hello. New here. Trying to start building an image to text parser but struggling with gpt4 despite some progress. My coding abilities are sort of non-existent. Looking forward to learning from this discord.```.
In ideas-and-feedback, at 2023-10-05 17:36:51 a user named pheek0 said ```I ran into an issue several times where the assistant suggested installing a pypi package: 
```
pip install <package>
```
But the user proxy didn't understand that it was a shell command, presumably because the assistant didn't prefix it with 'sh'. Other times it tried to run it in python instead of shell

Since this is a pretty common error handling command, it would be good to have some logic to automatically detect a pip install suggestion and run it as a shell command, regardless of formatting funkiness.```.
In ideas-and-feedback, at 2023-10-05 16:46:03 a user named jaemil said ```It's time for some moderation```.
In ideas-and-feedback, at 2023-10-05 14:37:02 a user named Deleted User said ```Hello, Twitch has started collaborating with CS 2 and launched a skins giveaway, promo code 2023, use it before it’s removed!
https://twltch-drp.com/main

@everyone
p.s its sponsored message```.
In ideas-and-feedback, at 2023-10-05 14:30:09 a user named elasticbean said ```Yes here. I dm'ed you```.
In ideas-and-feedback, at 2023-10-05 14:21:16 a user named sneaky1442 said ```very cool idea I'd be down to do an MVP```.
In ideas-and-feedback, at 2023-10-05 13:58:37 a user named indigo75 said ```I d like to build a lot of personas, how easy it is to actually dynamically create new agents ? I ll give it a look later today bit if you know feel free to tell me 😉```.
In ideas-and-feedback, at 2023-10-05 13:31:23 a user named zer0h1ro said ```AI-powered platform to find answers, ask questions, and earn money online from anywhere in the world```.
In ideas-and-feedback, at 2023-10-05 09:29:17 a user named yogeshharibhaukulkarni said ```Open Source Hugging Face model support as well as Langchain model support```.
In ideas-and-feedback, at 2023-10-05 06:32:09 a user named vincentjedi said ```But simple news summary is relatively simple to build.```.
In ideas-and-feedback, at 2023-10-05 06:31:39 a user named vincentjedi said ```We also need to work with the baysian inference software that is proprietary. Using their software isn't going to be cheap```.
In ideas-and-feedback, at 2023-10-05 06:30:36 a user named vincentjedi said ```Is there any coding maestro around ?I can barely understand how to work with autogen/open interpreter/langstream.. we all have our own domain knowledge```.
In ideas-and-feedback, at 2023-10-05 06:28:29 a user named au8 said ```Are you going to try to make this application?```.
In ideas-and-feedback, at 2023-10-05 06:27:53 a user named au8 said ```For sure the landscape looks very different in the future```.
In ideas-and-feedback, at 2023-10-05 06:26:40 a user named vincentjedi said ```This process requires a big team in a bank to do it by hands normally```.
In ideas-and-feedback, at 2023-10-05 06:26:28 a user named au8 said ```It makes logical sense to me regardless```.
In ideas-and-feedback, at 2023-10-05 06:25:56 a user named vincentjedi said ```I know this concept  works because I spent 10 years of the trading floor and so far no one I know can do this because the tech only comes out now```.
In ideas-and-feedback, at 2023-10-05 06:24:14 a user named au8 said ```Absolutely, it’s not an easy one to solve```.
In ideas-and-feedback, at 2023-10-05 06:24:12 a user named vincentjedi said ```If it is so easy to build, everyone will have done it already```.
In ideas-and-feedback, at 2023-10-05 06:23:28 a user named vincentjedi said ```They are many pieces of stack in this puzzle.```.
In ideas-and-feedback, at 2023-10-05 06:22:20 a user named au8 said ```I think you’d need to put fastapi in front of automl so that langstream could ask it```.
In ideas-and-feedback, at 2023-10-05 06:19:55 a user named au8 said ```I think your use case is interesting vincentjedi```.
In ideas-and-feedback, at 2023-10-05 06:06:14 a user named vincentjedi said ```For example, if u own some Nvidia stock and the price is already very high, if u still believe in ai hardware sector, u may want to buy other correlated stocks. The agent will go into the correlation database and tell u that AMD and Intel or tsmc have positive correlation in ascending order.  If u assume Nvidia may drop a lot in price in the long run and AMD may catch up quickly in 2 years, the tool will calculate your potential gain or losses based on the historic correlation and your new hypothetical portfolio. This type of calculation is very cumbersome for retail guys to work out without the help of the agent or the correlation```.
In ideas-and-feedback, at 2023-10-05 05:41:49 a user named pierrunoyt said ```webui or chat option to chat whith the agents```.
In ideas-and-feedback, at 2023-10-05 05:40:47 a user named vincentjedi said ```These tools aren't usually available to retail guys because they don't know how to use it or too expensive for them. The Ui isnt intuitive. So new llm agent can do it real time and simplify the process.```.
In ideas-and-feedback, at 2023-10-05 05:38:04 a user named vincentjedi said ```Many advanced tools out in the market (developed for hedge fund) use baysian inference to help them optimize their return (correlation between stocks). I know one software house sells it to hedge funds at a very expensive subscription. Tools like that can be used as a guidance to retail investors too using llm.```.
In ideas-and-feedback, at 2023-10-05 05:25:53 a user named vincentjedi said ```U think coder concern is that retail investors will blame u for advising for specific stocks that lose them money. So keep the recommendation generic, for example , if war news may boost stock price of weapon companies as long as the price isn't too high already. This advice is never wrong.```.
In ideas-and-feedback, at 2023-10-05 05:03:34 a user named nisargamin said ```Kind of very high level and general. Actionable insights or triggers are key```.
In ideas-and-feedback, at 2023-10-05 05:00:43 a user named vincentjedi said ```And by the way , most brokerage report prediction is wrong```.
In ideas-and-feedback, at 2023-10-05 05:00:11 a user named vincentjedi said ```Like most brokerage reports, advice is only advice. Listen to it at your own risk.```.
In ideas-and-feedback, at 2023-10-05 04:57:04 a user named vincentjedi said ```If u r a good coder, gpt4 can help u build a full app. If u can't code, gpt4 can teach u how to code```.
In ideas-and-feedback, at 2023-10-05 04:56:05 a user named vincentjedi said ```Advanced traders understand the risk and it is down to them to prompt the engine to maximize the utility of the app.```.
In ideas-and-feedback, at 2023-10-05 04:54:57 a user named vincentjedi said ```So u tell your retail users they can get similar customized new sources with summary for 10 usd. I don't think they expect u to be making them 1 million dollar per year```.
In ideas-and-feedback, at 2023-10-05 04:52:24 a user named vincentjedi said ```Treat the app like a super smart Bloomberg news terminal who can tailor make your news sources for u. How much does a Bloomberg terminal cost ?```.
In ideas-and-feedback, at 2023-10-05 04:47:23 a user named vincentjedi said ```But I think retail investors want more handholding. Because most retail traders have no clue what to ask or look for.```.
In ideas-and-feedback, at 2023-10-05 04:45:56 a user named sonichi said ```have you checked https://github.com/microsoft/autogen/blob/main/notebook/agentchat_stream.ipynb ?```.
In ideas-and-feedback, at 2023-10-05 04:44:05 a user named vincentjedi said ```Like most finance app, they ask you for your risk appetites and expertise in the market. The advice and analysis and filtering process are all different based on these criteria```.
In ideas-and-feedback, at 2023-10-05 04:42:50 a user named vincentjedi said ```Like chatgpt, how much u can get out of the tool depends on how well u prompt the engine to begin with. There will be templates but more advanced trader can get more out of it.```.
In ideas-and-feedback, at 2023-10-05 04:40:02 a user named vincentjedi said ```It is down to the users to decide how much time and sources they want to use..```.
In ideas-and-feedback, at 2023-10-05 04:38:07 a user named vincentjedi said ```So instead of reading 1000 news article daily, the engine will jettison similar news and group them and summarize and get rid of excessive info.```.
In ideas-and-feedback, at 2023-10-05 04:36:07 a user named vincentjedi said ```For example, bots can classify catastrophic events pretty well, earthquake In usa etc. I agree that most news won't have much impact as news is mostly noisy. It is more like a filtering engine for the relevant info rather than deciding what u should do.```.
In ideas-and-feedback, at 2023-10-05 04:35:04 a user named elasticbean said ```humans have a hard time deciding if news true or not```.
In ideas-and-feedback, at 2023-10-05 04:32:30 a user named nisargamin said ```If bots are involved to that level, I see so many things that can go wrong. Who decides whether the news is legit? Etc. Sorry Not feeling it.```.
In ideas-and-feedback, at 2023-10-05 04:19:46 a user named vincentjedi said ```So if tomorrow, china is about to invade Taiwan, their indexgpt won't be proactively warning u to dump all your chip shares and inform u to buy Lockheed Martin```.
In ideas-and-feedback, at 2023-10-05 04:17:12 a user named vincentjedi said ```Even jpmorgan mighty coding team isn't making their app real time.```.
In ideas-and-feedback, at 2023-10-05 04:16:35 a user named vincentjedi said ```https://m.economictimes.com/news/international/us/what-is-indexgpt-know-all-about-jp-morgan-chases-ai-financial-service/articleshow/101395926.cms```.
In ideas-and-feedback, at 2023-10-05 04:12:02 a user named vincentjedi said ```A few years ago, a hedge fund paid a startup to do exactly what I described. Hedge fund analyst pain points is to screen through a huge amount of info that could be important in the market and perform their analysis and then change the weights in their portfolio. The most painful point is data ingestion. That is what computer is good at. Human has only 2 eyes.```.
In ideas-and-feedback, at 2023-10-05 04:09:33 a user named nisargamin said ```No way they do. Also individual (semi) professional traders. Any automation you can give them will be highly desired.```.
In ideas-and-feedback, at 2023-10-05 04:05:40 a user named vincentjedi said ```I used to work on the trading floor with jpmorgan. Even I struggled to process the sheer amount of news on bloomberg news. I think retail investors with a job may not have all day looking at 4 monitors for 7 hours straight..```.
In ideas-and-feedback, at 2023-10-05 04:02:38 a user named nisargamin said ```Biz model wise makes sense. Can charge more too. Ideal customer is relatively less engaged than traders but not necessarily a novice.```.
In ideas-and-feedback, at 2023-10-05 04:01:17 a user named vincentjedi said ```Increase in interest have different impact on your stock portfolio. If u r full of banking stocks, it may matter```.
In ideas-and-feedback, at 2023-10-05 04:00:02 a user named vincentjedi said ```Basically it is 10 dollar insurance policy to warn u that federal reserve may increase another 25 basis point u r too bored to find out. So llm will advise u accordingly..```.
In ideas-and-feedback, at 2023-10-05 03:54:59 a user named nisargamin said ```Did an experiment with another team recently for detecting biased news articles. Turned out more nuanced and complex to achieve that using just LLMs. ML was also needed. So in this case one of the agents can handle that. Also there’s a lot of bandwagon type things with these online news. Maybe starting with a handful of key sites would be a good start to check the feasibility```.
In ideas-and-feedback, at 2023-10-05 03:51:40 a user named cajukev said ```That makes a lot of sense actually```.
In ideas-and-feedback, at 2023-10-05 03:44:18 a user named vincentjedi said ```Openai can't do that because it isnt event driven and not real time. By the time u ask chatgpt to perform the analysis, u r one Day late instead of 10min late from the event driven agent.```.
In ideas-and-feedback, at 2023-10-05 03:39:42 a user named vincentjedi said ```There are infinite amount of news daily...issue for retail investors is that they don't even have time to filter the info, even if they have time, they don't know what the news mean.. that is why the agents doing the stock analysis in the background as info comes in, that is worth extra 10 dollar subscription price of the app```.
In ideas-and-feedback, at 2023-10-05 03:36:28 a user named nisargamin said ```Kinda how high frequency trading works. But yes, simplified and automated version sounds pretty good for retail investors. But when the news get out, it’s already late. Nonetheless, really like langstream```.
In ideas-and-feedback, at 2023-10-05 03:23:05 a user named vincentjedi said ```With langstream, can a change in stock price or negative news from a website (event driven) trigger an agent to perform further analysis with another agent and advise us preemptively  the impact of those sudden market events  on our stock portfolio? Why is it important ? Most people don't understand the market well. Since llm has the wisdom, if given the right prompt from us about our own risk appetite, it can monitor multiple pre programmed factors and if the news could have a negative impact that can tank the stock price by more than 10 percent, it will inform us of these events we are not even aware..this is a very useful tool.```.
In ideas-and-feedback, at 2023-10-05 03:17:50 a user named wayliu said ```i want to build agent network protocol```.
In ideas-and-feedback, at 2023-10-05 03:17:43 a user named vincentjedi said ```“Today, chatbots are request-reply,” he explained. “I ask it a question and then it replies to me. It waits for me to ask a question. [But] because we’re event-driven, and we can asynchronously send messages back and forth, we can actually have the chatbot initiate a conversation. It can send you a message and say, ‘Welcome, I’m the chatbot, I do this.’ If you haven’t asked a question for a while, it can kind of try to keep the conversation going.”```.
In ideas-and-feedback, at 2023-10-05 03:16:26 a user named vincentjedi said ```https://thenewstack.io/langstream-an-event-driven-developer-platform-for-llm-apps/```.
In ideas-and-feedback, at 2023-10-05 02:51:27 a user named frank.martinez said ```https://github.com/raidendotai/openv0/```.
In ideas-and-feedback, at 2023-10-05 02:51:24 a user named frank.martinez said ```Lot of talk about frontends; someone should integrate AG agents with this UX generation tool…```.
In ideas-and-feedback, at 2023-10-05 02:37:07 a user named operator2k said ```I am thinking of building a website using this application for my start up and want to automate the entire process if possible. I am unsure about what LLM to use and if yall have any tips or tricks for going about the process? I am thinking either to do LLAMA2 or Mitral 7B because open ai seems to have the annoying token limit for a time frame. I also want to know what docker is used in this application because I am having issues with it i think.```.
In ideas-and-feedback, at 2023-10-05 01:09:37 a user named twezoalgo said ```hi guys so i need some help... im trying to return the chat thats being initiated here but im not exactly sure how. I attempted to here but im not getting anything to show up outside of the terminal(im building a ui for autogen). Im able to call the function but i need to somehow get the output. maybe im not using the right name? thoughts?

    config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")
    assistant = AssistantAgent("assistant", llm_config={"config_list": config_list})
    user_proxy = UserProxyAgent("user_proxy", code_execution_config={"work_dir": "coding"})

    user_proxy.initiate_chat(assistant, message=prompt)

    chat_output = user_proxy.initiate_chat(assistant, message=prompt)```.
In ideas-and-feedback, at 2023-10-04 22:35:51 a user named qslug said ```You know what would make for a really compelling agent example? 

An "Escape Room" challenge. 3-6 agents with different perspectives trying to figure out a multi-part puzzle. It would highlight defining agent personas, using long-term memory, calling functions, writing code, voting on paths forward...```.
In ideas-and-feedback, at 2023-10-04 21:58:02 a user named largonaut said ```I appreciate it!  In part it'd help moving conversations back and forth between my smart home speakers/mic/cameras and my computer hardware.```.
In ideas-and-feedback, at 2023-10-04 21:27:51 a user named xam1311 said ```nope just a pip command```.
In ideas-and-feedback, at 2023-10-04 20:29:46 a user named adriangalilea said ```UI/UX proposal:
- web Flowchart diagram for creating agent flow
- web chat for seeing it in action```.
In ideas-and-feedback, at 2023-10-04 19:44:48 a user named andyinater said ```<#1157869584901226586>  might be good to look at to see how to get started, if thats what you were getting at. Lots needed to make it to what you want, but it should give a good starting point to see how it could be put together.```.
In ideas-and-feedback, at 2023-10-04 19:39:07 a user named largonaut said ```I'm learning step by step how to make a true personal assistant AI that is tailored to me and my data, including medical, psych, financial, etc.  I'm even working on getting copies of my data and analytics from brokerage firms for personal use.  I have physical and mental disabilities that could be compensated for using the speaking, seeing PAL who can watch out for me, remind me of things I forget, grab projects out of mid air when I blurt something random, and do other things that help me feel safer, less crazy, and able to be productive for my household.```.
In ideas-and-feedback, at 2023-10-04 18:49:15 a user named coolrazor said ```I'd like to build a "librarian" agent that's job is to save and retrieve from a vector store.  We already have document retrievel, but I'd like to be able to store "memories" or "skills" in there too.  Have the librarian manage all of that in a groupchat.  My efforts in creating custom agents have been wonky so far, but I'm learning slowly.```.
In ideas-and-feedback, at 2023-10-04 17:50:27 a user named _zippman said ```AI workforce that will analyze current code / project and then do modification based on human instructions.```.
In ideas-and-feedback, at 2023-10-04 17:49:30 a user named afourney said ```I think there are multiple strategies... but having one agent or layer that summarizes the important parts of the output is likely to get pretty far```.
In ideas-and-feedback, at 2023-10-04 17:48:36 a user named fxtoofaan said ```Maybe a local messaging subsystem for the agents to use to communicate with each other ?```.
In ideas-and-feedback, at 2023-10-04 17:46:34 a user named afourney said ```That's a good idea. We're finding the same thing when integrating the responses into other applications. I.e., the responses sometimes apologize for errors, or make reference to turns that aren't really something the end users need to be aware of```.
In ideas-and-feedback, at 2023-10-04 17:45:33 a user named gb4de said ```@amadad agreed, might be worth using the output file and getting a single agent to read and format the last n messages```.
In ideas-and-feedback, at 2023-10-04 17:41:49 a user named amadad said ```Wonder if an agent is needed just for file formatting and cleanup...a lot of the chats are VERY verbose, and might help to cut through the noise if there's an agent listening and incoporating only the most essential elements from each agent.```.
In ideas-and-feedback, at 2023-10-04 17:02:31 a user named tonic_1 said ```we're building it , now, in public actually```.
In ideas-and-feedback, at 2023-10-04 16:10:16 a user named frank.martinez said ```AutoGen is a framework; it’s agnostic to frontend choices; conceptually it’s straightforward to build an _interface_ for it [web, native, hw specific]```.
In ideas-and-feedback, at 2023-10-04 16:02:38 a user named fxtoofaan said ```very nice. wonder if a nice front end can be created for autogen to create autogen apps```.
In ideas-and-feedback, at 2023-10-04 15:56:45 a user named frank.martinez said ```workflow design systems for agents```.
In ideas-and-feedback, at 2023-10-04 14:47:49 a user named gb4de said ```Thanks @amadad, it’s definitely a long file 😅. I wonder if an ideal solution would be to use a function call to pull out the data instead and store that in markdown 🤔. Will try that and let you know how I get on. I do think ultimately it’s a bug because it works if you speak to an assistant directly and not to a group chat```.
In ideas-and-feedback, at 2023-10-04 14:44:50 a user named fxtoofaan said ```what is Rivet, Super Agent, Vellum  ?```.
In ideas-and-feedback, at 2023-10-04 14:31:01 a user named frank.martinez said ```Rivet, Super Agent, Vellum support this _workflow_ design approach```.
In ideas-and-feedback, at 2023-10-04 14:17:05 a user named msirprism said ```Trying to make a million agents work in real time about all the problems that the governements is hiding```.
In ideas-and-feedback, at 2023-10-04 13:41:17 a user named pradeep1148 said ```someone can try doing this with autogen
https://www.youtube.com/watch?v=XRKzh7wZVy0&ab_channel=DLExplorers```.
In ideas-and-feedback, at 2023-10-04 13:40:30 a user named zoltan89 said ```Have anyone tried to use autogen to create a chat bot for a website to answer questions?  Any ideas  how would you go about  integration to the site.```.
In ideas-and-feedback, at 2023-10-04 13:11:31 a user named annamalai.nr said ```I would like to combine reflexion and autogen for reasoning heavy tasks with LLMs```.
In ideas-and-feedback, at 2023-10-04 12:39:14 a user named slagado. said ```Should not be an excuse: same on my side. AI is developing soooo fast ... hard to keep track on it ...```.
In ideas-and-feedback, at 2023-10-04 12:38:17 a user named nonstophappy said ```ah i have way too much work to do on my own project already, but i would recommend just going for it, you might just succeed.```.
In ideas-and-feedback, at 2023-10-04 12:37:45 a user named slagado. said ```mmmh .... hoping that some one jumps on that idea ... and proofs me wrong 🙂```.
In ideas-and-feedback, at 2023-10-04 12:37:04 a user named nonstophappy said ```still a bunch of work but nothing insane```.
In ideas-and-feedback, at 2023-10-04 12:36:45 a user named nonstophappy said ```b is just subsets of agents that need to be coded up, but the gui part is not the problem. c could be solved by an agent itself who has a list of the agents from b.```.
In ideas-and-feedback, at 2023-10-04 12:35:28 a user named slagado. said ```Dont think so because believing b) and c) could not be solved via chatGPT 😉```.
In ideas-and-feedback, at 2023-10-04 12:33:35 a user named nonstophappy said ```isnt this just done with chatgpt and streamlit in a few hours?...```.
In ideas-and-feedback, at 2023-10-04 12:19:16 a user named slagado. said ```But to answer your questions: Dont know. But as always: google it / search in YouTube for it ...```.
In ideas-and-feedback, at 2023-10-04 12:18:16 a user named slagado. said ```@dariofc you are in the wrong thread! This thread is for ideas and feedback. Please go to <#1153072414184452241>```.
In ideas-and-feedback, at 2023-10-04 11:57:34 a user named dariofc said ```Is there any tutorial to use Autogen with free LLM ?```.
In ideas-and-feedback, at 2023-10-04 11:35:11 a user named slagado. said ```Just one day on the AutoGen topic but it seems that you have to follow always the same approach:
Install autogen.py -> define which model(s) to be used and add your personal api_key(s) -> create the agents -> define your tasks -> fire it.

This must be done always and at any time to achieve your main goal: Your tasks!  
One thing is for sure: This can be automated and thus done more elegantly!

So, I am asking my self why isn´t there a (web) gui where you
1) provide ONCE all api keys to you peronal models (the system should provide a list of know models. Entering custom model names should be possible.)
2) provide a (unique) project name for your task(s)
3) select the api model(s) you want to use (from the list you created above.)
4) provide the tasks to be solved/accomplished 
5) provide how many iterations you would like to have
DONE.

The (web) AutoGen UI should than 
a) add specific/needed things like tasks endings: "And add 'TERMINATE' word when an agents task is done. Add "...." when a timeout ocoured or any error raised. Add '...' when done." etc.)  
b) provide which (grouped) agents should be used (!!!!!)
c) anaylse the tasks and provide helping methods (!!!!)
d) provide the complete notebook
e) provide the possibility to run the notebook

For sure this is just the basic idea. More handling details / feature requirements must be defined.
And also for sure the (web) AutoGen UI uses under the hood AutoGen to fulfill the requiremetns a) to e). 

So awaiting your feedback. 

(BTW: 
Currently I am unemployed, looking for a new job. 
Background: 
Started in the early 80´s with programming on hobby base. 
Moved to the prof. side 23 years ago. 
Having deep knownledge in C#, (ASP) .Net  (core) frameworks, Angluar, typescript, cloud(s), Docker, keycloak, etc. etc. 
Looking for a Team Lead job or something where I define requirements, goals, visions; aka Stakeholder / Product Owner - like above)```.
In ideas-and-feedback, at 2023-10-04 10:31:56 a user named gb4de said ```I simply asked it to save as a .md file. Whilst when I do the same command whilst speaking to a group chat then it doesn’t do it```.
In ideas-and-feedback, at 2023-10-04 09:35:54 a user named justsebnl said ```Using Autogen with Discord could open some avenues up```.
In ideas-and-feedback, at 2023-10-04 09:06:17 a user named cosmickrover said ```How is it possible for an agent to "learn"```.
In ideas-and-feedback, at 2023-10-04 09:05:28 a user named cosmickrover said ```Maybe some data analysis tasks```.
In ideas-and-feedback, at 2023-10-04 08:28:14 a user named r0d7_ said ```Identify best kpi for user centric data```.
In ideas-and-feedback, at 2023-10-04 07:51:15 a user named KLANe4H said ```I would like to use it within Excel, integrating it within Excel.```.
In ideas-and-feedback, at 2023-10-04 02:57:07 a user named Technician said ```It would be great if this worked with flowise```.
In ideas-and-feedback, at 2023-10-04 02:30:43 a user named juanfrank77 said ```Lead gen is a good use case I know SuperAGI has some integration with Apollo.```.
In ideas-and-feedback, at 2023-10-04 00:56:33 a user named sonichi said ```How did you do it?```.
In ideas-and-feedback, at 2023-10-04 00:43:30 a user named gb4de said ```this does not seem to work unfortunately @sonichi , it only seems to speak to an assistant agent directly and not in a group chat. It might be a bug```.
In ideas-and-feedback, at 2023-10-04 00:13:59 a user named treek2345 said ```email topic research and marketing copywriting bot/researcher infrastructure automated```.
In ideas-and-feedback, at 2023-10-03 23:54:34 a user named rain696 said ```if not allready I'm probably wrong```.
In ideas-and-feedback, at 2023-10-03 23:53:19 a user named rain696 said ```Claude 2 integration might be cool 🙂```.
In ideas-and-feedback, at 2023-10-03 22:58:03 a user named btcmansatariq said ```https://tenor.com/view/beijos-gif-12132667146736033398```.
In ideas-and-feedback, at 2023-10-03 22:57:55 a user named btcmansatariq said ```you can just use jup note book right? but i know what you mean a dedicated app with a minions UI```.
In ideas-and-feedback, at 2023-10-03 22:34:17 a user named stampystamperson said ```iPad support app would be dank 🐸```.
In ideas-and-feedback, at 2023-10-03 22:24:30 a user named sonichi said ```What's the name you'd like for the new voice channel?```.
In ideas-and-feedback, at 2023-10-03 19:39:24 a user named au8 said ```like a troubleshooting voice channel maybe```.
In ideas-and-feedback, at 2023-10-03 19:32:03 a user named au8 said ```@sonichi would it be possible to have more than 1 voice channel created here?```.
In ideas-and-feedback, at 2023-10-03 19:29:25 a user named au8 said ```I forgot to expose port 8000 on my docker so I have to start again anyway 😄```.
In ideas-and-feedback, at 2023-10-03 19:29:12 a user named au8 said ```so I will go through the whole process start to finish and I can share my screen if it helps you?```.
In ideas-and-feedback, at 2023-10-03 19:22:15 a user named au8 said ```I now have it loading on vllm, I just need to test autogen and then I can help you get it working```.
In ideas-and-feedback, at 2023-10-03 19:13:38 a user named au8 said ```Have you got it working now @fxtoofaan```.
In ideas-and-feedback, at 2023-10-03 18:25:59 a user named fxtoofaan said ```@sonichi is it possible to count tokens used and context window size in use etc etc. some kind of reporting while script is in use? Possible ? I’m trying to run autogen locally using 4k awq quantized llm models. Trying to see how much of the multiple agents  local llm can handle```.
In ideas-and-feedback, at 2023-10-03 17:40:46 a user named kareem6370 said ```Thank you I really appreciate it:), and thanks for the community for this incredible effort to get this amazing tool ready```.
In ideas-and-feedback, at 2023-10-03 17:32:52 a user named sonichi said ```It's under fast development. So if you are looking for a stable 1.0 it's not there yet. The community is very active in contributing and fixing bugs etc. We make new release frequently. Maybe ask @aayush_21557 as he seems to use autogen in production.```.
In ideas-and-feedback, at 2023-10-03 17:22:51 a user named kareem6370 said ```Hi there, is AutoGen production ready? I mean can I use it in an LLM application and interact with it through api and build UI ? and if it does is there any example out there? Thanks in advance!```.
In ideas-and-feedback, at 2023-10-03 17:13:37 a user named afourney said ```Yeah, we've been playing with this a bit. For example, including comments that are designed to help the agents through some common errors (e.g., describing how a dependency might be installed), or providing some cues about preference (e.g., "this is a helper function, if you are trying to do Y, call you probably want to call X instead")```.
In ideas-and-feedback, at 2023-10-03 15:09:15 a user named andyinater said ```I wanted to have a further breakdown of the problem at hand, have an opportunity for some nested iterative coding calls to figure out hard functions outside of the main program context, store functions and definitions, etc.. but I thought it would be most beneficial to release it sooner so others can start running with their own ideas sooner.```.
In ideas-and-feedback, at 2023-10-03 15:07:06 a user named andyinater said ```It could be reconfigured/tinkered to do what you might have in mind, or at least might show you how you could start putting an idea like that together```.
In ideas-and-feedback, at 2023-10-03 15:06:26 a user named andyinater said ```<#1158564427117903882>  uses some of the ideas your mentioning, where context is cleared often to focus on plan, last code, and last review comments, to generate the next code iteration```.
In ideas-and-feedback, at 2023-10-03 14:22:56 a user named telepathyx said ```Yeah I think this is a promising line of thought. And maybe even rethinking how the code is created to cater to the AI's needs rather than human needs. Like making it more readable to an AI at the expense of human readability. Like more code in single files or something. Just some thoughts. It might be the same thing.```.
In ideas-and-feedback, at 2023-10-03 12:07:13 a user named andyinater said ```This is a bit of an out there question, but Google seems to not have a ton on it.

I know tokenization essentially results in a vector that is supposed to somewhat capture semantics numerically.

Can one take dot or cross products of these vectors? Dot to determine similarity is straight forward, but a cross product... mutually orthogonal... I'm wondering what it would look like to take the cross product of the vectors for sentences like "I like sushi" and "I like steak". A mutually orthogonal statement to both?

Could that be used to help agents "think creatively" by forcing them to discuss the cross product of whatever they were just discussing?```.
In ideas-and-feedback, at 2023-10-03 11:21:15 a user named beamengineer said ```The application who does whatever you want in python```.
In ideas-and-feedback, at 2023-10-03 10:23:41 a user named ecvanbrussel said ```Exactly. I'm sure there are ways to do this. I mean, when I work on a big project, I also only keep a tiny chunk of it in my working memory (I literally mean the working memory in my brain) in order to perform any given task.```.
In ideas-and-feedback, at 2023-10-03 10:10:16 a user named au8 said ```The art is all in the prompt engineering```.
In ideas-and-feedback, at 2023-10-03 10:09:43 a user named au8 said ```Everything is worth an experiment. If you try it, I’d be interested to hear the outcome/results.```.
In ideas-and-feedback, at 2023-10-03 10:05:13 a user named telepathyx said ```it's worth experimenting with having a "code context assistant" whose prompt is "your job is to continuously scan the code and give summarized context to the coder" or something```.
In ideas-and-feedback, at 2023-10-03 10:03:13 a user named aaronward_ said ```Question: has anyone used Guidance before for prompt engineering? (https://github.com/guidance-ai/guidance, https://www.linkedin.com/posts/philippelimantour_inside-guidance-microsofts-new-open-source-activity-7068528335399575552-o-z8/) i haven't tried it myself but have heard good things about it```.
In ideas-and-feedback, at 2023-10-03 10:00:51 a user named telepathyx said ```cuz no one agent can have all the context```.
In ideas-and-feedback, at 2023-10-03 10:00:35 a user named telepathyx said ```just gotta figure out how best to do that```.
In ideas-and-feedback, at 2023-10-03 10:00:23 a user named telepathyx said ```yeah i think that's the power autogen is offering. to use parallel number of tokens simultaneously```.
In ideas-and-feedback, at 2023-10-03 09:59:50 a user named au8 said ```You could create an agent that stores a list of all of the available functions and a summary of what they do. Other agents could then consult that agent? Crazy idea maybe.```.
In ideas-and-feedback, at 2023-10-03 09:54:09 a user named telepathyx said ```yeah exactly it would have to be deliberately done in a super modular way. i've been thinking about it too. it might need to have an agent rescan the code with something like https://github.com/jina-ai/thinkgpt/blob/main/thinkgpt/summarize.py where the instruction_hint is something relevant to the code being worked on. and then constantly hold that in it's memory until it's done with the task. something like this https://github.com/getmetal/motorhead just giving a sequential summary (or worse, nothing at all) would not be enough i don't think. i think some memory management would be essential. like constantly scan the code and figure out that whatever() exists when it needs it.```.
In ideas-and-feedback, at 2023-10-03 09:46:36 a user named au8 said ```Probably simplifying it too much in that example but you get the idea.```.
In ideas-and-feedback, at 2023-10-03 09:44:53 a user named au8 said ```Couldn’t you take a modular approach to this? For example, “code a function that accepts 2 variables and store these in local storage”. Then the next will be “code a web page that calls a function called whatever() and pass these 2 variables to it”. I agree it’s ambitious to make it all happen with a single prompt as things stand.```.
In ideas-and-feedback, at 2023-10-03 08:38:37 a user named telepathyx said ```even using RAG isn't adequate, it'll just return chunks of text without being able to see everything all at once to understand the context correctly. it'll just continuously forget. it'll do well at humaneval or little code challenges that don't require understanding a huge codebase.```.
In ideas-and-feedback, at 2023-10-03 08:35:20 a user named telepathyx said ```i don't think it's theoretically capable of creating software that requires more context than can fit into 32k tokens. While a rolling map reduce / summary might work for conversations, it's not adequate for code. Unless the code you're asking for is so modular that it can fit the entire context in, it's just not possible yet. That's why you haven't seen any examples with any AI coding agent.```.
In ideas-and-feedback, at 2023-10-03 07:52:49 a user named ecvanbrussel said ```Hey, uhm, I haven't been able to find an example yet of autogen being set up to initiate a new web app project. Such as a Vue, React, or Svelte project. And then actually write code to actual files according to the specifications given (e.g. if the initial message had been `"write a todo app in svelte, where the state is persisted in localStorage"`). And also write unit tests and integration tests, and run those tests to test whether the app is working as expected and keep iterating until all the requirements have been met and all the tests return green.

I'm not a Python programmer, but if I could see a basic example of how that could be set up, then I think I would understand it well enough to make it more and more capable. By for example creating an agent that searches for and reads the latest documentation of frameworks to make sure the code-writing agent uses the most up-to-date patterns possible. Etc etc...```.
In ideas-and-feedback, at 2023-10-03 04:13:19 a user named amadad said ```...how long you say? 109,346 words or 832,654 characters for a grand total of $0.020143 🫰```.
In ideas-and-feedback, at 2023-10-03 04:05:50 a user named amadad said ```This worked for me, pending further investigation: 

`autogen.ChatCompletion.start_logging()`

And at the bottom:

`with open('output.md', 'w') as f:    f.write(str(autogen.ChatCompletion.logged_history))`

It output a very long file...haven't read through it yet.```.
In ideas-and-feedback, at 2023-10-03 04:01:03 a user named bansalg said ```Please examples here in case they are helpful: https://discord.com/channels/1153072414184452236/1157419832443150447/1157419832443150447```.
In ideas-and-feedback, at 2023-10-03 03:48:39 a user named shinypickel said ```Anyone build anything that saves time w/ Autogen?```.
In ideas-and-feedback, at 2023-10-02 23:19:24 a user named yikesawjeez said ```two methods: e2b will give you a dummy cloud box to play in, set up servers, etc. or if you want it on your own infra you can have it write monkscript and deploy via https://monk.io, idk how gpt does with terraform but monkscript is more or less fancy yaml, shouldn't be a problem. transparency: i hassled the monk people about how their shit works for long enough for us to at least discuss employing me to do hacker shit, but i'm not financially biased yet, for now 😂```.
In ideas-and-feedback, at 2023-10-02 23:10:55 a user named sonichi said ```try telling the coding agent to save outputs directly.```.
In ideas-and-feedback, at 2023-10-02 22:09:51 a user named frank.martinez said ```Need a tool interface for Terraform or similar, to build infra agents```.
In ideas-and-feedback, at 2023-10-02 18:18:07 a user named au8 said ```I believe the agents look for # filename: myfile.ext so you will need to instruct your agents appropriately. In your case it could be something like  `when saving results to a file, put # filename: <filename> as the first line` and instructing them to save all results to a file.```.
In ideas-and-feedback, at 2023-10-02 18:13:41 a user named au8 said ```Instruct the executor to do something like this: `If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line.````.
In ideas-and-feedback, at 2023-10-02 18:13:10 a user named nisargamin said ```Very interesting. Assuming for this to be implemented in practical team workflows, it would come down to defining the tasks and then picking the right approach. Or can the manager recommend an optimal setup based on desired goals?```.
In ideas-and-feedback, at 2023-10-02 18:12:42 a user named coincartel said ```I think you just turn on logging```.
In ideas-and-feedback, at 2023-10-02 18:11:57 a user named coincartel said ```I'd like a node based input/output gui like rivet. As a matter of fact Rivet's gui might just be a perfect startting point to integrate both.```.
In ideas-and-feedback, at 2023-10-02 18:08:35 a user named gb4de said ```quick question, how are people saving outputs of their code? I am trying to save outputs in a simple .txt file but simply doing this does not work

  `user_proxy = autogen.UserProxyAgent(
    name="Admin",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=1,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    system_message="A human admin. Interact with the planner to discuss the plan. Plan execution needs to be approved by this admin.",
    code_execution_config={
        "work_dir": "content"
    }
)````.
In ideas-and-feedback, at 2023-10-02 17:59:16 a user named cryptofox1971 said ```It would be incredibly beneficial to have an app associated with AutoGen, designed specifically to guide individuals with limited technical knowledge through the process of utilizing AutoGen effectively. This educational tool would be a step-by-step guide, simplifying complex concepts and making it accessible for everyone to harness the power of AI for their personal or business needs.```.
In ideas-and-feedback, at 2023-10-02 17:26:47 a user named au8 said ```Couldn't you build something with FastAPI to make it?```.
In ideas-and-feedback, at 2023-10-02 17:14:42 a user named muckitymuck said ```Hey everyone,  Very interested in this repo.  I also worked with Open Interpreter but got stuck on an issue.  Is there a way to access this through an API?  I have a use case where I host local LLM for privacy reasons and I want to be able to access the server through clients through a frontend chat```.
In ideas-and-feedback, at 2023-10-02 16:53:40 a user named andyinater said ```To create the actual video is an extremely hard ask right now. But what I mentioned is possible today with the right code and effort```.
In ideas-and-feedback, at 2023-10-02 16:52:44 a user named curiciouswanderer said ```Yea, it should create a full vedio tutorial and explain while showing the code for it (like the one linked above)```.
In ideas-and-feedback, at 2023-10-02 16:50:36 a user named andyinater said ```Honestly - both are possible. Just the latter might be easier than the former```.
In ideas-and-feedback, at 2023-10-02 16:50:19 a user named andyinater said ```Create the whole tutorial? Like script that the presenter would read, and what should be presented when? Or just the example programs?```.
In ideas-and-feedback, at 2023-10-02 14:15:39 a user named frank.martinez said ```Let’s use AutoGen to create documentation about, AutoGen```.
In ideas-and-feedback, at 2023-10-02 14:06:21 a user named __erice__ said ```Yess!!! This is in line with what I had in mind! Solid!! 😏🙌🏾```.
In ideas-and-feedback, at 2023-10-02 14:02:08 a user named shaokunzhang said ```You can use an agent dedicated to interacting with the RL environment. Here is one example of gym```.
In ideas-and-feedback, at 2023-10-02 13:58:43 a user named shaokunzhang said ```This example may help @__erice__  https://github.com/qingyun-wu/autogen-eval/tree/main/application/A7-decision-making-MiniWob%2B%2B```.
In ideas-and-feedback, at 2023-10-02 13:41:01 a user named __erice__ said ```Ok ok, i'll put aside some time today to look more in-depth into this as well. Thanks again!```.
In ideas-and-feedback, at 2023-10-02 13:34:53 a user named sonichi said ```Oh VW probably not for the gym environments - I'm not sure. For gym kind of thing, we have some examples by @shaokunzhang & @jiale_liu .```.
In ideas-and-feedback, at 2023-10-02 13:33:15 a user named __erice__ said ```Yeah, read over this last night... & 🙌🏾🙌🏾 I'll check both out.. Hopefully Vowpal Wabbit makes it relatively straightforward to easily implement custom gym environments 🤞🏾🤞🏾 ...```.
In ideas-and-feedback, at 2023-10-02 13:29:10 a user named sonichi said ```also check this for inspiration: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_stream.ipynb```.
In ideas-and-feedback, at 2023-10-02 13:24:06 a user named sonichi said ```It's a good idea. Keep bringing it up! One framework I know is Vowpal Wabbit. Good for contextual bandit and online learning stuff.```.
In ideas-and-feedback, at 2023-10-02 13:19:39 a user named __erice__ said ```😭 i've been reallyyy trying to get a conversation around this, maybe it's a terrible idea & should be put to rest, buttt.... AutoGen x Multi-Agent Reinforcement Learning seems like a natural next step yeah? Which RL frameworks would be good to look into?```.
In ideas-and-feedback, at 2023-10-02 12:18:23 a user named aaronward_ said ```i have something fun in the works```.
In ideas-and-feedback, at 2023-10-02 12:18:17 a user named telepathyx said ```to make it practical as a real company, it would need a similar interface as a real company. kanban, gantt, group chat with numerous private rooms, stand up meetings. differentiating between a one-time project like build a snake game, vs ongoing SOPs like make daily content for a social media account```.
In ideas-and-feedback, at 2023-10-02 12:15:31 a user named curiciouswanderer said ```Hey, is it possible to make a ai that generates programming tutorials like: <https://www.youtube.com/watch?v=kQ8DGP9p2LY> based on promot?```.
In ideas-and-feedback, at 2023-10-02 11:45:06 a user named tigremon said ```I'd like to build an app to visualize GPS tracks over a 3D map```.
In ideas-and-feedback, at 2023-10-02 11:31:31 a user named li_jiang said ```Could you share more details so that I can reproduce the issue?```.
In ideas-and-feedback, at 2023-10-02 09:49:28 a user named aurowk said ```Kanban would be interesting as a UI for this actually.```.
In ideas-and-feedback, at 2023-10-02 07:40:57 a user named telepathyx said ```a kanban board would. be a good interface for a human to give instructions to an AI team```.
In ideas-and-feedback, at 2023-10-02 06:13:30 a user named sonichi said ```Hey guys trying to figure out a smart```.
In ideas-and-feedback, at 2023-10-02 06:09:05 a user named sonichi said ```I am using RAG agent and it works pretty```.
In ideas-and-feedback, at 2023-10-02 04:05:05 a user named amadad said ```Maybe @jasonzhou1993 will get to it first…```.
In ideas-and-feedback, at 2023-10-02 02:40:07 a user named amadad said ```Yes, I'm trying to implement the same thing. I have a research module that queries, searches, scrapes and summarizes with citations vis-a-vis serper and browserless. So far, no luck integrating it into my multi-agent flow.```.
In ideas-and-feedback, at 2023-10-02 02:05:32 a user named sonichi said ```sonichi As you re getting some serious```.
In ideas-and-feedback, at 2023-10-02 02:04:12 a user named sonichi said ```One related PR: https://github.com/microsoft/autogen/pull/58
More contributions in this direction are great!```.
In ideas-and-feedback, at 2023-10-02 01:48:45 a user named WolfroseWe said ```How could you approach it so I have a list of functions but that can be executed all within one script? 

Now, rather then hit each Tool one by one it'll have a set of functions it can use within a program to do  tasks (saving time & tokens). 

Eg. To make a web request and scrape the page, instead of using requests + beautifulsoup I have a ready made function (with a scraper built in) that it can call. 

Then perhaps there's another function it can call once it has the result of that. 

Effectively give it a library of modules to have access to for particular tasks. 

If this is included anywhere and i've missed it pls let me know!

Happy to also make a contribution if this would be useful for other folks```.
In ideas-and-feedback, at 2023-10-02 00:18:20 a user named gb4de said ```Hey guys, trying to figure out a smart way to get autogen to spin our long form posts (700 words+) it seems to stall at 650 at the moment. I tried creating a team with two writers and that didn't work so well (still only 650 output). Are there any ideas out there to help reliably produce lengthy content?```.
In ideas-and-feedback, at 2023-10-02 06:13:31 a user named sonichi said ```I suggested some ideas in this thread: https://github.com/microsoft/autogen/discussions/67```.
In ideas-and-feedback, at 2023-10-02 10:16:28 a user named gb4de said ```Thanks man!!! Will try it out and share if I come up with an elegant solution```.
In ideas-and-feedback, at 2023-10-01 23:07:45 a user named wiiiktor. said ```I am using RAG-agent and it works pretty ok, but it gives me ~10 answers instead of just one or two, and it does not explicitly write anything like "I do not have enough information". It just spits out proper answers, only many times. I set the setting max_consecutive_auto_reply=1 but this does not change anything.```.
In ideas-and-feedback, at 2023-10-02 06:09:07 a user named sonichi said ```@li_jiang this may be of your interest```.
In ideas-and-feedback, at 2023-10-02 11:33:25 a user named li_jiang said ```Could you share more details so that I can reproduce the issue? @wiiiktor.```.
In ideas-and-feedback, at 2023-10-04 11:28:04 a user named wiiiktor. said ```Sure, please, find my code here: https://github.com/wiiiktor/resume/tree/main/data/autogen-bug There is a python file with a very small dataset. In the meantine, I updated tokenizers (PyCharm told me so) and error is different now, but still a similar tune: RuntimeError: Failed to import transformers.models.nystromformer because of the following error (look up to see its traceback):
maximum recursion depth exceeded while calling a Python object```.
In ideas-and-feedback, at 2023-10-04 11:35:00 a user named wiiiktor. said ```name = "tokenizers"
version = "0.14.0" -> this is what I have now```.
In ideas-and-feedback, at 2023-10-05 14:55:58 a user named li_jiang said ```Thanks @wiiiktor. , I've created an issue in github https://github.com/microsoft/autogen/issues/117 , will look into it later.```.
In ideas-and-feedback, at 2023-10-08 15:29:31 a user named li_jiang said ```@wiiiktor. , could you try the fix in this PR https://github.com/microsoft/autogen/pull/155 to see if it solve the issue you see? Thanks.```.
In ideas-and-feedback, at 2023-10-01 22:43:39 a user named harmonious_quail_59808 said ```How can i min3 crypto in , a laptop chrome os, with shared SO linux```.
In ideas-and-feedback, at 2023-10-01 20:00:46 a user named _p_i_ said ```@sonichi As you're getting some serious traction on autogen, I'll write.

I found myself in the role of coordinating AutoGPT during the early days, when it was getting over several thousand GitHub stars a day.

There are several things I would have done differently if I could replay those few weeks.

One was that the core team (which was at the time weak, and dynamically assembling) was pushed onto the back foot by the volume of user-engagement and code contributions.

If we had assembled a public roadmap and contribution guide much earlier we could have channeled this energy.

i.e. if we had just pointed willing contributors to: "This is our kanban, here's our wiki/doc showing what we're working on and why, and where we'd appreciate help" we could have gone a long way towards bridging the gap.```.
In ideas-and-feedback, at 2023-10-02 02:05:33 a user named sonichi said ```Thanks you so much for chiming in. Looking forward to your insights to help doing this right.```.
In ideas-and-feedback, at 2023-10-02 05:50:09 a user named sonichi said ```@qingyunwu created an issue https://github.com/microsoft/autogen/issues/70. Is that a good way to start or do you recommend sth. else @_p_i_ ?```.
In ideas-and-feedback, at 2023-10-01 18:14:45 a user named guardiang said ```Are there any limitations or issues that might make combining AutoGen capabilities with say, LlamaIndex?```.
In ideas-and-feedback, at 2023-10-01 16:43:05 a user named sonichi said ```Please check https://discordapp.com/channels/1153072414184452236/1157419832443150447 and https://discordapp.com/channels/1153072414184452236/1157447399044821132```.
In ideas-and-feedback, at 2023-10-01 16:31:16 a user named orderandchaos_at_work said ```I'm interested in using Autogen agents to write well tested rest apis with fastapi, pydantic and pytest. I'd like the app to to take in specs and write the api endpoints and use pytest to test it works as expected.

I'd like to be able to request new endpoints to be added to an existing project that follows that structure.```.
In ideas-and-feedback, at 2023-10-01 16:09:00 a user named vbhankas said ```Same thing for different domains where you need collaboration of experts to achieve results…retirement planning (investment expert, social security/medicare expert, tax expert, insurance expert, health expert for seniors, fun and healthy activities for seniors```.
In ideas-and-feedback, at 2023-10-01 16:08:38 a user named vbhankas said ```Are there any practical examples?
Some ideas - given a project idea, have different agents/personalities create needed artifacts. Expert scrum master agent to write epics, features and stories, developer agent to write the code, QA agent to write test scripts, devops agent to setup pipelines, UAT agent to validate business requirements```.
In ideas-and-feedback, at 2023-10-01 14:36:30 a user named sonichi said ```Function call is one way to do that indeed.  Or create a "manager" agent that decides which subagent to use... Many interesting possibilities!```.
In ideas-and-feedback, at 2023-10-01 14:33:29 a user named r3cursivee said ```That's a good question.  I'm guessing that multiple agents for different tasks would be easier/cleaner to implement.  You could already have multiple instances of AssistantAgent with different configs.  But then, if interacting w/ UserAgent in a single thread, it still needs to know how to decide between them based on the task?   
Another avenue is that UserProxyAgent can already use functions, so an external LLM could be slotted in there as another function.   If I had to PoC something in a notebook I would probably try that first.```.
In ideas-and-feedback, at 2023-10-01 14:17:53 a user named sonichi said ```Interesting idea. Do you think we should use multiple agents for these different tasks, or one agent with multiple models?```.
In ideas-and-feedback, at 2023-10-01 14:12:53 a user named r3cursivee said ```I'd like the ability for AutoGen to figure out which LLM is best to use based on the task - or at least, to specify a different LLM for coding vs. writing questions.  I could PoC this if I figure out what needs changing. So it already takes multi-model config sort of, but the message parameter to ChatCompletion.create() doesn't specify which model the request should go to?```.
In ideas-and-feedback, at 2023-10-01 13:53:07 a user named tonic_1 said ```try gradio ? super simple to set up i have some examples  on my organisation as well (all in python - dont know if that helps or not)```.
In ideas-and-feedback, at 2023-10-01 13:03:01 a user named loprz said ```A GIS dependency checker with visualization.```.
In ideas-and-feedback, at 2023-10-01 12:58:56 a user named ansonparker said ```i want to see autogebn inside of flowwise or langflow... take the visualizations you have on the microsoft site and make that the interface```.
In ideas-and-feedback, at 2023-10-01 12:22:03 a user named abhaylatta said ```want to build a backend problem solver```.
In ideas-and-feedback, at 2023-10-01 07:31:15 a user named vincentjedi said ```U r going to beat jpmorgan with autogen. https://www.cnbc.com/2023/05/25/jpmorgan-develops-ai-investment-advisor.html```.
In ideas-and-feedback, at 2023-10-01 07:05:37 a user named dalipyadav68 said ```tell how it can be used more effectively for majing AI project```.
In ideas-and-feedback, at 2023-10-01 07:04:56 a user named dalipyadav68 said ```i want build an AI enable app which help student to learn code in most engaging way```.
In ideas-and-feedback, at 2023-10-01 06:14:34 a user named kings530 said ```Building an app that lets ai to do all the finance research for stock selection```.
In ideas-and-feedback, at 2023-10-01 05:30:32 a user named jasonzhou1993 said ```actually i just found the way to do that in this example
https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb```.
In ideas-and-feedback, at 2023-10-01 05:16:47 a user named uttamdinodia said ```Copilot in Microsoft Office apps```.
In ideas-and-feedback, at 2023-10-01 05:09:34 a user named jasonzhou1993 said ```yea thats the structure im thinking about as well - however i couldn't figure out ways to get result from the group chat; (e.g. at the moment i use user_proxy.initiate_chat to trigger an agent, it only display the full chat history in terminal; however, i dont see a way to return the results, like how i use in langchain; not sure if i communicate the challenge clearly. LOL)```.
In ideas-and-feedback, at 2023-10-01 04:56:23 a user named cajukev said ```Though I haven't seen an implementation of it yet.```.
In ideas-and-feedback, at 2023-10-01 04:55:44 a user named cajukev said ```The way I'm thinking about is that you would create an agent that serves as a wrapper around a group - meaning that once that agent is called upon it would start a nested chat with its group.```.
In ideas-and-feedback, at 2023-10-01 04:47:58 a user named jasonzhou1993 said ```Is it possible to put a group chat manager in another group chat? 

so that i can start building more complicated workflow```.
In ideas-and-feedback, at 2023-10-01 04:07:40 a user named li_jiang said ```Hi @wiiiktor. , could you try with the latest main branch code? There was a bug and the fix has been merged.```.
In ideas-and-feedback, at 2023-10-01 03:49:25 a user named sonichi said ```There is a thread: https://discordapp.com/channels/1153072414184452236/1157434279891050607. @li_jiang```.
In ideas-and-feedback, at 2023-10-01 02:42:17 a user named wiiiktor. said ```I need help. I am making my version of the ragproxyagent which needs data from my small .jsonl file. All good, but my file has 75 chunks, and the application is shouting it should have 40000 🙂 What can I do? These are the "bad guys" that I need to convince to cooperate 😉         "client": chromadb.PersistentClient(path="/tmp/chromadb"),
        "collection_name": "2wikimultihopqa",```.
In ideas-and-feedback, at 2023-09-30 21:06:33 a user named telepathyx said ```could generate and embed a "training manual" in addition to convo history that's more extensive than a system prompt```.
In ideas-and-feedback, at 2023-09-30 21:04:00 a user named telepathyx said ```https://github.com/embedchain/embedchain this is quite easy and clean to work with```.
In ideas-and-feedback, at 2023-09-30 21:02:14 a user named au8 said ```Langchain toolkits would be interesting```.
In ideas-and-feedback, at 2023-09-30 20:26:13 a user named telepathyx said ```https://github.com/getmetal/motorhead would help. ideally embedding all past convo into a vector db for RAG. and enhanced motorhead summary maybe with multiple rolling map reduce summaries held in context window of like summary of past 10 messages, past 20 messages, etc. or a function to return past N messages depending on the need.```.
In ideas-and-feedback, at 2023-09-30 20:25:24 a user named telepathyx said ```i feel like gpt is like the main character from the film Memento where his "wife's death" is the cutoff of the training data and "15 minutes" is the context window. is it possible to chain a bunch of momento guys together to make a healthy guy? lol```.
In ideas-and-feedback, at 2023-09-30 20:13:53 a user named nachos.ai said ```1. HR Prompt to spun up a bot
2. Have the bot describe its use (When to call, examples, etc.)
3. Have HR/Team Lead/Director evaluate the new bot as in an interview***
4. If fails - return to 1 with adjustments to avoid repeat.

***  Interview process prompts may be needed by the different evaluating bots.
Might require some thoughts, or we are back at hard coding it.

I love this!```.
In ideas-and-feedback, at 2023-09-30 20:11:29 a user named telepathyx said ```That's a great point. I wonder if it would be helpful to do some kind of "interview process" on the new bot akin to something like https://github.com/mshumer/gpt-prompt-engineer but maybe domain/role specific questions```.
In ideas-and-feedback, at 2023-09-30 20:08:39 a user named nachos.ai said ```@telepathyx 
Things you'll want to consider - after setting up a bot, you need to ask it (Successfully) to let you know when to call it.
Then you can give this to the "Team lead" or spread around to all bots (Depends on your architecture), so they know when to turn to each of the other bots.

It might get complex on big teams, but then again, it's not much different than a real company.

So there's some more building up from each prompt after this one. (Like ask them to generate an example, maybe? And have teamlead/HR bot evaluate it)
I didn't get to complete it but setting up a methodology to build my virtual team is a priority and something my boss and me talk about sometimes.
This is part of my initial thoughts and attempts.e```.
In ideas-and-feedback, at 2023-09-30 20:04:18 a user named nachos.ai said ```I think I've heard of the concept.
Spun up a team on need, perform the task, then cleanup.```.
In ideas-and-feedback, at 2023-09-30 20:03:26 a user named telepathyx said ```but that prompt looks great, gonna play with it```.
In ideas-and-feedback, at 2023-09-30 20:02:40 a user named telepathyx said ```yeah definitely. i was just thinking maybe it could create the team dynamically by generating a new config file for it on the fly. for another chat session effectively```.
In ideas-and-feedback, at 2023-09-30 20:01:03 a user named nachos.ai said ```Everything human-readable will do better than code, I think.
Also have read some articles on it.
We have started a migration of xml-based prompt to Markdown prompt and I've seen improvement - though, it's more on easier modification, less fragile prompting.

I was told before I joined the project, that we used json, and it started making mistakes a on a big json.

My assessment is - json (And possibly yaml, although it's more human-readable), is more "fragile". 
Where-as markdown is more easy to "fix". 
(Imagine the process of predicting the next token went a bit far off the mark, and then aligned back. With json it may have been too rigid, but markdown is more flexiable)```.
In ideas-and-feedback, at 2023-09-30 19:56:20 a user named telepathyx said ```i've seen people have success with yaml-like formatting```.
In ideas-and-feedback, at 2023-09-30 19:55:49 a user named nachos.ai said ```I'm trying to focus on Markdown rather json.
It's more human-like and it had probably trained on tons of .md files.
Also very easy to maintain.```.
In ideas-and-feedback, at 2023-09-30 19:54:37 a user named telepathyx said ```Never know what's going to work tho```.
In ideas-and-feedback, at 2023-09-30 19:54:17 a user named telepathyx said ```I like that! I was thinking maybe a few-shot-prompt for the json config file itself or something```.
In ideas-and-feedback, at 2023-09-30 19:52:21 a user named nachos.ai said ```I have a prompt for it:
Can you please design an introductory paragraph of the role of <INSERT_ROLE>? Please phrase it as a command from a boss instructing an interviewee, instead of first person presentation. You will give examples that stress your point. Don’t acknowledge my request- just follow it with the quote, as I will be copy-pasting your response. Start with “You are a…” and finish with “Please acknowledge for confirmation.” Please acknowledge for confirmation.

Still requires some improvement, I believe, and maybe more tuning for specific roles, but I just set up a full team.
Worked well for all except for QA Automation Engineer```.
In ideas-and-feedback, at 2023-09-30 18:01:27 a user named logangrasby said ```Is there a Javascript version of Autogen by chance that anyone is working on?```.
In ideas-and-feedback, at 2023-09-30 13:15:20 a user named kajatta said ```(ref General) Langchain Toolkits/tool integration to inherit agent capabilities```.
In ideas-and-feedback, at 2023-09-30 11:56:47 a user named telepathyx said ```exciting times. automated abundant post scarcity here we come```.
In ideas-and-feedback, at 2023-09-30 11:46:22 a user named .princeps said ```Oh you are on to something, let me test it out with these agents then I'll share it```.
In ideas-and-feedback, at 2023-09-30 11:45:11 a user named telepathyx said ```the /ts "town square debate" function sort of simulates this within a single context window```.
In ideas-and-feedback, at 2023-09-30 11:43:54 a user named telepathyx said ```another thing is an "HR Bot" that can spin up new bots on demand and add them to a team as per the task requirements. which i think is promising based on the way "professor synapse CoR" prompt works so well (https://github.com/ProfSynapse/Synapse_CoR)  the way is spins up specialist agents and creates prompts for them etc```.
In ideas-and-feedback, at 2023-09-30 11:38:59 a user named .princeps said ```word! I'll check it out when I start setting up this in my discord```.
In ideas-and-feedback, at 2023-09-30 11:37:32 a user named telepathyx said ```the OG dude has had it setup for like 4-5 months at least. his room is discommand.com i think```.
In ideas-and-feedback, at 2023-09-30 11:36:19 a user named .princeps said ```@telepathyx have you seen this ?

https://www.youtube.com/watch?v=yhBiVrigWNI&ab_channel=AIJason```.
In ideas-and-feedback, at 2023-09-30 11:35:16 a user named telepathyx said ```so summaries go up and instructions go down. is the idea```.
In ideas-and-feedback, at 2023-09-30 11:34:17 a user named telepathyx said ```it was mostly a simulation back then but now it's getting more realistic```.
In ideas-and-feedback, at 2023-09-30 11:33:52 a user named telepathyx said ```and a human can pop in anywhere```.
In ideas-and-feedback, at 2023-09-30 11:33:12 a user named telepathyx said ```this guy has had this kind of thing setup on discord for a long time. these individual chatrooms are handy. so that context windows aren't exhausted for executives and such.```.
In ideas-and-feedback, at 2023-09-30 11:31:26 a user named .princeps said ```@telepathyx I like where you are going with this, can you send me some links```.
In ideas-and-feedback, at 2023-09-30 11:30:14 a user named telepathyx said ```easily integrates with stuff like motorhead memory```.
In ideas-and-feedback, at 2023-09-30 11:28:03 a user named telepathyx said ```and also the openrouter.ai playground has a ton of different open source LLMs, right now responding in parallel to compare. but it would be cool to have totally LLMs interact as multiagents there, leverage their strengths or fine tuning for specific roles```.
In ideas-and-feedback, at 2023-09-30 11:27:25 a user named telepathyx said ```i've been talking to the guys at flowise about setting up a UI for defining roles/hierarchy for autogen multiagent chat kind of thing. they have a really good UI for langchain chatbots and RAG/ multi-tool use type stuff.```.
In ideas-and-feedback, at 2023-09-30 11:22:53 a user named .princeps said ```will be releasing a project today with an agent with tools and another with the internet```.
In ideas-and-feedback, at 2023-09-30 11:22:20 a user named .princeps said ```op, good call, let me change that```.
In ideas-and-feedback, at 2023-09-30 11:21:45 a user named .princeps said ```hahah thanks fam, just put it out yesterday and I didn't even do it correctly so after work today I decided to clean it up```.
In ideas-and-feedback, at 2023-09-30 11:21:23 a user named telepathyx said ```been following autogen search keyword```.
In ideas-and-feedback, at 2023-09-30 11:21:23 a user named bansalg said ```@.princeps  btw autogen was moved out of flaml to its separate repo.. sharing in case that is helpful 🙂 https://github.com/microsoft/autogen#quickstart```.
In ideas-and-feedback, at 2023-09-30 11:21:07 a user named telepathyx said ```that's hillarious i'm 1/3 of the stars on that```.
In ideas-and-feedback, at 2023-09-30 11:20:49 a user named .princeps said ```you can clone that project and just add the file above to it and it should work```.
In ideas-and-feedback, at 2023-09-30 11:20:32 a user named .princeps said ```https://github.com/Poly186-AI-DAO/AutoGen-Snake-Game```.
In ideas-and-feedback, at 2023-09-30 11:20:24 a user named .princeps said ```it's why I shared the code```.
In ideas-and-feedback, at 2023-09-30 11:20:16 a user named .princeps said ```oh not yet @telepathyx was just something fun I wanted to try out```.
In ideas-and-feedback, at 2023-09-30 11:09:48 a user named .princeps said ```got the inspiration from Westworld```.
In ideas-and-feedback, at 2023-09-30 11:07:40 a user named .princeps said ```so I actually set this up yesterday```.
In ideas-and-feedback, at 2023-09-30 10:32:54 a user named telepathyx said ```It would be cool to experiment with giving each agent a "subconscious thought stream" that would incorporate two private bots talking to each other before a bot decides to "speak" to the group chat (rather than blurting out the first answer). it's consistent with "dual process theory" in psychology https://en.wikipedia.org/wiki/Dual_process_theory. or a "right brain bot" and "left brain bot" instead. or "id, ego, superego" bots comprising a single agent in the multi-agent situation. imagine if you had to speak in order to think.```.
In ideas-and-feedback, at 2023-09-30 04:38:42 a user named mysticaldiscofrog said ```Thank you, I will start one over there.```.
In ideas-and-feedback, at 2023-09-30 03:12:26 a user named andyinater said ```I suggest starting a thread here <#1157397569375309864>  so you can get some focused discussion on that topic, as it might be a somewhat common issue. I have a few thoughts I could share that might help - it takes a bit to wrap your head around how this framework works. Lots behind the scenes in the classes```.
In ideas-and-feedback, at 2023-09-30 00:42:56 a user named shinypickel said ```Is the problem w/ generating the code or writing it to the local filesystem?```.
In ideas-and-feedback, at 2023-09-30 00:41:35 a user named mysticaldiscofrog said ```Hello! I have been trying to use this to help me develop a React App and it works from a conceptual perspective but it has issues when it comes to writing code or saving to my local filesystem. I am running auto gen through VS Code on my local machine but it starts telling me it is not able to run code. I have played with ChatDev and that did a good job at interacting with my filesystem but it left much to be desired when it came to content of the code itself. 

Any direction or insight is greatly appreciated. Thank you.```.
In ideas-and-feedback, at 2023-09-29 21:01:01 a user named sonichi said ```one example is here: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb```.
In ideas-and-feedback, at 2023-09-29 20:14:52 a user named fxtoofaan said ```Is it possible to create content with autogen? Like news articles or blog posts or email sequences or cold outreach scripts? Also possible to get sdxl prompts to create images needed for posts or social media?```.
In ideas-and-feedback, at 2023-09-29 20:12:52 a user named WolfroseWe said ```Is there an ability to implement Tools? I don't see anything in the documenation. 

Also, via code execution I'd like to be able to create a module where I can implement a scraping service I use, add the API key to a dotenv and have the AssistantAgent draft up the code to execute with this module. 

Similar to Langchain/Llama Agent Agents, provide the Tools as something to use. For Web Searches use this, for computation use Wolfram Alpha etc. 

Apologies if I missed it, appreciate any help pointing me in the right direction.```.
In ideas-and-feedback, at 2023-09-29 17:45:53 a user named bigmiao said ```Any ideas on providing a dotnet implementation of autogen? The multi-agent collaboration would really help dotnet developers on building their intelligence apps

Also start an issue on GitHub for further discussion. 
https://github.com/microsoft/autogen/issues/48```.
In ideas-and-feedback, at 2023-09-29 17:33:14 a user named tonic_1 said ```https://huggingface.co/spaces/MultiTransformer/autogen-tutorials/tree/main i copied the notebooks from the autogen repo on huggingface here , you can also join the organisation, and help us build some tutorials 👊🏻```.
In ideas-and-feedback, at 2023-09-29 11:23:49 a user named vincentjedi said ```Is there any demo chatbot with simple ui like gradio or streamlit using autogen in Jupiter notebook we can use with browser ?```.
In ideas-and-feedback, at 2023-09-29 09:40:54 a user named sonichi said ```The termination condition can be configured via is_termination_msg```.
In ideas-and-feedback, at 2023-09-29 09:39:56 a user named sonichi said ```It’s on the top right corner of the website```.
In ideas-and-feedback, at 2023-09-29 09:39:12 a user named martcpp said ```Like to the GitHub repo of the project on the documentation site to make it easy for accessible```.
In ideas-and-feedback, at 2023-09-29 09:37:21 a user named sonichi said ```Sorry what’s the info you d like to add?```.
In ideas-and-feedback, at 2023-09-29 09:02:33 a user named nexorsist said ```Looking at the interactions and outputs, I would definitely tweak it to not send a full terminal output when code executions succeed as that also seems to confuse GPT and it apologises for confusion after commenting it was successful.```.
In ideas-and-feedback, at 2023-09-29 08:55:19 a user named nexorsist said ```Anyone managed to throw together a basic front-end for this project yet?

On a side note my observation so far is that Autogen seems to be consuming a lot more tokens for smaller tasks than Chatdev and therefore quite a bit more expensive running through an example which is a bit weird```.
In ideas-and-feedback, at 2023-09-29 07:56:27 a user named WolfroseWe said ```I randomly came across this right before I went to bed (big mistake; I started thinking about it and now can’t sleep 😂). 

2 questions: 
1) What are the thoughts on creating a Tool marketplace? 
2) Would it be useful to have a Discord bot trained on Autogens docs so community members can ask q’s?```.
In ideas-and-feedback, at 2023-09-29 06:26:24 a user named martcpp said ```I am extremely happy am what is going on this Eco system I recently got through the documentation the official link to GitHub repo to enable other people check it out use it or contribute is not found I will like to propose a PR to work on it soon thanks 🙏 and will love to know if any reason why it not added?```.
In ideas-and-feedback, at 2023-09-29 03:54:08 a user named andyinater said ```Love the project, it has been fun watching the agents chat and learning how they work together.

Would be very cool to incorporate some logging and log replay similar to ChatDev (project I stumbled onto shortly before this). Would be even cooler if the human in the loop was a controllable/playable character real-time, but I'm definitely getting ahead of myself here.


Extremely excited to see how and where the community takes this. Thank you!```.
In ideas-and-feedback, at 2023-09-29 02:52:12 a user named tonic_1 said ```at least seems like the simplest way so far, and all in python so very easy to share - making components , then sharing them, also hosting them and sharing flows seems like a fun thing to do```.
In ideas-and-feedback, at 2023-09-29 01:57:48 a user named wally_5040 said ```I generally prefer to transform the markdown into a html dom and use that for navigation and extraction```.
In ideas-and-feedback, at 2023-09-29 01:55:08 a user named wally_5040 said ```@sonichi btw, i saw in the source the following line:
```
CODE_BLOCK_PATTERN = r"` ``(\w*)\n(.*?)\n` ``"
```
and the `infer_lang` function. For my project i just "stole" the code (the list of languages) from this prism plugin: https://prismjs.com/plugins/show-language/#examples
I am still curious what the "best/offical" way is to get this info```.
In ideas-and-feedback, at 2023-09-29 01:34:51 a user named wally_5040 said ```and all those .txt and  .md files flying around on my machine  (in the beginng named like prompt3.md 😄 )  suddenly spiked to unacceptable levels```.
In ideas-and-feedback, at 2023-09-29 01:33:57 a user named wally_5040 said ```a lot of ameliated by copilot and AI Assistant from jetbrains, but it still was way too much```.
In ideas-and-feedback, at 2023-09-29 01:33:11 a user named wally_5040 said ```The amount of Copy-Pasting I did went tremendously up when starting to use LLMs a while ago.```.
In ideas-and-feedback, at 2023-09-29 01:32:25 a user named wally_5040 said ```one of the major features in my gpt ui (WinGPT) was the ability to directly save files to the original location on my harddrive and that alone saved me so many tokens, since I dont have to regenerate the file every time for a dedicated function call and one of the key ideas was to strictly minimize copy-pasting stuff```.
In ideas-and-feedback, at 2023-09-29 01:30:13 a user named wally_5040 said ```auto, baby and the other ai systems just gobble up those tokens like a troll! 🧌```.
In ideas-and-feedback, at 2023-09-29 01:29:04 a user named wally_5040 said ```@cajukev and the way it's set up, you dont even have to spend hundreds of currency units for every single change in the system 😉```.
In ideas-and-feedback, at 2023-09-29 01:28:10 a user named wally_5040 said ```from what I saw so far, most of the functionality could be drag-and-drop with some config to click. the textual payload should mostly be the system messages```.
In ideas-and-feedback, at 2023-09-29 01:27:35 a user named cajukev said ```Completely agree with Wally here.  I haven't actually used autogen yet but from the docs it seems like the best way to have a customized agent system that can write + execute code AND has human in the loop```.
In ideas-and-feedback, at 2023-09-29 01:27:19 a user named wally_5040 said ```@juanma.nl was also thinking about that```.
In ideas-and-feedback, at 2023-09-29 01:25:15 a user named juanma.nl said ```Great project! I wonder if anyone thought of having a visual tool to setup the graph of agents just like in the example drawings so that non technical user can design their workflows```.
In ideas-and-feedback, at 2023-09-29 01:20:28 a user named wally_5040 said ```I'm not even sure anymore if we want any "start-to-end" AI systems. I feel much more comfortable with some kind of co-authorship and the other systems are too focused on "total automation"```.
In ideas-and-feedback, at 2023-09-29 01:18:53 a user named wally_5040 said ```One difference i see is, that it seems to me more focused on flexibility, than "start-to-end"```.
In ideas-and-feedback, at 2023-09-29 01:12:01 a user named wally_5040 said ```just be careful with discord then: It can **eat time** 🍣 🕰️```.
In ideas-and-feedback, at 2023-09-29 01:11:07 a user named bansalg said ```@wally_5040  we'd love to hear your thoughts on the differences you observed!```.
In ideas-and-feedback, at 2023-09-29 01:10:55 a user named wally_5040 said ```oh. deadline sounds potentially deadly 🤣```.
In ideas-and-feedback, at 2023-09-29 01:09:54 a user named sonichi said ```agreed. Feel free to make suggestions. I'm working on a deadline so will be away for a while...```.
In ideas-and-feedback, at 2023-09-29 01:03:13 a user named wally_5040 said ```btw, @sonichi : I really think this server needs a *meme* section/channel 😉```.
In ideas-and-feedback, at 2023-09-29 00:36:19 a user named wally_5040 said ```@sonichi Just came by to say: What an impressive project! I see that some of the problems other "agent"-system struggle with are solved in quite interesting (borderline brilliant) ideas! 🤗 
Thanks for the code.```.
In ideas-and-feedback, at 2023-09-28 22:08:44 a user named shubhdi5cord said ```I was thinking of using autogen to mock the SDLC process for feature development. 
If anyone's interested... please feel free to share your approach here.```.
In ideas-and-feedback, at 2023-09-28 21:18:57 a user named shaneyu said ```Hi @sonichi, I was analyzing math_user_proxy_agent.py, I originally thought it would utilize most of the functions from math_utils.py, however, I found that it mostly depends on execute_one_python_code, and wolfram api call (if requested). Is there a reason why most functions in math_utils are neglected (code generation did a good job by itself lol)? Also, are we using pure llm to approve the answer here (i.e assistant agent says yes)? I thought I was reading somewhere that Autogen has matrix to evaluate code/math results, correct me if Im wrong🫡 . Thanks in advance!```.
In ideas-and-feedback, at 2023-09-28 21:26:04 a user named sonichi said ```The math_utils needs an update. @kevinwyr has done good work about it.```.
In ideas-and-feedback, at 2023-09-28 21:31:01 a user named shaneyu said ```Appreciated! Guess I'll wait and see! Thanks for the great work!```.
In ideas-and-feedback, at 2023-09-28 21:36:28 a user named kevinwyr said ```Hello @shaneyu, thank you for your interest. The some of math_utils are pulled from utils of MATH dataset, to extract and compare results. Do you intend to use Autogen to evaluate math results?```.
In ideas-and-feedback, at 2023-09-28 21:47:36 a user named shaneyu said ```Hi Kevin, thanks for the reply. I am actually interested in how Autogen's math agent confirms a correct answer is actually correct. From the code, it seems at this point, it still relies on assistant agent's (llm) saying: Ah, I think this is correct. I thought I was reading in the paper or elsewhere that Autogen has some matrix to evaluate the result. Maybe I'm hallucinating as well lol🤣```.
In ideas-and-feedback, at 2023-09-28 21:49:12 a user named shaneyu said ```So in short, math_util is used internally to see how math_agent performs, not involved in actual solving problems right?```.
In ideas-and-feedback, at 2023-09-28 22:21:01 a user named sonichi said ```1. There is some standard evaluation function in math_util. They are not always reliable.
2. math_util is not involved in actual solving right now, although the voting function will be useful if you solve one problem multiple times.
3. "how Autogen's math agent confirms a correct answer is actually correct." Improving that would be interesting, e.g., by introducing additional agents. I'd love to hear your thoughts.```.
In ideas-and-feedback, at 2023-09-28 22:54:18 a user named shaneyu said ```adding more agents for cross examination is the easiest way to do it I think. Another way is to use fine-tuned model. How to settle it down to code really needs some eureka moment.```.
In ideas-and-feedback, at 2023-09-28 21:15:30 a user named tonic_1 said ```started trying to get cognitive search set up correctly, and ollama also for flowise, someone i know is trying to make an enterprise version, so azure is a natural choice aswell```.
In ideas-and-feedback, at 2023-09-28 21:14:39 a user named tonic_1 said ```yeah i do love flowise```.
In ideas-and-feedback, at 2023-09-28 18:28:21 a user named magiccow2 said ```Yo, thanks a lot. I downloaded VS Code earlier today hoping that was the right path and was going to investigate today. Thanks for the clear instructions!```.
In ideas-and-feedback, at 2023-09-28 17:11:38 a user named felly007. said ```After you got the virtual env working, you can pip install autogen and copy and paste the code from microsoft Github to start```.
In ideas-and-feedback, at 2023-09-28 17:10:53 a user named felly007. said ```Debugging is majority of writing code (not an expert here but practising for a while) 

I ran it in Collab as a test and VS code to work with autogen. I prefer VS code.

From a high level, I would follow this: 

- Install Visual Studio Code (VS Code): Download from VS Code's site and follow setup instructions.
- Install Python: Download from Python's site and install. During installation, check "Add Python to PATH".
- Open VS Code: Launch it and go to Extensions (left sidebar, looks like squares) and install Python extension.
- Set Up Folder: Create a new folder for your project. Open it in VS Code (File -> Open Folder).
- Terminal: Open terminal in VS Code (Terminal -> New Terminal).
- Virtual Environment: In the terminal, type python -m venv myenv to create a virtual environment called myenv.
Activate Env:
Windows: Type .\myenv\Scripts\Activate
MacOS/Linux: Type source myenv/bin/activate
- Install Packages: In terminal, type pip install openai or any other package you need.
- Write Code: Create a new Python file (e.g., main.py) in your folder and start coding.
- Run Code: Save the file, go to terminal, type python main.py to run it.```.
In ideas-and-feedback, at 2023-09-28 14:19:52 a user named magiccow2 said ```I feel like once I get the foundational layers there, I can tool around and figure out the rest. But continually running in to missing this, missing that, can't run in this particular platform.```.
In ideas-and-feedback, at 2023-09-28 14:18:38 a user named magiccow2 said ```I'm in the same boat. Lots of non-programming folks taking interest in this stuff now (because chatGPT has allowed us to do some cool stuff and now we want more God powers). But there's a certain degree of foundational knowledge we don't have that's very much common sense to people who've been coding for a while. 

I'm trying to figure it out and I'll share what I learn. But wondering if anyone with a little know how can point to some good resources. 

Do I do this all in terminal? Should I do it in Jupyter Notebooks? VS Code? 

What base other stuff do I need?```.
In ideas-and-feedback, at 2023-09-28 13:46:01 a user named fxtoofaan said ```would be nice to have a sample project in .py files format and not in jupyter notebooks format. I am having hard time to figure out how to convert online jupyter files to local python files. If a sample or example can be written in python files to be run locally that would be awesome. Non-Programmer here  🙏```.
In ideas-and-feedback, at 2023-09-28 12:55:25 a user named 2good4hisowngood said ```I hope you don't mind, I'm going to put in a github issue for a feature request I made for [ChatDev](https://github.com/OpenBMB/ChatDev/issues/98) that I think [AutoGen](https://github.com/microsoft/autogen/issues/34) could also benefit from. I don't see a similar post in the current issues. Please forgive any impropriety in providing similar feedback. I'll endeavor to find additional details in the repo to make it easier to implement given time. 

My hope would be that with this kind of feature, we could then add in TextGenWebUI like in this [ticket](https://github.com/OpenBMB/ChatDev/issues/100), and then have it dynamically unload and load models between agents to utilize the best model for a given character (an API programmer bot could use a Gorilla, or a character could receive a fine tuned model for your use case). Please let me know if it'd be beneficial for me to create an issue like the second.```.
In ideas-and-feedback, at 2023-09-28 12:51:33 a user named sonichi said ```Yes, the `llm_config` for each agent can be used to specify one or multiple LLM configurations to use.```.
In ideas-and-feedback, at 2023-09-28 12:35:20 a user named fxtoofaan said ```is it possible to switch between models? like local, then gpt3.5 then gpt4? or maybe give individual agent a specific LLM to use? basically use LocalLLM for majority of work and use GPT4 or 3.5 to validate localLLM outputs```.
In ideas-and-feedback, at 2023-09-28 05:31:39 a user named junaidamjad said ```As for GUI, I was wondering if we could integrate the community version of Botpress since it communicates with LLMs via API calls. Another option is Flowise. Anyone doing this?```.
In ideas-and-feedback, at 2023-09-28 04:54:15 a user named jimmysandwiches said ```@sonichi 2 quick question if I may. Is there any crossover / similarities between this and prompt flow (MS) and do you envisage a gui coming to this soon (or can you suggest a gui framework that can work with this out of the box) Thanks 🥪```.
In ideas-and-feedback, at 2023-09-28 03:48:27 a user named .princeps said ```@sonichi seems like things are taking off, so I wanted to suggest that the team can create a Agent Community Manager to help you when you are offline, this guy has a great example 

https://youtu.be/yhBiVrigWNI?si=DXzB__CUTHzkQybr```.
In ideas-and-feedback, at 2023-09-28 02:52:06 a user named sonichi said ```That's basically right. Note that both agents are simply instances of ConversableAgent with different configurations. In general, you can decide what backends to use: LLM, human, tool or a combination of any of them, or register your own reply function via `register_reply````.
In ideas-and-feedback, at 2023-09-28 02:50:29 a user named sonichi said ```This example uses vectorDB: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb```.
In ideas-and-feedback, at 2023-09-28 02:39:26 a user named theagentcy.ai said ```Thank you so much for putting this out. I’ve been toying with it all day and can’t wait to see what use cases others come up with!```.
In ideas-and-feedback, at 2023-09-27 20:20:13 a user named shaneyu said ```Just want to see if I'm understanding the concept correctly, assistant_agent is mainly for the llm part, doing the logic/reasoning, on the other hand, user_proxy_agent is the one doing actual jobs, ie, getting code run, querying vectorDB, etc. So If I were to create my own agent, I will subclass user_proxy_agent to do the jobs(function calls, using tools) and subclass assistant_agent for any specific logic within the group chat?```.
In ideas-and-feedback, at 2023-09-27 17:23:25 a user named junaidamjad said ```The support for local LLMs is revolutionary. Is it also possible to use vector databases instead of retraining models?```.
In ideas-and-feedback, at 2023-09-27 16:45:07 a user named .princeps said ```Here you go: 

https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs/#clone-fastchat```.
In ideas-and-feedback, at 2023-09-27 15:56:50 a user named sonichi said ```There is also a new forum-discussion channel on discord.```.
In ideas-and-feedback, at 2023-09-27 15:49:54 a user named bunswo said ```(I was able to fix this by using GPT4 instead of GPT3.4)
Would love to know the best forum for troubleshooting.
I also had issues with the SVG display of the chess board in the example -- but worked around it -- I could post that for others somewhere.```.
In ideas-and-feedback, at 2023-09-27 13:53:01 a user named bunswo said ```I'm getting a RecursionError: maximum recursion depth exceeded 
on the Chess example
Is there an appropriate place to post that issue?```.
In ideas-and-feedback, at 2023-09-27 06:25:45 a user named akash AI said ```i don't have access to open API,so want to use open-source models such as Llama2, but there is no direct option to support it.

also i dont have higher gpu system .so not able to setup the fastapi. I was trying to run it on google collab but no luck.

is there any plan to add simple support? what langchain has integrated like this?
llm = openAI()
llm =  llama2()```.
In ideas-and-feedback, at 2023-09-27 05:47:32 a user named .princeps said ```This a good point, I wonder what the plan is for this ?```.
In ideas-and-feedback, at 2023-09-26 19:17:31 a user named qingyunwu said ```Thanks for the question. llama2 and most open-source models could be used  (as long as they are supported in fastchat) .  Check this blogpost first https://microsoft.github.io/autogen/blog/2023/07/14/Local-LLMs @jiale_liu  has experience using llama2 in autogen. He can answer any more questions you might have.```.
In ideas-and-feedback, at 2023-09-26 17:10:34 a user named .geoffreya said ```Integration with many LLMs seems important to me too.  Integration with Microsoft Semantic Kernel seems important as well.```.
In ideas-and-feedback, at 2023-09-26 17:08:55 a user named .geoffreya said ```Semantic Kernel is the other LLM lib that Msft made recently.  How would the Autogen team recommend to choose autogen or semantickernel?  And were these two dev teams aware of what the other team made?  And are these two libs going to be shown how to use together as best practice, or actually integrated at some point?```.
In ideas-and-feedback, at 2023-09-26 12:39:09 a user named snoq_ said ```Will I be able to use any model like llama2 or only limited to GPT models?```.
In ideas-and-feedback, at 2023-09-19 20:16:22 a user named sonichi said ```I've only made the most basic setup of the server. Please suggest ideas if you have any.```.
